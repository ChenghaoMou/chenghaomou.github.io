---
aliases:
  - Large Language Models Are Zero-Shot Reasoners
  - "Large Language Models are Zero-Shot Reasoners"
linter-yaml-title-alias: Large Language Models Are Zero-Shot Reasoners
order: -20220605111758
tags: [natural_language_processing, natural_language_processing/prompting, natural_language_processing/chain_of_thought]
title: Large Language Models Are Zero-Shot Reasoners
---

# Large Language Models Are Zero-Shot Reasoners

(6/5/2022, 11:17:58 AM)

“but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.” ([Kojima et al., 2022, p. 1](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=1&annotation=ML6HSJ7N))

“chain of thought prompting (CoT), which feed LLMs with the step-by-step reasoning examples rather than standard question and answer examples (see Fig. 1-a). Such chain of thought demonstrations facilitate models to generate a reasoning path that decomposes the complex reasoning into multiple easier steps. Notably with CoT, the reasoning performance then satisfies the scaling laws better and jumps up with the size of the language models.” ([Kojima et al., 2022, p. 2](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=2&annotation=S4H2678T))

“the versatility of this single prompt across diverse reasoning tasks hints at untapped and understudied zero-shot fundamental capabilities of LLMs, such as higher-level broad cognitive capabilities like generic logical reasoning \[Chollet, 2019\].” ([Kojima et al., 2022, p. 3](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=3&annotation=CZJKYD4P))

“In commonsense reasoning tasks, Zero-shot-CoT does not provide performance gains. It is expected as Wei et al. \[2022\] also reports that even Few-shot-CoT does not provide performance gains on Lambda (135B), but does improve StrategyQA when combined with substantially larger PaLM (540B) model, which may also apply for ours.” ([Kojima et al., 2022, p. 5](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=5&annotation=3X2QUGM3))

“(1) In commonsense reasoning (CommonsenseQA), Zero-shot-CoT often produces flexible and reasonable chain of thought even when the final prediction is not correct.” ([Kojima et al., 2022, p. 6](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=6&annotation=U37EX2AW))

“Zero-shot-CoT often output multiple answer choices when the model find it is difficult to narrow it down to one” ([Kojima et al., 2022, p. 6](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=6&annotation=CYE6WFLC))

“Without chain of thought reasoning, the performance does not increase or increases slowly as the model scale is increased, i.e., the curve is mostly flat. In contrast, the performance drastically increases with chain of thought reasoning, as the model size gets bigger.” ([Kojima et al., 2022, p. 7](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=7&annotation=FGA8AG4T))

“When the model size is smaller, chain of thought reasoning is not effective.” ([Kojima et al., 2022, p. 7](zotero://select/library/items/I5REN6BR)) ([pdf](zotero://open-pdf/library/items/WHBWU3ED?page=7&annotation=DQZ8LVWT))

***
- @kojima_2022