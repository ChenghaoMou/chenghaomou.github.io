---
aliases:
  - "“Ensuring Safe, Secure, and Trustworthy AI”: What those seven companies avoided committing to"
url: https://medium.com/@emilymenonbender/ensuring-safe-secure-and-trustworthy-ai-what-those-seven-companies-avoided-committing-to-8c297f9d71a
author: Emily M. Bender
publisher: Medium
date: 2023-07-29
tags: []
---

## Highlights
<mark>Documentation empowers us to ask questions, including: * Procurers: Is this system appropriate for the users I anticipate will interact with it? * Policymakers: Are rights respected in the development and deployment of systems? * Community activists: What patterns are being reproduced which adversely affect my community?</mark>

<mark>First, the commitments only address “audio and visual” content, with exactly zero mention of synthetic text. When OpenAI set up the easy interface to ChatGPT, when Meta briefly provided an interface to Galactica (misleadingly billed as way to access scientific knowledge), when Microsoft and Google incorporated chatbots into their search interfaces, they created the equivalent of an oil spill into our information ecosystem. Anyone can go at any time to one of these sources (except Galactica, which was taken down) and produce seemingly authoritative text in the style of their choice. They can then easily post this text on the internet where others might turn it up without knowing its origin.</mark>

<mark>The reason I make the analogy to oil spills is that this isn’t just about the harms to the person who initially receives the information. There are systemic risks as well: the more polluted our information ecosystem becomes with synthetic text, the harder it will be to find trustworthy sources of information and the harder it will be to trust them when we’ve found them. Rich Felker makes this point well over on Mastodon in a thread on the importance of provenance, without which information is just words.</mark>

<mark>So yeah — this is weak sauce. The companies say they’ll try to mitigate some pollution down the road, but do not wish to do anything about the toxic waste they’re currently spewing.</mark>

<mark>This is fluff, it’s PR, and its inclusion in this document just underscores how it the commitments are really an exercise in marketing and an attempt to forestall meaningful regulation. We pinky promise to be good, now please go away while we continue to practice massive data theft while creating poorly engineered “everything machines” that can’t possibly be evaluated.</mark>

