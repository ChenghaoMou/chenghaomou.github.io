---
title: "34772815"
url: https://www.vox.com/future-perfect/23971093/artificial-intelligence-chatgpt-language-mind-understanding
author: Raphaël Millière
date: 2023-12-10
time: 11:22 AM
source: "reader"
aliases:
  - Why It’s Important to Remember That AI Isn’t Human
---
## Highlights
> Reasoning as though chatbots had human-like mental lives is a useful way of coping with their linguistic virtuosity, but it should not be used as a theory about how they work ([View Highlight](https://read.readwise.io/read/01hgfqw7e0ps2nj2r8mn9nvz7w))

> To avoid this kind of mistake, we must repudiate the assumption that the psychological properties that explain the human capacity for language are the same properties that explain the performance of language models. That assumption renders us gullible and blinds us to the potentially radical differences between the way humans and language models work. ([View Highlight](https://read.readwise.io/read/01hgfqypzjssv3tw02s5zvtk08))

> Another pitfall when thinking about language models is anthropocentric chauvinism, or the assumption that the human mind is the gold standard by which all psychological phenomena must be measured. Anthropocentric chauvinism permeates many skeptical claims about language models, such as the [claim](https://theconversation.com/chatgpt-cant-think-consciousness-is-something-entirely-different-to-todays-ai-204823) that these models cannot “truly” think or understand language because they lack hallmarks of human psychology like consciousness. This stance is antithetical to anthropomorphism, but equally misleading. ([View Highlight](https://read.readwise.io/read/01hgfr0g8z0z5r2s2ysvnq5x9n))

> Consider the following analogy: The human mind emerged from the learning-like process of natural selection, which maximizes genetic fitness. This bare fact entails next to nothing about the range of competencies that humans can or cannot acquire. The fact that an organism was designed by a genetic fitness maximizer would hardly, on its own, lead one to expect the eventual development of distinctively human capacities like music, mathematics, or meditation. Similarly, the bare fact that language models are trained by means of next-word prediction entails rather little about the range of representational capacities that they can or cannot acquire. ([View Highlight](https://read.readwise.io/read/01hgfr7q9mx4qdeazqh1m9cqjm))t entails next to nothing about the range of competencies that humans can or cannot acquire. The fact that an organism was designed by a genetic fitness maximizer would hardly, on its own, lead one to expect the eventual development of distinctively human capacities like music, mathematics, or meditation. Similarly, the bare fact that language models are trained by means of next-word prediction entails rather little about the range of representational capacities that they can or cannot acquire. ([View Highlight](https://read.readwise.io/read/01hgfr7q9mx4qdeazqh1m9cqjm))---
title: "Why It’s Important to Remember That AI Isn’t Human"
url: https://www.vox.com/future-perfect/23971093/artificial-intelligence-chatgpt-language-mind-understanding
author: Raphaël Millière
date: 2024-02-09
time: 12:01 AM
source: "reader"
aliases:
  - "Why It’s Important to Remember That AI Isn’t Human"
---
# Why It’s Important to Remember That AI Isn’t Human

## Highlights
> Reasoning as though chatbots had human-like mental lives is a useful way of coping with their linguistic virtuosity, but it should not be used as a theory about how they work ([View Highlight](https://read.readwise.io/read/01hgfqw7e0ps2nj2r8mn9nvz7w))

> To avoid this kind of mistake, we must repudiate the assumption that the psychological properties that explain the human capacity for language are the same properties that explain the performance of language models. That assumption renders us gullible and blinds us to the potentially radical differences between the way humans and language models work. ([View Highlight](https://read.readwise.io/read/01hgfqypzjssv3tw02s5zvtk08))

> Another pitfall when thinking about language models is anthropocentric chauvinism, or the assumption that the human mind is the gold standard by which all psychological phenomena must be measured. Anthropocentric chauvinism permeates many skeptical claims about language models, such as the [claim](https://theconversation.com/chatgpt-cant-think-consciousness-is-something-entirely-different-to-todays-ai-204823) that these models cannot “truly” think or understand language because they lack hallmarks of human psychology like consciousness. This stance is antithetical to anthropomorphism, but equally misleading. ([View Highlight](https://read.readwise.io/read/01hgfr0g8z0z5r2s2ysvnq5x9n))

> Consider the following analogy: The human mind emerged from the learning-like process of natural selection, which maximizes genetic fitness. This bare fact entails next to nothing about the range of competencies that humans can or cannot acquire. The fact that an organism was designed by a genetic fitness maximizer would hardly, on its own, lead one to expect the eventual development of distinctively human capacities like music, mathematics, or meditation. Similarly, the bare fact that language models are trained by means of next-word prediction entails rather little about the range of representational capacities that they can or cannot acquire. ([View Highlight](https://read.readwise.io/read/01hgfr7q9mx4qdeazqh1m9cqjm))

---
title: "Why It’s Important to Remember That AI Isn’t Human"
url: https://www.vox.com/future-perfect/23971093/artificial-intelligence-chatgpt-language-mind-understanding
author: Raphaël Millière
date: 2024-02-11
time: 2:52 PM
source: "reader"
aliases:
  - "Why It’s Important to Remember That AI Isn’t Human"
---
# Why It’s Important to Remember That AI Isn’t Human

## Highlights
> Reasoning as though chatbots had human-like mental lives is a useful way of coping with their linguistic virtuosity, but it should not be used as a theory about how they work ([View Highlight](https://read.readwise.io/read/01hgfqw7e0ps2nj2r8mn9nvz7w))

> To avoid this kind of mistake, we must repudiate the assumption that the psychological properties that explain the human capacity for language are the same properties that explain the performance of language models. That assumption renders us gullible and blinds us to the potentially radical differences between the way humans and language models work. ([View Highlight](https://read.readwise.io/read/01hgfqypzjssv3tw02s5zvtk08))

> Another pitfall when thinking about language models is anthropocentric chauvinism, or the assumption that the human mind is the gold standard by which all psychological phenomena must be measured. Anthropocentric chauvinism permeates many skeptical claims about language models, such as the [claim](https://theconversation.com/chatgpt-cant-think-consciousness-is-something-entirely-different-to-todays-ai-204823) that these models cannot “truly” think or understand language because they lack hallmarks of human psychology like consciousness. This stance is antithetical to anthropomorphism, but equally misleading. ([View Highlight](https://read.readwise.io/read/01hgfr0g8z0z5r2s2ysvnq5x9n))

> Consider the following analogy: The human mind emerged from the learning-like process of natural selection, which maximizes genetic fitness. This bare fact entails next to nothing about the range of competencies that humans can or cannot acquire. The fact that an organism was designed by a genetic fitness maximizer would hardly, on its own, lead one to expect the eventual development of distinctively human capacities like music, mathematics, or meditation. Similarly, the bare fact that language models are trained by means of next-word prediction entails rather little about the range of representational capacities that they can or cannot acquire. ([View Highlight](https://read.readwise.io/read/01hgfr7q9mx4qdeazqh1m9cqjm))

