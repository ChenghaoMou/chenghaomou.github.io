---
aliases:
  - "Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation"
  - "Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation"
authors: "Patrick Fernandes, Aman Madaan, Emmy Liu, António Farinhas, Pedro Henrique Martins, Amanda Bertsch, José G. C. de Souza, Shuyan Zhou, Tongshuang Wu, Graham Neubig, André F. T. Martins"
date: '2024-01-06 11:23:53'
tags: []
title: "Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation"
url: "https://arxiv.org/abs/2305.00955v1"
---

# Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation

## Abstract
Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.

![[statics/fernandes_2023/image-3-x54-y389.png]] ^005c23

```
@misc{Fernandes_Madaan_Liu_Farinhas_Martins_Bertsch_de Souza_Zhou_Wu_Neubig_et al._2023, title={Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation}, url={[https://arxiv.org/abs/2305.00955v1](https://arxiv.org/abs/2305.00955v1)}, abstractNote={Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.}, note={{"size": 394060, “pages”: 24, “previous”: " "}}, journal={arXiv.org}, author={Fernandes, Patrick and Madaan, Aman and Liu, Emmy and Farinhas, António and Martins, Pedro Henrique and Bertsch, Amanda and de Souza, José G. C. and Zhou, Shuyan and Wu, Tongshuang and Neubig, Graham and Martins, André F. T.}, year={2023}, month=may, language={en} }
```