---
aliases:
  - An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems
linter-yaml-title-alias: An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems
order: -20220605111720
tags: [machine_learning/multitasking, evolution, natural_language_processing/pre-trained_language_models]
title: An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems
---

# An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems

(6/5/2022, 11:17:20 AM)

“The generated multitask model is sparsely activated and integrates a task-based routing that guarantees bounded compute cost and fewer added parameters per task as the model expands.” ([Gesmundo and Dean, 2022, p. 1](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=1&annotation=4EVJNUHP))

“The proposed method relies on a knowledge compartmentalization technique to achieve immunity against catastrophic forgetting and other common pitfalls such as gradient interference and negative transfer.” ([Gesmundo and Dean, 2022, p. 1](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=1&annotation=P9DLE3P5))

“The multitask system and evolutionary process is initialized with one root model.” ([Gesmundo and Dean, 2022, p. 2](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=2&annotation=SA2K8ME8))

“During the evolutionary process, the proposed method searches for the best model for a single task at a time, referred to as the active task.” ([Gesmundo and Dean, 2022, p. 2](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=2&annotation=J6S8N6EY))

“During the active phase of a task, a population of models trained on the active task is evolved: the active population.” ([Gesmundo and Dean, 2022, p. 2](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=2&annotation=FI84BXIQ))

“The active population is iteratively extended by: 1) sampling a parent model (Section 3.2), 2) applying to the parent model a sampled set of mutations (Section 3.3) to produce a child model, 3) performing cycles of training and validation in order to train and score the child model.” ([Gesmundo and Dean, 2022, p. 3](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=3&annotation=8ZVQK8AG))

“An active phase is composed of multiple generations in which multiple batches of child models are sampled and trained in parallel.” ([Gesmundo and Dean, 2022, p. 3](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=3&annotation=Y4J6LQB3))

“At the end of a task active phase, only its best scoring model is retained as part of the multitask system.” ([Gesmundo and Dean, 2022, p. 3](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=3&annotation=553DSPGI))

“Each model, m, can be accepted as parent with probability: pparent(m|t)=0.5#selections(m,t). Where #selections(m, t) denotes the number of times the candidate model, m, has been previously selected as parent to generate a child models for task t.” ([Gesmundo and Dean, 2022, p. 3](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=3&annotation=2XSKMZWI))

“This method prioritizes the exploitation of high scoring models that had few attempts at generating an improved model for the active task. But also, in combination with early pruning, it automatically transitions toward a more exploratory behavior in case the higher scoring models are unable to generate an improvement.” ([Gesmundo and Dean, 2022, p. 3](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=3&annotation=DB3TVLUC))

“Layer cloning mutations create a copy of any parent model layer that can be trained by the child model. If a layer of the parent model is not selected for cloning, then it is shared with the child model in a frozen state to guarantee immutability of pre-existing models.” ([Gesmundo and Dean, 2022, p. 3](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=3&annotation=LBECT8JY))

“Hyperparameter mutations can be applied to modify the configuration inherited from the parent.” ([Gesmundo and Dean, 2022, p. 4](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=4&annotation=6Q2RB9JU))

“The score can be defined to optimize a mixture of factors such as validation quality, inference latency, training compute or model size, depending on the applications requirements.” ([Gesmundo and Dean, 2022, p. 4](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=4&annotation=23V7XV7W))

“Once a model has been trained, the parameters storing its knowledge cannot be modified. This method guarantees immunity from catastrophic forgetting, since the knowledge of a trained model is always preserved. It also provides a solution to negative transfer, since it automates the selection of the knowledge that is most relevant for each new task. Furthermore, it also avoids gradient interference, that can arise when multiple gradients are synchronously applied to the same set of parameters.” ([Gesmundo and Dean, 2022, p. 4](zotero://select/library/items/V9XNLL38)) ([pdf](zotero://open-pdf/library/items/U5GHU3NN?page=4&annotation=HPY8CQV3))

***
- @gesmundo_2022