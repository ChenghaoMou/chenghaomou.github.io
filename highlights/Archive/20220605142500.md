---
aliases:
  - On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations
linter-yaml-title-alias: On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations
order: -20220605142500
tags: [natural_language_processing, machine_learning/data_balancing, machine_learning/spurious_correlation, processed]
title: On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations
---

# On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations

#### [Page 1](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=1)

> increasingly-powerful models keep exploiting ever-smaller
> spurious correlations, and as a re- sult even balancing all
> single-word features is insufficient for mitigating all of these
> corre- lations.

> In contrast to humans, supervised models of- ten fail to
> generalize and understand implicit con- text, instead resorting
> to low-level correlations in

> the data, leading to amplified bias (Zhao et al., 2017;
> Stanovsky et al., 2019) and brittle perfor- mance (Schwartz et
> al., 2017; Gururangan et al., 2018).

#### [Page 2](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=2)

> their existence in large training sets is both inevitable and to
> some extent even de- sired, as they are an inherent property of
> natural language understanding.

> balancing single-word features is insufficient for eliminating
> all spurious correlations, and that balancing feature combina-
> tion is needed for that purpose

> balancing too much leads to datasets that contain no learnable
> signal either

> We argue that in such cases, the model should not fallback to
> default assumptions, but rather abstain or interact with the
> user to clear ambiguities.

#### [Page 3](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=3)

> approaches like AF converge to removing all low-level
> correlations,2 and there- fore a fully balanced dataset.

![Page3Image308.13100000000003_690.9904-215.748_78.60329999999999.jpg](Page3Image308.13100000000003_690.9904-215.748_78.60329999999999.jpg)

> One conceptual defini- tion, denoted here ingenuine (e.g., Wang
> and Culotta, 2020; Rogers, 2021) is a feature corre- lated with
> some output label for no apparent rea- son. Such features often
> result from the annotation process (referred to as annotation
> artifacts; Gu- rurangan et al., 2018).

> This definition is appealing: we want our models to learn real
> information about the world, and not properties of a given
> dataset.

#### [Page 4](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=4)

> In an alternative definition, denoted ungeneralizable, a
> spurious feature is one that works well for specific examples
> but does not hold in general (Chang et al., 2021; Yaghoobzadeh
> et al., 2021).

#### [Page 5](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=5)

> The practice of dataset balancing is designed to prevent models
> from learning that some words or expressions have a common
> fallback meaning that can stem from dataset artifacts (e.g.,
> “cat” as an in- dicator of contradiction) but also from cultural
> and historical contexts (e.g., Biden is the U.S. president in
> 2022).

> Fallback meanings are crucial for under- standing language, as
> contexts are often underspec- ified (Graesser, 2013).

> As a result, to truly mitigate all spurious correla- tions in a
> dataset, balancing feature combinations is required as well.

> Nonetheless, balancing this dataset for pairs of features would
> result in no informa- tion, and thus prevent any model from
> learning this function (Tab. 4, right).

#### [Page 6](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=6)

> These examples illustrate that a model that learns these
> correlations and relies exclusively on them to make predictions
> is limited and is bound to make mistakes in some contexts.

> In essence, an interpreter’s task (be it human or machine) is to
> infer the most prob- able context in which a statement is made,
> and as a result, it should have a fallback option for such world
> knowledge and common sense assertions.

chain of thoughts + assumptions of thoughts?

> the question is whether we want models to make a prediction in
> cases of uncertainty based on the fallback option.

> The implicit assumption of dataset balancing is that in order to
> mitigate spurious correlations the model has to unlearn them

#### [Page 7](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=7)

> We suggest taking into account different types of contexts
> during dataset design. In particular, collecting training
> examples with contexts such as negation (Morante and Blanco,
> 2012), humor (Weller and Seppi, 2019; Annamoradnejad and Zoghi,
> 2020), sarcasm (Davidov et al., 2010; Oprea and Magdy, 2020), or
> metaphors (Tsvetkov et al., 2014; Mohammad et al., 2016).

> Even for tasks with a large label set (e.g., language modeling),
> models still have to output a valid vocabulary item. Here we
> argue that this practice creates an inductive bias towards using
> spurious correlations in cases of uncertainty, as the model has
> “nothing to lose” in case of low certainty, and is encouraged to
> always make some prediction, potentially relying on spurious
> correlations.10

![](Page7Image305.426_645.662-219.69380000000007_126.36130000000003.jpg)

> To address this problem, we suggest adopting ap- proaches that
> allow models to abstain and interact when they cannot make a
> decision with high confi- dence (Chow, 1957; Hellman, 1970;
> Laidlaw and Feizi, 2019; Balcan et al., 2020).

#### [Page 8](highlights://Schwartz%20and%20Stanovsky%20-%202022%20-%20On%20the%20Limitations%20of%20Dataset%20Balancing%20The%20Lost%20#page=8)

> We hypothesize that encouraging the model to provide this output
> when it is unsure, rather than making a semi-educated guess,
> potentially based on spurious correlations, could reduce its
> depen- dency on such correlations.

> In the context of this work, focusing on few-shot learning might
> allow models to not learn some of the correlations that result
> from manual annotation (Schwartz et al., 2017; Gururangan et
> al., 2018; Poliak et al., 2018), as they will not be exposed to
> many of them to begin with.

> for datasets or tasks for which the state of the art is close to
> or surpasses the human baseline, we should consider moving to
> few-shot setups.

***
- @schwartz_2022