---
order: -1
tags: 
title: Piantadosi_Hill_2022_Meaning without reference in large language models
---

#### [Page 1](highlights://Piantadosi_Hill_2022_Meaning%20without%20reference%20in%20large%20language%20models#page=1)

> On the other hand, the core objective of word prediction is a
> cen- tral piece of human language processing (e.g. Alt- mann and
> Kamide, 1999; Hale, 2001; Levy, 2008) and has long been shown
> capable of providing a learning signal from which linguistic
> structures and semantic categories can emerge (Elman, 1990).

***

#### [Page 2](highlights://Piantadosi_Hill_2022_Meaning%20without%20reference%20in%20large%20language%20models#page=2)

> One is that there are many terms that are meaningful to us but
> have no discernible referent at all, such as abstract words like
> “justice” and “wit.” People can think of new concepts like
> “aphid-sized accordion” that don’t exist (thus no referent), or
> even terms that have no possible referent like “perpetual motion
> machine” or “imaginary cup of tea.” We can think of concepts
> like “king of San Francisco” that pick out nobody, but are at
> least meaningful enough to reason about (for example: “If there
> was a King of San Francisco, he’d live in The Presidio.”). Other
> examples show reference can be quite decoupled from meaning.
> Terms like “treaty” and “contract” are often thought to have a
> concrete referent, but what is important is actually an abstract
> entity: a treaty is still valid if the piece of paper is
> destroyed. Frege’s example is of the “morning star” and the
> “evening star.” Both are terms for the planet Venus, but were
> once conceived of as different entities without knowing that
> they are the same object.

Can referents only be direct?

***

> In this view, the meaning of the word is intrinsically
> intertwined with other concepts like “payment”, “letter” and
> “delivery.” The interrelation is key (see, e.g. Deacon, 1998;
> Santoro et al., 2021) because when the associated terms shift in
> meaning even slightly (e.g. credit cards were developed as
> wholly new a form of “payment”) the meaning of “postage stamp”
> comes along for the ride (we know right away that they can be
> paid for by a credit card).

***

> What is a natural category or concept depends on our mental con-
> ception of how the underlying pieces relate, and

***

#### [Page 3](highlights://Piantadosi_Hill_2022_Meaning%20without%20reference%20in%20large%20language%20models#page=3)

> concepts can even be assembled fluidly, in an ad hoc manner or
> context-dependent manner

***

#### [Page 4](highlights://Piantadosi_Hill_2022_Meaning%20without%20reference%20in%20large%20language%20models#page=4)

> In much the same way, we see no reason to assume that the world
> of a system that receives input from a single sensory modality
> is meaningless, even if the addition of further sensors provides
> clear enrichment. When thinking about improving LLMs it we
> should therefore consider ways to enrich the internal conceptual
> roles of these systems, including to better reflect the
> structure, in- ference and algorithmic sophistication of humans

***

> In church-encoding, a representation is constructed in one
> system (e.g. lambda calculus or a neural network) in order to
> mimic the behavior of another system (e.g. boolean logic) in the
> sense that the rep- resentations in the first system interact
> with each other in a way that yields the desired conceptual
> roles of the second.

***

> The key question for LLMs is whether training to predict text
> could actually support discovery of conceptual roles. To us the
> question is empirical, and we believe has been answered in a
> promis- ing, partial affirmative by studies showing success on
> tasks that require knowledge of relationships between concepts.

^0d78e5

***

#### [Page 5](highlights://Piantadosi_Hill_2022_Meaning%20without%20reference%20in%20large%20language%20models#page=5)

> People use concepts in thinking and reasoning based on their
> meaning, and text is a low-dimensional projection of some of
> these patterns of use, so it is plausible that some properties
> of the real meaning could be inferred from text.

***

