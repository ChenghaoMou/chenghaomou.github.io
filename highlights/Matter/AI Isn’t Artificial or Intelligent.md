---
url: "https://www.vice.com/en/article/wxnaqz/ai-isnt-artificial-or-intelligent"
author: "Jason Koebler"
publisher: "Vice"
published: 2022-12-06
aliases:
  -  AI Isn’t Artificial or Intelligent
title: AI Isn’t Artificial or Intelligent
---

## Highlights
> These tasks, deemed rote and unglamorous for many in-house developers, are often outsourced to gig workers and workers who largely live in South Asia and Africa and work for data training companies such as iMerit, Sama, and Alegion. For example, Facebook has one of the most advanced algorithmic content moderation systems on the internet. That system's so-called artificial intelligence, though, is "learning from thousands of human decisions" made by human moderators.

> The biggest tech companies in the world imagine a near future where AI will replace a lot of human labor, unleashing new efficiency and productivity. But this vision ignores the fact that much of what we think of as “AI” is actually powered by tedious, low-paid human labor.

> “They lead people to believe that AI is smarter and more advanced than where it actually is, which is [why] we're still training it every single day.”

> “I think that the public doesn't have a good awareness of the fact that this is a supply chain. It’s a global supply chain, it contains uneven geographic flows and relations. And that it is based on a huge amount of human labor,” Kelle Howson, a postdoctoral researcher on the Fairwork project at the Oxford Internet Institute, told Motherboard.

> Howson can’t say for sure whether tech companies are intentionally obscuring human AI laborers, but that doing so certainly works in their interests. “I think that in some ways it supports their business models to do so because there's this perception that the work is done,” said Howson. “You as a client access a platform interface, post your project, and the work is delivered immediately. It's almost like magic. There was maybe never any human involved or [that’s what] it feels like, and so there's a sense of efficiency. And that really goes along with the kind of narrative that Silicon Valley likes to tell. The disruption, the tech solutionism, the move fast and break things kind of ideas.”

> In an investigation by TIME Magazine, Sama’s mission to provide poor countries with “ethical” and “dignified digital work” was quickly proven to be a facade of “participation-washing,” which is what researchers like Forlano define as companies including workers in “a post-colonial structure of global power” as a form of virtue signaling, rather than having them as meaningful, democratic partners. Motaung and other Sama employees told TIME that they were taking home as little as $1.50 per hour, and at least two content moderators were diagnosed with mental illnesses such as PTSD following their work viewing graphic images and videos depicting rape, murder, and dismemberment.

> “One of the logical conclusions that a computer scientist might come to is that if you just add more and correct data to the systems that ultimately they will become better. But that in itself is a fallacy. No amount of data is going to fix the systems.”

> Most people can agree on the fact that humans will always be part of AI, from developing models to checking for certain biases and errors. Thus, AI experts argue that the focus should be on how to decolonize the AI development process and include humans in an ethical and sustainable way.

> The study’s authors suggest that all participants in training AI should be recognized as work, which gives everyday users the ability to opt-in or opt-out of free online labor practices that would train a Machine Learning (ML) system. And if they choose to opt-in, they should be compensated accordingly or be provided with greater incentives. “People should be compensated for the work that they do to improve systems,” Forlano said. “And that if it's not done in an equitable way, it's just another kind of exploitation.”

