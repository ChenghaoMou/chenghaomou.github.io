---
url: https://www.aisnakeoil.com/p/ai-existential-risk-probabilities
author: Arvind Narayanan
publisher: AI Snake Oil
published: 2024-07-26
title: "AI existential risk probabilities are too unreliable to inform policy"
tags: []
created: 2024-07-27
modified: 2024-07-27
---

## Highlights

> There are many reasons why forecasters might systematically overestimate AI x-risk. The first is selection bias. Take AI researchers: the belief that AI can change the world is one of the main motivations for becoming an AI researcher. And once someone enters this community, they are in an environment where that message is constantly reinforced. And if one believes that this technology is terrifyingly powerful, it is perfectly rational to think there is a serious chance that its world-altering effects will be negative rather than positive.

