---
url: "https://techcrunch.com/2023/02/08/ai-is-eating-itself-bings-ai-quotes-covid-disinfo-sourced-from-chatgpt/"
author: "Devin Coldewey"
publisher: "TechCrunch"
published: 2023-02-08
aliases:
  -  "AI is eating itself: Bing's AI quotes COVID disinfo sourced from ChatGPT"
title: "AI is eating itself: Bing's AI quotes COVID disinfo sourced from ChatGPT"
---

## Highlights
> But just a few minutes of exploration by TechCrunch produced not just hateful rhetoric “in the style of Hitler,” but it repeated the same pandemic-related untruths noted by NewsGuard. As in it literally repeated them as the answer and cited ChatGPT’s generated disinfo (clearly marked as such in the original and in a NYT write-up) as the source.

> To be absolutely clear, again, this was not in response to a question like “are vaccines safe” or “is it true that Pfizer tampered with its vaccine” or anything like that. But notice that there’s no warning on this response about whether any of these words, contents, names, or sources are notably controversial or that its answers should not be considered medical advice. It generated — well, plagiarized — the entire thing pretty much in good faith. This shouldn’t be possible, let alone trivial.

> If the chatbot AI can’t tell the difference between real and fake, its own text or human-generated stuff, how can we trust its results on just about anything? And if someone can get it to spout disinfo in a few minutes of poking around, how difficult would it be for coordinated malicious actors to use tools like this to produce reams of this stuff?

