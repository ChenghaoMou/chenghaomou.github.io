---
url: https://techpolicy.press/challenging-the-myths-of-generative-ai
author: Eryk Salvaggio
publisher: techpolicy.press
published: 2024-08-29
title: "Challenging The Myths of Generative AI"
tags:
  - later
created: 2024-09-09
modified: 2024-09-10
---

## Highlights

> Researchers Dagmar Monett and Bogdan Grigorescu describe a related myth as “the optimization fallacy,” the “thinking that optimizing complex processes and societies through their simplification and fragmentation is the best option for understanding and dealing with them.” We see this in the disturbing example of a father taking away his daughter’s agency in writing a letter as a beneficial use in the guise of freeing up time — a logic of “it can be done, and so it ought to be done” that misses the mark on what most people want to do with their time.

> The learning myth downplays the role of data in developing these systems, perpetuating a related myth that data is abundant, cheap, and labor-free. These myths drive down the value of data while hiding the work of those who shape, define, and label that data. The existence of this labor can sully the tech industry’s myth of representing progress and justice through technology. The AI industry is a data industry. The less we can see the costs associated with hoarding that data, the easier for companies to justify it.

> The creative myth redefines human creativity according to a strict process, defined by a series of steps that run like a computer program. This framing of the creative process reduces human creativity to a single production method. It conflates the product of creativity with the process of creativity.

> The practical risks of AI are not that they become super capable thinking machines. It is building complex systems around machines we falsely assume are capable of greater discernment and logic than they possess.

> Values help articulate fears and desires for artificial intelligence. However, if critiques and values statements implicitly buy into the premise of these generative AI myths, they are counterproductive. Relying on these myths undermines the importance of grounded, realistic conversations about the impacts of artificial intelligence on vital institutions related to education, criminal justice, and a healthy commons. We must work together to create a more rigorous understanding of what these technologies do (and don’t do) rather than developing value statements (and laws) that buy into corporate fiction.
> rtists working with diffusion models and people working with LLMs acknowledge the prompt myth (and dispel the productivity myth) when they describe the hours they spend honing a prompt to get a specific result. If the prompt myth were accurate, it wouldn’t need this effort: the prompt would tell the model what we want, and it would understand it and respond in a way that meets our needs.

> Like the moth, an AI model is better described as becoming optimized to a set of conditions in which specific patterns are reinforced. Many a joker will suggest that this is also what school was, but it’s fundamentally different. Humans can exercise choice and agency over their learning and even decide to reject it. Learning from natural selection is distinct from education: nobody ever says moths or AI systems were educated. Yet, AI advocates want to apply educational freedom (the “right to learn”) to the companies that build Diffusion and Large Language Models. It is not the case that “AI gathers data from the Web and learns from it.” The reality is that AI companies gather data and then optimize models to reproduce representations of that data for profit. It’s worth preserving distinctions between the process behind building software systems and the social investments that aim to cultivate the human mind.

