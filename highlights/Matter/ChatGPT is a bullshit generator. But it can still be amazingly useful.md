---
aliases:
  - ChatGPT is a bullshit generator. But it can still be amazingly useful
url: https://aisnakeoil.substack.com/p/chatgpt-is-a-bullshit-generator-but
author: Arvind Narayanan
publisher: Sayash and Arvind from AI Snake Oil
order: -20221206071946
date: 2022-12-06
tags:
---

## Highlights
<mark>The philosopher Harry Frankfurt defined bullshit as speech that is intended to persuade without regard for the truth. By this measure, OpenAI’s new chatbot ChatGPT is the greatest bullshitter ever. Large Language Models (LLMs) are trained to produce plausible text, not true statements. ChatGPT is shockingly good at sounding convincing on any conceivable topic. But OpenAI is clear that there is no source of truth during training. That means that using ChatGPT in its current form would be a bad idea for applications like education or answering health questions. Even though the bot often gives excellent answers, sometimes it fails badly. And it’s always convincing, so it’s hard to tell the difference.</mark>

<mark>Yet, there are three kinds of tasks for which ChatGPT and other LLMs can be extremely useful, despite their inability to discern truth in general: 1. Tasks where it’s easy for the user to check if the bot’s answer is correct, such as debugging help. 2. Tasks where truth is irrelevant, such as writing fiction. 3. Tasks for which there does in fact exist a subset of the training data that acts as a source of truth, such as language translation.</mark>

<mark>But the danger is that you can't tell when it's wrong unless you already know the answer.</mark>

<mark>We tried some basic information security questions. In most cases, the answers sounded plausible but were, in fact, bullshit. And here’s what happened with more complex questions:</mark>

<mark>The fact that these models can’t discern the truth is why Meta’s Galactica, an LLM for science, was an ill-conceived idea. In science, accuracy is the whole point. The backlash was swift, and the public demo was pulled down after three days. Similarly, correctness and reliability are everything if you want to use an LLM for answering health-related queries.</mark>

<mark>Note that GPT-3 is 2.5 years old. We're told the field is progressing every week, so that's like centuries. When it was released, people confidently predicted that there would be a “Cambrian explosion” of applications. But so far, there have been zero mainstream applications — except GitHub Copilot, if you count programming as mainstream.</mark>

<mark>Debugging code is an application where programmers, especially novices, could benefit from LLMs. Note that once a bug is pointed out, it is generally easy to verify, so the fact that the bot’s answers might sometimes be wrong isn’t as much of a concern.</mark>

<mark>Before we get carried away by this potential: racist, sexist, and biased outputs are still a problem for all generative models, including ChatGPT. The model includes a content filter that declines inappropriate requests, which works well enough to feel like a big improvement over previous tools, but there is still a long way to go.</mark>

<mark>One possibility is that in a conversation between two speakers of different languages, a tool like ChatGPT could play the role of an interpreter, the advantage being that a tool used within a conversation can keep track of the dialog. This would allow it to rely on context and perform much more effectively and with far less awkwardness for the users.</mark>

<mark>Generative AI releases tend to look impressive based on cherry-picked examples that go viral. But that's not the full picture. For many applications, even a 10% failure rate is too high. There seem to be a fairly limited set of use cases where the lack of a source of truth isn’t a deal breaker. While these uses are still tremendously exciting, it’s far from obvious that people will soon be using chatbots in their everyday lives — for learning, or as a search replacement, or as a conversation partner.</mark>

<mark>Meanwhile, we’ve seen the first prominent use of LLMs for misinformation (on Stack Overflow). Of course, spammers were already using GPT-3 for search engine marketing and are delighted to get their hands on ChatGPT. But just as the predictions of transformation are overblown, we don’t agree with claims that the web will soon drown in an ocean of misinformation.</mark>

