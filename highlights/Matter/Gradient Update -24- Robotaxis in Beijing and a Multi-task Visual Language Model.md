---
url: "https://thegradientpub.substack.com/p/gradient-update-24-robotaxis-in-beijing"
author: "The Gradient"
publisher: "The Gradient's Newsletter"
published: 2022-05-10
aliases:
  -  "Gradient Update #24: Robotaxis in Beijing and a Multi-task Visual Language Model"
title: "Gradient Update #24: Robotaxis in Beijing and a Multi-task Visual Language Model"
---

## Highlights
> It is able to process images, video, and text presented in arbitrary orders. Since it is trained on uncurated data, Flamingo is likely to learn more general information beyond the structure that might be present in a curated dataset.

> For language, Flamingo uses a pretrained Chinchilla language model with 70 billion parameters. For vision, Flamingo uses a contrastively pretrained Normalizer Free ResNet (NFNet) with 435 million parameters. During

> Flamingo leverages two sources of strength: pretrained single modality models, and uncurated multimodal data.

> It should allow teams to prototype and train models faster without spending substantial time in data cleaning and preprocessing.

