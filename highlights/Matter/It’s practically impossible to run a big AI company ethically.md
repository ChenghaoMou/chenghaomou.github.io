---
url: https://www.vox.com/future-perfect/364384/its-practically-impossible-to-run-a-big-ai-company-ethically
author: Sigal Samuel
publisher: Vox
published: 2024-08-02
title: "It’s practically impossible to run a big AI company ethically"
tags: []
created: 2024-08-09
modified: 2024-08-11
---

## Highlights

> An AI company may want to build safe systems, but in such a hype-filled industry, it faces enormous pressure to be first out of the gate. The company needs to pull in investors to supply the gargantuan sums of money needed to build top AI models, and to do that, it needs to satisfy them by showing a path to huge profits. Oh, and the stakes — should the tech go wrong — are much higher than with almost any previous technology.

> But Anthropic is lobbying to water down the bill. It wants to scrap the idea that the government should enforce safety standards before a catastrophe occurs. “Instead of deciding what measures companies should take to prevent catastrophes (which are still hypothetical and where the ecosystem is still iterating to determine best practices)” the company urges, “focus the bill on holding companies responsible for causing actual catastrophes.” In other words, take no action until something has already gone terribly wrong.

> “Anthropic is trying to gut the proposed state regulator and prevent enforcement until after a catastrophe has occurred — that’s like banning the FDA from requiring clinical trials,” Max Tegmark, president of the Future of Life Institute, told me. The US has enforceable safety standards in industries ranging from pharma to aviation. Yet tech lobbyists continue to resist such regulations for their own products. Just as social media companies did years ago, they make voluntary commitments to safety to placate those concerned about risks, then fight tooth and nail to stop those commitments being turned into law.

> Why would Anthropic take the risk of using lifted data from, say, YouTube, when the platform has explicitly forbidden it and copyright infringement is such a hot topic right now? Because AI companies need ever-more high-quality data to continue boosting their models’ performance. Using synthetic data, which is created by algorithms, doesn’t look promising. Research shows that letting ChatGPT eat its own tail leads to bizarre, unusable output. (One writer coined a term for it: “Hapsburg AI,” after the European royal house that famously devolved over generations of inbreeding.) What’s needed is fresh data created by actual humans, but it’s becoming harder and harder to harvest that.

