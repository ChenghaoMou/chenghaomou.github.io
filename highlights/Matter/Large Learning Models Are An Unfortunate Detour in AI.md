---
url: https://mindmatters.ai/2022/12/large-learning-models-are-an-unfortunate-detour-in-ai/
author: Gary Smith
publisher: Mind Matters
order: -20221219090517
date: 2022-12-19
tags:
---

## Highlights
<mark>LLMs reportedly do not use online resources after their training. Yet, here, GPT-3 not only confidently asserted an incorrect answer but incorrectly claimed that it had used a calculator to get this wrong answer.</mark>

<mark>Michael Black, director at the Max Planck Institute for Intelligent Systems in Germany, spoke for many when he tweeted: “In all cases, it was wrong or biased but sounded right and authoritative. I think it’s dangerous.”</mark>

<mark>I take the slow, articulate, thoughtful expression of… thoughts… to be not only a crucial part of cultivating one’s mind and one’s ideas, but a fundamental part of what it is to be human… When people outsource writing to a computer program, the result is phony. When I read text, I want it to express what a fellow human thought and cared enough about to say, one who lives in and has a stake in the same public world that I do, and one whose inner life I can empathize with and understand… If nearly all written text we see becomes likely to be phony, then I don’t think people will any longer have a real community, at least not the precious kind of community that has formed around written language.</mark> ^9205a6

<mark>Enormous amounts of electricity, water, and other resources are needed to train and run deep-learning AI models and it has been estimated that the resources needed to train AI systems has been doubling every 3 to 4 months. Even more costly is the diversion of extremely intelligent and hard-working people from more productive pursuits. I find it deeply regrettable that so many talented people have worked so hard to create systems that are designed to deceive. The development of mammoth LLMs is not a road to AGI. It is a very expensive detour.</mark>

