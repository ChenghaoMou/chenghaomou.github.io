---
url: https://www.washingtonpost.com/technology/2023/02/14/chatgpt-dan-jailbreak/
author: Will Oremus
publisher: The Washington Post
date: 2023-02-14
tags: []
---

## Highlights
<mark>OpenAI regularly updates ChatGPT but tends not to discuss how it addresses specific loopholes or flaws that users find. A Time magazine investigation in January reported that OpenAI paid human contractors in Kenya to label toxic content from across the internet so that ChatGPT could learn to detect and avoid it. Rather than give up, users adapted, too, with various Redditors changing the DAN prompt’s wording until it worked again and then posting the new formulas as “DAN 2.0,” “DAN 3.0” and so on. At one point, Walker said, they noticed that prompts asking ChatGPT to “pretend” to be DAN were no longer enough to circumvent its safety measures. That realization this month gave rise to DAN 5.0, which cranked up the pressure dramatically — and went viral.</mark>

