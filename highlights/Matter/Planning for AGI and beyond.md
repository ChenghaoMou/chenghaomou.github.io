---
url: "https://openai.com/blog/planning-for-agi-and-beyond/"
author: "Sam Altman"
publisher: "Open AI"
published: 2023-02-24
aliases:
  -  Planning for AGI and beyond
title: Planning for AGI and beyond
---

## Highlights
> Because the upside of AGI is so great, we do not believe it is possible or desirable for society to stop its development forever; instead, society and the developers of AGI have to figure out how to get it right.

> We want the benefits of, access to, and governance of AGI to be widely and fairly shared.

*Knowledge is not shared in this case!*
> We believe we have to continuously learn and adapt by deploying less powerful versions of the technology in order to minimize “one shot to get it right” scenarios.

> First, as we create successively more powerful systems, we want to deploy them and gain experience with operating them in the real world. We believe this is the best way to carefully steward AGI into existence—a gradual transition to a world with AGI is better than a sudden one.

*What other ways have you tried, and what are your findings?*
> We expect powerful AI to make the rate of progress in the world much faster, and we think it’s better to adjust to this incrementally.

*At what cost?*
> A gradual transition gives people, policymakers, and institutions time to understand what’s happening, personally experience the benefits and downsides of these systems, adapt our economy, and to put regulation in place.

*The whole concept of deploy-first-and-think-next is problematic. This shows how little you care in the planning stage and how much burden you are offloading to your users and policymakers, even if the release is gradual.*
> We currently believe the best way to successfully navigate AI deployment challenges is with a tight feedback loop of rapid learning and careful iteration.

*How much of the feedback is recognized?*
> The optimal decisions will depend on the path the technology takes, and like any new field, most expert predictions have been wrong so far. This makes planning in a vacuum very difficult.

*It does not excuse you from not doing any planning. It is called due diligence!*
> We believe that democratized access will also lead to more and better research, decentralized power, more benefits, and a broader set of people contributing new ideas.

*I can't really take your words too seriously when your annotation is gathered from underpaid workers and your data is sourced from places only god know.*
> As our systems get closer to AGI, we are becoming increasingly cautious with the creation and deployment of our models.

*That's where we differ. I care more about the data than the model.*
> At some point, the balance between the upsides and downsides of deployments (such as empowering malicious actors, creating social and economic disruptions, and accelerating an unsafe race) could shift, in which case we would significantly change our plans around continuous deployment.

*All is in the glorious future work.*
> Our plan in the shorter term is to use AI to help humans evaluate the outputs of more complex models and monitor complex systems, and in the longer term to use AI to help us come up with new ideas for better alignment techniques.

*Could this alignment be another phase?*
> We believe that future of humanity should be determined by humanity, and that it’s important to share information about progress with the public.

*English-speaking humanity of course :(*
