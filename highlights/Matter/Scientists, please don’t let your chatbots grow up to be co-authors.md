---
url: "https://garymarcus.substack.com/p/scientists-please-dont-let-your-chatbots"
author: "Gary Marcus"
publisher: "The Road to AI We Can Trust"
published: 2023-01-14
aliases:
  -  Scientists, please don’t let your chatbots grow up to be co-authors
title: Scientists, please don’t let your chatbots grow up to be co-authors
---

## Highlights
> ChatGPT is a tool, but not a person. It’s at best, more like a spell-checker, or a grammar-checker, or a stats package, than it is like a scientist.

> Co-authorship is defined differently in different fields, but is generally defined as making a substantive scientific contribution. ChatGPT simply cannot reason well enough to to do this; as

> ChatGPT has proven itself to be both unreliable and untruthful. It makes boneheaded arithmetical errors, invents fake biographical details, bungles word problems, defines non-existent scientific phenomenon, stumble over arithmetic conversion, and on and on. If you don’t know that, you are not up on the AI literature; if you do know that, you show that you just don’t care, which is even worse. If you declare it as a co-author, it says you are more interested in being on trend, than in being on target.

> You wouldn’t trust a calculator that is 75% correct; if you blatantly advertise that you are excited about “writing” your paper with a tool with a shoddy track record, years before it has matured, why should I trust you?

> Scientific writing is in part about imparting truth in a clear way to others. If you treat ChatGPT as a sentient being, when it clearly is not, you are misleading the public into thinking ChatGPT is sentient; rather than communicating good science, you are hyping bullshit. Just stop.

