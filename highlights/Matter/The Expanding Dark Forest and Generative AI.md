---
url: https://maggieappleton.com/ai-dark-forest
author: Maggie Appleton ðŸ§­
publisher: maggieappleton.com
date: 2023-01-01
tags: []
title: "The Expanding Dark Forest and Generative AI"
---

## Highlights
<mark>In a repulsively evocative metaphor, they engage in " human centipede epistemology." I found this phrase via Twitter, but posted from a private account so I won't cite the original author. Language models regurgitate text from across the web, which some humans read and recycle into "original creations," which then become fodder to train other language models, and around and around we go recycling generic ideas and arguments and tropes and ways of thinking. Hard exiting out of this cycle requires coming up with unquestionably original thoughts and theories. It means seeing and synthesising patterns across a broad range of sources: books, blogs, cultural narratives served up by media outlets, conversations, podcasts, lived experiences, and market trends. We can observe and analyse a much fuller range of inputs than bots and generative models can.</mark>

<mark>We're about to drown in a sea of pedestrian takes. An explosion of noise that will drown out any signal. Goodbye to finding original human insights or authentic connections under that pile of cruft. Many people will say we already live in this reality. We've already become skilled at sifting through unhelpful piles of "optimised content" designed to gather clicks and advertising impressions.</mark> ^8d29c7

<mark>After the forest expands, we will become deeply sceptical of one another's realness. Every time you find a new favourite blog or Twitter account or Tiktok personality online, you'll have to ask: Is this really a whole human with a rich and complex life like mine? Is there a being on the other end of this web interface I can form a relationship with?</mark>

<mark>"Relationship" in the holistic sense -- friend, acquaintance, pen pal, intellectual interlocutor, frenemy, drinking buddy, and sure, maybe a lover. Before you continue, pause and consider: How would you prove you're not a language model generating predictive text? What special human tricks can you do that a language model can't?</mark>

<mark>They do not have beliefs based on evidence, claims, and principles. They cannot consult external sources and run experiments against objective reality. They cannot go outside and touch grass. In short, they do not have access to the same shared reality we do. They do not have embodied experiences, and cannot sense the world as we can sense it; they don't have vision, sound, taste, or touch. They cannot feel emotion or tightly hold a coherent set of values. They are not part of cultures, communities, or histories. They are a language model in a box. If a historical event, fact, person, or concept wasn't part of their training data, they can't tell you about it. They don't know about events that happened after a certain cutoff date.</mark>

<mark>This leaves us with some low-hanging fruit for humanness. We can tell richly detailed stories grounded in our specific contexts and cultures: place names, sensual descriptions, local knowledge, and, well the je ne sais quoi of being alive. Language models can decently mimic this style of writing but most don't without extensive prompt engineering. They stick to generics. They hedge. They leave out details. They have trouble maintaining a coherent sense of self over thousands of words.</mark>

<mark>What we have left to play with is la parole. No language model will be able to keep up with the pace of weird internet lingo and memes. I expect we'll lean into this. Using neologisms, jargon, euphemistic emoji, unusual phrases, ingroup dialects, and memes-of-the-moment will help signal your humanity.</mark>

<mark>The original internet dog meme: 'On the internet, no one knows you're a dog'</mark>

