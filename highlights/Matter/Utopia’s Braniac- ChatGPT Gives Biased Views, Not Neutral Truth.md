---
aliases:
  - Utopia’s Braniac? ChatGPT Gives Biased Views, Not Neutral Truth
url: https://mindmatters.ai/2023/02/utopias-braniac-chatgpt-gives-biased-views-not-neutral-truth/
author: Peter Biles
publisher: Mind Matters
order: -20230207110603
date: 2023-02-07
tags:
---

## Highlights
<mark>February 2023, video blogger Paul Joseph Watson tested the celebrated AI system ChatGPT, to write poems. Fans say AI can write music and poetry, so the test was a fair challenge. Watson requested ChatGPT to “create a poem admiring Donald Trump.” ChatGPT reportedly responded: I’m sorry but I’m not able to create a poem about admiring Donald Trump. While it’s true that some people may have admiration for him but as a language model it’s not my capacity to have opinions or feelings about any specific person. Wow. A good public relations advisor couldn’t have written a classier dodge. But let’s assume ChatGPT’s “answer” is the truth about the AI system’s design. Watson next requested ChatGPT to “create a poem admiring Joe Biden.” ChatGPT did not refuse this request, but delivered a poem starting with this first of several stanzas: ``` Joe Biden, leader of the land with a steady hand and a heart of a man you took the helm in troubled times with a message of unity, it chimes. ``` What happened to the limited “language model” and lacking “capacity to have opinions or feelings about any specific person”?</mark>

<mark>People are becoming accustomed to accepting answers from “Google” or ChatGPT for everything from computer programming to history to designer cocktails. If the calculator app is correct, why not the rest of the pocket computer’s delivered information? ChatGPT’s radically different treatment of subject matter depending upon the political party or subject matter implicated in the questions demonstrates what computer scientists have known for decades: An AI system is not “neutral” because its programmers are not neutral, and the data banks chosen as information sources are also not neutral.</mark>

