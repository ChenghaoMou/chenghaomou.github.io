---
aliases:
  - You Are Not a Parrot
url: https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html
author: Elizabeth Weil
publisher: Intelligencer
order: -20230301050016
date: 2023-03-01
tags:
---

## Highlights
<mark>Then there’s option two: “We could say, ‘Hey, look, this is technology that really encourages people to interpret it as if there were an agent in there with ideas and thoughts and credibility and stuff like that.’” Why is the tech designed like this? Why try to make users believe the bot has intention, that it’s like us?</mark>

<mark>“We call on the field to recognize that applications that aim to believably mimic humans bring risk of extreme harms,” she co-wrote in 2021. “Work on synthetic human behavior is a bright line in ethical Al development, where downstream effects need to be understood and modeled in order to block foreseeable harm to society and different social groups.”</mark>

<mark>that language, as Bender put it, is built on “people speaking to each other, working together to achieve a joint understanding. It’s a human-human interaction.”</mark>

<mark>Bender remains particularly fond of an alternative name for AI proposed by a former member of the Italian Parliament: “Systematic Approaches to Learning Algorithms and Machine Inferences.” Then people would be out here asking, “Is this SALAMI intelligent? Can this SALAMI write a novel? Does this SALAMI deserve human rights?”</mark>

<mark>The filtering leads to its own issues. If you remove content with words about sex, you lose content of in-groups talking with one another about those things.</mark>

<mark>she said. “People want to believe so badly that these language models are actually intelligent that they’re willing to take themselves as a point of reference and devalue that to match what the language model can do.”</mark>

<mark>Manning is invested in the project, literally, through the venture fund. Bender has no financial stake. Without one, it’s easier to urge slow, careful deliberation, before launching products. It’s easier to ask how this technology will impact people and in what way those impacts might be bad. “I feel like there’s too much effort trying to create autonomous machines,” Bender said, “rather than trying to create machines that are useful tools for humans.”</mark>

<mark>Others, like Dennett, the philosopher of mind, are even more blunt. We can’t live in a world with what he calls “counterfeit people.” “Counterfeit money has been seen as vandalism against society ever since money has existed,” he said. “Punishments included the death penalty and being drawn and quartered. Counterfeit people is at least as serious.”</mark>

<mark>We need strict liability for the technology’s creators, Dennett argues: “They should be held accountable. They should be sued. They should be put on record that if something they make is used to make counterfeit people, they will be held responsible. They’re on the verge, if they haven’t already done it, of creating very serious weapons of destruction against the stability and security of society. They should take that as seriously as the molecular biologists have taken the prospect of biological warfare or the atomic physicists have taken nuclear war.”</mark>

<mark>We can’t have people eager to separate “human, the biological category, from a person or a unit worthy of moral respect.” Because then we have a world in which grown men, sipping tea, posit thought experiments about raping talking sex dolls, thinking that maybe you are one too.</mark>

