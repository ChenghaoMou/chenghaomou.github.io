---
id: e7cb7330-c39a-11ee-a828-fb27bafbf7bb
alias:
  - Diving deep into OpenAI’s new study on LLM’s and bioweapons
title: "Diving deep into OpenAI’s new study on LLM’s and bioweapons"
author: |
  Gary Marcus
date: 2024-02-04 21:30:15
url: https://garymarcus.substack.com/p/when-looked-at-carefully-openais
---

# Diving deep into OpenAI’s new study on LLM’s and bioweapons

[Read on Omnivore](https://omnivore.app/me/diving-deep-into-open-ai-s-new-study-on-llm-s-and-bioweapons-18d75c7fe6f)
[Read Original](https://garymarcus.substack.com/p/when-looked-at-carefully-openais)

## Highlights

> It should go without saying that any risk-benefit analyses that with respect to the tradeoffs involved in AI needs to reflect studies that are not just methodologically sound but also interpreted accurately. It is great that companies like OpenAI are looking into these questions, and posting their findings publicly, but the media and the public need to realize that company white papers are _not_ peer-reviewed articles. Particularly when it comes to safety-critical questions, peer-review is essential. [⤴️](https://omnivore.app/me/diving-deep-into-open-ai-s-new-study-on-llm-s-and-bioweapons-18d75c7fe6f#2233d3e5-3188-4631-bf60-fd0f993f5e0e)  ^2233d3e5

