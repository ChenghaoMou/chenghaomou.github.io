---
id: ca27b2da-cdd1-11ee-a95f-279f91f1d5b8
aliases:
  - I worry our Copilot is leaving some passengers behind - Josh Collinsworth blog
title: "I worry our Copilot is leaving some passengers behind - Josh Collinsworth blog"
date: 2024-02-17 20:38:31
url: https://joshcollinsworth.com/blog/copilot
tags:
  - TODO
---

# I worry our Copilot is leaving some passengers behind - Josh Collinsworth blog

[Read on Omnivore](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a)

[Read Original](https://joshcollinsworth.com/blog/copilot)

## Highlights

> “They’re not perfect” may as well be the tagline for LLMs. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#db1b9456-4ac8-49d6-b5ec-b94d87499e9a)  ^db1b9456

> But if we’re giving one of the world’s major corporations our money, in exchange for this tool that’s supposed to make us better…shouldn’t it be held to _some_ standard of quality? Shouldn’t the results I get from a paid service at _least_ be better than a bad StackOverflow suggestion that got down-voted to the bottom of the page (and which would probably come with additional comments and suggestions letting me know why it was ranked lower)? [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#edace6c9-aa8a-4dbb-a0a5-58febddf922e)  ^edace6c9

> Products of all kinds are required to ensure misuse is discouraged, at a minimum, if not difficult or impossible. I don’t see why LLMs should be any different. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#2be829c0-b3e4-4e40-a6ed-09513ef18fe2)  ^2be829c0

> Plus, there are _far less_ sophisticated technologies that are fully capable of warning us, or even stopping us, when we’re writing inaccessible or improper code. Why should we just accept that LLM tools not only _fail_ to at least give us the same warnings, but _actively push us the wrong way_? [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#68907321-291d-4956-bd01-446897b750c2)  ^68907321

> One benefit of Copilot people commonly tout is how helpful it is when working in a new or unfamiliar language. But if you’re in that situation, _how will you know a bad idea when you see it_? [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#5fad49f6-2e9f-4a71-931b-49488974bc28)  ^5fad49f6

> If ensuring quality is _your responsibility_, and the tool you’re using pushes bad quality your way, you are fighting against gravity in that situation. It’s you versus the forces of entropy. And unless you fight perfectly (which you won’t), the end result is, unavoidably, a worse one. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#883edcfe-291f-413a-8a79-7f86ea2a56ba)  ^883edcfe

> In any case, if we know we exist on an uneven playing field (which we do), _we shouldn’t see the slant as the baseline_. If the status quo is already inequitable (which it is), we shouldn’t see something that’s _equally inequitable_ as just fine, just because that’s the current reality. It’s _not_ fine. It’s just more of the same inequitable slant. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#82851e2e-ee0d-4ed9-b1ad-d58e18b08b4b)  ^82851e2e

> If organizations actually cared about putting resources towards accessibility, they’d already be doing it. They don’t. They care about profit, and the moment you have 40% more time, you’re going to spend 100% of it on something that makes the company money. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#df1e091b-515c-4a28-a97a-b36f7fd13f2c)  ^df1e091b

> There’s no credit card for inequity. I don’t think it’s ethically sound to suggest that any present wrongdoing is justified by a future solution that will undo it, especially given points 1 and 2. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#4fc39b33-8bba-40f3-99ec-9a89d5ae4cc3)  ^4fc39b33

> That’s _invaluable_ context. Not only are you now better equipped to understand _this_ solution, you learned more for next time. You’re a better developer than you were.
> 
> Not so with Copilot. You gained zero context. You didn’t really learn anything. I certainly wouldn’t be learning Rust, if I were just letting Copilot generate it all for me. I got a workable answer of unknown quality handed to me, and my brain was not challenged or wrinkled in the slightest. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#483c62c9-d197-4872-82aa-ea32f83bdb70)  ^483c62c9

> In a lot of ways, in fact, “AI” is just the newest iteration of a very old form of colonial capitalism; build a wall around something you didn’t create, call it yours, and charge for access. (And when the natives complain, call them primitive and argue they’re blocking inevitable progress.) [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#0ae3547c-6051-45d0-a2f3-7471a14ec93c)  ^0ae3547c

> As more and more of the internet is generated by LLMs, more and more of it will reinforce biases. Then more and more LLMs will consume that biased content, use it for their own training, and the cycle will accelerate exponentially. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#b809211b-3877-4c72-9d03-6f13c70e93aa)  ^b809211b

> The internet is already an overwhelmingly inequitable place.
> 
> I don’t think we should accept that what we get in exchange for our money is, inevitably, a force for further inequity, and yes, ultimately, for discrimination. [⤴️](https://omnivore.app/me/i-worry-our-copilot-is-leaving-some-passengers-behind-josh-colli-18db8b8e64a#3b390804-5e6b-4dbd-8059-6d182d95ebad)  ^3b390804

