---
id: dd4ec04d-2750-4036-a842-beaa030a904f
title: '"AI safety" is AI hype • Buttondown'
aliases:
  - '"AI safety" is AI hype • Buttondown'
---

# "AI safety" is AI hype • Buttondown

[Read on Omnivore](https://omnivore.app/me/ai-safety-is-ai-hype-buttondown-18e43a01e98)

[Read Original](https://buttondown.email/maiht3k/archive/ai-safety-is-ai-hype/)

## Highlights

> The use of "frontier" in that description is particularly appalling, evoking both Star Trek and the idea that these companies are building the future as imagined in science fiction, one the one hand, and on the other settler colonialism where the lands and life worlds of Indigenous peoples of North America were seen as empty space to be conquered and tamed. [⤴️](https://omnivore.app/me/ai-safety-is-ai-hype-buttondown-18e43a01e98#0f87835d-ab3f-42d5-ab20-9b1989056903)  ^0f87835d

> that somehow these piles of linear algebra, if they just reach critical mass, will combust into consciousness and agency. And then, as always, the bar is conveniently just beyond what's already been built. The rest of the paragraph locates the danger of these models in their "weights", that is the result of training them, rather than the large-scale [theft](https://news.artnet.com/art-world/lawyers-for-artists-suing-ai-companies-file-amended-complaint-after-judge-dismisses-some-claims-2403523) of [creative](https://www.theverge.com/2023/7/9/23788741/sarah-silverman-openai-meta-chatgpt-llama-copyright-infringement-chatbots-artificial-intelligence-ai) [work](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html), the [exploitation](https://time.com/6247678/openai-chatgpt-kenya-workers/) of [workers](https://www.wsj.com/articles/chatgpt-openai-content-abusive-sexually-explicit-harassment-kenya-workers-on-human-workers-cf191483) to sanitize system output, the [ongoing](https://x.com/emilymbender/status/1756342308960895281?s=20) [pollution](https://medium.com/@emilymenonbender/advocating-for-protections-for-the-information-ecosystem-89fbe95e9de2) of the [information ecosystem](https://dl.acm.org/doi/10.1145/3649468), the [environmental](https://arxiv.org/abs/2311.16863) [impacts](https://dl.acm.org/doi/10.1145/3360647) of [compute-hungry](https://www.theatlantic.com/technology/archive/2024/03/ai-water-climate-microsoft/677602/) [models](https://www.buzzsprout.com/2126417/13931174-episode-19-the-murky-climate-and-environmental-impact-of-large-language-models-november-6-2023), the [reproduction](https://nyupress.org/9781479837243/algorithms-of-oppression/) of [systems of oppression](https://www.youtube.com/watch?v=QxuyfWoVV98) in [system output](https://dl.acm.org/doi/10.1145/2460276.2460278), the use of [algorithmic decision making](https://us.macmillan.com/books/9781250074317/automatinginequality) to [shirk collective responsibilities of care](https://algorithmwatch.org/en/bamf-dialect-recognition/), and so on. [⤴️](https://omnivore.app/me/ai-safety-is-ai-hype-buttondown-18e43a01e98#2644f82b-ce6c-4345-a003-e0e240ff9124)  ^2644f82b

