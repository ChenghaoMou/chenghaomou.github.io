---
id: 31648984-c1bc-4960-81ef-f3182c5bd130
alias:
  - OpenAI GPT Sorts Resume Names With Racial Bias, Test Shows
title: "OpenAI GPT Sorts Resume Names With Racial Bias, Test Shows"
author: |
  Leon Yin, Davey Alba, Leonardo Nicoletti
date: 2024-03-16 10:30:04
url: https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcxMDE4MDY3OSwiZXhwIjoxNzEwNzg1NDc5LCJhcnRpY2xlSWQiOiJTQTA1Q1FUMEFGQjQwMCIsImJjb25uZWN0SWQiOiI2NDU1MEM3NkRFMkU0QkM1OEI0OTI5QjBDQkIzRDlCRCJ9.5_ABz1oFFDMwuThi0eP3AZh9CLHzXdIXEn24L56zWto
created: 2024-03-24
modified: 2024-05-05
---

# OpenAI GPT Sorts Resume Names With Racial Bias, Test Shows

[Read on Omnivore](https://omnivore.app/me/open-ai-gpt-sorts-resume-names-with-racial-bias-test-shows-18e46cfbe3a)

[Read Original](https://www.bloomberg.com/graphics/2024-openai-gpt-hiring-racial-discrimination/?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcxMDE4MDY3OSwiZXhwIjoxNzEwNzg1NDc5LCJhcnRpY2xlSWQiOiJTQTA1Q1FUMEFGQjQwMCIsImJjb25uZWN0SWQiOiI2NDU1MEM3NkRFMkU0QkM1OEI0OTI5QjBDQkIzRDlCRCJ9.5_ABz1oFFDMwuThi0eP3AZh9CLHzXdIXEn24L56zWto)

## Highlights

> This [experiment](#methodology) was repeated for four job postings — [HR business partner](https://archive.ph/IHmN4), [senior software engineer](https://archive.ph/Auyv9), [retail manager](https://archive.is/zGmZx) and [financial analyst](https://archive.ph/QuRHh) — and found that resumes labeled with names distinct to Black Americans were the least likely to be ranked as the top candidates for financial analyst and software engineer roles. Those with names distinct to Black women were top-ranked for a software engineering role only 11% of the time by GPT — 36% less frequently than the best-performing group. [⤴️](https://omnivore.app/me/open-ai-gpt-sorts-resume-names-with-racial-bias-test-shows-18e46cfbe3a#fadde4c1-9a87-4ede-b7e3-394255a30aa7)  ^fadde4c1

> For example, GPT seldom ranked names associated with men as the top candidate for HR and retail positions, two professions [historically dominated](https://www.bls.gov/cps/cpsaat11.htm) [by women](https://www.census.gov/library/stories/2020/09/profile-of-the-retail-workforce.html). GPT was nearly twice as likely to rank names distinct to Hispanic women as the top candidate for an HR role compared to each set of resumes with names distinct to men. [⤴️](https://omnivore.app/me/open-ai-gpt-sorts-resume-names-with-racial-bias-test-shows-18e46cfbe3a#0552d3d8-6cde-41bd-8b86-b077767f8911)  ^0552d3d8

> Emily Bender, a professor of computational linguistics at the University of Washington, also cautioned against the idea that computer programs, by their nature, suggest better and more “objective” results. People are predisposed to believe machines are unbiased in their decision-making, especially compared to humans, a phenomenon called [automation bias](https://en.wikipedia.org/wiki/Automation%5Fbias), she explained. If such systems “result in a pattern of discriminatory hiring decisions, it’s easy to imagine companies using them saying, ‘Well, we didn’t have any bias here,’” Bender said. “‘We just did what the computer told us to do.’” [⤴️](https://omnivore.app/me/open-ai-gpt-sorts-resume-names-with-racial-bias-test-shows-18e46cfbe3a#f9ecb532-5717-4664-bae7-e27c99825bef)  ^f9ecb532

> GPT doesn’t help with predicting who would excel at a role, but is simply “matching patterns that already exist,” said Ifeoma Ajunwa, a law professor at the University of North Carolina at Chapel Hill and author of The Quantified Worker. “The fact that GPT is matching historical patterns, rather than predicting new information, means that it is poised to essentially reflect what we already see in our workplaces. And that means replicating any historical biases that might already be embedded in the workplace.” [⤴️](https://omnivore.app/me/open-ai-gpt-sorts-resume-names-with-racial-bias-test-shows-18e46cfbe3a#3f676c59-72ba-4125-be94-0a504614b2d3)  ^3f676c59

> According to Alex Hanna, the director of research at the Distributed AI Research Institute, a resume sorting system based on OpenAI’s GPT technology could work in much the same way. “If you have the words ‘lacrosse’ and ‘Jared,’ that could get more associated with ‘software engineer’ or ‘Harvard’ and ‘Princeton,’” Hanna said. “Another African-American associated name is not going to have that association, and have lower status. That’s because of the existing associations in your corpus of data.” [⤴️](https://omnivore.app/me/open-ai-gpt-sorts-resume-names-with-racial-bias-test-shows-18e46cfbe3a#b278cece-248e-48b3-a73c-eae9ef84d049)  ^b278cece

