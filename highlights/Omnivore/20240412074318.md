---
id: 024f7dd0-ddaa-4721-b5dd-3edb0b0674ba
alias:
  - "You can't build a moat with AI"
title: "You can't build a moat with AI"
author: |
  Vikram Sreekanti, Joseph E. Gonzalez
date: 2024-04-12 07:43:18
url: https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai?triedRedirect=true
created: 2024-04-12
modified: 2024-04-21
---

# You can't build a moat with AI

[Read on Omnivore](https://omnivore.app/me/https-open-substack-com-pub-generatingconversation-p-you-cant-bu-18ed10bd305)

[Read Original](https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai?triedRedirect=true)

## Highlights

> Whatever the case may be, it’s become clear to us that there’s not very much you can do to differentiate yourself using just LLMs[1](https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai?r=c2wbd&triedRedirect=true#footnote-1-143493573). **The real differentiation lies in your data you feed into your models.** [⤴️](https://omnivore.app/me/https-open-substack-com-pub-generatingconversation-p-you-cant-bu-18ed10bd305#cd7e89cf-084c-4cef-9360-b1daee606865)  ^cd7e89cf

> Everyone today can easily switch between models and experiment with what works best today for their application. That means that whatever you’re building, the advantage you get by picking the right model is small.
> 
> Deviating from the norm is also dangerous — it might get you unexpectedly good answers in some cases and unexpectedly bad answers in other cases. When a lot of AI startups are working to build trust, that’s a risky proposition, and as a result, most teams default back to using the safe models. That means that what you put into the model matters more than ever. [⤴️](https://omnivore.app/me/https-open-substack-com-pub-generatingconversation-p-you-cant-bu-18ed10bd305#70d52482-d264-4752-a4d8-1e5b5872abcd)  ^70d52482

> **And your prompts aren’t IP.** It might feel like your applications’ prompts or prompt templates are a good form of differentiation. After all, your top-notch engineering team has invested days into tuning them to have the right response characteristics, tone, and output style. Of course, giving your competitors your prompts would probably accelerate their progress, but any good engineering team will figure out the right changes quickly. The main reason is that the experimentation (with the right evaluation data!) is quick and easy — trying a new prompt template isn’t much harder than writing it out. All it really takes is a little bit of patience, some creativity, and extra Azure OpenAI credits. [⤴️](https://omnivore.app/me/https-open-substack-com-pub-generatingconversation-p-you-cant-bu-18ed10bd305#5ddac442-b53a-40d3-9a15-25cc3f6e0ace)  ^5ddac442

