---
id: 5ae10811-54ec-42da-a8fb-cd05f2dadfef
alias:
  - "The LLMentalist Effect: how chat-based Large Language Models replicate the mechanisms of a psychic's con"
title: "The LLMentalist Effect: how chat-based Large Language Models replicate the mechanisms of a psychic's con"
author: |
  Baldur Bjarnason, July 4th, 2023
date: 2024-04-14 16:33:47
url: https://softwarecrisis.dev/letters/llmentalist/
created: 2024-05-06
modified: 2024-05-06
---

# The LLMentalist Effect: how chat-based Large Language Models replicate the mechanisms of a psychic's con

[Read on Omnivore](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd)

[Read Original](https://softwarecrisis.dev/letters/llmentalist/)

## Highlights

> Subjective validation, sometimes called personal validation effect, is a cognitive bias by which people will consider a statement or another piece of information to be correct if it has any personal meaning or significance to them. People whose opinion is affected by subjective validation will perceive two unrelated events (i.e., a coincidence) to be related because their personal beliefs demand that they be related. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#6d2c522a-0f70-4d25-93dc-2adc677a1c69)  ^6d2c522a

> This is where the con often becomes insidious: the effect becomes stronger the more cooperative the mark is, and they often become more cooperative over time.
> 
> What’s more, susceptibility has nothing to do with intelligence. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#16c8deec-21c8-47d4-a5a8-e5a92b906e2c)  ^16c8deec

> Our current environment of relentless hype sets the stage and builds up an expectation for at least glimmers of genuine intelligence. For all the warnings vendors make about these systems not being general intelligences, those statements are always followed by either an implied or an actual “yet”. The hype strongly implies that these are “almost” intelligences and that you should be able to perceive “sparks” of intelligence in them. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#1daacd8b-f990-4d62-87a6-e0fd2f639cc3)  ^1daacd8b

> Anthropomorphising concepts such as using “hallucination” as a term help dismiss the fact that statistical responses are completely disconnected from meaning and facts. The hype and _mythology_ of AI primes the audience to think of these systems as persons to be understood and engaged with, all but guaranteeing subjective validation. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#03bf1386-d728-46ee-bed9-c334e7d686bc)  ^03bf1386

> You’re the one finding ways to validate those responses as being specific to you as the subject of the conversation. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#68249d35-1f53-43c9-b420-257804fdcb1f)  ^68249d35

> Once you’ve trained on most of the past twenty years of the web, large collections of stolen ebooks, all of Reddit, most of social media, and a substantial amount of custom interactions by low-wage workers, the model will have a response for almost everything you can think of, or can use a variation of something it’s already seen. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#65aade81-2b8b-4130-8e8f-f6b89006af6c)  ^65aade81

> This lack of concrete specificity likely means that RLHF models in general are likely to reward responses that _sound_ accurate. As the reward model is likely just another language model, it can’t reward based on facts or anything specific, so it can only reward output that has a tone, style, and structure that’s commonly associated with statements that have been rated as accurate. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#0cb48ca6-4984-4389-b2a0-dfd7eecbed63)  ^0cb48ca6

> Even the ratings themselves are suspect. Most, if not all, of the workers who provide this feedback to AI vendors are low-paid workers who are unlikely to have specialised knowledge relevant to the topic they’re rating, and even if they do, they are unlikely to have the time to fact-check everything.
> 
> That means they are going to be ranking the conversations almost entirely based on tone and sentence structure. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#506a7f67-599a-4062-a589-10476b3b453f)  ^506a7f67

> Once you’re so deep into it that you’ve done a press tour and committed yourself as a public figure to this idea, dislodging the belief that we now have a proto-AGI becomes impossible. Much like a scientist publicly stating that they believe in a particular psychic, their self-image becomes intertwined with their belief in that psychic. Any dismissal of the phenomenon will feel to them like a personal attack. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#60b11780-feb5-423f-9ebe-fe8b6675e1a2)  ^60b11780

> Taken together, these flaws make LLMs look less like an information technology and more like a modern mechanisation of the _psychic hotline_. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#4f62acc3-9cba-4e24-b753-84ed665427a6)  ^4f62acc3

> Delegating your decision-making, ranking, assessment, strategising, analysis, or any other form of reasoning to a chatbot becomes the functional equivalent to phoning a psychic for advice. [⤴️](https://omnivore.app/me/the-ll-mentalist-effect-how-chat-based-large-language-models-rep-18edd3e3ebd#99740b0c-14b6-43b6-a062-7356568bf4e3)  ^99740b0c

