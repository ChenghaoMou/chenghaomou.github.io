---
id: 67a40e87-9fb3-4fbd-82db-1d8b03a42c87
alias:
  - LLMs and the Harry Potter problem
title: LLMs and the Harry Potter problem
author: |
  Aman RaghuvanshiCEO, Pyq AI
date: 2024-04-23 23:25:28
url: https://www.pyqai.com/blog/llms-and-the-harry-potter-problem
---

# LLMs and the Harry Potter problem

[Read on Omnivore](https://omnivore.app/me/https-www-pyqai-com-blog-llms-and-the-harry-potter-problem-18f0d105d09)

[Read Original](https://www.pyqai.com/blog/llms-and-the-harry-potter-problem)

## Highlights

> Imagine you give an LLM (note: not an agent - explanation for why we care about the LLM’s ability later in this article) a chapter of Harry Potter and ask it to count how many times the word “wizard” is mentioned. GPT4, Claude 3 Opus, Gemini Ultra and Mixtral - arguably representative of SOTA as of this writing - all fail at this task despite having big context windows. [⤴️](https://omnivore.app/me/https-www-pyqai-com-blog-llms-and-the-harry-potter-problem-18f0d105d09#eb952df2-dd74-4436-8beb-74209e2baa29)  ^eb952df2

> This test admittedly has a split focus: it is measuring the model’s in-context recall and its ability to count, both of which are weak points. [⤴️](https://omnivore.app/me/https-www-pyqai-com-blog-llms-and-the-harry-potter-problem-18f0d105d09#64ac8297-179a-45c9-865d-86d0691da7bd)  ^64ac8297

> For it to work, an agent would need to autonomously digest the entire document, develop an ontology that addresses your use-case, and figure out a way to parse said document with all of its complexities. [⤴️](https://omnivore.app/me/https-www-pyqai-com-blog-llms-and-the-harry-potter-problem-18f0d105d09#789e66b8-b866-48dc-b8ea-e8e6518e689f)  ^789e66b8

