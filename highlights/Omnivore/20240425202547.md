---
id: 0e505ba1-4a57-493e-96f2-c02842b8b969
alias:
  - The “it” in AI models is the dataset. – Non_Interactive – Software & ML
title: The “it” in AI models is the dataset. – Non_Interactive – Software & ML
author: |
  unknown
date: 2024-04-25 20:25:47
url: https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/
---

# The “it” in AI models is the dataset. – Non_Interactive – Software & ML

[Read on Omnivore](https://omnivore.app/me/the-it-in-ai-models-is-the-dataset-non-interactive-software-ml-18f16b8969c)

[Read Original](https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/)

## Highlights

> It’s becoming awfully clear to me that these models are truly approximating their datasets to an incredible degree. What that means is not only that they learn what it means to be a dog or a cat, but the interstitial frequencies between distributions that don’t matter, like what photos humans are likely to take or words humans commonly write down.
> 
> What this manifests as is – trained on the same dataset for long enough, pretty much every model with enough weights and training time converges to the same point. Sufficiently large diffusion conv-unets produce the same images as ViT generators. AR sampling produces the same images as diffusion. [⤴️](https://omnivore.app/me/the-it-in-ai-models-is-the-dataset-non-interactive-software-ml-18f16b8969c#013eda02-1933-4db8-b8bd-1e57448da495)  ^013eda02

> This is a surprising observation! It implies that model behavior is not determined by architecture, hyperparameters, or optimizer choices. It’s determined by your dataset, nothing else. Everything else is a means to an end in efficiently delivery compute to approximating that dataset. [⤴️](https://omnivore.app/me/the-it-in-ai-models-is-the-dataset-non-interactive-software-ml-18f16b8969c#aff9d405-0dde-479f-9847-2e6548644838)  ^aff9d405

