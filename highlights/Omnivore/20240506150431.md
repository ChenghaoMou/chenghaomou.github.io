---
id: 68172e78-8556-49d0-a76e-7dd38db4bee0
alias:
  - Pornhub's Nonconsensual 'Nudify' Ad
title: Pornhub's Nonconsensual 'Nudify' Ad
author: |
  Emanuel Maiberg
date: 2024-05-06 15:04:31
url: https://www.404media.co/email/87ab3a1f-0380-4811-90b3-b6cb68c4b977/
---

# Pornhub's Nonconsensual 'Nudify' Ad

[Read on Omnivore](https://omnivore.app/me/pornhub-s-nonconsensual-nudify-ad-18f4e386988)

[Read Original](https://www.404media.co/email/87ab3a1f-0380-4811-90b3-b6cb68c4b977/)

## Highlights

> The use of these “undress” apps is some of the most harmful consequences of AI tools. These apps have spread to [schools](https://www.nbcnews.com/news/us-news/little-recourse-teens-girls-victimized-ai-deepfake-nudes-rcna126399?ref=404media.co) across the country, and recently resulted in the [arrest](https://www.wired.com/story/florida-teens-arrested-deepfake-nudes-classmates/?ref=404media.co) of two middle school students in Florida. In February, we [covered a case in a Washington State high school](https://www.404media.co/what-was-she-supposed-to-report-police-report-shows-how-a-high-school-deepfake-nightmare-unfolded/) where several students were investigated by the police for using an “undress” app that takes a real photograph of a person and makes them appear nude. In that story, the police report indicates the students found the app on TikTok, which previous [reporting](https://www.vice.com/en/article/m7b4b3/x-lags-behind-tiktok-meta-in-restricting-nudify-apps-for-non-consensual-ai-porn?ref=404media.co) has shown also promoted these types of apps. [⤴️](https://omnivore.app/me/pornhub-s-nonconsensual-nudify-ad-18f4e386988#3823b90a-6192-4792-abc8-0b55b78091fb)  ^3823b90a

