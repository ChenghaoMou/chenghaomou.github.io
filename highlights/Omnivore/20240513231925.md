---
id: 5eb5e508-7bd8-4295-a15b-4d49c0c9fff1
alias:
  - The Evolving Landscape of LLM Evaluation
title: "The Evolving Landscape of LLM Evaluation"
author: |
  Sebastian Ruder
date: 2024-05-13 23:19:25
url: https://newsletter.ruder.io/p/the-evolving-landscape-of-llm-evaluation
created: 2024-05-19
modified: 2024-05-19
---

# The Evolving Landscape of LLM Evaluation

[Read on Omnivore](https://omnivore.app/me/https-newsletter-ruder-io-p-the-evolving-landscape-of-llm-evalua-18f740a000f)

[Read Original](https://newsletter.ruder.io/p/the-evolving-landscape-of-llm-evaluation)

## Highlights

> What can we do to mitigate memorization? [Ravaut et al. (2024)](https://arxiv.org/abs/2404.00699) highlight some best practices to reduce contamination in their survey:
> 
> 1. **Encrypting evaluation datasets**. The authors of the [MTOB](https://arxiv.org/abs/2309.16575) dataset (discussed in a [previous newsletter](https://newsletter.ruder.io/p/true-zero-shot-mt)) did this. The downside: if the dataset is shared unencrypted at any point, it is hard to contain it again.
> 2. **Scanning newly released evaluation datasets**. We can make sure to only evaluate on uncontaminated data.
> 3. **Preventing data leakage to closed-source APIs**. Evaluating on closed-source APIs inadvertently leaks data to them whether or not the data is made available online or not. [⤴️](https://omnivore.app/me/https-newsletter-ruder-io-p-the-evolving-landscape-of-llm-evalua-18f740a000f#59fdd7ed-971b-4d14-ba58-42320d77c4f9)  ^59fdd7ed

> As we already evaluate LLMs how we assess humans—on standardized exams and general aptitude and proficiency tests—**we should also follow a similar design process for future LLM evals: With regularly updated tests, assuming access to all prior exam data and accounting for a willingness to exploit loopholes**.
> 
> Overall, we need to rethinking the way we evaluate LLMs and shift to efficient evaluation processes that can keep track with the pace of model advances. [⤴️](https://omnivore.app/me/https-newsletter-ruder-io-p-the-evolving-landscape-of-llm-evalua-18f740a000f#0e65fee7-ffa6-48f7-bbad-98a77ae59970)  ^0e65fee7

