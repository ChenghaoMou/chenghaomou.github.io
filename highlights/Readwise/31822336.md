---
title: "31822336"
url: https://www.truthdig.com/articles/before-its-too-late-buddy/
author: Émile P. Torres
date: 2023-12-10
time: 11:22 AM
source: "reader"
aliases:
  - ‘Before It’s Too Late, Buddy’
---
## Highlights
> I’ve since [modified and elaborated](https://www.newstatesman.com/ideas/2023/08/longtermism-threat-humanity) parts of these arguments, and [now prefer the word](https://www.truthdig.com/articles/the-acronym-behind-our-wildest-ai-dreams-and-nightmares/) “TESCREALism” to “longtermism” because the acronym “TESCREAL” does a better job of capturing the array of overlapping ideas that have shaped the general outlook. ([View Highlight](https://read.readwise.io/read/01h9d5psxfk8fyx989rakvfys5))
Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, and Longtermism

> Over and over again, history shows that the march to utopia can leave a trail of destruction in its wake. If the ends can justify the means, and the end is paradise, then what exactly is off the table for protecting and preserving this end? ([View Highlight](https://read.readwise.io/read/01h9d65j9fvx191b4rtgtx0ep4))

> Yudkowsky talks out of both sides of his mouth, giving mixed messages. He wants us to believe that his proposals for avoiding an AGI apocalypse are within the bounds of established norms, yet in a moment of honesty he says that he would “probably” bomb laboratories in Wuhan, if he can do this “secretly.” He opposes nuclear first strikes, yet implies that more than 8 billion people should be “allowed” to die, if it means keeping the door open to “reaching the stars someday.” And his extraordinary over-confidence, fueled by his egomania, that a misaligned AGI will kill everyone on Earth is inspiring the sort of radical, dangerous discussions like those recorded in the Berkeley workshop meeting minutes. ([View Highlight](https://read.readwise.io/read/01h9d69dw66dfkvj0q77fjvtta))

> When people inside a community become too afraid to publicly criticize it, that community starts to [look rather like a cult](https://twitter.com/SarahTaber_bww/status/1617194799261487108?lang=de). ([View Highlight](https://read.readwise.io/read/01h9d6cwff16pvrkv28x137hy7))---
title: "‘Before It’s Too Late, Buddy’"
url: https://www.truthdig.com/articles/before-its-too-late-buddy/
author: Émile P. Torres
date: 2024-03-02
time: 10:01 PM
source: "reader"
aliases:
  - "‘Before It’s Too Late, Buddy’"
---
# ‘Before It’s Too Late, Buddy’

## Highlights
> I’ve since [modified and elaborated](https://www.newstatesman.com/ideas/2023/08/longtermism-threat-humanity) parts of these arguments, and [now prefer the word](https://www.truthdig.com/articles/the-acronym-behind-our-wildest-ai-dreams-and-nightmares/) “TESCREALism” to “longtermism” because the acronym “TESCREAL” does a better job of capturing the array of overlapping ideas that have shaped the general outlook. ([View Highlight](https://read.readwise.io/read/01h9d5psxfk8fyx989rakvfys5))
Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, and Longtermism

> Over and over again, history shows that the march to utopia can leave a trail of destruction in its wake. If the ends can justify the means, and the end is paradise, then what exactly is off the table for protecting and preserving this end? ([View Highlight](https://read.readwise.io/read/01h9d65j9fvx191b4rtgtx0ep4))

> Yudkowsky talks out of both sides of his mouth, giving mixed messages. He wants us to believe that his proposals for avoiding an AGI apocalypse are within the bounds of established norms, yet in a moment of honesty he says that he would “probably” bomb laboratories in Wuhan, if he can do this “secretly.” He opposes nuclear first strikes, yet implies that more than 8 billion people should be “allowed” to die, if it means keeping the door open to “reaching the stars someday.” And his extraordinary over-confidence, fueled by his egomania, that a misaligned AGI will kill everyone on Earth is inspiring the sort of radical, dangerous discussions like those recorded in the Berkeley workshop meeting minutes. ([View Highlight](https://read.readwise.io/read/01h9d69dw66dfkvj0q77fjvtta))

> When people inside a community become too afraid to publicly criticize it, that community starts to [look rather like a cult](https://twitter.com/SarahTaber_bww/status/1617194799261487108?lang=de). ([View Highlight](https://read.readwise.io/read/01h9d6cwff16pvrkv28x137hy7))

