---
title: "General OCR Theory Towards OCR-2.0 via a Unified End-to-end Model"
alias:
  - General OCR Theory Towards OCR-2.0 via a Unified End-to-end Model
created: 1772-11-30
updated: 2024-11-03 14:51:21:017000
modified: 2024-12-07
authors:
  - Haoran Wei
  - Chenglong Liu
  - Jinyue Chen
  - Jia Wang
  - Lingyu Kong
  - Yanming Xu
  - Zheng Ge
  - Liang Zhao
  - Jianjian Sun
  - Yuang Peng
  - Chunrui Han
  - Xiangyu Zhang
url: http://arxiv.org/abs/2409.01704
zotero_url: zotero://open-pdf/library/items/5ZVJYINR
tags:
  - reMarkable
---

# General OCR Theory Towards OCR-2.0 via a Unified End-to-end Model

[Open in Zotero](zotero://open-pdf/library/items/5ZVJYINR)

## Abstract

Traditional OCR systems (OCR-1.0) are increasingly unable to meet people's usage due to the growing demand for intelligent processing of man-made optical characters. In this paper, we collectively refer to all artificial optical signals (e.g., plain texts, math/molecular formulas, tables, charts, sheet music, and even geometric shapes) as "characters" and propose the General OCR Theory along with an excellent model, namely GOT, to promote the arrival of OCR-2.0. The GOT, with 580M parameters, is a unified, elegant, and end-to-end model, consisting of a high-compression encoder and a long-contexts decoder. As an OCR-2.0 model, GOT can handle all the above "characters" under various OCR tasks. On the input side, the model supports commonly used scene- and document-style images in slice and whole-page styles. On the output side, GOT can generate plain or formatted results (markdown/tikz/smiles/kern) via an easy prompt. Besides, the model enjoys interactive OCR features, i.e., region-level recognition guided by coordinates or colors. Furthermore, we also adapt dynamic resolution and multi-page OCR technologies to GOT for better practicality. In experiments, we provide sufficient results to prove the superiority of our model.

## Pages

### Page 2

**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">architecture, we adopt the unsophisticated encoder-decoder paradigm for the model. Specifically,GOT enjoys a high compression rate encoder to transfer the optical image to tokens as well as along context length decoder to output the corresponding OCR results. The encoder has approximately 80M parameters posing 1024×1024 input size which is enough to deal with commonlyused photo/document input styles. Each input image will be compressed to tokens with 256×1024dimensions. The decoder of GOT, with 0.5B parameters, supports 8K max length tokens to ensureit can tackle long-context scenarios. We devise an effective and efficient training strategy for GOT,which can be divided into three procedures, i.e., decoupled pre-training of the encoder, joint-trainingof the encoder with a new decoder, and further post-training of the decoder. Besides, to further liftthe practicality of GOT, we additionally adapt the fine-grained OCR feature for better interactivity,dynamic resolution strategy for ultra-high-resolution images (e.g., over 2K), and the multi-page OCRtechnology to alleviate the problem of difficulty in breaking pages in PDF image-text pairs (e.g.,page breaks in .tex files). To support each training stage, we do many data engines for synthetic data</mark>

### Page 4

**Highlights**:

![Image (page 4)](statics/837393cb0dc6/tmp333kgvrw.png)

### Page 5

**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">• Math formulas. We crawl a large number of LATEX source .tex files on Arxiv and extract about 1Mformula fragments from them. Next, we transfer the formula sources to Mathpix format and usethe Chorme-driver to call Mathpix-markdown-it tool to render the sources to HTML format. Wethen convert the HTML files to SVGs and save them as PNG images. We find that this renderingmethod is more than 20× faster than directly using the LATEX.</mark>
![Image (page 5)](statics/837393cb0dc6/tmp_gol5grq.svg)