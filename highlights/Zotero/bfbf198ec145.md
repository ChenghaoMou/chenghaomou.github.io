---
title: "GSM-Symbolic Understanding the Limitations of Mathematical Reasoning in Large Language Models"
alias:
- "GSM-Symbolic Understanding the Limitations of Mathematical Reasoning in Large Language Models"
created: 2024-11-30 14:54:06:517500
updated: 2024-11-02 19:42:08:279000
modified: 2024-11-30 14:54:06:517506
authors: ['Iman Mirzadeh', 'Keivan Alizadeh', 'Hooman Shahrokhi', 'Oncel Tuzel', 'Samy Bengio', 'Mehrdad Farajtabar']
url: https://arxiv.org/abs/2410.05229v1
zotero_url: zotero://open-pdf/library/items/LC27CE4A
tags:
- reMarkable
---

# GSM-Symbolic Understanding the Limitations of Mathematical Reasoning in Large Language Models
[Open in Zotero](zotero://open-pdf/library/items/LC27CE4A)
## Abstract

Recent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has significantly improved in recent years, it remains unclear whether their mathematical reasoning capabilities have genuinely advanced, raising questions about the reliability of the reported metrics. To address these concerns, we conduct a large-scale study on several SOTA open and closed models. To overcome the limitations of existing evaluations, we introduce GSM-Symbolic, an improved benchmark created from symbolic templates that allow for the generation of a diverse set of questions. GSM-Symbolic enables more controllable evaluations, providing key insights and more reliable metrics for measuring the reasoning capabilities of models.Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. Furthermore, we investigate the fragility of mathematical reasoning in these models and show that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is because current LLMs cannot perform genuine logical reasoning; they replicate reasoning steps from their training data. Adding a single clause that seems relevant to the question causes significant performance drops (up to 65%) across all state-of-the-art models, even though the clause doesn't contribute to the reasoning chain needed for the final answer. Overall, our work offers a more nuanced understanding of LLMs' capabilities and limitations in mathematical reasoning.
## Pages
### Page 3
**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">Our work, however, suggests a more fundamental issue: LLMs struggle evenwhen given multiple shots of the same question, indicating deeper challenges in problem-solving thatcannot be resolved with few-shot prompting or fine-tuning on unseen distractions or variations ofthe same or different difficulty levels.</mark>
### Page 5
**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">However, performance drops more significantly when values are changed,with this trend continuing as both changes are applied simultaneously (Sec. 4.2). We then examinethe impact of question difficulty, as indicated by the number of clauses added to or removed fromthe questions. Our results show that as the number of clauses increases, average performance drops,and the variance in performance increases consistently across all models (Sec. 4.3).</mark>
<mark style="background-color: rgba(255, 237, 117, 255)">across different sets. For instance, for the Gemma2-9B, the gap between the worst performanceand the best performance is more than 12%, while for Phi-3.5-mini, this gap is around 15%. It isinteresting that this variation even exists, as the only differences across different instances of eachquestion are the changes in names and values, while the overall reasoning steps needed to solve aquestion remain the same.</mark>
### Page 7
**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">names compared to numbers. Notably, the original GSM8K accuracy of models is now much closerto the center of the changed proper names distribution, in contrast to changed numbers or both.Furthermore, a gradual shift in the means of distributions from right to left, along with an increase invariance, is evident across almost all models. It is both striking and concerning that such performancevariance exists when only changing proper names, as this level of variability would not be expectedfrom a grade-school student with genuine mathematical understanding.</mark>
### Page 8
**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">across all models: as the difficulty increases, the performance decreases and the variance increases.Note that overall, the rate of accuracy drop also increases as the difficulty increases. This is in linewith the hypothesis that models are not performing formal reasoning, as the number of requiredreasoning steps increases linearly, but the rate of drop seems to be faster. Moreover, considering thepattern-matching hypothesis, the increase in variance suggests that searching and pattern-matchingbecome significantly harder for models as the difficulty increases.</mark>
### Page 9
**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">additional failure cases from GSM-NoOp. Overall, we find that models tend to convert statements tooperations without truly understanding their meaning. For instance, a common case we observe isthat models interpret statements about “discount” as “multiplication”, regardless of the context. Thisraises the question of whether these models have truly understood the mathematical concepts wellenough. Consequently, as shown in Fig. 8a, there is a catastrophic performance decline across alltested models, with the Phi-3-mini model experiencing over a 65% drop, and even stronger modelssuch as o1-preview showing significant declines.</mark>
### Page 11
**Highlights**:

<mark style="background-color: rgba(255, 237, 117, 255)">mathematical reasoning. The high variance in LLM performance on different versions of the samequestion, their substantial drop in performance with a minor increase in difficulty, and their sensitivityto inconsequential information indicate that their reasoning is fragile. It may resemble sophisticatedpattern matching more than true logical reasoning. We remind the reader that both GSM8K andGSM-Symbolic include relatively simple grade-school math questions, requiring only basic arithmeticoperations at each step. Hence, the current limitations of these models are likely to be morepronounced in more challenging mathematical benchmarks.</mark>