---
title: "July 9"
created: 2024-07-09
modified: 2024-07-09
---
1. What is the biggest issue or challenge with the current ML platform right now?
2. **What are missing today if AWS already offers a lot of tools around model registry, deployment, and monitor?** **Inferentia**
	1. dev staging production
	2. knowledge base
	3. Datadog metrics uptime issue
	5. - LLM inference, AWS serverless lambda
3. What does the platform work start and where does it ends at Fresco?
	1. Model
	2. Data
4. What is the goal for the platform in the next five years?
	1. Establish workflow; Optimisation + challenges; Tooling;
	2. RAG: triton inference server;

- HM
- Fresco: KitchenOS siloed experience: Q: carplay/anroid auto;
- intelligence layer, assistant features or personalisation; adoptation; Cookable recommendation;
- MLE vs MLPE? Specialised SLM; Scalable million users; Overlap: MLE services, platform help on tooling and enablement;
- Amazon CDK: github actions; sagemaker

Streamline the process; Q: inference: vLLM paged attention; LLMs certain tools; speculative decoding and, 8B LLMs leverage both inferentia chip? Cost of instances;

DVC; AML Versioning; lineage; (configuration); feature stores;

- System Design;
- Coding Interview;
- Final Interview;