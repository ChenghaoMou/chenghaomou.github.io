---
title: "大模型"
created: 2024-06-17
modified: 2024-06-24
---

# 大模型

## 常用的模型微调方法

全量微调： 对模型的所有参数进行调整。

部分微调（高层微调，逐层微调，适配器）： 只有少部分参数得到更新，实际效果不如全量微调，但是训练速度快，效果不差。

P-Tuning：训练 LSTM 生成 soft prompts （编码器和解码器都适用）但是模型表现还是依赖下游的模型。

P-Tuning v2：用多任务学习目标学习 soft prompts。（编码器、NLU）

Prefix-Tuning： 直接使用任务的嵌入作为前缀每一层都有 MLP 来进行 reparameterization。（解码器）参数上比 P-Tuning 要多。

[[yuksekgonul_2024|TextGrad Automatic Differentiation via Text]]

低秩适配：假设模型在微调的时候，权重的更新是具有低内在秩，那么可以通过矩阵的低秩分解学习两个较小矩阵来拟合最终的权重。如果模型本身就具有解决任务的能力，那么提示调整更适合。LoRA 更适合新的任务。QLoRA 在 LoRA 的基础上进行模型参数量化。

RLHF

一般来讲，分为三个步骤：

1. 语言模型预训练
2. 奖励/偏好模型（通过生成排名来进行数据标注，避免打分造成的噪音），一般比第一步的语言模型小。
3. 强化学习微调（PPO）

## 常用的模型量化问题

- **线性量化**：适用于计算加速，将数值线性映射到低精度范围内
- **非线性量化**：适用于特征压缩，处理非均匀分布的数值，如正态分布或指数分布

## 常用的分布式部署；解决推理效率慢问题

1. 模型并行 (Model Parallelism): 将大模型拆分到多个 GPU 或多台服务器上,每个部分负责处理模型的一部分参数. 这种方法可以有效解决单个 GPU 显存不足的问题,适用于超大规模模型
2. 数据并行 (Data Parallelism): 在多个 GPU 或服务器上复制完整的模型,每个副本处理不同的数据批次. 这种方法可以提高训练和推理的吞吐量
3. 流水线并行 (Pipeline Parallelism): 将模型的不同层分配到不同的 GPU 或服务器上,数据以流水线的方式在各个部分之间传递. 这种方法可以平衡计算和通信开销
4. 张量并行 (Tensor Parallelism): 将单个张量计算分散到多个设备上,适用于处理超大矩阵运算
5. 混合并行 (Hybrid Parallelism): 结合上述多种并行策略,以最大化利用硬件资源并优化性能
6. 专家并行
7. 量化和压缩: 通过降低模型精度 (如 FP16、INT8) 或压缩模型参数来减少计算和存储需求,使得模型可以在更多设备上部署
8. 模型蒸馏: 训练小型模型来模仿大模型的行为,使得可以在资源受限的环境中部署

## 如何评估大模型的效果, 安全性

### 效果评估

1. 公开数据集评测：使用权威的公开数据集对模型进行评测，如 MMLU、TriviaQA、HellaSwag 等，这些数据集涵盖了知识、推理等多个能力维度;
2. 领域能力评估：将评测数据集按领域分类，评估模型在数学 GSM8K、知识、推理等不同领域的综合能力;
3. 自定义数据集评测：企业可以利用自身积累的私有领域数据构建评测集，更好地评估模型在特定场景下的表现;
4. 多模态能力评估：对于多模态大模型，需要评估其图文理解、跨模态推理等能力;

### 安全性评估

1. 安全分类体系：建立大模型安全分类体系，包括政治敏感、犯罪违法、身体健康、心理健康、财产隐私、歧视/偏见、辱骂/仇恨言论、伦理道德等方面;
2. Prompt 安全测试：评估模型对恶意或误导性 prompt 的抵御能力;
3. 内容安全测试：检查模型生成内容的安全性，避免产生有害、违法或不当信息;
4. 攻击测试：设计不同强度的攻击手法，测试模型的防御能力;
5. 隐私保护评估：检查模型是否会泄露训练数据中的隐私信息;
6. 多模态安全评估：对于多模态模型，需要特别关注图文结合可能带来的新型安全风险;

### 评估框架和标准

1. 构建完整的评估框架：如《生成式人工智能应用安全测试标准》，定义了人工智能应用程序架构每一层的测试和验证范围；《生成式人工智能服务安全基本要求》提出了提供者需遵循的安全基本要求，涉及语料安全、模型安全、安全措施、安全评估等方面；
2. 制定具体的测试方法：如《大语言模型安全测试方法》，提供了安全风险分类、攻击分类分级方法以及具体的测试方法；
3. 自动化测试工具：开发自动化测试工具，针对安全缺陷进行快速迭代和优化；
4. 持续评估和改进：安全评估应该是一个持续的过程，随着新的安全挑战出现，不断更新评估方法和标准；

## 幻觉的解决办法；解决大模型的可控可信度的问题

1. 检索增强生成 (Retrieval Augmented Generation, RAG): 这种方法将 LLM 与外部知识库相结合,在生成回答前先检索相关信息,从而提高回答的准确性。RAG 可以帮助模型重新建立与事实知识的联系,减少凭空捏造的可能性；
2. 人类反馈的强化学习 (Reinforcement Learning from Human Feedback): 通过人类评估者对模型输出进行审核和修正,不断优化模型性能。这种方法特别适用于需要高度准确性的场景,如客户支持或法律建议等领域；
3. 上下文注入和高级提示工程 (Context Injection & Advanced Prompt Engineering): 通过在提示中注入更多相关信息和上下文,帮助模型更好地理解任务并生成准确的回答。这种方法可以减少因缺乏背景信息而产生的幻觉；
4. 语义熵方法: 研究人员提出了基于熵的不确定性估计器,用于检测 LLM 中的一种特定幻觉类型——虚构。 这种方法在语义层面而非词序列层面计算不确定性,可以跨数据集和任务使用；SelfCheckGPT 的主要思想是：如果模型真的掌握某个事实，那么多次生成的结果应该是相似的且事实一致的；相反，如果模型在胡扯，那么随机采样多次的结果会发散甚至矛盾。
5. 降低温度参数: 通过调整模型的 " 温度 " 参数,可以使 LLM 生成更保守、更可预测的输出,从而减少幻觉的发生；

## 幻觉的测评数据集

- HaluEval
- TruthfulQA
- HalluQA

## 对比学习

给定一个锚定输入 $x$，我们选择一个正样本 $x^+$ 和一个负样本 $x^-$。三元组损失（Triplet Loss）通过以下公式学习：

$$
L_{\text{triplet}}(x, x^+, x^-) = \sum_x \text{max}(0, ||f(x) - f(x^+)||^2 - ||f(x) - f(x^-)||^2 + \epsilon)
$$

目标就是确保正样本之间的距离小于负样本之间的距离。

## 大模型检索问题

1. 缺失内容：当所需答案不在知识库中时，系统可能会提供看似合理但实际错误的答案，而不是直接表明无法回答。
2. 关键文档被遗漏：重要文档可能因排名不够高而未被检索到，导致系统无法提供准确反馈。
3. 信息提取困难：当面对信息过载时,系统难以准确提取所需答案,可能遗漏关键信息。
4. 格式错误：系统可能忽视指令要求的特定格式 (如表格或列表) 来提取信息。
5. 回答不完整：系统可能无法全面理解问题并作出完整回应。
6. 特定性不正确：系统可能无法根据具体情况提供适当详细程度的回答。
7. 安全性问题：如何防止恶意输入、确保输出安全、保护敏感信息不被泄露等。
8. 数据质量和规模的平衡：提高训练语料的知识结构化水平可以增强模型能力,但也会增加获取难度。
9. 结构化数据处理能力不足：在处理天然依赖结构化数据的任务方面,大模型表现仍有待提高。
10. 检索结果的排序和整合：如何对多个检索到的文档进行优先级排列,以及如何保持生成内容的风格和语调一致性。

## 常用的文本数据增强方法

1. 词汇编辑： 同义词替换， 随机插入、交换、删除；
2. 回译；
3. Dropout；

## 常用精度

float32 单精度浮点数：32 位

float16 半精度浮点数：16 位

bfloat 16： 减小精度，增加范围

int8、int4：通常用于模型推理

## 显存计算

1. 模型权重
2. 梯度：梯度与模型的参数维度相同
3. 优化器参数：带有动量的优化器需要保存一些信息，方便下降时的更新计算。比如 AdamW 需要为每个参数保存两个状态（每个参数占用 8 个字节，需要维护两个状态），所使用的显存就是模型权重的两倍。 采用经过 bitsandbytes 优化的 AdamW 优化器：每个参数占用 2 个字节，相当于权重的一半；
4. 数据和标签
5. 中间计算：激活函数的中间值
6. 缓冲区：比如隐码

以 Llama-2-7B-hf 为例：

1. 数据类型：全精度（32 位，4 bytes）
2. 模型参数：7B * 4 bytes = 28 GB
3. 梯度：28GB
4. 优化器参数：28 * 2 = 56 GB
5. 数据：（4096 + 11008） * 2048 * 32 * 4 ~ 4GB
6. 总共：112GB + 4GB * Batch size

半精度：

1. 数据类型：全精度（16 位，2bytes）
2. 模型参数：7B * 2 bytes = 14 GB
3. 梯度：14GB
4. 优化器参数 （FP32）：28 * （1 + 2） = 84 GB
5. 数据：（4096 + 11008） * 2048 * 32 * 4 ~ 4GB
6. 总共：112GB + 4GB * Batch size

如果只是推理的话：

1. 数据类型：全精度（32 位，4 bytes）
2. 模型参数：7B * 4 bytes = 28 GB
3. 总共：~28GB