---
aliases:
  - Machine Learning Compilers and Optimizers
  - "Machine Learning Compilers and Optimizers"
linter-yaml-title-alias: Machine Learning Compilers and Optimizers
order: -20210926153100
references: ["https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html"]
tags: [artificial_intelligence/deep_learning/compiler, artificial_intelligence/deep_learning/optimizer]
title: Machine Learning Compilers and Optimizers
---
# Machine Learning Compilers and Optimizers

Compilers and optimizers are very standard components in programming languages like C++ or C. To bring the same efficiency and optimization into the current deep learning community, various compilers and optimizers are invented to *lower* your code from *high-level framework code* into *low-level hardware-native code*.

## Compilers

^a1f1b9

Compilers translate framework code (PyTorch, TensorFlow or Jax) into difference levels of **intermediate representations** that can eventually be executed on various pieces of hardware. This process is often called lowering.

High-level Intermediate Representation: hardware-agnostic but framework-specific;
Low-level Intermediate Representation: framework-agnostic but hardware-specific;

Some examples of compilers are:

- [The LLVM Compiler Infrastructure Project](https://llvm.org)
- [XLA: Optimizing Compiler for Machine Learning  |  TensorFlow](https://www.tensorflow.org/xla)
- [CUDA LLVM Compiler | NVIDIA Developer](https://developer.nvidia.com/cuda-llvm-compiler)
- [MLIR](https://mlir.llvm.org)
- [Apache TVM](https://tvm.apache.org)
- [pytorch/glow: Compiler for Neural Network hardware accelerators](https://github.com/pytorch/glow)

## Optimizers

Optimizers optimize the code throughout the different levels of representations for performance.

## Advantages

Using compilers and optimizers, you can:

- Convert any high-level framework code into the same intermediate code, that can run anywhere;
- Optimize the model so that it can run on edge devices with more privacy, fast IO, high independence, and lower cloud cost;

## Caveats

- Models optimized for one platform does not always translate to other platforms;
- Optimizing a model can take a long time;
- New architectures will suffer from little support at the beginning;
