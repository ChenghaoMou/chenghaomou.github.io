---
aliases:
- PyTorch Tricks
created: '2021-12-25'
tags: []
title: PyTorch Tricks
---

# PyTorch Tricks

## Scheduler

Both following schedulers prove to be faster in convergence, with the cost of introduction of few extra hyper-parameters – minimum learning rate, maximum learning rate. [^1]
- [CyclicLR — PyTorch 1.10.1 documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CyclicLR.html#cycliclr) based on [@smith_2017](zotero://select/items/@smith_2017)
- [OneCycleLR — PyTorch 1.10.1 documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html)

## Dataloader

- Using multiple data workers to speed up loading the dataset, but be aware of the data duplicates:[^1]
	- For map-style dataset, data is retrieved with indices generated by sampler, so no duplication is created;
	- For iterable-style dataset, each worker should have specific handling according to its init function and parameters;
- `pin_memory` speeds up data transfer from memory to GPU memory. [^1]

## [Automatic Mixed Precision](https://pytorch.org/docs/stable/amp.html#gradient-scaling)

```python
import torch
# Creates once at the beginning of training
scaler = torch.cuda.amp.GradScaler()

for data, label in data_iter:
   optimizer.zero_grad()
   # Casts operations to mixed precision
   with torch.cuda.amp.autocast():
      loss = model(data)

   # Scales the loss, and calls backward()
   # to create scaled gradients
   scaler.scale(loss).backward()

   # Unscales gradients and calls
   # or skips optimizer.step()
   scaler.step(optimizer)

   # Updates the scale for next iteration
   scaler.update()
```

## [[20210926153100]] Machine Learning Compilers and Optimizers

- [AdamW — PyTorch 1.10.1 documentation](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)
- [Adam — PyTorch 1.10.1 documentation](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)

## [TorchScript](https://pytorch.org/docs/stable/jit.html#creating-torchscript-code)

***

[^1]: [https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide](https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide)