---
aliases:
  - Language Understanding, World Knowledge, and Scaling
  - "Language Understanding, World Knowledge, and Scaling"
linter-yaml-title-alias: Language Understanding, World Knowledge, and Scaling
order: -20220625181723
tags: [natural_language_processing]
title: Language Understanding, World Knowledge, and Scaling
---

# Language Understanding, World Knowledge, and Scaling

Highlights: [[Hendrycks et al_2021_Measuring Massive Multitask Language Understanding]]
Zotero link: [@hendrycks_2021b](zotero://select/items/@hendrycks_2021b)

It is shown that current SOTA large pre-trained language models come short of human performance on a diverse set of benchmarks that typically require years of expertise for human learners. Such benchmarks span across many domains such as legal, healthcare, STEM, and economics.

Some domains in this suite are highly contextualized, such as morality and laws. Though the authors did not include any ablations in regard to the diversity of such topics.

Knowing how text should be pieced together does not guarantee understanding of the language, not to mention the understanding of the world. Solving this benchmark, IMHO, does not mean the model has the human-level intelligence since we still have little knowledge on how they solve these problems in the first place. Even if their logic makes sense to us and its generation looks/sounds amazingly intelligent, it is in our interpretation that we are granting such “intelligence” to the model instead of them possessing it directly. It can be very useful and efficient, but lifeless nonetheless.

Before we can answer what intelligence means for ourselves — a metric we can measure and track — we cannot make any concrete claims about models having intelligence.

The authors also observed under-calibrated predictions from large models, which should not be a surprise at all. The task of modeling **probability** was never introduced to the model explicitly, the output being within the $[0, 1]$ interval is just the artifact of the activation functions, and we often use it as an approximation of probability just because it is easy to do so.