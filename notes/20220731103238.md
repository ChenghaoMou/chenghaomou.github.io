---
aliases:
  - Positional Embeddings
  - Positional Embeddings
tags:
  - artificial_intelligence/deep_learning/transformers
title: "Positional Embeddings"
---

# Positional Embeddings

Highlights: [[Natural Language Processing with Transformers]]

Positional Embeddings are representations of positions of a token in a sequence. There are several kinds of positional embeddings:

1. Learnable Positional Embeddings: normal learnable embeddings.
2. Absolute Positional Embeddings: static embeddings.
3. Relative Positional Embeddings: locality-focused embeddings, which can add additional positional information in an attention component.