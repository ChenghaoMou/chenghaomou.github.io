---
aliases:
- Quantization
- Quantization
created: '2022-07-31'
date: '2022-07-31'
modified: '2022-07-31'
tags: []
title: Quantization
---

# Quantization

Highlights: [[Natural Language Processing with Transformers]]

Quantization is a process of approximating full-precision models with less precision.

## Quantization-aware Training

`FP32` values are rounded during training (both forward and backward passes) to mimic quantization.

## Static Quantization

Using a **representative** example to learn a good quantization schema based on its activations. Such quantization is only done once and therefore much faster.

## Dynamic Quantization

During inference, the conversion from `FP32` to `INT8` is taking place on the fly but more optimized than [[#Static Quantization]]. The conversion could pose a bottleneck, though.