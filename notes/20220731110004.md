---
aliases:
  - Quantization
  - "Quantization"
linter-yaml-title-alias: Quantization
order: -20220731110004
tags: [artificial_intelligence/deep_learning/transformers]
title: Quantization
---

# Quantization

Highlights: [[Natural Language Processing with Transformers]]

Quantization is a process of approximating full-precision models with less precision.

## Quantization-aware Training

`FP32` values are rounded during training (both forward and backward passes) to mimic quantization.

## Static Quantization

Using a **representative** example to learn a good quantization schema based on its activations. Such quantization is only done once and therefore much faster.

## Dynamic Quantization

During inference, the conversion from `FP32` to `INT8` is taking place on the fly but more optimized than [[#Static Quantization]]. The conversion could pose a bottleneck, though.