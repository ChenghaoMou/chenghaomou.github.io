---
aliases:
  - Meaning and Referent
  - "Meaning and Reference"
linter-yaml-title-alias: Meaning and Referent
order: -20220814211819
tags: [natural_language_processing]
title: Meaning and Referent
---

# Meaning and Referent

Highlights: [[Piantadosi_Hill_2022_Meaning without reference in large language models]]

[Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data - ACL Anthology](https://aclanthology.org/2020.acl-main.463/) argues that [[20220814212300|Referents]] are important to understanding the meaning. But as [@piantadosi_2022](zotero://select/items/@piantadosi_2022) argues, it might not be the case.

Instead, they formulate that the **interrelation between conceptual roles — internal representational states** — is more crucial than referents. ^9abb87

But the question is: Can models learn such interrelation from text data with some objectives? The weak empirical answer from the paper suggests yes, based on the success from variety of tasks and benchmarks.

![[Piantadosi_Hill_2022_Meaning without reference in large language models#^0d78e5]]

I find it strange that the original paper [[Climbing towards NLU On Meaning Form and Understanding in the Age of Data]] clearly admits tasks like entailment do have some information related to meaning learnable beyond text. Yet, this paper seems to ignore that part.

Additionally, text can be considered as a low-dimension projection of the meaning, and it is possible to infer high-dimension information from low-dimension projections based on some studies in other domains. (This is actually mentioned at the end of [[Climbing towards NLU On Meaning Form and Understanding in the Age of Data#^862047]], did they read the paper at all?)