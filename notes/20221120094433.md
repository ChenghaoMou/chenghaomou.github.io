---
aliases:
- Cognitive Model
- Cognitive Model
created: '2022-11-20'
tags: []
title: Cognitive Model
---

# Cognitive Model

According to [[Three ideas from linguistics that everyone in AI should know]], a cognitive model is a __persisting but dynamic sense of the world__.

> As Brenden Lake and Greg Murphy have put it, that’s not enough, “Current models are too strongly linked to the text-based patterns in large corpora, and too weakly linked to the desires, goals, and beliefs that people express through words.”

Our brain does not have direct access to the world and is stimulated by the signals perceived by other organs. How different are those signals different from the signals those models get from text? One main difference I can see is that our perception is much more well-situated and grounded — we experience the signals in a much larger context than a sliding window on some text. This echoes one of the suggestions from [[bender_2020]]: train models with multi-modality data. How can we model desired "responses" even if we manage to compress what one person can perceive in real life?

Some also use the phrase world model — a mental model of the world[^1]. Such a model is constantly being updated by our daily interactions in a way that we can't fully understand yet. In such a model, our use of language is very different from the model's as well[^1].

It is shown that models can learn some aspects of the world, even though in a very narrow sense and in an artificial setting[^2]. Nonetheless, they are still proven useful in prediction and seemingly aligned with human understanding.

[^1]: [[Transcript- Ezra Klein Interviews Gary Marcus|Transcript: Ezra Klein Interviews Gary Marcus]]
[^2]: [[Large Language Model- world models or surface statistics-|Large Language Model: world models or surface statistics?]]