---
aliases:
  - Cognitive Model
  - "Cognitive Model"
linter-yaml-title-alias: Cognitive Model
order: -20221120094433
tags: 
title: Cognitive Model
---

# Cognitive Model

According to [[Three ideas from linguistics that everyone in AI should know]], a cognitive model is a __persisting but dynamic sense of the world__.

> As Brenden Lake and Greg Murphy have put it, that’s not enough, “Current models are too strongly linked to the text-based patterns in large corpora, and too weakly linked to the desires, goals, and beliefs that people express through words.”

Our brain does not have direct access to the world and is stimulated by the signals perceived by other organs. How different are those signals different from the signals those models get from text? One main difference I can see is that our perception is much more well-situated and grounded — we experience the signals in a much larger context than a sliding window on some text. This echos one of the suggestions from [[bender_2020]] which is to train models with multi-modality data. How can we model desired "responses" even if we manage to compress what one person can perceive in real life?

Some use the phrase world model as well — a mental model about the world[^1]. Such a model is constantly being updated by our daily interactions in a way that we can't fully understand yet. In such a model, our use of language is very different from the model's as well[^2].

It is shown that models can learn some aspects of the world, even though in a very narrow sense and an artificial setting[^3]. Nonetheless, they are still proven to be useful in terms of prediction and seemingly aligned with human understanding.

[^1]: [[Transcript Ezra Klein Interviews Gary Marcus#^614965]]
[^2]: [[Transcript Ezra Klein Interviews Gary Marcus#^90a064]]
[^3]: [[Large Language Model world models or surface statistics]]