---
aliases:
  - Situating Search
title: "Situating Search"
---

# Situating Search

Source: [[shah_2022|Situating Search]]

To understand what a search engine can or should provide, we need to understand what [[20221120131920|use-cases]] a person has when searching.

Search engine should:
- be trustworthy: provide verifiable and traceable results, leaving decisions (& responsibility) to the users;
- be helpful and supportive, not authoritative: help user make sense of retrieved information;
- be transparent: what is included and why is that, what it is capable of and whatnot, what harm it might cause or limitation it has;
- understand user intentions and scenarios and adapts accordingly and iteratively;
- evolving as the underlying data evolves[^1];

In some cases, a chatbot interface cannot bare such functionalities to fulfil user's search needs:
1. A typical search engine connects the user with content written by real people who care about the truth, while ChatGPT does not distinguish truth or lies, nor does it want you to leave[^2];
2. The existence of prompt engineering and prompt hacking is actually putting the burden on the user to ask the "right" question, while in reality, this is not we communicate at all[^3] [^4].
3. It also takes advantage of the human tendency to trust a conversation more than search results[^5], and the tendency of taking things at face value, or shall I say title value[^6]. It is a dangerous combination when the model is just generating [[20230115161911|Bullshit]].

[^1]: [[Why We Should Not Trust Chatbots As Sources of Information#^ad06eb]]
[^2]: [[Why ChatGPT Wonâ€™t Replace Google]]
[^3]: [[Natural language is the lazy user interface]]
[^4]: [[Prompt Engineering Shouldn't Exist]]
[^5]: [[AI chatbots are coming to search engines - can you trust the results-|AI chatbots are coming to search engines - can you trust the results?]]
[^6]: [[AI Search Engines And The Quest For Ignorance|AI Search Engines And The Quest For Ignorance]]