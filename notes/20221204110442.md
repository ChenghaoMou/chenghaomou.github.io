---
aliases:
- How to Build a Large Web Dataset
- How to Build a Large Web Dataset
created: '2022-12-04'
date: '2022-12-04'
modified: '2022-12-04'
tags: []
title: How to Build a Large Web Dataset
---

# How to Build a Large Web Dataset

## Source

Being able to access a search engine (not as a user, but as a owner) has huge advantage over using a crawler:
1. Search engines or search products have access to user feedbacks, though mostly indirect, about website quality, while cralwed dataset only has limited static link analysis([[overwijk_2022#^00fc66]], [[overwijk_2022#^3038d9]]).
2. Search services, especially international ones, also have access to wider variaty and coverage.
3. Websites often give special privilage to search engines but not crawlers.

## Quality

HTMLs can be a mess, complicated by the presence of CSS and Javascript. To fully assess a webpage's quality, [@overwijk_2022](zotero://select/items/@overwijk_2022) took the following steps:
1. Render the website using a headless browser.
2. Such rendering enables the combination of HTML DOM and visual features (vDOM).
3. Semantic annotation segments the webpage into different parts (Title, Primary Content, Paragraph, Table, List etc.) using a neural network([[overwijk_2022#^d38572]], [[overwijk_2022#^2bea7d]], [[overwijk_2022#^3d62d2]]).
4. Enhanced parsing allows the parser to ingest both vDOM and semantic structural information to derive the final clean content of the web page.