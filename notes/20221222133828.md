---
aliases:
  - Decomposing Embeddings
  - "Decomposing Embeddings"
linter-yaml-title-alias: Decomposing Embeddings
order: -20221222133828
tags: 
title: Decomposing Embeddings
---

# Decomposing Embeddings

Reference: [[opitz_2022]]

When using something like [SentenceTransformers](https://www.sbert.net/), you usually get one vector for the whole input. You don't really have a clue what it means when comparing two embeddings and the only result you get is a single number.

Authors in [[opitz_2022]] decomposes such embeddings into subspaces by utilizing [[20221219203111|Abstract Meaning Representation (AMR)]], so one could measure differences in various aspects of semantic similarity.

Some aspects included are:

- Frames: AMR graph similarity regarding PropBank predicates.
- Named entity: AMR graph similarity regarding named entities.
- Negation: AMR graph similarity based on expressions of negation.
- Concepts: AMR graph similarity based only on AMR node labels.
- Co-reference: AMR graph similarity based on co-referent structures.
- Semantic role labeling: AMR graph similarity based on predicate substructures.
- Unlabeled: AMR graph similarity without semantic edge labels.
- Quantifier: AMR graph similarity based on quantifier structures.

To summarize the training process:
1. Use an AMR parser to acquire AMR graphs for a pair of input.
2. Train a model to model different similarities from the AMR oracle similarities with decomposed embeddings (explainability), while minimizing the difference between the overall similarities with a frozen sentence transformer (consistency).

There is no need for an AMR parser during inference.