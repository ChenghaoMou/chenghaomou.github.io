---
aliases:
- Prompt Engineering
created: '2023-02-26'
date: '2023-02-26'
modified: '2023-02-26'
tags: []
title: Prompt Engineering
---

# Prompt Engineering

Prompts are text input that are often used to prime models to perform certain tasks. Prompt engineering describes the designing process of effective prompts. Malicious instructions are also frequently referred to as prompt hacking or prompt injection.

Whether [[Prompt Engineering Shouldn't Exist]] or not, there will always be people trying to circumvent content filters and rudimentary guardrails[^1] [^2] and they will likely succeed if they are built as an afterthought. Therefore, those hacks will coexist and co-evolve with those models if this is the direction we take, willingly or not.

[^1]: [[Meet ChatGPT’s evil twin, DAN|Meet ChatGPT’s evil twin, DAN]]
[^2]: [[Hackaday Newsletter 0x66|Security in Genearative AI]]