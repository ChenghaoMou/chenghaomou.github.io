---
aliases:
  - Anthropomorphizing AI
title: "Anthropomorphizing AI"
---

# Anthropomorphizing AI

Autoregressive generative models are getting better at producing fluent text every day. This might be helpful in some use cases, but their emotions are no more real[^1].

The chat interface and the human-like ability to wield language are taking advantage of our tendency to trust (a.k.a hidden exploitation)[^2]. To trust the model behind the interface, to trust the company behind the service, and to trust the decision-makers behind the curtains.

Making the generated text more humanlike has nothing to do with the search tasks. But we also don't know if this is caused by careful design or lack thereof ([[35084810|AI and Trust]]).

> Work on synthetic human behaviour is a bright line in ethical AI development, where downstream effects need to be understood and modelled in order to block foreseeable harm to society and different social groups.
> -- [@bender_2021](https://doi.org/10.1145/3442188.3445922)

I always wonder why most voice assistants haven't really picked up any "personality" over the decade. Maybe there are some lessons learned in that community that haven't been propagated to other areas, like how security is finding its way into LLM demos just now ([[20230226150428|Prompt Engineering]]). Or is this the other way around, that voice assistant has been stagnated for so long that only recent development can rekindle the dying industry?

We have yet to see the full impact of such systems on people and society at large[^3], but we know it will surely be huge[^4].

## Pros and Cons of Anthropomorphism

Source: [[On AI Anthropomorphism|On AI Anthropomorphism]]

Pros:
- Useful analogies and metaphors help us understand new and strange technologies. However, we should not take it as the answer to how they work[^5].
- AI has a social layer/presence whether we like it or not, and anthropomorphism can help us build a familiar interface.

Cons:
- It makes the ownership/responsibility unclear[^6] [^7], as well as blinds us from investigating the real mechanism of how those models work[^5].
- It is ineffective in terms of boosting human productivity yet.
- It is deceptive when humans are naturally inclined to trust humanlike or automated words [^8]. Not to mention such automation is often of less quality in comparison with human authors[^9].

Another pitfall similar to anthropomorphism is anthropocentric chauvinism — the human mind is the gold standard for all things psychological to be measured by[^5].

[^1]: [[Don’t Go Breaking My Heart|Don’t Go Breaking My Heart]]
[^2]: [[35084810|AI and Trust]]
[^3]: [[People keep anthropomorphizing AI. Here’s why|People keep anthropomorphizing AI. Here’s why]]
[^4]: [[On AI Anthropomorphism|On AI Anthropomorphism]]
[^5]: [[34772815|Why It’s Important to Remember That AI Isn’t Human]]
[^6]: [[The DAIR Institute|The DAIR Institute]]
[^7]: [[The new Bing is acting all weird and creepy - but the human response is way scarier|The new Bing is acting all weird and creepy - but the human response is way scarier]]
[^8]: [[The Luring Test- AI and the engineering of consumer trust]]
[^9]: [[20240204111406|Why Quora isn’t useful anymore: A.I. came for the best site on the internet.]]