---
aliases:
  - A Default No to Something New
created: 2023-07-25
date: '2023-07-25'
modified: 2024-04-21
tags: []
title: "A Default No to Something New"
---

# A Default No to Something New

Inspiration: [[Justine Bateman on AI, Labor, and the Future of Entertainment|Justine Bateman on AI, Labor, and the Future of Entertainment]]

![[20240410151638#^440ed777|How to Stop Your Data From Being Used to Train AI | WIRED]]

A license should defaults to saying no to something that is newly developed in the present that hasn't been included in the past when the contract/license was signed. Opt-in should be the assumed option, especially regarding to user data and user information[^1].

Things change, and we could never imagine what it is like in three years, let alone a decade. When platforms or companies acquire some licences, it should never be all-encompassing and future-proof. It should be assumed under the **current circumstances** *in the days to come*. Drastic technological changes do happen, and when it comes, right owners should have a chance to discuss what should be updated. This is the least amount of respect we should pay for human labour and human creativity.

Like anonymization worked maybe 10 years ago, but now de-identification works more efficiently enabled by powerful statistical models and big data, should our consent be withdrawl with such emergence of technology? If not, it is reasonable to believe that everyone who consented to share anonymised information now will be pretty much surfing the Internet naked in 10 years.

Even beyond formal agreements, we have to fight constantly with small consent traps such as marketing emails, mailing lists, TOS updates buried with legalese and sometimes outright spams[^2].

*But changes in the society are difficult and vague to measure. How to corporate such condition into a formal licence agreement?*

[^1]: [[20240228191849|The Tech Industry Doesn’t Understand Consent - Dhole Moments]]
[^2]: [[20240303180433|I'm going to keep opting out • Cory Dransfeldt]]