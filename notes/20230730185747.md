---
aliases:
- Oil Spill in Our Information Ecosystem
created: '2023-07-30'
date: '2023-07-30'
modified: '2023-07-30'
title: Oil Spill in Our Information Ecosystem
---

# Oil Spill in Our Information Ecosystem

A metaphor mentioned in [[“Ensuring Safe, Secure, and Trustworthy AI”- What those seven companies avoided committing to]], which actually is very similar in spirit to the dark forest metaphor used in [[The Expanding Dark Forest and Generative AI|The Expanding Dark Forest and Generative AI]].

The oil spill — the spread of misinformation or unreliable generation at a much larger scale thanks to popularised Generative AI — impacts the people who receive the information (e.g. [[36129681|The I in LLM Stands for Intelligence]], [[A Concerning Trend]]) and pollutes the ecosystem as a whole, making trust and authenticity increasingly harder to find and give.

Even worse, the information does not have to be wrong or made up — partial information or outdated information can be as effective in events like election[^2].

Moreover, the problem is compounded when such spills get picked up as the training data for the next iteration (a.k.a [[20230212190751|The Model Centipede]]). Case in point: [[34910990|Multifaceted: The Linguistic Echo Chambers of LLMs]]

Even more LLMs, we have enough SEO-engineered websites lurking in the search results, but now LLM-enabled or LLM-targeted spams will likely make it worse[^1].

[^1]: [[36715976|Google Search Really Has Gotten Worse, Researchers Find]]
[^2]: [[20240302192225|Seeking Reliable Election Information? Don’t Trust AI]]