---
aliases:
- Paperclip Maximizer
created: '2023-12-06'
title: Paperclip Maximizer
---

# Paperclip Maximizer

![[35084810#^6cc420|AI and Trust]]

Existential risks aside, the idea that models, no matter how innocuously designed, can cause harm to humans is on the spot.

It brings us to the idea that placing regulations on the models themselves is a misguided policy. As these models lack agency or any kind of affordance of responsibility (going on a trial or to jail), it is the humans — the model controllers — that should be regulated[^1].

[^1]: [[35084810|AI and Trust]]