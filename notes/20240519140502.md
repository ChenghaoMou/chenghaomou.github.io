---
aliases:
  - Evaluation Contamination
title: "Evaluation Contamination"
created: 2024-05-19
updated: 2024-05-19
modified: 2024-05-19
---

# Evaluation Contamination

The larger the training dataset becomes, the more likely it will contain some benchmark data, especially when we don't have a standard way of cataloging, identifying or filtering benchmarks.

Some measures can be taken to reduce the chance of contanmination[^1]:
1. **Encryption**. Benchmark dataset is encrypted and only decrpyted when using. This puts additional responsibility and constraints on the user because once the unencrypted version is leaked, it is no longer possible to reverse the tide.
2. **Filtering**. This is often done with exact substring matching, sometimes with fuzzy search or fingerprint detection.
3. **Avoid sending benchmark through an API**. If the benchmark is not yet realised, avoid sending it through some closed-source APIs as they could be used for model training.

## A Dynamic Evaluation with Compromised Data

[[20240513231925|The Evolving Landscape of LLM Evaluation]] proposed a dynamic and ever-changing test where all prior benchmarks should be considered compromised and all shortcuts will be taken.

[^1]: [[20240513231925|The Evolving Landscape of LLM Evaluation]]