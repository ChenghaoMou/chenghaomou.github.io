---
aliases:
  - Data Composition
title: "Data Composition"
created: 2024-06-21
updated: 2024-06-21
modified: 2024-06-21
---

# Data Composition

Source: [[li_2024a|DataComp-LM: In search of the next generation of training sets for language models]]

Generally, when we construct a dataset, we rely more on easy-to-compute proxy metrics for its quality or impact on the downsteam performance. Building models and testing model performance on top of the dataset is much more expensive.

DataComp provides a streamlined evaluation framework for data curation strategies by *unifying model training budget and model evaluation with fixed ranges to better test data quality*. For example, one could compare different text extraction methods, scaling property, filtering or deduplication efficay with all other parameters fixed. The baseline model trained with their default settings shows very competitive performance across different scales.