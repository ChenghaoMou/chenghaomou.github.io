---
aliases:
  - Mixture of Depth
title: "Mixture of Depth"
created: 2024-09-05
updated: 2024-09-05
modified: 2024-09-05
---

# Mixture of Depth

Source: [[raposo_2024|Mixture-of-Depths: Dynamically allocating compute in transformer-based language models]]

Another interesting implementation of [[20210926153300|Adaptive Computation]].

This time, the computation is selective:
1) on layers used in processing a token: One token can be processed (in attention or MLP) or residual connected to the next component (layer or block);
2) on how tokens are attended: Routers are used to route tokens into attention (maybe with decoupled query, key, and value weights) and skip connection, allowing more efficient computation compared with full attention.

Additionally, such routing can also be tuned with hardware limits where cost of computation can be controlled with the mount of tokens allowed to be processed;