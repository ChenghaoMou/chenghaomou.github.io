---
aliases:
  - Whisper
title: "Whisper"
created: 2024-10-13
updated: 2024-10-13
modified: 2024-11-26
---

# Whisper

Source: [[radford_2022a|Robust Speech Recognition via Large-Scale Weak Supervision]]

## Data

Data source has not been disclosed, only some references on how filtering was carried out: The main idea is to remove **machine-generated transcripts** (I wonder if they still do that after their first release claiming to be human-level accuracy, do they use their own transcribed text as part of the training data?) and **low-quality sources** by inspecting model predictions and data manually.

There is also one small part where they have to fine-tune the model to get rid of the behaviour of predicting speaker's name due to some noise in the data.

## Model

![[radford_2022a#^59b0fb|Robust Speech Recognition via Large-Scale Weak Supervision]]

The model is trained with 30-second segments, so it's not designed for real-time application where typically you would have ~100 milliseconds audio chunks streamed in.

## Evaluation

What's also talked about at length is evaluation â€” how suboptimal the existing evaluation metrics are and how unfair to compare human performance with a fine-tuned model. They also created their own version of text normalisation to discount spurious differences in the ground truth and the model predictions.

Additionally, they adopted a sliding window mechanism for transcribing long-form audio and some tweaks, thresholds, and heuristics for more reliable results.

Undoubtedly, Whisper has become the standard for speech recognition, at least in the anglosphere. Despite its claim of support of 99 languages, the inequality of the performance among languages is often less discussed about. Not to mention its troubled data source problems, the one people have been saying about OpenAI for the past few years[^1] [^2].

[^1]: [[OpenAI's Whisper is another case study in Colonisation|OpenAI's Whisper is another case study in Colonisation]]
[^2]: [[20230205135315|Data Sovereignty]]