---
aliases:
  - Adversarial Compression Ratio
title: "Adversarial Compression Ratio"
created: 2024-11-16
updated: 2024-11-16
modified: 2024-11-16
---

# Adversarial Compression Ratio

ACR is proposed in [[Rethinking LLM Memorization|Rethinking LLM Memorization]] to measure the strength of memorization. This is essentially a ratio between input and output tokens â€” if the model can recite a whole passage with a short cue/prompt ($ACR < 1$), then more likely it has memorized the content. Such completion is said to be compressed within the weights of the model based on the inequality of information presented.