<!DOCTYPE html>
<html lang="en"><head><title>Folder: 4archives/Literature-Notes/Readings</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=IBM Plex Sans:wght@400;700&amp;family=IBM Plex Sans:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Folder: 4archives/Literature-Notes/Readings"/><meta property="og:description" content="No description provided"/><meta property="og:image" content="https://sleeplessindebugging.blog/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../../../static/icon.png"/><meta name="description" content="No description provided"/><meta name="generator" content="Quartz"/><link href="../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="4archives/Literature-Notes/Readings/index"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../../..">Sleepless in Debugging</a></h2><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../4archives/">4archives</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../4archives/Literature-Notes/">Literature Notes</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../4archives/Literature-Notes/Readings/">Readings</a></div></nav><h1 class="article-title">Folder: 4archives/Literature-Notes/Readings</h1></div></div><div class="popover-hint"><article></article><div class="page-listing"><p>38 items under this folder.</p><div><ul class="section-ul"><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Video-Transformer-in-Transformer" class="internal">Video Transformer in Transformer</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/talk">talk</a></li><li><a class="internal tag-link" href="../../../tags/transformer">transformer</a></li><li><a class="internal tag-link" href="../../../tags/computer-vision">computer-vision</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Research-Two-sample-Hypothesis-Testing" class="internal">Research Two-sample Hypothesis Testing</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/data">data</a></li><li><a class="internal tag-link" href="../../../tags/statistics">statistics</a></li><li><a class="internal tag-link" href="../../../tags/hypothesis-testing">hypothesis-testing</a></li><li><a class="internal tag-link" href="../../../tags/machine-learning">machine-learning</a></li><li><a class="internal tag-link" href="../../../tags/distribution">distribution</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Spelling-Correction-with-Denoising-Transformer" class="internal">Spelling Correction with Denoising Transformer</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Switch-Transformers-Scaling-to-Trillion-Parameter-Models-with-Simple-and-Efficient-Sparsity" class="internal">Paper Switch Transformers Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Switch-Transformers" class="internal">Paper Switch Transformers</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Post-Embedding-Layer-might-not-be-Necessary-for-Your-Next-NLP-Project" class="internal">Post Embedding Layer might not be Necessary for Your Next NLP Project</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Language-Models-are-Few-Shot-Learners" class="internal">Second Pass</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Muppet-Massive-Multi-task-Representations-with-Pre-Finetuning" class="internal">Paper Muppet Massive Multi-task Representations with Pre-Finetuning</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Robust-Open-Vocabulary-Translation-from-Visual-Text-Representations" class="internal">Paper Robust Open-Vocabulary Translation from Visual Text Representations</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Shortformer-Better-Language-Modeling-using-Shorter-Inputs" class="internal">Second Pass</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Supervised-Contrastive-Learning-for-Pre-trained-Language-Model-Fine-tuning" class="internal">Paper Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/DIT-SELF-SUPERVISED-PRE-TRAINING-FOR-DOCUMENT-IMAGE-TRANSFORMER" class="internal">DIT SELF-SUPERVISED PRE-TRAINING FOR DOCUMENT IMAGE TRANSFORMER</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/document-understanding">document-understanding</a></li><li><a class="internal tag-link" href="../../../tags/transformer">transformer</a></li><li><a class="internal tag-link" href="../../../tags/document-image-pre-training">document-image-pre-training</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Gu-et-al_2021_UniDoc" class="internal">Gu et al_2021_UniDoc</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Learning-with-Signatures" class="internal">Learning with Signatures</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/paper-reading">paper-reading</a></li><li><a class="internal tag-link" href="../../../tags/signature-transform">signature-transform</a></li><li><a class="internal tag-link" href="../../../tags/few-shot-learning">few-shot-learning</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-A-Practical-Survey-on-Faster-and-Lighter-Transformers" class="internal">Paper A Practical Survey on Faster and Lighter Transformers</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation" class="internal">Paper CANINE Pre-training an Efficient Tokenization-Free Encoder for Language Representation</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Data2Vec" class="internal">Paper Data2Vec</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/Natural-Language-Processing">Natural-Language-Processing</a></li><li><a class="internal tag-link" href="../../../tags/Multi-modality">Multi-modality</a></li><li><a class="internal tag-link" href="../../../tags/Representation">Representation</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-DeBERTa-Decoding-enhanced-BERT-with-disentangled-attention" class="internal">Paper DeBERTa Decoding-enhanced BERT with disentangled attention</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Fastformer-Additive-Attention-Can-Be-All-You-Need" class="internal">Paper Fastformer Additive Attention Can Be All You Need</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Article-Reflections-on-my-(Machine-Learning)-PhD-Journey" class="internal">Article Reflections on my (Machine Learning) PhD Journey</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Article-Scikit-learn-Pitfalls" class="internal">Article Scikit-learn Pitfalls</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/machine-learning">machine-learning</a></li><li><a class="internal tag-link" href="../../../tags/pitfalls">pitfalls</a></li><li><a class="internal tag-link" href="../../../tags/scikit-learn">scikit-learn</a></li><li><a class="internal tag-link" href="../../../tags/programming">programming</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Article-Top-10-Open-Source-MLOps-Tools" class="internal">Article Top 10 Open Source MLOps Tools</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Book-Digital-Zettelkasten" class="internal">Book Digital Zettelkasten</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/productivity">productivity</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Book-How-to-Take-Smart-Notes" class="internal">Book How to Take Smart Notes</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE" class="internal">AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/paper-reading">paper-reading</a></li><li><a class="internal tag-link" href="../../../tags/computer-vision">computer-vision</a></li><li><a class="internal tag-link" href="../../../tags/transformer">transformer</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Article-Lessions-from-my-PhD" class="internal">Article Lessions from my PhD</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/academia">academia</a></li><li><a class="internal tag-link" href="../../../tags/career">career</a></li><li><a class="internal tag-link" href="../../../tags/study">study</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Mar 02, 2024</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Article-Redefining-SOTA" class="internal">Article Redefining SOTA</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">May 23, 2022</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/UNICORN-on-RAINBOW-A-Universal-Commonsense-Reasoning-Model-on-a-New-Multitask-Benchmark" class="internal">UNICORN on RAINBOW A Universal Commonsense Reasoning Model on a New Multitask Benchmark</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/paper-reading">paper-reading</a></li><li><a class="internal tag-link" href="../../../tags/natural-language-processing">natural-language-processing</a></li><li><a class="internal tag-link" href="../../../tags/commonsense-reasoning">commonsense-reasoning</a></li><li><a class="internal tag-link" href="../../../tags/benchmark">benchmark</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">May 11, 2022</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/UniDoc-Unified-Pretraining-Framework-for-Document-Understanding" class="internal">UniDoc Unified Pretraining Framework for Document Understanding</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/document-understanding">document-understanding</a></li><li><a class="internal tag-link" href="../../../tags/natural-language-processing">natural-language-processing</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">May 05, 2022</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Unified-Pretraining-Framework-for-Document-Understanding" class="internal">Unified Pretraining Framework for Document Understanding</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/document-understanding">document-understanding</a></li><li><a class="internal tag-link" href="../../../tags/language-modeling">language-modeling</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Feb 21, 2022</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Gradients-without-Backpropagation" class="internal">Gradients without Backpropagation</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/backpropagation">backpropagation</a></li><li><a class="internal tag-link" href="../../../tags/algorithms">algorithms</a></li><li><a class="internal tag-link" href="../../../tags/neural-networks">neural-networks</a></li><li><a class="internal tag-link" href="../../../tags/gradients">gradients</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Feb 20, 2022</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Research-Deduplication-in-Modern-Large-scale-LM-Datasets" class="internal">Deduplication in Modern Large-scale LM Datasets</a></h3></div><ul class="tags"></ul></div></li><li class="section-li"><div class="section"><p class="meta">Nov 19, 2021</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Book-Zettlekasten-Principles" class="internal">Book Zettlekasten Principles</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/productivity/zettelkasten">productivity/zettelkasten</a></li><li><a class="internal tag-link" href="../../../tags/note-taking">note-taking</a></li><li><a class="internal tag-link" href="../../../tags/productivity">productivity</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Nov 18, 2021</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Book-How-to-Write-a-Paper-with-ZettleKasten" class="internal">Book How to Write a Paper with ZettleKasten</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/writing">writing</a></li><li><a class="internal tag-link" href="../../../tags/note-taking">note-taking</a></li><li><a class="internal tag-link" href="../../../tags/productivity/zettelkasten">productivity/zettelkasten</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Nov 02, 2021</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-UNIPELT-A-Uniﬁed-Framework-for-Parameter-Efﬁcient-Language-Model-Tuning" class="internal">Paper UNIPELT A Uniﬁed Framework for Parameter-Efﬁcient Language Model Tuning</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/mixture-of-experts">mixture-of-experts</a></li><li><a class="internal tag-link" href="../../../tags/conditional-computation">conditional-computation</a></li><li><a class="internal tag-link" href="../../../tags/efficient-computation">efficient-computation</a></li><li><a class="internal tag-link" href="../../../tags/fine-tuning">fine-tuning</a></li><li><a class="internal tag-link" href="../../../tags/transformers">transformers</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Oct 17, 2021</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-Hidden-Techinical-Debt-in-Machine-Learning-Systems" class="internal">Annotation Summary of Sculley Et Al. - Hidden Technical Debt in Machine Learning Systems.pdf.</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/machine-learning">machine-learning</a></li><li><a class="internal tag-link" href="../../../tags/engineering">engineering</a></li><li><a class="internal tag-link" href="../../../tags/practice">practice</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Oct 11, 2021</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Paper-LayoutReader-Pre-training-of-Text-and-Layout-for-Reading-Order-Detection" class="internal">LayoutReader: Pre-training of Text and Layout for Reading Order Detection</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/document">document</a></li><li><a class="internal tag-link" href="../../../tags/layout">layout</a></li><li><a class="internal tag-link" href="../../../tags/natural-language-processing">natural-language-processing</a></li></ul></div></li><li class="section-li"><div class="section"><p class="meta">Sep 10, 2021</p><div class="desc"><h3><a href="../../../4archives/Literature-Notes/Readings/Random-Log-in-Python" class="internal">Random Log in Python</a></h3></div><ul class="tags"><li><a class="internal tag-link" href="../../../tags/python">python</a></li><li><a class="internal tag-link" href="../../../tags/programming">programming</a></li></ul></div></li></ul></div></div></div><hr/><div class="page-footer"></div></div><div class="right sidebar"></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.3.0</a> © 2024</p><ul><li><a href="https://codeberg.org/Chenghao2023/blog">CodeBerg</a></li><li><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></li></ul></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="../../../postscript.js" type="module"></script></html>