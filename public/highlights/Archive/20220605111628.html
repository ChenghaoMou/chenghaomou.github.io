<!DOCTYPE html>
<html lang="en"><head><title>Paragraph-based Transformer Pre-training for Multi-Sentence Inference</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=IBM Plex Sans:wght@400;700&amp;family=IBM Plex Sans:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Paragraph-based Transformer Pre-training for Multi-Sentence Inference"/><meta property="og:description" content="Paragraph-based Transformer Pre-training for Multi-Sentence Inference (6/5/2022, 11:16:28 AM) “Pre-trained transformers such as BERT are used for these tasks as cross-encoders ..."/><meta property="og:image" content="https://sleeplessindebugging.blog/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../../static/icon.png"/><meta name="description" content="Paragraph-based Transformer Pre-training for Multi-Sentence Inference (6/5/2022, 11:16:28 AM) “Pre-trained transformers such as BERT are used for these tasks as cross-encoders ..."/><meta name="generator" content="Quartz"/><link href="../../index.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="highlights/Archive/20220605111628"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="../..">Sleepless in Debugging</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../highlights/">highlights</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../highlights/Archive/">Archive</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Paragraph-based Transformer Pre-training for Multi-Sentence Inference</a></div></nav><h1 class="article-title">Paragraph-based Transformer Pre-training for Multi-Sentence Inference</h1><div show-comma="true" class="content-meta"><p><span class="tag-field">UPDATED</span> <span class="tag-value">Apr 13, 2024</span>  <span class="tag-field">READING TIME</span> <span class="tag-value">4 min(s)</span></p></div></div></div><article class="popover-hint"><h1 id="paragraph-based-transformer-pre-training-for-multi-sentence-inference">Paragraph-based Transformer Pre-training for Multi-Sentence Inference<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#paragraph-based-transformer-pre-training-for-multi-sentence-inference" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>(6/5/2022, 11:16:28 AM)</p>
<p>“Pre-trained transformers such as BERT are used for these tasks as cross-encoders by setting them as sentence-pair classification problems, i.e, aggregating inferences independently over each candidate.” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 1<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=1&amp;annotation=6UEG9SFW" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“Specifically, given a target sentence s and multiple sentences (from the same/different paragraph/document), the model needs to recognize which sentences belong to the same paragraph as s in the document used.” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 1<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=1&amp;annotation=JVQ36WUH" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“Multi-Sentence Inference: Inference over a set of multiple candidates” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 2<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=2&amp;annotation=CIEJU72X" class="external">pdf<span class="external-icon">⤴</span></a>) Multiple choices
Fact verification
Answer extraction</p>
<p>“DeCLUTR (Giorgi et al., 2021) uses a contrastive learning objective for cross-encoding two sentences coming from the same/different documents in a transformer.” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 2<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=2&amp;annotation=T2HA9SH8" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“Multi-sentence Inference Tasks AS2: We denote the question by q, and the set of answer candidates by C={c1,…cn}. The objective is to re-rank C and find the best answer A for q.” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 2<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=2&amp;annotation=CJ6LXJZM" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“Intuitively, modeling interrelated information between multiple ci’s can help in selecting the best answer candidate (Zhang et al., 2021).” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 2<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=2&amp;annotation=BBIIWXQV" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“Fact Verification: We denote the claim by F , and the set of evidences by C={c1 …cn} that are retrieved using DocIR. The objective is to predict whether F is supported/refuted/neither using C (at least one evidence ci is required for supporting/refuting F ).” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 2<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=2&amp;annotation=KKXXIQIS" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“We pad (or truncate) each sentence si to the same fixed length L (total input length L⇥(k + 1)), and use the embedding for the [CLS] / [SEP] token in front of each sentence si as its embedding (denoted by Ei).” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 3<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=3&amp;annotation=UNU6KHFB" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“IE1: a linear layer on the output embedding E0 of s0 (similar to BERT) referred to as the Individual Evidence (IE1)” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 3<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=3&amp;annotation=T5UQLBNU" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“AE1: a linear layer on the average of the output embeddings [E0,E1,…,Ek] to explicitly factor in information from all candidates, referred to as the Aggregated Evidence (AE1)” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 3<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=3&amp;annotation=BXEEM6L2" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“IEk: a shared linear layer applied to the output embedding Ei of each candidate si ,i2{1 …k} referred to as k-candidate Individual Evidence (IEk)” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 3<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=3&amp;annotation=6EYTQP8S" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“AEk: a shared linear layer applied to the concatenation of output embedding E0 of input s0 and the output embedding Ei of each candidate si ,i2{1 …k} referred to as kcandidate Aggregated Evidence (AEk)” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 3<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=3&amp;annotation=MENHXZ5T" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“we design a new pre-training task where the model is (i) provided with (k + 1) sentences {s0 …sk}, and (ii) tasked to predict which sentences from {s1 …sk} belong to the same paragraph P as s0 in the document D. We call this pre-training task Multi-Sentences in Paragraph Prediction (MSPP)” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 3<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=3&amp;annotation=6Q78EJ9V" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“We randomly sample a sentence from a paragraph P in a document D to be used as s0, and then (i) randomly sample k1 sentences (other than s0) from P as positives, (ii) randomly sample k2 sentences from paragraphs other than P in the same document D as hard negatives, and (iii) randomly sample k3 sentences from documents other than D as easy negatives” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 3<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=3&amp;annotation=DSVK2ATT" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“Student t-test with 95% confidence level” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 4<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=4&amp;annotation=DV38TZZ2" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<p>“The performance gap stems from questions for which the pairwise RoBERTa model was unable to rank the correct answer at the top position, but support from other candidates in the top-k helped the joint model rank it in the top position.” (<a href="zotero://select/library/items/C58NHYJJ" class="external">Di Liello et al., 2022, p. 5<span class="external-icon">⤴</span></a>) (<a href="zotero://open-pdf/library/items/ZWHBG8SX?page=5&amp;annotation=IAFJQSLU" class="external">pdf<span class="external-icon">⤴</span></a>)</p>
<hr/>
<ul>
<li>@diliello_2022</li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li>No backlinks found</li></ul></div></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.4</a> © 2024</p><ul><li><a href="https://codeberg.org/Chenghao2023/blog">CodeBerg</a></li><li><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></li></ul></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="../../postscript.js" type="module"></script></html>