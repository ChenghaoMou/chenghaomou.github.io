<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><style>:where(img){height:auto}</style><title>Calibration in Machine Learning</title><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=IBM Plex Sans Condensed:wght@400;700&amp;family=IBM Plex Sans Condensed:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"><meta name="viewport" content="width=device-width,initial-scale=1"><meta property="og:title" content="Calibration in Machine Learning"><meta property="og:description" content="Calibration in Machine Learning We often assume whatever we see after the Softmax layer can be interpreted as probability. This assumption can be alarmingly wrong if the model is under-calibrated."><meta property="og:image" content="https://sleeplessindebugging.blog/static/og-image.png"><meta property="og:width" content="1200"><meta property="og:height" content="675"><link rel="icon" href="../static/icon.png"><meta name="description" content="Calibration in Machine Learning We often assume whatever we see after the Softmax layer can be interpreted as probability. This assumption can be alarmingly wrong if the model is under-calibrated."><meta name="generator" content="Quartz"><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve=""><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve=""><script src="../prescript.js" type="application/javascript" spa-preserve=""></script><script type="application/javascript" spa-preserve="">const fetchData=fetch("../static/contentIndex.json").then(t=>t.json());
</script></head><body data-slug="notes/20211003180000"><div id="quartz-root" class="page"><div id="quartz-body"><div class="sidebar left"><h1 class="page-title"><a href="..">Sleepless in Debugging</a></h1><div class="mobile-only spacer"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../notes/">notes</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="">Calibration in Machine Learning</a></div></nav><h1 class="article-title">Calibration in Machine Learning</h1><p show-comma="true" class="content-meta"><span>Apr 13, 2024</span><span>3 min read</span></p></div></div><article class="popover-hint"><h1 id="calibration-in-machine-learning">Calibration in Machine Learning<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#calibration-in-machine-learning" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>We often assume whatever we see after the Softmax layer can be interpreted as probability. This assumption can be alarmingly wrong if the model is under-calibrated. Models, especially large neural networks, tend to overestimate the probabilities while being a good classifier/discriminator<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label" class="internal alias">1</a></sup> <sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label" class="internal alias">2</a></sup>. Simply put, a working decision boundary might not be the best boundary, and that’s where calibration comes into play.</p>
<p>Calibration ensures that the predicted probabilities and distribution are close to what is observed in the training data.</p>
<h2 id="calibration-curve">Calibration Curve<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#calibration-curve" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>The easiest way to help you understand if your model is well-calibrated or not is to plot the calibration curve. The idea is simple: out of all the examples that the model predicts having a “~70%” probability of being positive, ~70% should be true positives.</p>
<h3 id="how-to-draw-a-calibration-curve-chart">How to Draw a Calibration Curve Chart<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#how-to-draw-a-calibration-curve-chart" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ol>
<li>Given a binary label set <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.22222em">Y</span></span></span></span> and a prediction set with positive probabilities <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9202em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9202em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:.22222em">Y</span></span><span style="top:-3.6023em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">~</span></span></span></span></span></span></span></span></span></span></li>
<li>Sort the data based on the predicted probabilities in ascending order</li>
<li>Bucketize the data based on the probabilities</li>
<li>Calculate the fraction of positive examples in each bucket/bin</li>
</ol>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="chart" data-theme="github-light github-dark"><code data-language="chart" data-theme="github-light github-dark" style="display:grid"><span data-line=""><span>type: bar</span></span>
<span data-line=""><span>labels: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]</span></span>
<span data-line=""><span>series:</span></span>
<span data-line=""><span>  - title: Positive Percentage</span></span>
<span data-line=""><span>    data: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]</span></span>
<span data-line=""><span>tension: 0.2</span></span>
<span data-line=""><span>width: 58%</span></span>
<span data-line=""><span>labelColors: true</span></span>
<span data-line=""><span>fill: true</span></span>
<span data-line=""><span>beginAtZero: true</span></span></code></pre></figure>
<p>Above is a perfect calibrated model – for all examples predicted with around probability <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal">x</span></span></span></span>, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal">x</span></span></span></span> of them are actual positives.</p>
<h2 id="mis-calibration">Mis-calibration<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#mis-calibration" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p><img src="https://miro.medium.com/max/2000/1*862Gd5xzAt2fvp6o2hwuRg.png" alt="" fetchpriority="high" decoding="async">
source <sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label" class="internal alias">3</a></sup></p>
<ul>
<li><strong>Systematic Overestimation</strong>: This happens when you have fewer positive examples.</li>
<li><strong>Systematic Underestimation</strong>: This happens when you have fewer negative examples.</li>
<li><strong>Center of the dist. is too heavy</strong>: This happens when “algorithms such as support vector machines and boosted trees tend to push predicted probabilities away from 0 and 1”<sup><a href="#user-content-fn-1" id="user-content-fnref-1-2" data-footnote-ref="" aria-describedby="footnote-label" class="internal alias">1</a></sup></li>
<li><strong>Tails of the dist. are too heavy</strong>: This happens when “Other methods such as Naive Bayes have the opposite bias and tend to push predictions closer to 0 and 1”<sup><a href="#user-content-fn-2" id="user-content-fnref-2-2" data-footnote-ref="" aria-describedby="footnote-label" class="internal alias">2</a></sup></li>
</ul>
<h2 id="how-to-calibrate">How to Calibrate<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#how-to-calibrate" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>Isotonic Regression on dev set: A non-parametric algorithm that fits a non-decreasing free-form line to the data. <strong>The fact that the line is non-decreasing is fundamental because it respects the original sorting.</strong></li>
<li>Logistic Regression on the dev set</li>
</ul>
<h2 id="expected-calibration-error">Expected Calibration Error<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#expected-calibration-error" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="python" data-theme="github-light github-dark"><code data-language="python" data-theme="github-light github-dark" style="display:grid"><span data-line=""><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">def</span><span style="--shiki-light:#6f42c1;--shiki-dark:#b392f0"> expected_calibration_error</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">(y, proba, bins </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#032f62;--shiki-dark:#9ecbff"> 'fd'</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">):</span></span>
<span data-line=""><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">	import</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> numpy </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">as</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	bin_count, bin_edges </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.histogram(proba, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">bins</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> bins)</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	n_bins </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff"> len</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">(bin_count)</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	bin_edges[</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff">0</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">] </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">-=</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff"> 1e-8</span><span style="--shiki-light:#b31d28;--shiki-dark:#fdaeb7;--shiki-light-font-style:italic;--shiki-dark-font-style:italic"> `</span><span style="--shiki-light:#6a737d;--shiki-dark:#6a737d;--shiki-light-font-style:italic;--shiki-dark-font-style:italic">#` because left edge is not included</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	bin_id </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.digitize(proba, bin_edges, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">right</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff"> True</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">) </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">-</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff"> 1</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	bin_ysum </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.bincount(bin_id, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">weights</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> y, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">minlength</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> n_bins)</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	bin_probasum </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.bincount(bin_id, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">weights</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> proba, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">minlength</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> n_bins)</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	bin_ymean </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.divide(bin_ysum, bin_count, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">out</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.zeros(n_bins), </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">where</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> bin_count </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">&gt;</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff"> 0</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">)</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	bin_probamean </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.divide(bin_probasum, bin_count, </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">out</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.zeros(n_bins), </span><span style="--shiki-light:#e36209;--shiki-dark:#ffab70">where</span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583"> =</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> bin_count </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">&gt;</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff"> 0</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">)</span></span>
<span data-line=""><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">	ece </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">=</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> np.abs((bin_probamean </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">-</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> bin_ymean) </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">*</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> bin_count).sum() </span><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">/</span><span style="--shiki-light:#005cc5;--shiki-dark:#79b8ff"> len</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8">(proba)</span></span>
<span data-line=""><span style="--shiki-light:#d73a49;--shiki-dark:#f97583">	return</span><span style="--shiki-light:#24292e;--shiki-dark:#e1e4e8"> ece</span></span></code></pre></figure>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#footnote-label" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ol>
<li id="user-content-fn-1">
<p><a href="https://www.researchgate.net/publication/221344679_Predicting_good_probabilities_with_supervised_learning" class="external">(PDF) Predicting good probabilities with supervised learning<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1" class="internal alias data-footnote-backref">↩</a> <a href="#user-content-fnref-1-2" data-footnote-backref="" aria-label="Back to reference 1-2" class="internal data-footnote-backref">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-2">
<p><a href="https://arxiv.org/abs/1706.04599" class="external">[1706.04599] On Calibration of Modern Neural Networks<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2" class="internal alias data-footnote-backref">↩</a> <a href="#user-content-fnref-2-2" data-footnote-backref="" aria-label="Back to reference 2-2" class="internal data-footnote-backref">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-3">
<p><a href="https://towardsdatascience.com/pythons-predict-proba-doesn-t-actually-predict-probabilities-and-how-to-fix-it-f582c21d63fc" class="external">Python’s «predict_proba» Doesn’t Actually Predict Probabilities (and How to Fix It) | by Samuele Mazzanti | Towards Data Science<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3" class="internal alias data-footnote-backref">↩</a></p>
</li>
</ol>
</section></article></div><div class="sidebar right"><div class="desktop-only toc"><button type="button" id="toc" class=""><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#calibration-in-machine-learning" data-for="calibration-in-machine-learning">Calibration in Machine Learning</a></li><li class="depth-1"><a href="#calibration-curve" data-for="calibration-curve">Calibration Curve</a></li><li class="depth-2"><a href="#how-to-draw-a-calibration-curve-chart" data-for="how-to-draw-a-calibration-curve-chart">How to Draw a Calibration Curve Chart</a></li><li class="depth-1"><a href="#mis-calibration" data-for="mis-calibration">Mis-calibration</a></li><li class="depth-1"><a href="#how-to-calibrate" data-for="how-to-calibrate">How to Calibrate</a></li><li class="depth-1"><a href="#expected-calibration-error" data-for="expected-calibration-error">Expected Calibration Error</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../notes/20220611204059" class="internal">Calibration Evaluation</a></li><li><a href="../notes/20221023141204" class="internal">Conformal Prediction</a></li></ul></div></div></div><footer class=""><hr><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.3</a> © 2024</p><ul><li><a href="https://codeberg.org/Chenghao2023/blog">CodeBerg</a></li><li><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></li></ul></footer></div><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">let mermaidImport;document.addEventListener("nav",async()=>{if(document.querySelector("code.mermaid")){mermaidImport||=await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs");const e=mermaidImport.default,t=document.documentElement.getAttribute("saved-theme")==="dark";e.initialize({startOnLoad:!1,securityLevel:"loose",theme:t?"dark":"default"}),await e.run({querySelector:".mermaid"})}});
</script><script src="../postscript.js" type="module"></script></body></html>