<!DOCTYPE html>
<html lang="en"><head><title>Large-scale Near-deduplication Behind BigCode</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=IBM Plex Sans Condensed:wght@400;700&amp;family=IBM Plex Sans Condensed:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Large-scale Near-deduplication Behind BigCode"/><meta property="og:description" content="Large-scale Near-deduplication Behind BigCode Intended Audience People who are interested in document-level near-deduplication at a large scale, and have some understanding ..."/><meta property="og:image" content="https://sleeplessindebugging.blog/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="Large-scale Near-deduplication Behind BigCode Intended Audience People who are interested in document-level near-deduplication at a large scale, and have some understanding ..."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="posts/20230220150602"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">Sleepless in Debugging</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../posts/">posts</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Large-scale Near-deduplication Behind BigCode</a></div></nav><h1 class="article-title">Large-scale Near-deduplication Behind BigCode</h1><p show-comma="true" class="content-meta"><span>Jun 30, 2024</span><span>16 min read</span></p></div></div><article class="popover-hint"><h1 id="large-scale-near-deduplication-behind-bigcode">Large-scale Near-deduplication Behind BigCode<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#large-scale-near-deduplication-behind-bigcode" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p><img src="../statics/CleanShot-2023-03-18-at-19.27.07.png" width="900" height="auto" alt="center "/></p>
<h2 id="intended-audience">Intended Audience<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#intended-audience" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>People who are interested in document-level near-deduplication at a large scale, and have some understanding of hashing, graph and text processing.</p>
<h2 id="motivations">Motivations<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#motivations" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>It is important to take care of our data before feeding it to the model, as the old saying goes, garbage in, garbage out. Even though it’s increasingly difficult to do so with headline-grabbing models (or should I say APIs) creating an illusion that data quality matters less.</p>
<p>One of the problems we face in both BigScience and BigCode for data quality is duplication, including possible benchmark contamination. It has been shown that models tend to output training data verbatim when there are many duplicates<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref aria-describedby="footnote-label" class="internal alias">1</a></sup> (though it is less clear in some other cases<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">2</a></sup>), and it also makes the model vulnerable to privacy attacks<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">3</a></sup>. Additionally, some typical advantages of deduplication also include:</p>
<ol>
<li>Efficient training: You can achieve the same performance with less training steps<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup> <sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup>.</li>
<li>Prevent possible data leakage and benchmark contamination: Non-zero duplicates discredit your evaluations and potentially make so-called improvement a false claim.</li>
<li>Accessibility. Most of us cannot afford to download or transfer thousands of gigabytes of text repeatedly, not to mention training a model with it. Deduplication, for a fix-sized dataset, makes it easier to study, transfer and collaborate with.</li>
</ol>
<h2 id="from-bigscience-to-bigcode">From BigScience to BigCode<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#from-bigscience-to-bigcode" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Allow me to share a story first on how I jumped on this near-deduplication quest, how the results have progressed, and what lessons I have learned along the way.</p>
<p>It all started with a conversation on LinkedIn when BigScience had already started for a couple of months. Huu Nguyen approached me when he noticed my pet project on GitHub, asking me if I were interested in working on deduplication for BigScience. Of course, my answer was a yes, completely ignorant of just how much effort will be required alone due to the sheer mount of the data.</p>
<p>It was fun and challenging at the same time. It is challenging in a sense that I didn’t really have much research experience with that sheer scale of data, and everyone was still welcoming and trusting you with thousands of dollars of cloud compute budget. Yes, I had to wake up from my sleep to double-check that I had turned off those machines several times. As a result, I had to learn on the job through all the trials and errors, which in the end opened me to a new perspective that I don’t think I would ever have if it weren’t BigScience.</p>
<p>Moving forward, one year later, I am putting what I have learned back into BigCode, working on even bigger datasets. In addition to LLMs that are trained for English<sup><a href="#user-content-fn-4" id="user-content-fnref-4-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup>, we have confirmed that deduplication improves code models too<sup><a href="#user-content-fn-5" id="user-content-fnref-5-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup>, while using a much smaller dataset. And now, I am sharing what I have learned with you, my dear reader, and hopefully, you can also get a sense of what is happening behind the scene of BigCode through the lens of deduplication.</p>
<p>In case you are interested, here is an updated version of the deduplication comparison that I started in BigScience:</p>



















































































































<div class="table-container"><table><thead><tr><th>Dataset</th><th>Input Size</th><th>Output Size or Deduction</th><th>Level</th><th>Method</th><th>Parameters</th><th>Language</th><th>Time</th></tr></thead><tbody><tr><td>OpenWebText2<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref aria-describedby="footnote-label" class="internal alias">6</a></sup></td><td>After URL dedup: 193.89 GB (69M)</td><td>After MinHashLSH: 65.86 GB (17M)</td><td>URL + Document</td><td>URL(Exact) + Document(MinHash LSH)</td><td><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">10</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?)</span></span></span></span></td><td>English</td><td></td></tr><tr><td>Pile-CC<sup><a href="#user-content-fn-6" id="user-content-fnref-6-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">6</a></sup></td><td><em>~306 GB</em></td><td><em>227.12 GiB (~55M)</em></td><td>Document</td><td>Document(MinHash LSH)</td><td><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">10</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?)</span></span></span></span></td><td>English</td><td>”several days”</td></tr><tr><td>BNE5<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref aria-describedby="footnote-label" class="internal alias">7</a></sup></td><td>2TB</td><td>570 GB</td><td>Document</td><td>Onion</td><td>5-gram</td><td>Spanish</td><td></td></tr><tr><td>MassiveText<sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref aria-describedby="footnote-label" class="internal alias">8</a></sup></td><td></td><td>0.001 TB ~ 2.1 TB</td><td>Document</td><td>Document(Exact + MinHash LSH)</td><td><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mclose">?</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.8</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">13</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">?)</span></span></span></span></td><td>English</td><td></td></tr><tr><td>CC100-XL<sup><a href="#user-content-fn-9" id="user-content-fnref-9" data-footnote-ref aria-describedby="footnote-label" class="internal alias">9</a></sup></td><td></td><td>0.01 GiB ~ 3324.45 GiB</td><td>URL + Paragraph</td><td>URL(Exact) + Paragraph(Exact)</td><td>SHA-1</td><td>Multilingual</td><td></td></tr><tr><td>C4<sup><a href="#user-content-fn-4" id="user-content-fnref-4-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup></td><td>806.92 GB (364M)</td><td>3.04% ~ 7.18% <strong>↓</strong> (train)</td><td>Substring or Document</td><td>Substring(Suffix Array) or Document(MinHash)</td><td>Suffix Array: 50-token, MinHash: <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">9000</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.8</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">20</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">450</span><span class="mclose">)</span></span></span></span></td><td>English</td><td></td></tr><tr><td>Real News<sup><a href="#user-content-fn-4" id="user-content-fnref-4-4" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup></td><td>~120 GiB</td><td>13.63% ~ 19.4% <strong>↓</strong> (train)</td><td>Same as <strong>C4</strong></td><td>Same as <strong>C4</strong></td><td>Same as <strong>C4</strong></td><td>English</td><td></td></tr><tr><td>LM1B<sup><a href="#user-content-fn-4" id="user-content-fnref-4-5" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup></td><td>~4.40 GiB (30M)</td><td>0.76% ~ 4.86% <strong>↓</strong> (train)</td><td>Same as <strong>C4</strong></td><td>Same as <strong>C4</strong></td><td>Same as <strong>C4</strong></td><td>English</td><td></td></tr><tr><td>WIKI40B<sup><a href="#user-content-fn-4" id="user-content-fnref-4-6" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup></td><td>~2.9M</td><td>0.39% ~ 2.76% <strong>↓</strong> (train)</td><td>Same as <strong>C4</strong></td><td>Same as <strong>C4</strong></td><td>Same as <strong>C4</strong></td><td>English</td><td></td></tr><tr><td>The BigScience ROOTS Corpus<sup><a href="#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref aria-describedby="footnote-label" class="internal alias">10</a></sup></td><td></td><td>0.07% ~ 2.7% <strong>↓</strong> (document) + 10.61%~32.30% <strong>↓</strong> (substring)</td><td>Document + Substring</td><td>Document (SimHash) + Substring (Suffix Array)</td><td>SimHash: 6-grams, hamming distance of 4, Suffix Array: 50-token</td><td>Multilingual</td><td>12 hours ~ few days</td></tr></tbody></table></div>
<p>This is the one for code datasets I created for BigCode as well. Model names are used when the dataset name isn’t available.</p>





















































<div class="table-container"><table><thead><tr><th>Model</th><th>Method</th><th>Parameters</th><th>Level</th></tr></thead><tbody><tr><td>InCoder<sup><a href="#user-content-fn-11" id="user-content-fnref-11" data-footnote-ref aria-describedby="footnote-label" class="internal alias">11</a></sup></td><td>Exact</td><td>Alphanumeric tokens/md5 + Bloom filter</td><td>Document</td></tr><tr><td>CodeGen<sup><a href="#user-content-fn-12" id="user-content-fnref-12" data-footnote-ref aria-describedby="footnote-label" class="internal alias">12</a></sup></td><td>Exact</td><td>SHA256</td><td>Document</td></tr><tr><td>AlphaCode<sup><a href="#user-content-fn-13" id="user-content-fnref-13" data-footnote-ref aria-describedby="footnote-label" class="internal alias">13</a></sup></td><td>Exact</td><td>ignore whiespaces</td><td>Document</td></tr><tr><td>PolyCode<sup><a href="#user-content-fn-14" id="user-content-fnref-14" data-footnote-ref aria-describedby="footnote-label" class="internal alias">14</a></sup></td><td>Exact</td><td>SHA256</td><td>Document</td></tr><tr><td>PaLM Coder<sup><a href="#user-content-fn-15" id="user-content-fnref-15" data-footnote-ref aria-describedby="footnote-label" class="internal alias">15</a></sup></td><td>Levenshtein distance</td><td></td><td>Document</td></tr><tr><td>CodeParrot<sup><a href="#user-content-fn-16" id="user-content-fnref-16" data-footnote-ref aria-describedby="footnote-label" class="internal alias">16</a></sup></td><td>MinHash + LSH</td><td><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">256</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.8</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></td><td>Document</td></tr><tr><td>The Stack<sup><a href="#user-content-fn-17" id="user-content-fnref-17" data-footnote-ref aria-describedby="footnote-label" class="internal alias">17</a></sup></td><td>MinHash + LSH</td><td><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">256</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.7</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></td><td>Document</td></tr></tbody></table></div>
<p>MinHash + LSH parameters <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mclose">)</span></span></span></span>:</p>
<ol>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> number of permutations/hashes</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> Jaccard similarity threshold</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> n-gram/shingle size</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> number of bands</li>
<li><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> number of rows</li>
</ol>
<p>To get a sense of how those parameters might impact your results, here is a simple demo to illustrate the computation mathematically: <a href="https://huggingface.co/spaces/bigcode/near-deduplication" class="external">MinHash Math Demo<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.</p>
<h2 id="minhash-walkthrough">MinHash Walkthrough<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#minhash-walkthrough" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>In this section, we will cover each step of MinHash, the one used in BigCode, and potential scaling issues and solutions. We will demonstrate the workflow via one example of three documents in English:</p>





















<div class="table-container"><table><thead><tr><th>doc_id</th><th>content</th></tr></thead><tbody><tr><td>0</td><td>Deduplication is so much fun!</td></tr><tr><td>1</td><td>Deduplication is so much fun and easy!</td></tr><tr><td>2</td><td>I wish spider dog<sup><a href="#user-content-fn-18" id="user-content-fnref-18" data-footnote-ref aria-describedby="footnote-label" class="internal alias">18</a></sup> is a thing.</td></tr></tbody></table></div>
<h3 id="shingles">Shingles<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#shingles" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Like in most applications involving text, we need to begin with tokenization. N-grams, a.k.a. shingles, are often used. In our example, we will be using word-level tri-grams, without any punctuations. We will circle back to how the size of ngrams impacts the performance in a later section.</p>





















<div class="table-container"><table><thead><tr><th>doc_id</th><th>shingles</th></tr></thead><tbody><tr><td>0</td><td>{“Deduplication is so”, “is so much”, “so much fun”}</td></tr><tr><td>1</td><td>{‘so much fun’, ‘fun and easy’, ‘Deduplication is so’, ‘is so much’}</td></tr><tr><td>2</td><td>{‘dog is a’, ‘is a thing’, ‘wish spider dog’, ‘spider dog is’, ‘I wish spider’}</td></tr></tbody></table></div>
<p>This operation has a time complexity of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">NM</span><span class="mclose">)</span></span></span></span> where <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> is the number of documents and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is the length of the document. This step can be easily scaled by parallelization by multiprocessing or distributed computation.</p>
<h3 id="fingerprint-computation">Fingerprint Computation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#fingerprint-computation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>In MinHash, each shingle will typically either be 1) hashed multiple times, or 2) permuted multiple times using one hash. Here, we choose to permute each hash 5 times.</p>





















<div class="table-container"><table><thead><tr><th>shingle</th><th>permuted hashes</th></tr></thead><tbody><tr><td>Deduplication is so</td><td>[403996643, 2764117407, 3550129378, 3548765886, 2353686061]</td></tr><tr><td>is so much</td><td>[3594692244, 3595617149, 1564558780, 2888962350, 432993166]</td></tr><tr><td>so much fun</td><td>[1556191985, 840529008, 1008110251, 3095214118, 3194813501]</td></tr></tbody></table></div>
<p>Taking the minimum value of each column within each document, we arrive at the final MinHash for this document:</p>





















<div class="table-container"><table><thead><tr><th>doc_id</th><th>minhash</th></tr></thead><tbody><tr><td>0</td><td>[403996643, 840529008, 1008110251, 2888962350, 432993166]</td></tr><tr><td>1</td><td>[403996643, 840529008, 1008110251, 1998729813, 432993166]</td></tr><tr><td>2</td><td>[166417565, 213933364, 1129612544, 1419614622, 1370935710]</td></tr></tbody></table></div>
<p>In implementation, you can easily vectorize these steps with <code>numpy</code> and expect to have a time complexity of <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">NM</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">)</span></span></span></span> where <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> is your number of permutations. Code modified based on <a href="https://github.com/ekzhu/datasketch" class="external">Datasketch<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="python" data-theme="github-light github-dark"><code data-language="python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> embed_func</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    content: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    idx: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    num_perm: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ngram_size: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    hashranges: List[Tuple[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]],</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    permutations: np.ndarray,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -> Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any]:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    a, b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> permutations</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    masks: np.ndarray </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.full(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">shape</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">num_perm, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">np.uint64, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">fill_value</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MAX_HASH</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tokens: Set[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot; &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.join(t) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> t </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ngrams(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">NON_ALPHA</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.split(content), ngram_size)}</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    hashvalues: np.ndarray </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([sha1_hash(token.encode(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;utf-8&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> token </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tokens], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dtype</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">np.uint64)</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    permuted_hashvalues </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.bitwise_and(</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        ((hashvalues </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.tile(a, (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(hashvalues), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)).T).T </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> b) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">%</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> MERSENNE_PRIME</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MAX_HASH</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    hashvalues </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.vstack([permuted_hashvalues, masks]).min(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Hs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bytes</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(hashvalues[start:end].byteswap().data) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> start, end </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> hashranges]</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;__signatures__&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Hs, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;__id__&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: idx}</span></span></code></pre></figure>
<p>If you are familiar with <a href="https://github.com/ekzhu/datasketch" class="external">Datasketch<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, you might ask, why do we bother to strip all the nice high-level functions the library provides? It is not because we want to avoid adding dependencies, but because we intend to squeeze as much CPU computation as possible during parallelization. Fusing few steps into one function call enables us to utilize our compute resources better.</p>
<p>Since one document’s calculation is not dependent on anything else. A good parallelizatin choice would be using the <code>map</code> function from the <code>datasets</code> library:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="python" data-theme="github-light github-dark"><code data-language="python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embedded </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ds.map(</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">	function</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">embed_func,</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">	fn_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;num_perm&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: args.num_perm,</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;hashranges&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">HASH_RANGES</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;ngram_size&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: args.ngram,</span></span>
<span data-line><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">		&quot;permutations&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">PERMUTATIONS</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	},</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">	input_columns</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[args.column],</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">	remove_columns</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">ds.column_names,</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">	num_proc</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">os.cpu_count(),</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">	with_indices</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">	desc</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Fingerprinting...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></figure>
<p>After the fingerprint calculation, one particular document is mapped to one array of integer values. To figure out what documents are similar to each other, we need to group them based on such fingerprints. Entering the stage, <strong>Locality Sensitive Hashing (LSH)</strong>.</p>
<p>LSH breaks the fingerprint array into bands, each band containing the same number of rows. If two documents share the same hashes in a band, they will be clustered into the same bucket and will be considered as candidates. Let’s use <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span> bands and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2</span></span></span></span> rows to group those documents. (Notice that the last value of the MinHash is ignored)</p>






























<div class="table-container"><table><thead><tr><th>band offset</th><th>band value</th><th>doc_ids</th></tr></thead><tbody><tr><td>(0, 2)</td><td>[403996643, 840529008]</td><td>0, 1</td></tr><tr><td>(2, 4)</td><td>[1008110251, 2888962350]</td><td>0, 1</td></tr><tr><td>(0, 2)</td><td>[166417565, 213933364]</td><td>2</td></tr><tr><td>(2, 4)</td><td>[1129612544, 1419614622]</td><td>2</td></tr></tbody></table></div>
<p>For each row in the <code>doc_ids</code> column, we can generate candidate pairs by paring every two of them. From the above table, we can infer two pairs, even though they are the same:</p>

















<div class="table-container"><table><thead><tr><th>x</th><th>y</th></tr></thead><tbody><tr><td>0</td><td>1</td></tr><tr><td>0</td><td>1</td></tr></tbody></table></div>
<h3 id="beyond-duplicate-pairs">Beyond Duplicate Pairs<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#beyond-duplicate-pairs" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>This is where many deduplication descriptions in papers or tutorials stop. We are still left with the question of what to do with them. Generally, we can proceed with two options:</p>
<ol>
<li>Double-check their Jaccard similarities by calculating their shingle overlap, which now becomes much more doable than computing all-pair similarities. This is also what we did at BigCode at the beginning, which worked reasonably well.</li>
<li>Treat them as true positives. You probably already noticed the issue here: the Jaccard similarity isn’t transitive, meaning <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> is similar to <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> is similar to <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span>, but <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> and <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> do not necessary share the similarity. However, our experiments from The Stack show that treating all of them as duplicates improves the downstream model’s performance the best. And now we gradually moved towards this method instead, and it saves time as well. But to apply this to your dataset, I still suggest going over your dataset and looking at your duplicates, and then making a data-driven decision.</li>
</ol>
<p>From such pairs, whether they are validated or not, we can now construct a graph with those pairs as edges, and duplicates will be clustered into communities or connected components. In terms of implementation, unfortunately, this is where <code>datasets</code> couldn’t help much because now we need something like a <code>groupby</code> where we can cluster documents based on their <em>band offset</em> and <em>band values</em>. Here are some options we have tried:</p>
<p><strong>Option 1: Iterate the datasets the old-fashioned way and collect edges. Then use a graph library to do community detection or connected component detection.</strong></p>
<p>This did not scale well in my test, and the reasons are multifold. First, iterating the whole dataset is slow and memory consuming at a large scale. Second, popular graph libraries like <code>graphtool</code> or <code>networkx</code> have a lot of overhead for graph creation.</p>
<p><strong>Option 2: Popular python frameworks such as <code>dask</code> to allow more efficient <code>groupby</code> operations</strong>, but then you still have problems of slow iteration and slow graph creation.</p>
<p>So, we ended up with a simple iteration + union find algorithm combo that works relatively well for medium datasets.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="python" data-theme="github-light github-dark"><code data-language="python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> table </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tqdm(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">HASH_TABLES</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dynamic_ncols</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">desc</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Clustering...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">	for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cluster </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> table.values():</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">		if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(cluster) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">			continue</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">		idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> min</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(cluster)</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">		for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cluster:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">			uf.union(x, idx)</span></span></code></pre></figure>
<p>For large datasets, our current best option is Spark.</p>
<p>We already know that steps up to the LSH part can be parallelized, which is also achievable in Spark. In addition to that, Spark supports distributed <code>groupBy</code> out of the box, and it is also straightforward to implement algorithms like <sup><a href="#user-content-fn-3" id="user-content-fnref-3-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">3</a></sup> for connected component detection. If you are wondering why we didn’t use Spark’s implementation of MinHash, the answer is that all our experiments so far stemmed from <a href="https://github.com/ekzhu/datasketch" class="external">Datasketch<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, which uses an entirely different implementation than Spark, and we want to ensure that we carry on the lessons and insights learned from that without going into another rabbit hole of ablation experiments.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="python" data-theme="github-light github-dark"><code data-language="python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">edges </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	records.flatMap(</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">		lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: generate_hash_values(</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">			content</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">			idx</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">			num_perm</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args.num_perm,</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">			ngram_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args.ngram_size,</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">			hashranges</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">HASH_RANGES</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">			permutations</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">PERMUTATIONS</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">		)</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	)</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	.groupBy(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: (x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]))</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	.flatMap(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x: generate_edges([i[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]))</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	.distinct()</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	.cache()</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></figure>
<p>A simple connected component algorithm based on <sup><a href="#user-content-fn-3" id="user-content-fnref-3-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">3</a></sup> implemented in Spark.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="python" data-theme="github-light github-dark"><code data-language="python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> edges</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">while</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a.flatMap(large_star_map).groupByKey().flatMap(large_star_reduce).distinct().cache()</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> b.map(small_star_map).groupByKey().flatMap(small_star_reduce).distinct().cache()</span></span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">	changes </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a.subtract(b).union(b.subtract(a)).collect()</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">	if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(changes) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span data-line><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">		break</span></span>
<span data-line> </span>
<span data-line><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">results </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> a.collect()</span></span></code></pre></figure>
<p>Additionally, thanks to cloud providers like GCP, we can set up Spark clusters like a breeze with services like DataProc. In the end, we can comfortably run the program to deduplicate 1.4 TB of data in just under 4 hours with a budget of $15 an hour.</p>
<h2 id="quality-matters">Quality Matters<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#quality-matters" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Scaling a ladder doesn’t get us to the moon. That’s why we need to make sure this is the right direction, and we are using it the right way.</p>
<p>Early on, our parameters were largely inherited from the CodeParrot experiments, and our ablation experiment indicated that those settings did improve the model’s downstream performance<sup><a href="#user-content-fn-17" id="user-content-fnref-17-2" data-footnote-ref aria-describedby="footnote-label" class="internal alias">17</a></sup>. We then set to further explore this path and can confirm that<sup><a href="#user-content-fn-5" id="user-content-fnref-5-3" data-footnote-ref aria-describedby="footnote-label" class="internal alias">5</a></sup>:</p>
<ol>
<li>Near-deduplication improves the model’s downstream performance with a much smaller dataset (6 TB VS. 3 TB)</li>
<li>We haven’t figured out the limit yet, but a more aggressive deduplication (6 TB VS. 2.4 TB) can improve the performance even more:
<ol>
<li>Lower the similarity threshold</li>
<li>Increase the shingle size (unigram → 5-gram)</li>
<li>Ditch false positive checking because we can afford to lose a small percentage of false positives</li>
</ol>
</li>
</ol>
<p><img src="../statics/Pasted-image-20230318111431.png" width="768" height="auto" alt="center "/>
<img src="../statics/Pasted-image-20230318111458.png" width="768" height="auto" alt="center "/></p>
<center>
Image: Two graphs showing the impact of similarity threshold and shingle size, the first one is using unigram and the second one 5-gram. The red dash line shows the similarity cutoff: any documents below would be considered as false positives — their similarities with other documents within a cluster are lower than the threshold.
</center>
<p>These graphs can help us understand why it was necessary to double-check the false positives for CodeParrot and early version of the Stack: using unigram creates many false positives; They also demonstrate that by increasing the shingle size to 5-gram, the percentage of false positives decreases significantly. A smaller threshold is desired if we want to keep the deduplication aggressiveness.</p>
<p>Additional experiments also showed that lowering the threshold removes more documents that have high similarities pairs, meaning an increased recall in the segment we actually would like to remove the most.</p>
<h2 id="scaling">Scaling<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#scaling" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p><img src="../statics/Pasted-image-20230315202712.png" width="768" height="auto" alt="center "/></p>
<center>Image: Deduplication time versus raw dataset size. This is achieved with 15 worker c2d-standard-16 machines on GCP, and each costed around $0.7 per hour. </center>
<p><img src="../statics/CleanShot-2023-03-18-at-17.40.37.png" width="900" height="auto" alt="center "/></p>
<center>Image: CPU usage screenshot for the cluster during processing JSON dataset.</center>
<p>This isn’t the most rigorous scaling proof you can find, but the deduplication time, given a fixed computation budget, looks practically linear to the physical size of the dataset. When you take a closer look at the cluster resource usage when processing JSON dataset, the largest subset in the Stack, you can see the MinHash + LSH (stage 2) dominated the total real computation time (stage 2 + 3), which from our previous analysis is <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">NM</span><span class="mclose">)</span></span></span></span> — linear to the dataset physical volume.</p>
<h2 id="proceed-with-caution">Proceed with Caution<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#proceed-with-caution" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Deduplication doesn’t exempt you from thorough data exploration and analysis. These discoveries hold true for The Stack, but it does not mean it is appliable to other datasets or languages. We still encourage you to perform similar analysis on your datasets before training. For example, it might not be very helpful to do deduplication if you have tight time and compute budget: <a href="http://arxiv.org/abs/2212.14034" class="external">@geiping_2022<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> mentions that substring deduplication didn’t improve their model’s downstream performance. Existing datasets might also require thorough examination before use, for example, <a href="http://arxiv.org/abs/2101.00027" class="external">@gao_2020<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> states that they only made sure the Pile itself, along with its splits, are deduplicated, and they won’t proactively deduplicating for any downstream benchmarks and leave that decision to readers.</p>
<p>In terms of data leakage and benchmark contamination, there is still much to explore. We had to retrain our code models because HumanEval was published in one of the GitHub repos in Python. Early near-deduplication results also suggest that MBPP<sup><a href="#user-content-fn-19" id="user-content-fnref-19" data-footnote-ref aria-describedby="footnote-label" class="internal alias">19</a></sup>, one of the most popular benchmarks for coding, shares a lot of similarity with many Leetcode problems (e.g., task 601 in MBPP is basically Leetcode 646, task 604 ≃ Leetcode 151.). And we all know GitHub is no short of those coding challenges and solutions. It will be even more difficult if someone with bad intentions upload all the benchmarks in the form of python scripts, or other less obvious ways, and pollute all your training data.</p>
<h2 id="future-directions">Future Directions<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#future-directions" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ol>
<li>Substring deduplication. Even though it showed some benefits for English<sup><a href="#user-content-fn-4" id="user-content-fnref-4-7" data-footnote-ref aria-describedby="footnote-label" class="internal alias">4</a></sup>, it is not clear yet if this should be applied to code data as well;</li>
<li>Repetition: paragraphs that are repeated multiple times in one document. <a href="http://arxiv.org/abs/2112.11446" class="external">@rae_2021<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> shared some interesting heuristics on how to detect and remove them.</li>
<li>Using model embeddings for semantic deduplication. It is another whole research question with scaling, cost, ablation experiments, and trade-off with near-deduplication. There are some intriguing takes on this<sup><a href="#user-content-fn-20" id="user-content-fnref-20" data-footnote-ref aria-describedby="footnote-label" class="internal alias">20</a></sup>, but we still need more situated evidence to draw a conclusion (e.g, <a href="http://arxiv.org/abs/2303.09540" class="external">@abbas_2023<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>’s only text deduplication reference is <a href="http://arxiv.org/abs/2107.06499" class="external">@lee_2022a<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, whose main claim is deduplicating helps instead of trying to be SOTA).</li>
<li>Optimization. There is always room for optimization: better quality evaluation, scaling, downstream performance impact analysis etc.</li>
<li>Then there is another direction to look at things: To what extent near-deduplication starts to hurt performance? To what extent similarity is needed for diversity instead of being considered as redundancy?</li>
</ol>
<h2 id="credits">Credits<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#credits" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>The banner image contains emojis (hugging face, Santa, document, wizard, and wand) from Noto Emoji (Apache 2.0). This blog post is proudly written without any generative APIs.</p>
<p>Huge thanks to Huu Nguyen and Hugo Laurençon for the collaboration in BigScience and everyone at BigCode for the help along the way! If you ever find any error, feel free to contact me: mouchenghao at gmail dot com.</p>
<h2 id="supporting-resources">Supporting Resources<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#supporting-resources" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li><a href="https://github.com/ekzhu/datasketch" class="external">Datasketch<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (MIT)</li>
<li><a href="https://github.com/seomoz/simhash-py/tree/master/simhash" class="external">simhash-py<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> and <a href="https://github.com/seomoz/simhash-cpp" class="external">simhash-cpp<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (MIT)</li>
<li><a href="https://github.com/google-research/deduplicate-text-datasets" class="external">Deduplicating Training Data Makes Language Models Better<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (Apache 2.0)</li>
<li><a href="https://github.com/serega/gaoya" class="external">Gaoya<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (MIT)</li>
<li><a href="https://github.com/bigscience-workshop" class="external">BigScience<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (Apache 2.0)</li>
<li><a href="https://github.com/bigcode-project" class="external">BigCode<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (Apache 2.0)</li>
</ul>
<h2 id="references">References<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#references" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<section data-footnotes class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#footnote-label" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ol>
<li id="user-content-fn-1">
<p>Nikhil Kandpal, Eric Wallace, Colin Raffel, <a href="http://arxiv.org/abs/2202.06539" class="external">Deduplicating Training Data Mitigates Privacy Risks in Language Models<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-1" data-footnote-backref aria-label="Back to reference 1" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>Gowthami Somepalli, et al., <a href="http://arxiv.org/abs/2212.03860" class="external">Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-2" data-footnote-backref aria-label="Back to reference 2" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>Raimondas Kiveris, Silvio Lattanzi, et al., <a href="https://doi.org/10.1145/2670979.2670997" class="external">Connected Components in MapReduce and Beyond<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2014 <a href="#user-content-fnref-3" data-footnote-backref aria-label="Back to reference 3" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-3-2" data-footnote-backref aria-label="Back to reference 3-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-3-3" data-footnote-backref aria-label="Back to reference 3-3" class="data-footnote-backref internal">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-4">
<p>Katherine Lee, Daphne Ippolito, et al., <a href="http://arxiv.org/abs/2107.06499" class="external">Deduplicating Training Data Makes Language Models Better<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-4" data-footnote-backref aria-label="Back to reference 4" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-4-2" data-footnote-backref aria-label="Back to reference 4-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-4-3" data-footnote-backref aria-label="Back to reference 4-3" class="data-footnote-backref internal">↩<sup>3</sup></a> <a href="#user-content-fnref-4-4" data-footnote-backref aria-label="Back to reference 4-4" class="data-footnote-backref internal">↩<sup>4</sup></a> <a href="#user-content-fnref-4-5" data-footnote-backref aria-label="Back to reference 4-5" class="data-footnote-backref internal">↩<sup>5</sup></a> <a href="#user-content-fnref-4-6" data-footnote-backref aria-label="Back to reference 4-6" class="data-footnote-backref internal">↩<sup>6</sup></a> <a href="#user-content-fnref-4-7" data-footnote-backref aria-label="Back to reference 4-7" class="data-footnote-backref internal">↩<sup>7</sup></a></p>
</li>
<li id="user-content-fn-5">
<p>Loubna Ben Allal, Raymond Li, et al., <a href="http://arxiv.org/abs/2301.03988" class="external">SantaCoder: Don’t reach for the stars!<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2023 <a href="#user-content-fnref-5" data-footnote-backref aria-label="Back to reference 5" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-5-2" data-footnote-backref aria-label="Back to reference 5-2" class="data-footnote-backref internal">↩<sup>2</sup></a> <a href="#user-content-fnref-5-3" data-footnote-backref aria-label="Back to reference 5-3" class="data-footnote-backref internal">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-6">
<p>Leo Gao, Stella Biderman, et al., <a href="http://arxiv.org/abs/2101.00027" class="external">The Pile: An 800GB Dataset of Diverse Text for Language Modeling<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2020 <a href="#user-content-fnref-6" data-footnote-backref aria-label="Back to reference 6" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-6-2" data-footnote-backref aria-label="Back to reference 6-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-7">
<p>Asier Gutiérrez-Fandiño, Jordi Armengol-Estapé, et al., <a href="http://arxiv.org/abs/2107.07253" class="external">MarIA: Spanish Language Models<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-7" data-footnote-backref aria-label="Back to reference 7" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>Jack W. Rae, Sebastian Borgeaud, et al., <a href="http://arxiv.org/abs/2112.11446" class="external">Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2021 <a href="#user-content-fnref-8" data-footnote-backref aria-label="Back to reference 8" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-9">
<p>Xi Victoria Lin, Todor Mihaylov, et al., <a href="http://arxiv.org/abs/2112.10668" class="external">Few-shot Learning with Multilingual Language Models<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2021 <a href="#user-content-fnref-9" data-footnote-backref aria-label="Back to reference 9" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-10">
<p>Hugo Laurençon, Lucile Saulnier, et al., <a href="https://openreview.net/forum?id=UoEw6KigkUn" class="external">The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-10" data-footnote-backref aria-label="Back to reference 10" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-11">
<p>Daniel Fried, Armen Aghajanyan, et al., <a href="http://arxiv.org/abs/2204.05999" class="external">InCoder: A Generative Model for Code Infilling and Synthesis<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-11" data-footnote-backref aria-label="Back to reference 11" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-12">
<p>Erik Nijkamp, Bo Pang, et al., <a href="http://arxiv.org/abs/2203.13474" class="external">CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2023 <a href="#user-content-fnref-12" data-footnote-backref aria-label="Back to reference 12" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-13">
<p>Yujia Li, David Choi, et al., <a href="http://arxiv.org/abs/2203.07814" class="external">Competition-Level Code Generation with AlphaCode<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-13" data-footnote-backref aria-label="Back to reference 13" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-14">
<p>Frank F. Xu, Uri Alon, et al., <a href="http://arxiv.org/abs/2202.13169" class="external">A Systematic Evaluation of Large Language Models of Code<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-14" data-footnote-backref aria-label="Back to reference 14" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-15">
<p>Aakanksha Chowdhery, Sharan Narang, et al., <a href="http://arxiv.org/abs/2204.02311" class="external">PaLM: Scaling Language Modeling with Pathways<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-15" data-footnote-backref aria-label="Back to reference 15" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-16">
<p>Lewis Tunstall, Leandro von Werra, Thomas Wolf, <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098136789/" class="external">Natural Language Processing with Transformers, Revised Edition<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-16" data-footnote-backref aria-label="Back to reference 16" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-17">
<p>Denis Kocetkov, Raymond Li, et al., <a href="http://arxiv.org/abs/2211.15533" class="external">The Stack: 3 TB of permissively licensed source code<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2022 <a href="#user-content-fnref-17" data-footnote-backref aria-label="Back to reference 17" class="data-footnote-backref internal alias">↩</a> <a href="#user-content-fnref-17-2" data-footnote-backref aria-label="Back to reference 17-2" class="data-footnote-backref internal">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-18">
<p><a href="https://projecthailmary.fandom.com/wiki/Rocky" class="external">Rocky | Project Hail Mary Wiki | Fandom<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> <a href="#user-content-fnref-18" data-footnote-backref aria-label="Back to reference 18" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-19">
<p>Jacob Austin, Augustus Odena, et al., <a href="http://arxiv.org/abs/2108.07732" class="external">Program Synthesis with Large Language Models<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2021 <a href="#user-content-fnref-19" data-footnote-backref aria-label="Back to reference 19" class="data-footnote-backref internal alias">↩</a></p>
</li>
<li id="user-content-fn-20">
<p>Amro Abbas, Kushal Tirumala, et al., <a href="http://arxiv.org/abs/2303.09540" class="external">SemDeDup: Data-efficient learning at web-scale through semantic deduplication<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, 2023 <a href="#user-content-fnref-20" data-footnote-backref aria-label="Back to reference 20" class="data-footnote-backref internal alias">↩</a></p>
</li>
</ol>
</section></article></div><div class="right sidebar"><div class="toc desktop-only"><button type="button" id="toc" class><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#large-scale-near-deduplication-behind-bigcode" data-for="large-scale-near-deduplication-behind-bigcode">Large-scale Near-deduplication Behind BigCode</a></li><li class="depth-1"><a href="#intended-audience" data-for="intended-audience">Intended Audience</a></li><li class="depth-1"><a href="#motivations" data-for="motivations">Motivations</a></li><li class="depth-1"><a href="#from-bigscience-to-bigcode" data-for="from-bigscience-to-bigcode">From BigScience to BigCode</a></li><li class="depth-1"><a href="#minhash-walkthrough" data-for="minhash-walkthrough">MinHash Walkthrough</a></li><li class="depth-2"><a href="#shingles" data-for="shingles">Shingles</a></li><li class="depth-2"><a href="#fingerprint-computation" data-for="fingerprint-computation">Fingerprint Computation</a></li><li class="depth-2"><a href="#beyond-duplicate-pairs" data-for="beyond-duplicate-pairs">Beyond Duplicate Pairs</a></li><li class="depth-1"><a href="#quality-matters" data-for="quality-matters">Quality Matters</a></li><li class="depth-1"><a href="#scaling" data-for="scaling">Scaling</a></li><li class="depth-1"><a href="#proceed-with-caution" data-for="proceed-with-caution">Proceed with Caution</a></li><li class="depth-1"><a href="#future-directions" data-for="future-directions">Future Directions</a></li><li class="depth-1"><a href="#credits" data-for="credits">Credits</a></li><li class="depth-1"><a href="#supporting-resources" data-for="supporting-resources">Supporting Resources</a></li><li class="depth-1"><a href="#references" data-for="references">References</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li>No backlinks found</li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.3</a> © 2024</p><ul><li><a href="https://codeberg.org/Chenghao2023/blog">CodeBerg</a></li><li><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></li></ul></footer></div></body><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="../postscript.js" type="module"></script></html>