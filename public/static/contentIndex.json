{"4archives/0-Lifestyle-Creep":{"title":"0 Lifestyle Creep","links":["202205292029a"],"tags":["finance","life"],"content":"Lifestyle Creep is when you increase your spending after an increase in income or purely as a result of peer pressure without any additional income.\n202205292029a"},"4archives/20211009132100":{"title":"Open Vocabulary","links":["4archives/Literature-Notes/Readings/Paper-Robust-Open-Vocabulary-Translation-from-Visual-Text-Representations","4archives/Literature-Notes/Readings/Paper-CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation","Paper-Charformer-Fast-Character-Transformers-via-Gradient-based-Subword-Tokenization"],"tags":["natural_language_processing/open_vocabulary","natural_language_processing/representation_learning","natural_language_processing/translation","natural_language_processing","todo"],"content":"Open Vocabulary\nProblems\nWord based models suffer from the Out-of-Vocabulary (OOV) problem. Character-level models can be useful if the sequence length is manageable. Recent sub-word models using 1, 2, and 3 are a good compromise. To some extend, they can be considered as open vocabulary since you can degenerate a word to complete characters (all Unicode characters theoretically, but ASCII characters in the English dominating world). But the problem of a vocabulary remains:\n\nYou have to store and maintain a physical copy of the vocabulary along side your model\nYou have to store the token embeddings, which can be a lot of parameters, in your model\n\nOpen, Low, and No Vocabulary\nIf we define open vocabulary as a criterion that there would be no OOV problem, then you can either have a finite vocabulary or no vocabulary at all(hash, VTR). If you do, the vocabulary can be small (bytes, ASCII characters), moderate or big(BPE w/ fixed size).\nNo Vocabulary\nTransclude of Paper-Robust-Open-Vocabulary-Translation-from-Visual-Text-Representations\n\n4\n5\n6\n\nLow Vocabulary\nTransclude of Paper-CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation\nTransclude of Paper-Charformer-Fast-Character-Transformers-via-Gradient-based-Subword-Tokenization\n\n7\n\nFootnotes\n\n\n[1609.08144v2] Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation ↩\n\n\n[1808.06226] SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing ↩\n\n\nByte pair encoding - Wikipedia ↩\n\n\naclanthology.org/D19-1506.pdf ↩\n\n\nGoogle AI Blog: Advancing NLP with Efficient Projection-Based Model Architectures ↩\n\n\n[2106.12672] Charformer: Fast Character Transformers via Gradient-based Subword Tokenization ↩\n\n\n[2105.13626] ByT5: Towards a token-free future with pre-trained byte-to-byte models ↩\n\n\n"},"4archives/202205292029a-How-Much-Lifestyle-Creep-Can-You-Afford":{"title":"How Much Lifestyle Creep Can You Afford","links":["4archives/0-Lifestyle-Creep"],"tags":[],"content":"How Much Lifestyle Creep Can You Afford\n0 Lifestyle Creep"},"4archives/AWS-Certified-Machine-Learning-Specialty/2-Data-Engineering":{"title":"2 Data Engineering","links":["4archives/AWS-Certified-Machine-Learning-Specialty/S3","4archives/AWS-Certified-Machine-Learning-Specialty/Kinesis","4archives/AWS-Certified-Machine-Learning-Specialty/Glue","4archives/AWS-Certified-Machine-Learning-Specialty/Athena","4archives/AWS-Certified-Machine-Learning-Specialty/Data-Stores","4archives/AWS-Certified-Machine-Learning-Specialty/Data-Pipeline","4archives/AWS-Certified-Machine-Learning-Specialty/Batch","4archives/AWS-Certified-Machine-Learning-Specialty/Database-Migration-Service-(DMS)","4archives/AWS-Certified-Machine-Learning-Specialty/Step-Functions"],"tags":["aws"],"content":"S3\nKinesis\nGlue\nAthena\nData Stores\nData Pipeline\nBatch\nDatabase Migration Service (DMS)\nStep Functions"},"4archives/AWS-Certified-Machine-Learning-Specialty/3-Exploratory-Data-Analysis":{"title":"3 Exploratory Data Analysis","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Data-Types","4archives/AWS-Certified-Machine-Learning-Specialty/Data-Distributions","4archives/AWS-Certified-Machine-Learning-Specialty/Time-Series","4archives/AWS-Certified-Machine-Learning-Specialty/Athena","4archives/AWS-Certified-Machine-Learning-Specialty/QuickSight","4archives/AWS-Certified-Machine-Learning-Specialty/Elastic-MapReduce","4archives/AWS-Certified-Machine-Learning-Specialty/Feature-Engineering","4archives/AWS-Certified-Machine-Learning-Specialty/Sagemaker-Groud-Truth"],"tags":["aws","data-analysis"],"content":"Data Types\nData Distributions\nTime Series\nAthena\nQuickSight\nElastic MapReduce\nFeature Engineering\nSagemaker Groud Truth"},"4archives/AWS-Certified-Machine-Learning-Specialty/4-Modeling":{"title":"4 Modeling","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Activation-Functions","4archives/AWS-Certified-Machine-Learning-Specialty/Elastic-MapReduce","4archives/AWS-Certified-Machine-Learning-Specialty/SageMaker","4archives/AWS-Certified-Machine-Learning-Specialty/High-Level-ML-Services"],"tags":["aws","machine-learning"],"content":"Activation Functions\nDeep Learning on EC2/Elastic MapReduce\n\nEMR\nVariant EC2 instances\nDeep Learning AMI\n\nBatch Size\n\nsmaller batch size can get out of local minima\nlarger batch size can converge on the wrong solution\n\nLearning Rate\n\nthe larger the learning rate is, the more easily a model overshoots\nthe smaller the learning rate is, the longer the training is going to take\n\nRegularization\n\nDropout\nTrimming\nEarly stopping\nL1 (feature selection, sparse) and L2 (computational efficient, dense)\n\nVanishing Gradients\n\nSub-networks\nGates\nResidual connections\nActivation Functions\n\nRecall, aka completeness\nPrecision, aka relevancy\nBagging VS. boosting\n\nBagging can be parallelized\nBagging prevents overfitting\nBoosting usually yields better results\n\nSageMaker\nHigh Level ML Services"},"4archives/AWS-Certified-Machine-Learning-Specialty/5-Implementation-and-Operations":{"title":"5 Implementation and Operations","links":["4archives/AWS-Certified-Machine-Learning-Specialty/S3"],"tags":["sagemaker"],"content":"SageMaker + Docker\n\nAll models are hosted with Docker containers\n\nTensorflow docker image is not automatically distributed. Use GitHub - horovod/horovod: Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. for this.\nIncluding the inference code and model artifacts\n\n\nNGINX + Flask + Gunicorn + uWSGI\nEnvironment variables\n\nSAGEMAKER_PROGRAM\n\n\nProduction Variants for A/B testing, with varying weights\n\nSageMaker Neo\n\nCompiling code for edge devices.\nAWS IoT Greengrass\n\nDeploying models to the actual edge device\n\n\n\nSageMaker Security\n\n\nIdentity and Access Management (IAM) with minimum permissions\n\n\nMFA\n\n\nSSL/TLS\n\n\nCloudTrail to log activities for auditing (CloudWatch is for monitoring)\n\n\nEncryption\n\n\nPII\n\n\nAt rest data encryption:\n\nKMS\nS3 ^8a6482\n\n\n\nIn transit\n\nEncrypted communication (inter container traffic communication)\nIAM\nTLS/SSL\n\n\n\nSageMaker VPC\n\nWhen network is disabled:\n\nUse PrivateLink or NAT Gateway to access S3\n\n\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Activation-Functions":{"title":"Activation Functions","links":[],"tags":["aws","deep-learning","activation"],"content":"ReLU:\n\nLeaky ReLU\nExponential Linear Unit (ELU)\nSwish\nMaxout\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Athena":{"title":"Athena","links":["4archives/AWS-Certified-Machine-Learning-Specialty/S3","4archives/AWS-Certified-Machine-Learning-Specialty/Glue","4archives/AWS-Certified-Machine-Learning-Specialty/Athena","4archives/AWS-Certified-Machine-Learning-Specialty/QuickSight"],"tags":["aws","athena"],"content":"Running SQL on the S3 data (with metadata from Glue Data Catalog) without managing the server.\nS3 → Glue → Athena → QuickSight\nCost\n\nPay-as-you-go\nUse column-format data to save cost and improve performance\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Batch":{"title":"Batch","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Glue"],"tags":["aws"],"content":"It is suitable for any computing docker-based jobs, not just ETL. Glue is mostly ETL in that regard."},"4archives/AWS-Certified-Machine-Learning-Specialty/BlazingText":{"title":"BlazingText","links":[],"tags":["aws","sagemaker","machine-learning"],"content":"Use-cases\n\nSentence (not document) classification\n\nFormat: __label__ sentence\n\n\nWord2vec ^8197ec\n\nFormat: sentence\nCBOW or Skip-gram or Batch Skip-gram (multiple nodes)\n\n\n\nHyperparameters\n\nModel\nLearning rate\nWindow size\nNegative sampling rate\nHidden dimension\nEpochs\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Course-AWS-Certified-Machinea-Learning-Specialty":{"title":"Course AWS Certified Machinea Learning Specialty","links":["4archives/AWS-Certified-Machine-Learning-Specialty/2-Data-Engineering","4archives/AWS-Certified-Machine-Learning-Specialty/3-Exploratory-Data-Analysis","4archives/AWS-Certified-Machine-Learning-Specialty/4-Modeling","4archives/AWS-Certified-Machine-Learning-Specialty/5-Implementation-and-Operations"],"tags":["aws","machine-learning","course"],"content":"2 Data Engineering\n3 Exploratory Data Analysis\n4 Modeling\n5 Implementation and Operations"},"4archives/AWS-Certified-Machine-Learning-Specialty/Data-Distributions":{"title":"Data Distributions","links":[],"tags":["aws","data","distribution","data-analysis"],"content":"\nNormal distribution - Wikipedia\nPoisson distribution - Wikipedia\nBinomial distribution - Wikipedia\nBernoulli distribution - Wikipedia\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Data-Pipeline":{"title":"Data Pipeline","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Glue"],"tags":["aws","data"],"content":"Data Pipeline VS. Glue:\n\nData pipeline has more control over the orchestration and code (not just Spark)\nGlue automatically scales so does its underlying Spark cluster\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Data-Stores":{"title":"Data Stores","links":["4archives/AWS-Certified-Machine-Learning-Specialty/S3"],"tags":["aws","data"],"content":"Supported types of data storage:\n\nRedshift (column based)\nRDS or Aurora (row based)\nDynamoDB (NoSQL)\nS3\nElasticSearch / OpenSearch\nAmazon ElastiCache\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Data-Types":{"title":"Data Types","links":[],"tags":["aws","data","data-type","data-analysis"],"content":"Data Types\n\nNumerical data: discrete or continuous\nCategorical data\nOrdinal data\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Database-Migration-Service-(DMS)":{"title":"Database Migration Service (DMS)","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Glue"],"tags":["aws","database"],"content":"No transformation is performed (unlike Glue) and continuous data replication."},"4archives/AWS-Certified-Machine-Learning-Specialty/DeepAR":{"title":"DeepAR","links":[],"tags":["aws","sagemaker","machine-learning","time-series"],"content":"DeepAR is for forecasting one-dimensional time series data. It is able to find the frequencies and seasonalities.\nInput\n\njsonl (timestamp, dynamic or categorical features, target)\n\nTraining\n\nUse all the data when possible\nInference on a small window in the future\nTrain on many series if possible\n\nHyperparameters\n\nContext length\nEpochs\nBatch size\nLearning rate\nHidden dimension/cells\n\nCPU can be sufficient, especially for inference."},"4archives/AWS-Certified-Machine-Learning-Specialty/Elastic-MapReduce":{"title":"Elastic MapReduce","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Kinesis"],"tags":["aws","data","spark"],"content":"Manged Hadoop cluster on EC2, including Spark, HBase, Presto, Flink, Hive and more.\n\nMaster node\nCore node for storage\nTask node for processing\n\nStorage\n\nHDFS\nEMRFS (S3 as HDFS)\nLocal FS\nEBS\n\nSpark\n\nSpark Streaming (w/ Kinesis)\nSpark SQL\nMLLib\nGraphX\nSpark Core\n\nNotebooks\n\nZeppelin\nNotebook\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Factorization-Machine":{"title":"Factorization Machine","links":[],"tags":["aws","sagemaker","factorization-machine"],"content":"Supervised classification and regression with sparse data.\nInput\nRecordIO-protobuf with float32\nDetails\nUser x item matrix for recommendation\nHyperparameters\n\ninitialization methods\n\nInstance Choice\nCPU and GPU"},"4archives/AWS-Certified-Machine-Learning-Specialty/Feature-Engineering":{"title":"Feature Engineering","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Kinesis"],"tags":["aws","data"],"content":"Apply your knowledge to the data and build models upon it.\nFeatures\nNot all features are relevant and all features can be harmful.\nImputation\nReplace missing values with computed/inferred values.\n\nCorrelations between columns might be missed\nDropping missing data might bias the dataset\n\nTry:\n\nKNN\nDL models (categorical labels)\nRegression models\nGet more data\n\nUnbalanced Data\n\nOversampling\nSMOTE\n\nOutliers\nThe Kinesis Analytics from Kinesis Analytics can be used to identify outliers.\nBinning\nBucketization: smooth out uncertainty in the measurements\nTransformation\n\nOne-hot encoding\nScaling\nNormalization\nShuffling\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Glue":{"title":"Glue","links":[],"tags":["aws","glue"],"content":"Data Catalog and Crawlers\nMetadata repository, created by crawlers and inferred automatically from the data.\nETL\nSupported Transformations:\n\nDrop(DropFields, DropNullFields)\nFilter\nJoin\nMap\nFindMatches (fuzzy match)\nConversion\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/High-Level-ML-Services":{"title":"High Level ML Services","links":["4archives/AWS-Certified-Machine-Learning-Specialty/Kinesis"],"tags":["aws","ai"],"content":"AWS Comprehend\n\nNLP and text analytics\nNER, Sentiment, Syntax, Language, Topics, and Classification\n\nAWS Translate\n\nCustom terminology\n\nAWS Transcribe\n\nAudio file or streaming\nSpeaker Identification\nChannel Identification\nCustom Vocabulary\n\nAWS Polly\n\nText-to-speech\nCustom lexicons\nSpeech Synthesis Markup Language\nSpeech Marks (animation)\n\nAWS Rekognition\n\nObject and scene detection\nImage moderation\nFacial analysis\nCelebrity recognition\nFace comparison\nText in image\nVideo analysis\n\nImages from S3 or request body, video comes from Kinesis.\nAWS Forecast\n\ntime series prediction\nauto ML included\ndataset groups, predictors, and forecast\n\nAWS Lex\n\nchat bot engine\nintent detection and slot-filling\n\nAWS Personalize\n\nrecommender engine\ndata – items, users, or interactions – from s3 or API integration + schema (Avro)\nget recommendations USER_PERSONALIZATION, similar items RELATED_ITEMS, or rankings PERSONALIZED_RANKING\nreal-time or batch\nnew users and new items\ncontextual recommendations based on the device, time or location\nsolutions:\n\ntraining\nobjectives\nhyper-parameter optimization (HPO)\n\nhidden_dimension for both user and item (id or metadata)\nbptt\nrecency_mask\nmin/max_user_history_length_percentile\nexploration_item_age_cut_off\nexporation_weight: relevancy\n\n\n\n\ncampaign for deployment\n\nTricks for Maintaining Relevance\n\nkeep the dataset up to date\nfeed real-time interactions\nre-train frequently\n\nSecurity\n\nno data between websites\nencryption at rest and in transit\n\nPricing\n\ndata ingestion: per GB\ntraining: per training hour\ninference: per TPS-hours\nbatch inference: by user or by item\n\nMisc\n\nAWS Textract\nAWS DeepRacer\nAWS DeepLens\nAWS Lookout: device or equipment monitoring\nAWS Monitron: end to end system for monitoring, including the sensors\nTorchServe and AWS Neuron (Inferentia chip)\nAWS Panorama: CV at the edge device\nAWS DeepComposer\nAWS Fraud Detector\nAWS CodeGuru\nContact Lens for Amazon Connect\nAWS Kendra\nAugmented AI: human in the loop\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Hyperparameter-Tuning":{"title":"Hyperparameter Tuning","links":[],"tags":["aws","sagemaker","hyperparamter-tuning"],"content":"It learns in the process, so it does not run all possible combinations.\n\nDon’t optimize many hyperparameters all at once.\nSmall ranges + logarithmic scale\nSmall batches for it to learn\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/IP-Insights":{"title":"IP Insights","links":[],"tags":["aws","sagemaker"],"content":"IP address pattern recognition\nInput\nCSV only\nDetails\nHyperparameters\n\nHash size\nVector dimension\nNN hyperparameters\n\nInstance Choice\nCPU or GPU"},"4archives/AWS-Certified-Machine-Learning-Specialty/Image-Classification":{"title":"Image Classification","links":[],"tags":["aws","sagemaker","image-classification"],"content":"Input\nRecordIO or raw images\nDetails\n\n[1512.03385] Deep Residual Learning for Image Recognition backbone\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/K-Means":{"title":"K-Means","links":[],"tags":["aws","sagemaker","clustering"],"content":"Input\n\nRecordIO-protobuf or CSV in file or pipe\nShardedByS3Key for training and FullyReplicated for testing\n\nDetails\n\nMore clusters at the beginning in SageMaker\nK-means++\nReduce clusters from K to k\n\nHyperparameters\n\nk (elbow-method)\nmini-batch size\nextra center\ninit method\n\nInstance Choice\nCPU or single GPU machines"},"4archives/AWS-Certified-Machine-Learning-Specialty/KNN":{"title":"KNN","links":[],"tags":["aws","sagemaker","knn"],"content":"Input\nRecordIO-protobuf or CSV in file or pipe\nDetails\n\nDimensionality Reduction included\n\nHyperparameters\n\nk\nsample size\n\nInstance Choice\nBoth CPU and GPU are supported"},"4archives/AWS-Certified-Machine-Learning-Specialty/Kinesis":{"title":"Kinesis","links":[],"tags":["aws","kinesis"],"content":"Kinesis is an alternative to Kafka. It is great for processing, analyzing and transforming real-time streaming data.\nKinesis Streams\n\nGood for general real-time streaming data\nProcessed in shards/partitions\nSize limit: 1MB\nRetention limits: 1 to 365 days\n\nKinesis Analytics\n\nGood for both real-time streaming and batched data\nUse case: ETL, metric generation, responsive analytic\nML algorithms:\n\nRANDOM_CUT_FOREST for online anomaly detection\nHOTSPOTS for finding dense areas in the feature space\n\n\n\nKinesis Firehose\n\nData aggregation and exportation\nBatch writes to target destinations (S3(compression supported), Redshift, ElasticSearch, Splunk)\nNear real-time output because of the batching\nAutomatic scaling\n\nKinesis Video Streams\n\nStreaming data from cameras, DeepLens etc.\nOne device, one stream\nRetention: 1 hour to 10 years\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Latent-Dirichlet-Allocation":{"title":"Latent Dirichlet Allocation","links":[],"tags":["aws","sagemaker","natural-language-processing","topic-modeling"],"content":"Input\nRecordIO-protobuf or CSV with tokenized ids id:count\nDetails\n\nNumber of topics\n\nHyperparameters\n\nAlpha\n\nthe concentration parameter: small value → sparse topic mixtures\n\n\n\nInstance Choice\nOnly CPU"},"4archives/AWS-Certified-Machine-Learning-Specialty/Neural-Topic-Model":{"title":"Neural Topic Model","links":[],"tags":["aws","sagemaker","natural-language-processing","topic-modeling"],"content":"Input\nRecordIO-protobuf or CSV with tokenized ids\nDetails\n\nNumber of topics\n\nInstance Choice\nBoth CPU and GPU are okay"},"4archives/AWS-Certified-Machine-Learning-Specialty/Object-Detection":{"title":"Object Detection","links":[],"tags":["aws","sagemaker","computer-vision","object-detection"],"content":"Input\nRecordIO or json format\nDetails\n\nSingle Shot multibox Detector (SSD)\nfine-tuning with pre-trained models\n\nInstance Choice\n\nmulti-GPU or multi-node\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Object2Vec":{"title":"Object2Vec","links":["4archives/AWS-Certified-Machine-Learning-Specialty/BlazingText"],"tags":["aws","sagemaker","machine-learning"],"content":"Word2Vec for arbitrary objects.\nInput\npair of tokens or a sequence of tokens\nArchitecture\nSiamese network with two encoders and a comparator\nInstance Choice\n\nSingle machine only (CPU, GPU or GPUs – M5 or P2)\nInference: M2 with INFERENCE_PREFERRED_MODE\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/PCA":{"title":"PCA","links":[],"tags":["aws","sagemaker","pca","dimensionality-reduction"],"content":"Input\nRecordIO-protobuf or CSV in file or pipe\nDetails\nsmall data: regular\nlarge data: randomized\nHyperparameters\n\nmode\nsubtract mean\n\nInstance Choice\nGPU or CPU"},"4archives/AWS-Certified-Machine-Learning-Specialty/QuickSight":{"title":"QuickSight","links":[],"tags":["aws","data"],"content":"Serverless business analytic service.\nUse-cases:\n\nvisualization\nad-hoc analysis\nstories\ndashboard and KPI\n\nSPICE\nSuper fast, parallel, in-memory calculation engine.\nMachine Learning Insights\n\nAnomaly detection\nForecasting\nAuto-narratives\n\nDashboard\nGraph types:\n\nBar chart\nLine chart\nScatter chart\nHeat-map\nPie chart\nTree map\nPivot table\nAuto chart\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Random-Cut-Forest":{"title":"Random Cut Forest","links":[],"tags":["aws","sagemaker","machine-learning"],"content":"Input\n\nRecordIO-protobuf or CSV\nFile or Pipe\n\nDetails\n\nEach tree is a partition of the data;\n\nHyperparameters\n\nnumber of trees\nnumber of samples per tree\n\nInstance Choice\nCPU machines"},"4archives/AWS-Certified-Machine-Learning-Specialty/Reinforcement-Learning":{"title":"Reinforcement Learning","links":["4archives/AWS-Certified-Machine-Learning-Specialty/SageMaker"],"tags":["aws","sagemaker","reinforcement-learning"],"content":"It is useful to navigate through a virtual environment.\nEnvironment state S, possible actions A, and a value of each state/action Q. Taking an action will impact the Q value.\nQnew(st​,at​)←old value Q(st​,at​)​​+learning rate α​​⋅(reward rt​​​+discount factor γ​​⋅estimate of optimal future valueamax​Q(st+1​,a)​​−old value Q(st​,at​)​​)​new value (temporal difference target) temporal difference​\naka. Markov Decision Process\nSageMaker uses Tensorflow and MXNet\nInput\nDetails\nHyperparameters\nDepends on your task\nInstance Choice\nmulti-core and multi-instance"},"4archives/AWS-Certified-Machine-Learning-Specialty/S3":{"title":"S3","links":[],"tags":["aws","s3","storage"],"content":"Amazon S3 is an object storage service that stores data as objects within buckets. An object is a file and any metadata that describes the file. A bucket is a container for objects.\nRequirements\n\nA bucket name must be globally unique\nAn object has a key being the full path to that object\nThe maximum size of an object is 5TB\nThe maximum number of tags of an object is 10\n\nFeatures\n\nS3 is the backbone of many ML services\nIt is an ideal candidate for creating a data lake\nIt has a centralized architecture\nIt supports partitioning for query speedup. For example:\n\nby data s3://bucket/year/month/day/file\nby product s3://bucket/product\n\n\n\nTiers\n\nS3 Standard General Purpose\nS3 Standard Infrequent Access(IA)\nS3 One Zone IA\nS3 Intelligent\nGlacier\n\nLife Cycle\n\nTransition actions\n\nFor example: Standard → IA\n\n\nExpiration actions\n\nFor example: IA → Glacier\n\n\n\nSecurity\n\nFour methods of encryption:\n\nSSE-S3: managed by AWS/S3\nSSE-KMS: managed by AWS Key Management Service\nSSE-C: managed by Client\nClient Side Encryption\n\nAccess Control\n\nUser based or resource based Access Control(Bucket Policies)\nVPC Endpoint Gateway\nLogging and Audit\nTags\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/SageMaker":{"title":"SageMaker","links":["4archives/AWS-Certified-Machine-Learning-Specialty/XGBoost","4archives/AWS-Certified-Machine-Learning-Specialty/Seq2Seq","4archives/AWS-Certified-Machine-Learning-Specialty/DeepAR","4archives/AWS-Certified-Machine-Learning-Specialty/BlazingText","4archives/AWS-Certified-Machine-Learning-Specialty/Object2Vec","4archives/AWS-Certified-Machine-Learning-Specialty/Object-Detection","4archives/AWS-Certified-Machine-Learning-Specialty/Image-Classification","4archives/AWS-Certified-Machine-Learning-Specialty/Semantic-Segmentation","4archives/AWS-Certified-Machine-Learning-Specialty/Random-Cut-Forest","4archives/AWS-Certified-Machine-Learning-Specialty/Neural-Topic-Model","4archives/AWS-Certified-Machine-Learning-Specialty/Latent-Dirichlet-Allocation","4archives/AWS-Certified-Machine-Learning-Specialty/KNN","4archives/AWS-Certified-Machine-Learning-Specialty/Reinforcement-Learning","4archives/AWS-Certified-Machine-Learning-Specialty/Hyperparameter-Tuning"],"tags":["aws","sagemaker"],"content":"Access:\n\nSageMaker notebook on EC2\nSageMaker console\n\nData:\n\nS3\n\nTraining Job\n\ndata\ncompute resources\noutput\ntraining code\n\nDeployment\n\nendpoint\nbatch transform\n\nBuilt-in Algorithms\n\nLinear Learner\n\nInput: RecordIO, CSV, file or pipe\nNormalization\nHyperparameters:\n\nclass weights\nlearning rate\nl1 or l2/weight decay\n\n\n\n\nXGBoost\nSeq2Seq\nDeepAR\nBlazingText\nObject2Vec\nObject Detection\nImage Classification\nSemantic Segmentation\nRandom Cut Forest\nNeural Topic Model\nLatent Dirichlet Allocation\nKNN\nReinforcement Learning\nHyperparameter Tuning\n\nSpark and SageMaker\n\nsagemaker-spark\nSageMakerEstimator returns a SageMakerModel\n\nSageMaker Studio\nMachine learning IDE\nSageMaker Experiments\nTracking and managing experiments\nSageMaker Debugger\n\nSaving gradients, model states or logs for debugging;\nReports\nBuild-in rules:\n\nMonitor system metrics\nProfile model operations\nDebug model parameters\n\n\nSMDebug client\nInsights Dashboard\nProfilerRule\nNotifications and actions\n\nSageMaker Autopilot\nIt supports:\n\n\nAlgorithms\n\n\nData preprocessing\n\n\nModel tuning\n\n\nInfrastructure\n\n\nHuman in the loop\n\n\nClassification or Regression\n\n\nTabular data\n\n\nIntegrates with SageMaker Clarify\n\n\nSageMaker Model Monitor\n\nDrift:\n\nData\nModel\nBias\nFeature\n\n\nOutliers and anomalies\nNew features\nIntegration with SageMaker Clarify for bias\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Sagemaker-Groud-Truth":{"title":"Sagemaker Groud Truth","links":["Rekognition","Comprehend"],"tags":["aws","sagemaker","data","annotation"],"content":"Model and human in the loop.\n\nMechanical Turk\nInternal team\nProfessional companies\n\nSimilar to Rekognition, Comprehend"},"4archives/AWS-Certified-Machine-Learning-Specialty/Semantic-Segmentation":{"title":"Semantic Segmentation","links":[],"tags":["aws","sagemaker","semantic-segmentation","computer-vision"],"content":"Input\n\nImages (JPG or PNG) with annotations\nAugmented manifest image format\n\nDetails\n\nGluon CV framework\n[1512.03385] Deep Residual Learning for Image Recognition backbone\n\nInstance Choice\n\nSingle GPU machine\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Seq2Seq":{"title":"Seq2Seq","links":[],"tags":["aws","sagemaker","machine-learning"],"content":"Input\n\nData in RecordIO Protobuf format with token ids\n\nHyperparameters\n\nBatch size\nOptimizer\nLearning rate\nNumber of layers\nMetric\n\nAccuracy\nPerplexity\nBLEU score\n\n\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/Step-Functions":{"title":"Step Functions","links":[],"tags":["aws","workflow"],"content":"It is useful for orchestrating workflows visually cross multiple services."},"4archives/AWS-Certified-Machine-Learning-Specialty/Time-Series":{"title":"Time Series","links":[],"tags":["aws","data","time-series","data-analysis"],"content":"Time Series\n\nTrends\nSeasonality\nCombination of both\nNoise (Additive or multiplicative)\n"},"4archives/AWS-Certified-Machine-Learning-Specialty/XGBoost":{"title":"XGBoost","links":[],"tags":["aws","machine-learning","xgboost","boosting"],"content":"eXtreme Gradient Boosting sagemaker.xgboost\nHyperparameters\n\nSubsample\n\nSubsample ratio of the training instances. Setting it to 0.5 means that XGBoost would randomly sample half of the training data prior to growing trees. and this will prevent overfitting. Subsampling will occur once in every boosting iteration.\n\n\nEta η\n\nalias: learning_rate\nStep size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative.\n\n\nGamma γ\n\nMinimum loss reduction required to make a further partition on a leaf node of the tree. The larger gamma is, the more conservative the algorithm will be.\n\n\nAlpha α\n\nL1 regularization term on weights. Increasing this value will make model more conservative.\n\n\nLambda λ\n\nL2 regularization term on weights. Increasing this value will make model more conservative.\n\n\neval_metric\nscale_pos_weight\n\nuseful for unbalanced data\n\n\nmax_depth\n\nprevents overfitting\n\n\n\nInstance Choice\n\nCPU: M5\nGPU: P3 (&gt;=1.2)\n"},"4archives/BASB/202203171851-Why-Do-We-Need-Digital-Notes":{"title":"202203171851 Why Do We Need Digital Notes","links":[],"tags":["BASB","PKM","note-taking","productivity"],"content":"Digital notes can help in the following areas:\n1. Building Connections\nWe all have access to massive information on the internet. What do we do with such information is what sets us apart. Building connections or drawing relationships is a very helpful and powerful action we can take upon such information. Digital notes, being a carrier of such information, makes it very easy to build connections – tagging, linking e.g.\nPersonally speaking, making connections implicitly means that we need to make efforts visiting notes and actively thinking and even rethinking about those notes. Those tags won’t tag themselves.\n2. We Are Visual Creatures\nSome interesting facts in this regard Humans Are Visual Creatures – Visual Communication of Science • Workshops &amp; Webinars\nDigital notes, along with modern note-taking apps, can help us learn visually, reducing the efforts needed to make connections even further. Some interesting features/apps such as:\n\nScrintal: A hybrid note-taking &amp; mind mapping whiteboard\nGraph view\n\n3. Incubating Ideas\nSitting on all the notes and connections, it is most likely you will bump into ideas that feel natural to think about. Just like open-floor offices encourage serendipitous encounters, digital notes encourage revisiting and refactoring and ultimately lead to birth of new ideas.\n4. Resources\nIdeas themselves aren’t enough. People have gazillions of ideas every day on earth, few of them really pan out. Digital notes, on one hand, give birth to new ideas through connections, on the other hand, provides data and supplementary information to support your ideas to the end."},"4archives/BASB/202204291344":{"title":"PARA","links":[],"tags":["BASB","PARA","CODE"],"content":"PARA\nPARA stands for Project, Area, Resource, and Archive.\nThe goal of PARA method is to organize your notes based on where it flows into.\nAera\n\nRole oriented: what is your responsibility assuming this role?\n\nYou have a standard to maintain even without some expected end goals;\n\n\nWork areas;\nPersonal areas;\n\nProject\nBased on your areas, you can have some ongoing projects that are:\n\nOutcome oriented: something is happening or will happen at some point in time;\n\nMeasurable: What is your objective?\nTrackable: How can you track the progress?\nCompletable: Can you cross this off from your list?\nActionable: What are the tasks needed?\n\nYou cannot do a project but only actions/tasks.\n\n\n\n\nThey are not a project if:\n\nNo deadline in sight\nNo outcome defined\nNo metric specified\nNo timeline scheduled\n\n\n\nQ: Why do we go from areas to projects?\nA: Figure out the projects based on your areas so that you have clear relation between your short-term efforts and your long-term goals.\nHaving a project mindset is like treating yourself as a one man vendor. Not only you have the tasks to finish, but also the resources and big picture that you need to consider.\nWhen a Project is Done\nKey actions at key moments:\n\nidea gathering when the project starts;\nrecycle the knowledge when the project ends;\n\nReflections upon completion:\n\nClean up tasks and goals\nSavage useful notes into proper folders\nArchive the rest of the project notes\n\nProject VS Hobby VS Dream\nHobbies do not contribute to your areas (unimportant)\nDreams do not have on-going projects (unachievable)\nResource\nInformation that contributes to ProjectArea]]\n\nMiscellaneous: interests or useful references;\nIf something that is not a project and does not fall into one of your areas, then it should be a resource;\n\nArchive\n\nInactive, obsolete projects, areas, or resources\n\nInformation Flow Based on Actionability\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimeActionabilityProject&lt; weeksmost actionableArealong-termactionableResourcesNAback-logArchiveNAread-only"},"4archives/BASB/202205011841-CODE":{"title":"202205011841 CODE","links":["4archives/BASB/202205011859-Capture","4archives/BASB/202203171851-Why-Do-We-Need-Digital-Notes","4archives/BASB/202205011857-Perspective","4archives/BASB/202205011858-12-Favorite-Problems","4archives/BASB/202205011901-Organize","4archives/BASB/202205011902-Distill","4archives/BASB/202205011903-Express"],"tags":["CODE","BASB","productivity"],"content":"CODE refers to C(apture)D(still)]]E(xpress)]].\nFrom 202203171851 Why Do We Need Digital Notes we know it is important to take notes for productivity and creativity. But before starting the CODE method that help us take better notes, it is important to reflect and recognize the motivation behind all these efforts. There are two different approaches we can take to help ourselves to understand better about why we need this CODE method, from a personal perspective.\n\n202205011857 Perspective\n202205011858 12 Favorite Problems\n\nWorkflow\n\n202205011859 Capture\n202205011901 Organize\n202205011902 Distill\n202205011903 Express\n"},"4archives/BASB/202205011857-Perspective":{"title":"202205011857 Perspective","links":[],"tags":["BASB","productivity"],"content":"Almost all information is accessible from the internet, so perspective – how we look at the information and convert it into knowledge – is what sets us apart.\nHow Does One’s Perspective Come into Being?\nYou can ask yourself a question: what do you remember deeply about {}? The answers are the foundation of your existence and source of your perspective.\n1. Place\n\nSmall town, everybody knows everybody else\nCool summer in the mountains\nKaraoke right below our apartment\nRiding to school everyday\n\n2. Family\n\nEducation is the highest priority\nSelf-dependent\nOnly child\nLiving with my parents and grandpa\nGrounded\nBig family with a lot of relatives\n\n3. Education\n\nGrades, grades\nLack of social knowledge\nStruggle with eyesight\n\n4. Experience\n\nStruggle with my sexuality\nLiving in a foreign country\nWork in school and in the industry\nFriends along the way\n"},"4archives/BASB/202205011858-12-Favorite-Problems":{"title":"202205011858 12 Favorite Problems","links":[],"tags":[],"content":"12 Favorite Problems\n\nRichard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, ‘How did he do it? He must be a genius!’\n– Gian-Carlo Rota, Indiscrete Thoughts\n\n\nHow to become a good software engineer?\nHow to become an efficient life-long learner?\nHow can I take steps to form relations?\nHow do I become a life-long minimalist?\nHow to communicate better with other people?\nHow to write or express myself in a more fluent way?\nHow to live rigorously?\nHow to become more active and motivated?\nHow to shift my attention from constantly worrying about self-improvement?\nHow to become vulnerable and strong at the same time?\nHow to take care of myself?\nWhat should I do to prevent anxiety and depression?\n\nThese questions are the journey we take on as a quest for answer, though answer itself is less relevant to the process as a result."},"4archives/BASB/202205011859-Capture":{"title":"202205011859 Capture","links":["4archives/BASB/202205011859-Capture","4archives/BASB/202205011858-12-Favorite-Problems","4archives/BASB/202205011900-Capture-Toolkit"],"tags":["BASB","CODE","PKM"],"content":"What Does Capturing Mean?\n\nSafeguard what information flows into the queue What is your filter;\nRemove content that is no longer interesting: if you skip it three times, remove it;\nOldest first or shortest first;\nKeep it separated from the second brain and only save the part that interests you in the second brain;\n\nReactivity Loop\nBy Capturing and not consuming right away, it shortens the reactivity loop such that we can stay in the workflow.\nInformation Diet\nInformation is food and you are what you eat. You can remind yourself by asking “am I consuming junk food?” every time you are thinking about capturing something.\nPossible Sources\n\nWebsites\nBooks\nVideos\nPodcasts\nPapers\nNewsletters\n\nIssues with Capture\nFrom one perspective regarding the output:\n\nOver-capturing: too much information is collected\nUnder-capturing: too little information is captured\n\nFrom another perspective regarding the workflow:\n\nTechnical issues: tools etc.\nReality: life change etc.\nMental blocks\n\nSo we need some control mechanism to guard the capturing gate – asking what is the goal of collecting this information? \nThis turns the capture process into a curation workflow, aka. capturing with an intention or a filter.\nWhat is Your Filter?\nFilter, or meaning, same thing here. It helps solicit the motivation and understanding of why we are looking for information in the first place. You can derive your filter based on 202205011858 12 Favorite Problems.\nEssentially, note-taking is very personal, and deeply tied to individual’s awareness of oneself.\nA Workflow for Yourself\nA project that we can use as a motivation, a drive and a filter to navigate our capture, such as creating a newsletter or journaling.\n202205011900 Capture Toolkit"},"4archives/BASB/202205011900-Capture-Toolkit":{"title":"202205011900 Capture Toolkit","links":[],"tags":["BASB","note-taking","productivity"],"content":"Why is it Important to Capture Information?\n\nInformation overload and exhaustion\nUnlimited access to massive information on-demand\n\nIf you don’t know it, you can’t even search it\nYou can’t internalize it from search engine results\nIs it the most suitable information?\n\n\n\nWhat Should We Capture?\n\n\nMotivational and inspiring\nUseful and practical\nSurprising and eye-opening\nPersonal\n\nStories\nExperiences\nInsights\nMemories\n\n\n\nOr follow the rule of thumb – capture what resonates. \nHow Do We Capture?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAreasAppsNote-takingObsidianSocial mediaTwitter + Reddit + Raindrop.io + MatterWeb clipperMatter + Raindrop.ioAudio/VideoSnipdeBookReadwise + KindleRead it LaterMatter + Raindrop.ioPaperZotero"},"4archives/BASB/202205011901-Organize":{"title":"202205011901 Organize","links":["4archives/BASB/202204291344"],"tags":["BASB","PKM","CODE","PARA"],"content":"Archive the past, and move on. A fresh start by archiving everything you have right now helps you focus on the goal, not the mess you are in right now. At the end of the day, it is the creative projects completed that matters.\nFor starters:\n\nArchive your current notes\nCreate an inbox folder for future notes\nFollow the PARA method\n\nWhen it comes down to organizing them, put index notes in projects first, if possible. This way,2 we put more emphasis on enabling the notes."},"4archives/BASB/202205011902-Distill":{"title":"202205011902 Distill","links":["4archives/BASB/202205011903-Express","4archives/BASB/202205011904-Progressive-Summarization","4archives/BASB/202205011900-Capture-Toolkit"],"tags":["CODE","BASB","Distill","note-taking","productivity"],"content":"Note as First-class Citizen\nWhen distilling notes, one could have many perspectives:\n\nTag first: it shows connections but carries no structure and therefore no progress (to track);\nFolder first: it enforces structure and hierarchical organization but not connections;\nNote first: you can still have tags in the note and notes in a folder but the mindset here is that you put more work on the note itself. For example, making connections between notes by directly linking them and refactoring them into atomic notes or Intermediate Packets so that you can reuse them in the future.\n\nBy taking Note First mindset, you choose to enjoy your notes.\nGoal of Distillation\nMaking your notes more:\n\nmeaningful\nconcrete\nvaluable\n\nHow to Distill\nUnderstand the layers of information Progressive Summarization:\n\nRaw source information\nCaptured notes\nRefined notes (Bolded, Highlighted, Dissected, Grouped or Summarized)\n\nGoing through this workflow or layer of transformations, aka refining, you are essentially engaging with your notes.\nNot to Do When Distilling\nYou Can’t Save Everything and You Don’t Need to\nCompressing or distilling your notes makes everything else more efficient – easier to remember(useful) and retrieve(accessible). Your notes should not be an ever expanding archive of information.\nYou Can’t Analysis Everything\nFollowing the Resonance Rule of Capturing, we also need such guidance in distillation.\nWe don’t necessarily have the mental energy to analyze all the captured notes, not to mention distilling all of them by scrutiny."},"4archives/BASB/202205011903-Express":{"title":"202205011903 Express","links":["Express-2022-04-30-10.48.36.excalidraw","Deep-Work","Atomic-Habits","tags/productivity/zettelkasten"],"tags":["BASB","CODE","PKM","note-taking","productivity","productivity/zettelkasten"],"content":"Return on Attention\nPouring our attention into notes and expressing ourselves is an investment of ourselves and our future. We can simplify this investment as a clean equation:\nAttention InvestedReturn​\nThe Return in this case can be different forms of our expression, such as blog post or youtube videos.\nTypical Attention Investment Curve\nTransclude of Express-2022-04-30-10.48.36.excalidraw\nThere will be friction in any kind of work nonetheless. We need recognize that and understand that such frictions might contribute to our procrastination. (On how to reduce the friction and inducing more Deep Work or Atomic Habits)\nAny interruptions that happening during the setup phase, it restart the whole process, meaning we have to go through the struggle all over again.\nIntermediate Packets\nIt refers to the intermediate and modular results of your workflow. For example, in the following work session, 4 ~ 7 can be intermediate packets.\n\nResearch\nNotes\nBrainstorms\nExamples\nOutlines\nPrototypes\nDrafts\nLast-minute crazy ideas\nFinal deliverables\n\nSuch packets, usually refined, can be reused in future projects. (This echos the concept of atomic notes fromzettelkasten where notes can live and connected simultaneously in multiple places)\nBy reframing projects into sequential of intermediate packets/tasks, you can marginalize the destructions interruptions can cause.\nHow to Create Intermediate Packets\nCreating intermediate packets is equal to expressing in this case.\n\nObserving, not an expression itself, is the prerequisite for all expressions. e.g. taking notes and consuming ideas.\nWriting\nDrawing\nActing\nProducing\nSelling\n\nWhy Express is Important\nVico, Giambattista | Internet Encyclopedia of Philosophy\nThe Verum-Factum Principle\n\nPerhaps the greatest significance of the Ancient Wisdom lies in its presentation of the verum-factum principle. This and the ideal eternal history are Vico’s two most famous ideas. The verum-factum principle holds that one can know the truth in what one makes. Vico writes, “For the Latins, verum (the true) and factum (what is made) are interchangeable, or to use the customary language of the Schools, they are convertible (Ancient Wisdom 45).”\n"},"4archives/BASB/202205011904-Progressive-Summarization":{"title":"202205011904 Progressive Summarization","links":["4archives/BASB/202205011900-Capture-Toolkit"],"tags":["CODE","BASB","Distill","Progressive-Summarization"],"content":"Any Form of Summarization is a Future Investment\nHighlighting or summarization is about deciding what to forget and what to remember.\nResonance as Guideline\nSame as in the capture guideline What should we capture\nThink About Use-cases\nWhy do you capture this in the first place? Do you have a use-case for this piece of information? “What dishes can you cook with this ingredient?”"},"4archives/BASB/202205052039-The-Creative-Process":{"title":"202205052039 The Creative Process","links":["Algorithms-to-Live-By","4archives/BASB/202205011859-Capture","4archives/BASB/202205011902-Distill"],"tags":["BASB","CODE"],"content":"Divergence\nLike exploration phase from Algorithms to Live By. This is the time where you explore different ideas and take different approaches.\nThis is also a stage that CaptureOrganize]] take place.\nConvergence\nThis is where you make the decision, on where to go, what to do or how to do it. Much like the exploit phase in Algorithms to Live By as well. This is the stage where we will produce.\nThis is when DistillExpress]] take place.\nMost people get stuck in the Divergence phase because of:\n\nShiny object syndrome - Wikipedia\nFear of cutting options for Convergence\n"},"4archives/BASB/202205121949-Retrieval":{"title":"202205121949 Retrieval","links":[],"tags":["BASB","PKM","CODE"],"content":"Four Stages of Retrieval\n\nSearch\n\nMoving related notes into one folder and directly work with them in a central place\n\n\nBrowse\nTags\nSerendipity\n"},"4archives/BASB/Tagging":{"title":"Tagging","links":[],"tags":["PKM","BASB","note-taking"],"content":"Tags are seen as virtual spaces or directories that one document can be living in those spaces simultaneously.\n"},"4archives/BASB/Write-of-Passage":{"title":"Write of Passage","links":["4archives/BASB/202205011903-Express","4archives/BASB/202205011841-CODE","Atomic-Habits"],"tags":["BASB","PKM","writing"],"content":"Writing is the staple of expression.\n80% Finished\nWithin the process of CODEexpress]] stage, you are actually 80% finished with your writing. You are not staring into the white screen with nothing.\nTo further reduce the friction of writing, you can now live with research or the first three parts of CODE on back burner.\nCompounding\n\nTaking notes is the closest thing we have to time travel.\n\nKendrick Lamar\n\n\nWriting is also an investment itself and we sure love the compounding returns.\nRepeatable\nOld but really useful saying like practice makes perfect and writing is no exception. Make it a habit, even better."},"4archives/BASB/folder_BASB":{"title":"BASB Overview","links":[],"tags":[],"content":"BASB Overview\ntype: folder_brief_live\nBuild a second brain."},"4archives/BigScience/Datasets/Arabic":{"title":"Arabic","links":[],"tags":["research","deduplication","projectnotes"],"content":"Arabic\n\nIdentifier::ar\nLanguage::Arabic\nPhysical Size::28.2 GB\nNumber of Rows::8051306\nUnique URLs:: 8048055\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 16583, 3: 7440, 2: 3110, 1: 954}\nSimHash Results:: 28087 matches/5748 clusters/17759 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 27445144911\nSubstring Duplicate Size:: 8130859489 (29.63%)\n\nExamples\n\n\n\n\n"},"4archives/BigScience/Datasets/Basque":{"title":"Basque","links":[],"tags":["research","deduplication","projectnotes"],"content":"Basque\n\nIdentifier::eu\nLanguage::Basque\nPhysical Size::562.7MB\nNumber of Rows::323806\nUnique URLs:: 323712\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 19794, 3: 6401, 2: 1872, 1: 504}\nSimHash Results:: 28571 matches/1884 clusters/8886 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 490184121\nSubstring Duplicate Size:: 49850895 (10.17%)\n\nExamples\n(4) Asteburu hau musikaz betea izango dugu. Ostiralean, Areetako Andres Isasi musika eskolan, Gintonik taldearen eskutik, kontzertu didaktikoa izango dugu. Bertan, entseguetan eta obrak prestatzeko tekniken eta prozeduren inguruan hitz egingo digute. Kontzertua 19:00 hasiko da eta sarrera gonbidapenekin kontrolatuko da. Beraz, gonbidapena lortzeko, eskolako idazkaritzatik lehenago pasatzea gomendatzen dizuegu, izan ere, ikusle asko espero dira.\n\n(4) Ostiralean, Areetako Andres Isasi musika eskolan, Gintonik taldearen eskutik, kontzertu didaktikoa izango dugu. Bertan, entseguetan eta obrak prestatzeko tekniken eta prozeduren inguruan hitz egingo digute. Kontzertua 19:00 hasiko da eta sarrera gonbidapenekin kontrolatuko da. Beraz, gonbidapena lortzeko, eskolako idazkaritzatik lehenago pasatzea gomendatzen dizuegu, izan ere, ikusle asko espero dira.\n\n(4) Zapatuan, urriaren 6an, Ikasleen Igeri Topaketak izango dira, Urolako Eskola Kirola Kontseiluak benjaminentzat eta alebinentzat prestatutako egutegiari jarraituta. Hain zuzen, LH3ko, LH4ko, LH5eko eta LH6ko ikasleen denboraldiko lehen topaketa izango da Azpeitiko Igerilekuan.\n\n(4) Zapatuan, otsailaren 9an, Ikasleen Igeriketa Topaketak izango dira, Urolako Eskola Kirola Kontseiluak benjaminentzat eta kimuentzat prestatutako egutegiari jarraituta. Hain zuzen, LH3ko, LH4ko, LH5eko eta LH6ko ikasleen denboraldiko bigarren topaketa izango da Azpeitiko Igerilekuan.\n\n(4) Bilaketak 36472 emaitza ditu, eta horietatik lehenengo 10000 emaitzak agertuko dira soilik. Mesedez, zehaztu bilaketaren irizpideak emaitza zehatzagoak izateko.\n\n(4) Bilaketak 67580 emaitza ditu, eta horietatik lehenengo 10000 emaitzak agertuko dira soilik. Mesedez, zehaztu bilaketaren irizpideak emaitza zehatzagoak izateko.\n\n(3) &#039;&#039;&#039;Baluarte&#039;&#039;&#039;, jauregiaofizialki &#039;&#039;&#039;Baluarte Batzar Jauregia eta Nafarroako Auditorioa&#039;&#039;&#039;, [[Iruñea|Iruñeko]] musika gune eta biltzar jauregia da, [[Patxi Mangado]] arkitekto lizarratarrak eraikia.\n\n(3) &#039;&#039;&#039;Baluarte&#039;&#039;&#039;, ofizialki &#039;&#039;&#039;Baluarte Batzar Jauregia eta Nafarroako Auditorioa&#039;&#039;&#039;, [[Iruñea|Iruñeko]] musika gune eta biltzar jauregia da, [[Patxi Mangado]] arkitekto lizarratarrak eraikia.\n"},"4archives/BigScience/Datasets/Bengali":{"title":"Bengali","links":[],"tags":["research","deduplication","projectnotes"],"content":"Bengali\n\nIdentifier::bn\nLanguage::Bengali\nPhysical Size::5GB\nNumber of Rows::841724\nUnique URLs:: 841571\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 377, 3: 221, 2: 108, 1: 50}\nSimHash Results:: 756 matches/273 clusters/638 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 5008061572\nSubstring Duplicate Size:: 1440245010 (28.76%)\n\nExamples\n\n\n"},"4archives/BigScience/Datasets/Catalan":{"title":"Catalan","links":[],"tags":["research","deduplication","projectnotes"],"content":"Catalan\n\nIdentifier::ca\nLanguage::Catalan\nPhysical Size::5GB\nNumber of Rows::2452837\nUnique URLs::2451968\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 3254, 3: 1758, 2: 835, 1: 329}\nSimHash Results:: 6176 matches/1779 clusters/5096 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 4650012960\nSubstring Duplicate Size:: 493713636 (10.61%)\n\nExamples\n(4) Comptem amb molts anys d&#039;experiència en la realització d’activitats familiars a prop de Conesa adaptades segons el nombre de persones, i tant per adults com per nens. Som especialistes en activitats Físico Esportives en el Medi Natural, i, des d’Esportec, volem donar a conèixer les possibilitats que ofereix el nostre entorn, ja sigui al mar o a la muntanya.\nÉs de coneixement general que la pràctica habitual d’esports o les visites culturals tenen una sèrie de beneficis que enforteixen els llaços d’amistat i familiars, i val la pena realitzar activitats a Conesa amb amics que fomentin i millorin la capacitat física i mental, i que alhora siguin activitats d&#039;esbarjo i diversió.\n\n(4) Comptem amb molts anys d&#039;experiència en la realització d’activitats familiars a prop de La Llagosta adaptades segons el nombre de persones, i tant per adults com per nens. Som especialistes en activitats Físico Esportives en el Medi Natural, i, des d’Esportec, volem donar a conèixer les possibilitats que ofereix el nostre entorn, ja sigui al mar o a la muntanya.\nÉs de coneixement general que la pràctica habitual d’esports o les visites culturals tenen una sèrie de beneficis que enforteixen els llaços d’amistat i familiars, i val la pena realitzar activitats a La Llagosta amb amics que fomentin i millorin la capacitat física i mental, i que alhora siguin activitats d&#039;esbarjo i diversió.\n\n(4) És de coneixement general que la pràctica habitual d’esports o les visites culturals tenen una sèrie de beneficis que aprofiten les empreses per organitzar activitats de teambuilding a Aiguaviva per empreses que fomentin el treball en equip i la cohesió amb l’objecte de millorar la relació entre els treballadors i l’empresa.\nL’estratègia consisteix a realitzar activitats de treball en equip a Aiguaviva fora dels horaris laborals per així generar en els treballadors la sensació que es tracta de jornades d’oci on poden socialitzar amb els seus companys. Per aquest motiu, des d’Esportec, per a qualsevol estació de l’any plantegem una sèrie d&#039;experiències de teambuilding a la zona de Aiguaviva ideals per aconseguir aconseguir el treball conjunt i efectiu dels treballadors arran d’aquestes pràctiques.\n\n(4) És de coneixement general que la pràctica habitual d’esports o les visites culturals tenen una sèrie de beneficis que aprofiten les empreses per organitzar activitats de teambuilding a Fonollosa per empreses que fomentin el treball en equip i la cohesió amb l’objecte de millorar la relació entre els treballadors i l’empresa.\nL’estratègia consisteix a realitzar activitats de treball en equip a Fonollosa fora dels horaris laborals per així generar en els treballadors la sensació que es tracta de jornades d’oci on poden socialitzar amb els seus companys. Per aquest motiu, des d’Esportec, per a qualsevol estació de l’any plantegem una sèrie d&#039;experiències de teambuilding a la zona de Fonollosa ideals per aconseguir aconseguir el treball conjunt i efectiu dels treballadors arran d’aquestes pràctiques.\n\n(4) Aquesta informació es va publicar originalment el 8 de març de 2018 i, per tant, la informació que hi apareix fa referència a la data especificada.\n\n(4) Aquesta informació es va publicar originalment el 22 de febrer de 2018 i, per tant, la informació que hi apareix fa referència a la data especificada.\n\n(3) Sol utilitzar-se el signe «més» al començament del número de telèfon en aquest format. Tanmateix, és més habitual substituir el signe «més» per una seqüència de números que avisa a la xarxa telefònica que vostè vol marcar un número de telèfon d&#039;un altre país. La UIT recomana utilitzar el 00, que també s&#039;utilitza en molts països, inclosos tots els països europeus. Com a alternativa a +36 85, que ha de marcar abans del número de telèfon d&#039;una persona de Marcali per trucar-la des de Espanya, també pot utilitzar 0036 85.\n\n(3) Sol utilitzar-se el signe «més» al començament del número de telèfon en aquest format. Tanmateix, és més habitual substituir el signe «més» per una seqüència de números que avisa a la xarxa telefònica que vostè vol marcar un número de telèfon d&#039;un altre país. La UIT recomana utilitzar el 00, que també s&#039;utilitza en molts països, inclosos tots els països europeus. Com a alternativa a +86 778, que ha de marcar abans del número de telèfon d&#039;una persona de Hechi per trucar-la des de Espanya, també pot utilitzar 0086 778.\n"},"4archives/BigScience/Datasets/Chinese":{"title":"Chinese","links":[],"tags":["research","deduplication","projectnotes"],"content":"Chinese\n\nIdentifier::zh\nLanguage::Chinese\nPhysical Size::93.7GB\nNumber of Rows::47541361\nUnique URLs:: 47499144\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 418711, 3: 217132, 2: 92562, 1: 29997}\nSimHash Results:: 758402 matches/97169 clusters/307118 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 87259637377\nSubstring Duplicate Size:: 28186394472 (32.30%)\n\nExamples\n(4) 管托//保温空调管托 主要原料以红松、白松及杨木为主，经过沥青漆侵泡和防水处理，具有防虫蛀、不吸水、防震、保温、隔冷、隔热等特点，适用于冶金、石油、化工、车辆、船舶、电力等机械机械液压系统中的油、气、水为介质的固定管道的安装。是油、气、水管道固定的理想用品。\n\n(4) 公司推荐 防腐空调管托 主要原料以红松、白松及杨木为主，经过沥青漆侵泡和防水处理，具有防虫蛀、不吸水、防震、保温、隔冷、隔热等特点，适用于冶金、石油、化工、车辆、船舶、电力等机械机械液压系统中的油、气、水为介质的固定管道的安装。是油、气、水管道固定的理想用品。\n\n(4) 延緩射精 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 瑜伽十分鐘速效燃脂 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。屈臣氏日本藤素 17歲陽瘺的最佳治療方法宫颈炎患者案列患上宫颈炎的症状人人健康 藥局買威而鋼 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 早洩吃六味地黃丸有用嗎 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 陰莖增粗 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 立大藥局 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 印度神油把我害苦 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。.\n\n(4) 美好挺藥局 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 購買必利勁的處方圖片 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 液態威心得 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 萬艾可好還是希愛力好能喝酒嗎 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 威爾剛哪裡買 男速效壯陽藥龜頭敏感團購與推薦月飛比價格 怎麼提高持久度和硬度 治療勃起不堅 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。\n\n(4) ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 威爾鋼,日本藤素效果,壯陽藥屈臣氏,德國黑金剛,威爾剛買,美國黑金,犀利士學名藥,前列腺肥大主要症狀①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 曹毅从肝肾阴虚论治痤疮经验 保健品銷售渠道有哪些各渠道銷售比重是多少 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 希愛力雙效片見效時間 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 日本藤素屈臣氏 [持久液哪裡買 ①本网所有内容均来自互联网或网友投稿，目的在于传递更多信息，并不代表本网赞同其观点或证实其内容的真实性，不承担此类作品侵权行为的直接责任及连带责任。其他媒体、网站或个人从本网转载时，必须保留本网注明的作品来源，并自负版权等法律责任。 大樹藥局犀利士 威而鋼吃半顆\n雅迪克延時噴劑的效果 網上買的延時藥有用嗎 改善女人性冷淡偏方 必利勁和萬艾可可以同時服用嗎 吃了壯陽藥會引起濕疹嗎 什麼壯陽藥最好 印度神油價格多少 希愛力一片幾粒 早洩如何自我治療 跑步對前列腺有好處嗎1003無標題 前列腺鈣化影響性功能嗎 前列腺囊腫後果 速效口服壯陽藥貨到付款 延時藥外用 印度神油用完勃不起來 前列腺並發症有哪些 犀利士副作用有用嗎多少錢 前列腺肥大早期症狀如何治療 壯陽補腎藥酒配方 使用達泊西汀真實效果口述 前列腺鈣化灶如何治療 印度女神之戀性藥 金戈屬於速效藥嗎 日常生活中補腎壯陽的食物 延時濕巾正確步驟 前列腺的自我療法 五粒裝萬艾可多少錢一盒 治療早洩的鍛煉方法 性保健品在哪裡進貨 人初油延時噴劑危害 女人性冷淡是什麼原因引起的 更年期症狀有哪些女性 更年期最嚴重的症狀 前列腺初期症狀都有哪些方面 微商夫妻保健品加盟 補腎壯陽速效藥自製 犀利士效果持續多久 犀利士的用途 犀利士噴了沒效果怎麼樣 用犀利士要帶套嗎 我不是藥神犀利士店前面那條街是什麼街 第一次吃必利勁的感受 犀利士使用視頻噴的 王子犀利士店圖片 必利勁提前多長時間吃 經常用犀利士好嗎 犀利士噴劑過期了還能用嗎 必利勁長期服用可治愈嗎 男人第一次用犀利士好不好 印度神油害了我噴的 医生为啥不建议服用必利劲 按摩哪些穴位對前列腺好 吃什麼補腎壯陽 印度希愛力真假 鹽酸達泊西汀片能根治早洩 更年期綜合症的表現及調理 癌症吃什麼保健品 勃起噴劑對身體有害嗎 精索靜脈曲張和前列腺炎 有哪些延時壯陽藥 長期服用速效壯陽藥的危害\n\n2020CPA考试时间科目安排已经公布，还不是很清楚考试时间的考生，也不要担心，小编整理了相关内容，大家快和小编一起来了解一下吧！一、2020cpa考试时间科目安排综合阶段考试：2020年10月11日8:30-12:00 职业能力综合测试（\n2020CPA科目考试时间具体是哪一天大家知道吗？大家在考试之前别忘记打印准考证。准考证建议大家多打几分以备不时之需。下面小编整理了相关内容，快来看一看吧！一、2020cpa科目考试时间综合阶段考试：2020年10月11日8:30-12:0\n对于考生来说，注册会计师经济法主观题有点难，因为需要记忆的地方真的太多了。很多考生咨询和经济法主观题分数有关的信息，那么cpa经济法主观题一般能得多少分，不了解的快来看看吧。 一、cpa经济法主观题一般能得多少分 cpa\n\n(3) 二手250型卧螺离心机转让由于其先天具有处理量大、自动化操作、脱水效果好等特点，在环境保护领域得到了广泛的使用和推广。卧螺离心机单品销售额占到了所有离心机产品的一半左右，奠定了其不可替代的地位。在国外，污水处理设备卧螺离心机。\n二手250型卧螺离心机转让一般可分为卧式螺旋过滤离心机和卧式螺旋沉降离心机。 卧螺离心机是一种卧式螺旋卸料、连续操作的沉降设备。本类离心机工作原理为:转鼓与螺旋以一定差速同向高速旋转，物料由进料管连续引入输料螺旋内筒，加速后进入转鼓，在离心力场作用下，较重的固相物沉积在转鼓壁上形成沉渣层。输料螺旋将沉积的固相物连续不断地推至转鼓锥端，经排渣口排出机外。较轻的液相物则形成内层液环，由转鼓大端溢流口连续溢出转鼓，经排液口排出机外。本机能在全速运转下，连续进料、分离、洗涤和卸料。具有结构紧凑、连续操作、运转平稳、适应性强、生产能力大、维修方便等特点。适合分离含固相物粒度大于0.005mm，浓度范围为2-40%的悬浮液。广泛用于化工、轻工、制药、食品、环保等行业。[1] 设备工作原理 折叠编辑本段选型 选择合适的卧螺离心机不仅可以解决生产问题、提高工作效率，同时也节约了生产成本，降低了经营风险。影响选型的主要因素有以下几点: 1.离心机的转速:一般卧螺离心机应在3000转以上，转速越高，离心机分离因数越高，分离效果就越好。 2.离心机的材质:不同材质其耐磨性、耐蚀性等理化指标不一样，国外的卧螺离心机一般最低材质为316L,或双相不锈钢，磨蚀元件须选用陶瓷合成材料。 3.离心机的差速控制:不同的差速器控制精度不同，且寿命及维修成本差距很大，差速精度越高，对物料的适应性越好，故宜选用差速精度高的设备。 4.长径比:卧螺离心机的长径比越大，其处理能力也越大，含湿率则越小。 5.控制系统:是否为自动化编程控制，目前国内外设备厂商已基本实现了该设备的全自动化控制。 6.安装功率:影响到能耗的控制、一般国内的设备能耗比高、国外的能耗比低。 7.加工制作工艺:卧螺离心机属于高精度加工要求的分离设备，不具有精加工能力的企业生产的产品维修率高，处理能力有限。[1]二手250型卧螺离心机转让\n\n山河智能SWDM160旋挖鉆機價格 三一SY285C9履帶挖掘機價格 吉尼GenieGH?-3.8超級提升機參數 山河智能SWRP580E鉤掘機價格 洛陽路通LTS316H全液壓單鋼輪壓路機價格 志高ZGYX-451整體式液壓潛孔鉆機參數 南方路機廠拌設備 東方之星DFR10輪式半回轉旋挖鉆機參數 利勃海爾LR1300履帶式起重機價格 柳工CLG628H全液壓振動壓路機參數 安百拓XAHS710Cd中型移動式空氣壓縮機參數 盛隆機械HBT50S1690C拖泵價格 寶鼎WYL75-7輪式挖掘機參數 森源重工Q25S汽車起重機價格 水山TD-45液壓鑿巖機參數 山寶PYGD-1411液壓圓錐破碎機參數 斗山DH60-7履帶挖掘機價格 中聯重科QAY260V733全路面起重機價格\n\n怎樣算早洩 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 早洩初期治療注意事項 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。女用印度女用偉妹 我是中国人我要回国岁中国天才拒绝美国绿卡回国好样的 印度神油 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 民間最猛壯陽酒的配方 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 日本藤素屈臣氏 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 美國黑金 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 延時杯百度百科 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。.\n参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 增大軟膏 怎么锻炼治早迣图关于痛风 必利勁副作用 前列腺液能檢查出什麼病 台灣威而鋼 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 陽痿怎麼辦 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 悍馬糖 聚易堂活动温州站易车与汽车经销商论道车险科技 伽拉陀印度神油好不好 他達拉非片哪個牌子好.\n阿拉伯擠奶 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 前列腺鈣化灶的症狀 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 腦速通價格 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 萬艾可跟金戈必利勁區別 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 樂威壯哪裡買 哮喘藥物最好的噴霧劑商丘看阳痿最好的医院阿吖萨德新浪博客 前列腺摘除術會影響生育嗎 便宜有效的壯陽藥 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。\n参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 犀利士價錢,男性持久液,犀利士哪裡買,超級延時温和助勃增硬雙效片,他達拉非,犀利士藥房,必利勁藥局,印度希愛力雙效官網参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 丁肇慰长江流域年生态系统质量及国际环保在线 必利劲什么时候出来的 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 多次網購希愛力雙效後 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 台製威而鋼 [犀利士副作用 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 美國黑金評價 性欲高涨欲罢不能\n他達拉非片片多少一盒 印度神油功效與用法 網上賣的延時噴劑有用嗎 前列腺增生症狀及治療方法圖解 前列腺全切除手術 東方保健品招商網站 增大陰莖的藥物是永久性的嗎 老中醫男性陽痿早洩偏方 必利劲对胃有影响吗 必利勁頭暈噁心 印度神油用多了好嗎 進口印度神油的作用與功效 joker助勃鎖精環 希愛力雙效片有副作用嗎 國內最好壯陽藥排行榜 速效口服壯陽藥正品 男性性功能障礙治療要多少錢 5到8分鐘見效壯陽酒配方 男用增大增長藥有哪些藥名 速效壯陽藥一粒見效批發一想就硬 最新速效延時壯陽藥 正常人第一次吃希愛力 前列腺炎難治療經歷 保健品女用藥品 weroilson男士包 提高延時訓練方法 治療舉而不堅中藥偏方 按摩前列腺小說 朱良春治陽痿早洩驗方 印度神油戴套嗎 前列腺按摩器舒服嗎 前列腺增生應注意什麼 前列腺炎按摩視頻大全 必利劲使用效果 早洩吃什麼藥好 吃了希愛力如何減輕副作用 增大增長膏的用法圖 30歲功能性痿陽怎麼自我恢復 治早迣手法視頻 早洩微創手術的危害 吃什麼中藥治陽萎早射 利必勁服用最佳時間 永久降低龜敏感方法 必利勁藥店能買到嗎 必利勁說明書 陽痿的症狀分中德 前列腺支架手術後遺症 吃完必利勁不做有影響嗎 男性陽痿怎麼治療 萬艾可多久起效 日本最好的壯陽藥排名 要小孩能用延時噴劑嗎 東風男科醫院 壯陽藥吃多了會死人嗎 前列腺炎怕不育 最常見的前列腺炎類型 求早洩中藥配方 必利勁的副作用是什麼 安太醫延時噴劑害人不淺 口碑好的壯陽藥 女性更年期盜汗吃什麼藥好\n\n(3) 威而剛購買 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 前列腺炎和腎虛有關嗎 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。犀利士購買藥局 犀利士酒後能服用嗎我想问下淘宝卖的阴茎增大器有用吗有没有副作用热备资讯 男用威而鋼 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 必利劲能和金戈一起服用吗 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 怎樣算早洩 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 液態威心得 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 前列腺切除術後膀胱沖洗的護理 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。.\n参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 液態威而鋼 天津樂威醫藥薪資待遇增大膏效果真实吗真相大揭开难友看来热备资讯 印度威爾鋼威而鋼雙效片 用延時噴劑好不好 更年期保養 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 如何補腎 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 速效增硬持久助勃壯陽藥 产业卖点遭质疑食用油不是保健食品 壯陽藥有副作用嗎 屈臣氏美好挺.\n必利勁騙人的 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 治療鼻炎的中藥噴劑有什麼 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 必利勁哪裡買 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 印度希愛力雙效片最好品牌 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 日本藤素可以每天吃嗎 如何讓自己更持久一點男保健品中药价格报价行情京东 真空助勃器的好處 日本藤素沒用 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。\n参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 爾剛助勃持久,抽菸陽痿,威爾剛買,威而鋼網購,犀利士價錢,必利勁副作用,陰莖增粗,前列腺增生是什麼情況参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 高端商务出行的首选座驾搭大众强动力试驾大众威然 享久三代噴劑使用說明 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 更年期心悸是冠心病嗎 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 犀利士吃半顆 [汗馬糖副作用 参考文献过于陈旧虽然不能说研究没有创新，但说明并非当前研究的热点，没有人研究和解决可以认为是前沿但选题的重要性也就值得怀疑。一些经典性文献长期以来被人引用，文献被引用的半衰期长短也是评价期刊和论文的理论性强弱的指标，但是从现有研究的文献引用情况来看，近五年的研究成果应该占有较大的比例。如果近五年里有很少相关的文献发表，那只能讲论文的选题并不被人们广泛关注。 犀利士吃兩顆 日本騰素正品\n什麼藥助勃延時 更年期喝什麼茶 物理延時套有效果嗎 老人前列腺增大伴鈣化 治療不孕不育哪裡好高效南京新協和看 萬艾可和希愛力一起吃 前列腺在哪裡 希愛力5毫克吃4粒 延時壯陽噴劑 國產壯陽藥那個品牌好 必利勁治什麼 extenze是什麼藥 犀利士在哪買 吃必利勁帶套有效果嗎 no17延時噴劑有用嗎 帕羅西汀治療早洩嘛 男人前列腺針灸視頻 真空助勃器使用壞處 藥品與保健品的區別有哪些 女性更年期怎麼保養 外用延時藥哪種好 讓女人舒服的六個姿勢圖解 哮喘片的功效與作用 壯陽藥排行榜壯陽中藥 黑金剛壯陽藥價格多少錢一盒 保健品圖片素材 女性先絕經還是先更年期 女神之戀藥房有賣嗎 合肥早洩醫院 速勃根的作用 增大增粗國藥准字藥品 治療頸椎病最好的膏藥 吃壯陽藥懷孕有影響嗎 印度雙效片使用方法 前列腺炎喝水有用嗎 吃什麼能夠治療早洩 吃金鎖固精丸多少錢一盒 潤喉糖多久吃一粒 好的男科醫院是哪家 陰痿有什麼症狀 簡單偏方冶陽萎 陽萎早謝吃什麼藥最好 中德醫院 牙科哪個醫院好點 心臟支架後不能勃起的原因 早洩微創手術的危害 必利勁什麼時候吃效果最好知乎網 說男的萎了啥意思 陽痿的症狀是什麼 必利勁吃幾個療程能治愈 怎麼壯陽 男性早洩吃六味地黃丸 延時龍水多少錢一瓶 必利劲多少一疗程 希愛力代謝時間 拼多多上的噴劑能用嗎 必利劲是白色的还是蓝色的 必利劲治疗效果好吗 延時套哪種好 前列腺液提取的故事 吃中藥真能讓陰莖二次發育嗎\n\n"},"4archives/BigScience/Datasets/English":{"title":"English","links":[],"tags":["research","deduplication","projectnotes"],"content":"English\n\nIdentifier::en\nLanguage::English\nPhysical Size::1TB\nNumber of Rows::413161976\nUnique URLs:: 413027882\nSimHash Tokenization::space-delimited 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 2028873, 3: 920150, 2: 330228, 1: 88703}\nSimHash Results:: 3367954 matches/228591 clusters/921522 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 982249623332\nSubstring Duplicate Size:: 200379191637 (20.40%)\n\nSpace-delimited tokenization is used mainly for speed."},"4archives/BigScience/Datasets/French":{"title":"French","links":[],"tags":["research","deduplication","projectnotes"],"content":"French\n\nIdentifier::fr\nLanguage::French\nPhysical Size::125.4GB\nNumber of Rows::55011257\nUnique URLs:: 54985905\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 1378902, 3: 546653, 2: 185761, 1: 47671}\nSimHash Results:: 2158987 matches/87682 clusters/476997 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 71307735562\nSubstring Duplicate Size:: 20661579444 (17.55%)\n\nExamples\n(4) Butterlin est un domaine référencé dans notre logiciel GRATUIT de gestion de cave à vin. cliquez ici pour créer gratuitement votre propre compte.\n\n(4) Château Villars est un domaine référencé dans notre logiciel GRATUIT de gestion de cave à vin. cliquez ici pour créer gratuitement votre propre compte.\n\n(4) En outre, Traitement peinture est susceptible d’acheter des espaces publicitaires directement ou par l’intermédiaire de prestataires (agences de conseil en communication) afin de promouvoir ses activités et ses offres sur des sites ou applications de tiers, au moyen de contenus publicitaires (texte, graphismes, animations, vidéos, etc.) diffusés par ces sites ou applications. De même, des cookies sont susceptibles d’être inclus dans les espaces publicitaires du Site. Ces espaces publicitaires affichent sur votre terminal des contenus publicitaires émanant d’annonceurs. Ces espaces contribuent au financement des contenus et des services que Traitement peinture met à votre disposition. Lors de l’affichage de tels contenus publicitaires, des informations relatives à la navigation de votre terminal (ordinateur, tablette, smartphone, etc.) sont susceptibles d’être enregistrées dans des fichiers « cookies » installés sur ce terminal, sous réserve des choix exprimés concernant les cookies. Sachez que seul l’émetteur d’un cookie est susceptible de lire ou de modifier des informations qui y sont contenues. Afin de permettre à nos systèmes de reconnaître votre appareil et de vous fournir des fonctionnalités, nous utilisons des « cookies ». Pour plus d’informations concernant les cookies et l’usage que nous en faisons, veuillez vous référer à la section ci-dessus.\nparticipe au Programme Partenaires d’Amazon EU, un programme d’affiliation conçu pour permettre à des sites de percevoir une rémunération grâce à la création de liens vers Amazon.fr. L’utilisateur reste tout à fait libre de chercher les produits Amazon.fr par lui-même s’il préfère ne pas passer par les liens du site.\n\n(4) En outre, Meilleur Luminaire est susceptible d’acheter des espaces publicitaires directement ou par l’intermédiaire de prestataires (agences de conseil en communication) afin de promouvoir ses activités et ses offres sur des sites ou applications de tiers, au moyen de contenus publicitaires (texte, graphismes, animations, vidéos, etc.) diffusés par ces sites ou applications. De même, des cookies sont susceptibles d’être inclus dans les espaces publicitaires du Site. Ces espaces publicitaires affichent sur votre terminal des contenus publicitaires émanant d’annonceurs. Ces espaces contribuent au financement des contenus et des services que Meilleur Luminaire met à votre disposition. Lors de l’affichage de tels contenus publicitaires, des informations relatives à la navigation de votre terminal (ordinateur, tablette, smartphone, etc.) sont susceptibles d’être enregistrées dans des fichiers « cookies » installés sur ce terminal, sous réserve des choix exprimés concernant les cookies. Sachez que seul l’émetteur d’un cookie est susceptible de lire ou de modifier des informations qui y sont contenues. Afin de permettre à nos systèmes de reconnaître votre appareil et de vous fournir des fonctionnalités, nous utilisons des « cookies ». Pour plus d’informations concernant les cookies et l’usage que nous en faisons, veuillez vous référer à la section ci-dessus.\nparticipe au Programme Partenaires d’Amazon EU, un programme d’affiliation conçu pour permettre à des sites de percevoir une rémunération grâce à la création de liens vers Amazon.fr. L’utilisateur reste tout à fait libre de chercher les produits Amazon.fr par lui-même s’il préfère ne pas passer par les liens du site.\nHAPPEL Caisse américaine en carton ondulé à déplier 432, (L)500 x (l)430 x (H)300 mm, marron, double cannelures qualité 2.30 BC en paquet de 10 pièces\n"},"4archives/BigScience/Datasets/Hindi":{"title":"Hindi","links":[],"tags":["research","deduplication","projectnotes"],"content":"Hindi\n\nIdentifier::hi\nLanguage::Hindi\nPhysical Size::10.2GB\nNumber of Rows::1982933\nUnique URLs:: 1982279\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 4735, 3: 1855, 2: 633, 1: 185}\nSimHash Results:: 7408 matches/914 clusters/3191 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 10327894620\nSubstring Duplicate Size:: 3087503973 (29.89%)\n\nExamples\n\n"},"4archives/BigScience/Datasets/Indonesian":{"title":"Indonesian","links":[],"tags":["research","deduplication","projectnotes"],"content":"Indonesian\n\nIdentifier::id\nLanguage::Indonesian\nPhysical Size::19.3GB\nNumber of Rows::11555544\nUnique URLs:: 11553941\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 1404992, 3: 390584, 2: 92815, 1: 17511}\nSimHash Results:: 1905902 matches/39272 clusters/260718 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 17176417706\nSubstring Duplicate Size:: 4250966690 (24.75%)\n\nExamples"},"4archives/BigScience/Datasets/Portuguese":{"title":"Portuguese","links":[],"tags":["research","deduplication","projectnotes"],"content":"Portuguese\n\nIdentifier::pt\nLanguage::Portuguese\nPhysical Size::60.5GB\nNumber of Rows::28103007\nUnique URLs:: 28095535\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 2541001, 3: 707649, 2: 154717, 1: 26112}\nSimHash Results:: 3429479 matches/36373/190889 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 56235780043\nSubstring Duplicate Size:: 11383797323 (20.24%)\n\nExamples\n(4) O sorteio da Lotofácil do dia 11/02/2015, aconteceu em Porto Seguro-BA no caminhão da sorte Resultado da Lotofácil 1170 está disponível com lista de ganhadores e prêmios. Quem acertar as 15 números leva o prêmio principal da Lotofácil. Mas para quem acertar 14, 13, 12, ou até mesmo acertar 11 números ganha prêmios de valor menor. Se ninguém acertar 15 dezenas no resultado da Lotofácil 1170 o valor do prêmio principal será acumulado o próximo sorteio da Lotofácil. 25 números para você escolher, de 01 a 25, você pode escolher de 15 a 18 números.\nOs ganhadores e valores de prêmios serão informados abaixo na tabela, junto com o valor do prêmio para o concurso da Lotofácil 1170.\nSorteio do concurso 508 da Lotofácil aconteceu dia 25/02/2010. Acertando 15 números leva o prêmio principal da Lotofácil 508.\n\n(4) Sorteio do concurso 1497 da Lotofácil aconteceu dia 10/04/2017. Acertando 15 números leva o prêmio principal da Lotofácil 1497.\nO sorteio da Lotofácil do dia 10/04/2017, aconteceu em São Paulo-SP no espaço caixa loterias Resultado da Lotofácil 1497 está disponível com lista de ganhadores e prêmios. Quem acertar as 15 números leva o prêmio principal da Lotofácil. Mas para quem acertar 14, 13, 12, ou até mesmo acertar 11 números ganha prêmios de valor menor. Se ninguém acertar 15 dezenas no resultado da Lotofácil 1497 o valor do prêmio principal será acumulado o próximo sorteio da Lotofácil. 25 números para você escolher, de 01 a 25, você pode escolher de 15 a 18 números.\nOs ganhadores e valores de prêmios serão informados abaixo na tabela, junto com o valor do prêmio para o concurso da Lotofácil 1497.\nAtravés de um design compacto e moderno, o SAT-iD é capaz de emitir cupons fiscais com segurança, alto desempenho e robustez.\n\n(4) Na maioria dos casos nossos especialistas resolvem o problema em sua cooktop no próprio local (residência ou empresa na região Jardim Nilópolis), somente em casos extremos removemos e levamos para nosso setor de análise técnica.\nSomos uma empresa reparadora de fogão Autorizada Viking unidade Jardim Nilópolis em São Paulo, com profissionais treinados na arte da manutenção, realizando qualquer tipo de reparos em sua adega.\n\n(4) Na maioria dos casos nossos especialistas resolvem o problema em sua máquina gelo no próprio local (residência ou empresa na região Jardim Nilópolis), somente em casos extremos removemos e levamos para nosso setor de análise técnica.\nSomos uma empresa reparadora de microondas Autorizada Viking unidade Jardim Nilópolis em São Paulo, com profissionais treinados na arte da manutenção, realizando qualquer tipo de reparos em sua adega.\n\n(1) O conteúdo do texto &quot;Valor de Vareta na Vila Clélia&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Aquecedor Bosch 23 Litros Vila Guilherme&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Sombreador de Garagem Jaçanã&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Andador com Rodinhas Barato São Luís&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Telha Ondulada Santa Isabel&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Alopatia Auditiva Barueri&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Buffet para Casamento Barato na Vila Esperança&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;divisória retrátil de vidro&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;peeling para acne e manchas&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;devcon solda a frio&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Onde Faz Encadernação Lombada Quadrada Centro&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;brita reciclada&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n(1) O conteúdo do texto &quot;Onde Encontro Fabricantes de Lixas e Abrasivos Biritiba Mirim&quot; é de direito reservado. Sua reprodução, parcial ou total, mesmo citando nossos links, é proibida sem a autorização do autor. Crime de violação de direito autoral – artigo 184 do Código Penal – Lei 9610/98 - Lei de direitos autorais.\n\n"},"4archives/BigScience/Datasets/Spanish":{"title":"Spanish","links":[],"tags":["research","deduplication","projectnotes"],"content":"Spanish\n\nIdentifier::es\nLanguage::Spanish\nPhysical Size::136.7GB\nNumber of Rows::57380621\nUnique URLs:: 57360530\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 717285, 3: 286455, 2: 95690, 1: 23595}\nSimHash Results:: 1123025 matches/59735 clusters/281827 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 69577115984\nSubstring Duplicate Size:: 24186634136 (18.74%)\n\nExamples\n(4) ✅ Existen muchos tutoriales gratuitos para rootear el OT 506, pero en muchos casos si se hace algo mal, el equipo puede dañarse y brickeado, si quiere hacer root su celular Alcatel con total garantía, experiencia y profesionalidad, le recomendamos que deje en manos de profesionales este proceso, en Movical.Net tenemos más de 15 años de experiencia con la manipulación de teléfonos, le proponemos un hacer root su celular de forma remota, nuestros técnicos se conectan a su PC remotamente y en pocos minutos hacen root el terminal, usted sólo debe seguir los pasos de nuestro soporte. No importa si usted es de USA o de otro país, este servicio se presta a todos los países.\n\n(4) ✅ Existen muchos tutoriales gratuitos para rootear el PRA-LX1 P8 Lite, pero en muchos casos si se hace algo mal, el equipo puede dañarse y brickeado, si quiere hacer root su celular Huawei con total garantía, experiencia y profesionalidad, le recomendamos que deje en manos de profesionales este proceso, en Movical.Net tenemos más de 15 años de experiencia con la manipulación de teléfonos, le proponemos un hacer root su celular de forma remota, nuestros técnicos se conectan a su PC remotamente y en pocos minutos hacen root el terminal, usted sólo debe seguir los pasos de nuestro soporte. No importa si usted es de USA o de otro país, este servicio se presta a todos los países.\n\n(1) * Cookies de análisis: Son aquéllas que permiten al responsable de las mismas, el seguimiento y análisis del comportamiento de los usuarios de los sitios web a los que están vinculadas. La información recogida mediante este tipo de cookies se utiliza en la medición de la actividad de los sitios web, aplicación o plataforma y para la elaboración de perfiles de navegación de los usuarios de dichos sitios, aplicaciones y plataformas, con el fin de introducir mejoras en función del análisis de los datos de uso que hacen los usuarios del servicio.\n\n(1) VERANDA utiliza cookies de análisis. Son aquéllas que permiten al responsable de las mismas, el seguimiento y análisis del comportamiento de los usuarios de los sitios web a los que están vinculadas. La información recogida mediante este tipo de cookies se utiliza en la medición de la actividad de los sitios web, aplicación o plataforma y para la elaboración de perfiles de navegación de los usuarios de dichos sitios, aplicaciones y plataformas, con el fin de introducir mejoras en función del análisis de los datos de uso que hacen los usuarios del servicio.\n\n(1) Cookies de análisis: aquéllas que permiten al responsable de las mismas, el seguimiento y análisis del comportamiento de los usuarios de los sitios web a los que están vinculadas. La información recogida mediante este tipo de cookies se utiliza en la medición de la actividad de los sitios web, aplicación o plataforma y para la elaboración de perfiles de navegación de los usuarios de dichos sitios, aplicaciones y plataformas, con el fin de introducir mejoras en función del análisis de los datos de uso que hacen los usuarios del servicio.\n"},"4archives/BigScience/Datasets/Urdu":{"title":"Urdu","links":[],"tags":["research","deduplication","projectnotes"],"content":"Urdu\n\nIdentifier::ur\nLanguage::Urdu\nPhysical Size::1.6GB\nNumber of Rows::371691\nUnique URLs:: 371628\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 135, 3: 96, 2: 35, 1: 19}\nSimHash Results:: 285 matches/167 clusters/407 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 1565304005\nSubstring Duplicate Size:: 231043706 (14.76%)\n\nExamples\n"},"4archives/BigScience/Datasets/Vietnamese":{"title":"Vietnamese","links":[],"tags":["research","deduplication","projectnotes"],"content":"Vietnamese\n\nIdentifier::vi\nLanguage::Vietnamese\nPhysical Size::34.2GB\nNumber of Rows::11326711\nUnique URLs:: 11322337\nSimHash Tokenization::character 6-gram\nSimHash Parameters::(4,6)\nSimHash Match Distribution::{4: 34044, 3: 15587, 2: 6025, 1: 1929}\nSimHash Results:: 57585 matches/9988 clusters/30973 hashes\nSubstring Length Threshold:: 100\nTotal Text Size:: 33284057146\nSubstring Duplicate Size:: 7951164041 (23.89%)\n\nExamples\n\n(4) - dùng &quot;Cookie&quot; để giúp cá nhân hóa và nâng cao tối đa hiệu quả sử dụng thời gian trực tuyến của quý khách.\n- Một trong những mục đích của Cookie là cung cấp những tiện ích để tiết kiệm thời gian của quý khách khi truy cập tại website hoặc viếng thăm website lần nữa mà không cần đăng ký lại thông tin sẵn có.\n- Quý khách có thể chấp nhận hoặc từ chối dùng cookie. Hầu hết những Browser tự động chấp nhận cookie, nhưng quý khách có thể thay đổi những cài đặt để từ chối tất cả những cookie nếu quý khách thích. Tuy nhiên, nếu quý khách chọn từ chối cookie, điều đó có thể gây cản trở và ảnh hưởng không tốt đến một số dịch vụ và tính năng phụ thuộc vào cookie tại website\n- thực sự quan ngại đến vấn nạn Spam (thư rác), các Email giả mạo danh tín chúng tôi gởi đi. Do đó, khẳng định chỉ gởi Email đến quý khách khi và chỉ khi quý khách có đăng ký hoặc sử dụng dịch vụ từ hệ thống của chúng tôi.\n- cam kết không bán, thuê lại hoặc cho thuê email của quý khách từ bên thứ ba. Nếu quý khách vô tình nhận được Email không theo yêu cầu từ hệ thống chúng tôi do một nguyên nhân ngoài ý muốn, xin vui lòng nhấn vào link từ chối nhận Email này kèm theo, hoặc thông báo trực tiếp đến ban quản trị Website.\n- Chúng tôi hoàn toàn có thể thay đổi nội dung trong trang này mà không cần phải thông báo trước, để phù hợp với các nhu cầu của cũng như nhu cầu và sự phản hồi từ khách hàng nếu có. Khi cập nhật nội dung chính sách này, chúng tôi sẽ chỉnh sửa lại thời gian “Cập nhật lần cuối” bên dưới.\n- Nội dung “Chính sách bảo mật” này chỉ áp dụng tại không bao gồm hoặc liên quan đến các bên thứ ba đặt quảng cáo hay có links tại Chúng tôi khuyến khích bạn đọc kỹ chính sách An toàn và Bảo mật của các trang web của bên thứ ba trước khi cung cấp thông tin cá nhân cho các trang web đó. Chúng tôi không chịu trách nhiệm dưới bất kỳ hình thức nào về nội dung và tính pháp lý của trang web thuộc bên thứ ba.\n\n(4) - dùng &quot;Cookie&quot; để giúp cá nhân hóa và nâng cao tối đa hiệu quả sử dụng thời gian trực tuyến của quý khách.\n- Một trong những mục đích của Cookie là cung cấp những tiện ích để tiết kiệm thời gian của quý khách khi truy cập tại website hoặc viếng thăm website lần nữa mà không cần đăng ký lại thông tin sẵn có.\n- Quý khách có thể chấp nhận hoặc từ chối dùng cookie. Hầu hết những Browser tự động chấp nhận cookie, nhưng quý khách có thể thay đổi những cài đặt để từ chối tất cả những cookie nếu quý khách thích. Tuy nhiên, nếu quý khách chọn từ chối cookie, điều đó có thể gây cản trở và ảnh hưởng không tốt đến một số dịch vụ và tính năng phụ thuộc vào cookie tại website\n- thực sự quan ngại đến vấn nạn Spam (thư rác), các Email giả mạo danh tín chúng tôi gởi đi. Do đó, khẳng định chỉ gởi Email đến quý khách khi và chỉ khi quý khách có đăng ký hoặc sử dụng dịch vụ từ hệ thống của chúng tôi.\n- cam kết không bán, thuê lại hoặc cho thuê email của quý khách từ bên thứ ba. Nếu quý khách vô tình nhận được Email không theo yêu cầu từ hệ thống chúng tôi do một nguyên nhân ngoài ý muốn, xin vui lòng nhấn vào link từ chối nhận Email này kèm theo, hoặc thông báo trực tiếp đến ban quản trị Website.\n- Chúng tôi hoàn toàn có thể thay đổi nội dung trong trang này mà không cần phải thông báo trước, để phù hợp với các nhu cầu của cũng như nhu cầu và sự phản hồi từ khách hàng nếu có. Khi cập nhật nội dung chính sách này, chúng tôi sẽ chỉnh sửa lại thời gian “Cập nhật lần cuối” bên dưới.\n- Nội dung “Chính sách bảo mật” này chỉ áp dụng tại không bao gồm hoặc liên quan đến các bên thứ ba đặt quảng cáo hay có links tại Chúng tôi khuyến khích bạn đọc kỹ chính sách An toàn và Bảo mật của các trang web của bên thứ ba trước khi cung cấp thông tin cá nhân cho các trang web đó. Chúng tôi không chịu trách nhiệm dưới bất kỳ hình thức nào về nội dung và tính pháp lý của trang web thuộc bên thứ ba.\n\n(4) - Một trong những mục đích của Cookie là cung cấp những tiện ích để tiết kiệm thời gian của quý khách khi truy cập tại website hoặc viếng thăm website lần nữa mà không cần đăng ký lại thông tin sẵn có.\n- Quý khách có thể chấp nhận hoặc từ chối dùng cookie. Hầu hết những Browser tự động chấp nhận cookie, nhưng quý khách có thể thay đổi những cài đặt để từ chối tất cả những cookie nếu quý khách thích. Tuy nhiên, nếu quý khách chọn từ chối cookie, điều đó có thể gây cản trở và ảnh hưởng không tốt đến một số dịch vụ và tính năng phụ thuộc vào cookie tại website\n- thực sự quan ngại đến vấn nạn Spam (thư rác), các Email giả mạo danh tín chúng tôi gởi đi. Do đó, khẳng định chỉ gởi Email đến quý khách khi và chỉ khi quý khách có đăng ký hoặc sử dụng dịch vụ từ hệ thống của chúng tôi.\n- cam kết không bán, thuê lại hoặc cho thuê email của quý khách từ bên thứ ba. Nếu quý khách vô tình nhận được Email không theo yêu cầu từ hệ thống chúng tôi do một nguyên nhân ngoài ý muốn, xin vui lòng nhấn vào link từ chối nhận Email này kèm theo, hoặc thông báo trực tiếp đến ban quản trị Website.\n- Chúng tôi hoàn toàn có thể thay đổi nội dung trong trang này mà không cần phải thông báo trước, để phù hợp với các nhu cầu của cũng như nhu cầu và sự phản hồi từ khách hàng nếu có. Khi cập nhật nội dung chính sách này, chúng tôi sẽ chỉnh sửa lại thời gian “Cập nhật lần cuối” bên dưới.\n- Nội dung “Chính sách bảo mật” này chỉ áp dụng tại không bao gồm hoặc liên quan đến các bên thứ ba đặt quảng cáo hay có links tại Chúng tôi khuyến khích bạn đọc kỹ chính sách An toàn và Bảo mật của các trang web của bên thứ ba trước khi cung cấp thông tin cá nhân cho các trang web đó. Chúng tôi không chịu trách nhiệm dưới bất kỳ hình thức nào về nội dung và tính pháp lý của trang web thuộc bên thứ ba.\nPhần dưới là các bài trả lời câu hỏi và giải các bài tập sách giáo khoa Lịch Sử 7 Bài 9 phần 2 ngắn nhất: Nước Đại Cồ Việt thời Đinh - Tiền Lê. Để xem lời giải Lịch Sử 7 tương ứng, bạn vào tên bài hoặc Xem lời giải.\nTrả lời câu hỏi Lịch Sử 7 Bài 9 trang 32 ngắn nhất: Em hãy điểm qua tình hình nông nghiệp nước ta thời Đinh – Tiền Lê?\n"},"4archives/BigScience/Goals":{"title":"Goals","links":["4archives/BigScience/SubProjects/SimHash-deduplication","4archives/BigScience/Datasets/Arabic","4archives/BigScience/Datasets/Basque","4archives/BigScience/Datasets/Bengali","4archives/BigScience/Datasets/Catalan","4archives/BigScience/Datasets/Chinese","4archives/BigScience/Datasets/English","4archives/BigScience/Datasets/French","4archives/BigScience/Datasets/Hindi","4archives/BigScience/Datasets/Indonesian","4archives/BigScience/Datasets/Portuguese","4archives/BigScience/Datasets/Spanish","4archives/BigScience/Datasets/Urdu","4archives/BigScience/Datasets/Vietnamese","4archives/BigScience/SubProjects/Suffix-Array-Substring-deduplication","4archives/BigScience/SubProjects/Deduplication-report","4archives/Literature-Notes/Readings/Research-Deduplication-in-Modern-Large-scale-LM-Datasets"],"tags":["goals","project","bigscience","research","deduplication"],"content":"\n SimHash deduplication ^c61205\n\n Finish running deduplication by 2022-03-04\n\n Arabic\n Basque\n Bengali\n Catalan\n Chinese\n English\n French\n Hindi\n Indonesian\n Portuguese\n Spanish\n Urdu\n Vietnamese\n\n\n\n\n Suffix Array Substring deduplication ^3fb13c\n\n Finish running deduplication by 2022-03-04\n\n Arabic\n Basque\n Bengali\n Catalan\n Chinese\n English\n French\n Hindi\n Indonesian\n Portuguese\n Spanish\n Urdu\n Vietnamese\n\n\n\n\n Deduplication report\n\n Finish writing the report by 2022-03-05\n\n Draft\n\n\n\n\n"},"4archives/BigScience/SubProjects/Deduplication-report":{"title":"Deduplication report","links":["4archives/BigScience/SubProjects/SimHash-deduplication","4archives/BigScience/SubProjects/Suffix-Array-Substring-deduplication"],"tags":[],"content":"SimHash Results\n\nFormat\n#matches.tsv (diff means simhash bit difference)\nid1     id2     diff\n5676323 8347653 4\n20899   10053778        4\n \n#clusters.tsv (-1 means no cluster)\nid      hash    cluster\n0       2471784231621897202     -1\n1       16314724221857303546    -1\n4       10666012509495373957    -1\nAnalysis\nFalse positives in long documents: Because SimHash is essentially a BOW algorithm that long documents are more likely ended up being similar to each other, it might be a good idea to combine Suffix Array Substring deduplication when filtering long duplicates:\n\nRemove short duplicates or closely-similar documents – documents with small bit difference – based on SimHash (e.g len &lt;= 1024 or diff &lt;= 3)\nRemove substring duplicates based on Suffix Array\n\nThe time took for SimHash hashing and clustering is usually faster given the same data and computation resources than Suffix Array, e.g:\n\nIt took a few hours to hashing and clustering English data with 96 cores and 1.4TB memory, while it took more than a day just to build the suffix array;\n\nSuffix Array Results\n\nNote: All offsets are byte offsets instead of string offsets.\nFormat\n# text.csv (line based documents, each document has replaced the newline character with space)\ndocument1\ndocument2\n \n# ids.csv (line based ids)\nid0\nid1\n \n# sa.txt (byte offsets of duplicates from text.csv)\n0 288\n658 765\n982 1246\n1298 1586\n \n# substring_bytes.tsv (restored line-based byte offsets)\n# e.g. document 0 has two byte sequence duplicates: doc0[0:288] and doc0[658:765]\nid      x       y\n0       0       288\n0       658     765\n1       150     414\n1       466     754\nAnalysis\nThe threshold is applied both to the generation of sa.txt and the restoration of substring_bytes.tsv, meaning:\n\nIf a substring is shorter than 50 bytes in text.csv, it will be ignored;\nIf a substring spans multiple documents with a length longer than 50, then during document boundary restoration aka. mapping the substring back to the each documents, any document-bound sub-substring that is shorter than 50 bytes will be further ignored;\n"},"4archives/BigScience/SubProjects/SimHash-deduplication":{"title":"SimHash deduplication","links":["4archives/BigScience/Goals"],"tags":["research","deduplication"],"content":"SimHash Deduplication\nProgress\nTABLE\n\tIdentifier AS &quot;Identifier&quot;,\n\trow[&quot;Physical Size&quot;] AS &quot;Physical Size&quot;,\n\trow[&quot;Number of Rows&quot;] AS &quot;Size&quot;,\n\trow[&quot;Unique URLs&quot;] AS &quot;Unique URLs&quot;,\n\trow[&quot;SimHash Tokenization&quot;] AS &quot;SimHash Tokenization&quot;,\n\trow[&quot;SimHash Parameters&quot;] AS &quot;SimHash Parameters&quot;,\n\trow[&quot;SimHash Match Distribution&quot;] AS &quot;SimHash Distribution&quot;,\n\trow[&quot;SimHash Results&quot;] AS &quot;SimHash Results&quot;\nFROM #deduplication AND #projectnotes \nSORT Identifier\n\nGoals\nTransclude of Goals#^c61205"},"4archives/BigScience/SubProjects/Suffix-Array-Substring-deduplication":{"title":"Suffix Array Substring deduplication","links":["4archives/BigScience/Goals"],"tags":["research","deduplication"],"content":"Suffix Array Deduplication\nProgress\nTABLE\n\tIdentifier AS &quot;Identifier&quot;,\n\tLanguage AS &quot;Language&quot;,\n\trow[&quot;Physical Size&quot;] AS &quot;Physical Size&quot;,\n\trow[&quot;Total Text Size&quot;] AS &quot;Total Text Size (bytes)&quot;,\n\trow[&quot;Substring Length Threshold&quot;] AS &quot;Substring Length Threshold&quot;,\n\trow[&quot;Substring Duplicate Size&quot;] AS &quot;Substring Duplicate Size (bytes)&quot;\nFROM #deduplication AND #projectnotes \nSORT Identifier\n\nGoals\nTransclude of Goals#^3fb13c"},"4archives/BigScience/Write-Up":{"title":"Write Up","links":[],"tags":[],"content":"To remove near duplicate documents in OSCAR which is already exact-deduplicated, we used SimHash (1, 2) with 6-grams and a hamming distance of 4. About 0.7% of the documents on average (0.07% ~ 2.7%) were identified as near duplicates. In order to further reduce false positives, especially in long documents based on our observation, and false negatives, we also applied substring deduplication 3 based on Suffix Array4 as a complementary deduplication method for documents with more than 6000 (TODO: CHECK THIS NUMBER) characters. With this method, we found on average 21.67% (10.61% ~ 32.30%) of the data (in bytes) are duplicates.\n\nFootnotes\n\n\nCharikar, M. (2002). Similarity estimation techniques from rounding algorithms. STOC ‘02. ↩\n\n\nManku, G.S., Jain, A., &amp; Sarma, A.D. (2007). Detecting near-duplicates for web crawling. WWW ‘07. ↩\n\n\nLee, K., Ippolito, D., Nystrom, A., Zhang, C., Eck, D., Callison-Burch, C., &amp; Carlini, N. (2021). Deduplicating Training Data Makes Language Models Better. ArXiv, abs/2107.06499. ↩\n\n\nManber, U., &amp; Myers, E.W. (1990). Suffix arrays: a new method for on-line string searches. SIAM J. Comput., 22, 935-948. ↩\n\n\n"},"4archives/BigScience/_Index_of_BigScience":{"title":"_Index_of_BigScience","links":["4archives/BigScience/Write-Up","4archives/BigScience/SubProjects/_Index_of_SubProjects","4archives/BigScience/Goals","4archives/BigScience/Datasets/_Index_of_Datasets","4archives/BigScience/folder_BigScience"],"tags":[],"content":"Write Up\n_Index_of_SubProjects\nGoals\n_Index_of_Datasets\nfolder_BigScience"},"4archives/BigScience/folder_BigScience":{"title":"BigScience Overview","links":[],"tags":[],"content":"BigScience Overview\ntype: folder_brief_live"},"4archives/BigScience/index_BigScience":{"title":"index_BigScience","links":["4archives/BigScience/Write-Up","4archives/BigScience/SubProjects/index_SubProjects","4archives/BigScience/Goals","4archives/BigScience/Datasets/index_Datasets","4archives/BigScience/folder_BigScience","4archives/BigScience/_Index_of_BigScience"],"tags":[],"content":"Write Up\nindex_SubProjects\nGoals\nindex_Datasets\nfolder_BigScience\n_Index_of_BigScience"},"4archives/Blog-Pages/MOC-Digital-Garden":{"title":"MOC Digital Garden","links":["4archives/Blog-Pages/Resources/Sources","4archives/Blog-Pages/Resources/Career","4archives/Blog-Pages/Resources/AI","4archives/Blog-Pages/Resources/Engineering","4archives/Blog-Pages/Resources/Productivity","4archives/Blog-Pages/Resources/Misc"],"tags":["resource","reference"],"content":"Transclude of Sources\nTransclude of Career\nTransclude of AI\nTransclude of Engineering\nTransclude of Productivity ^3b071a\nTransclude of Misc"},"4archives/Blog-Pages/MOC-Ideas":{"title":"MOC Ideas","links":[],"tags":["idea","project"],"content":"\nA classification alternative to SummVis: Interactive Visual Analysis of Models, Data, and Evaluation for Text Summarization\nA review paper on low-vocabulary and open-vocabulary embeddings\nClassification as IR – show me the relevant examples in training set when inferring on unseen example\nSpacy ports of NLP-Cube\nAn evaluation tool for a company, how many of its employees actively contribute to OSS.\n"},"4archives/Blog-Pages/MOC-OSS-Projects":{"title":"MOC OSS Projects","links":[],"tags":["project","open-source"],"content":"\nNLP Projects\n\ntext-embeddings low-and-no-vocabulary text embeddings, compatible with transformers.\nai2 is a succinct commonsense-reasoning training and evaluation framework for transformer-based models. \npytorch-pqrnn is a PyTorch implementation of pQRNN model.\ntext-dedup All-in-one text de-duplication tool with edit distance, LSH and embeddings.\ntransformer with pointer generator Pointer generator in Transformer for low resource machine translation.\n\nFor Fun\n\nkarafulu shows traditional Chinese colors in your terminal.\ntouchbar-lyric shows synced lyrics inside your touch-bar.\nbender-ruler an ACL conference bender rule evaluation tool, inspired by the #BenderRule @emilymbender\n"},"4archives/Blog-Pages/MOC-Posts":{"title":"MOC Posts","links":["4archives/Literature-Notes/Readings/Post-Embedding-Layer-might-not-be-Necessary-for-Your-Next-NLP-Project"],"tags":["article","post"],"content":"Articles\n\nPost Embedding Layer might not be Necessary for Your Next NLP Project\n"},"4archives/Blog-Pages/MOC-Reading-List":{"title":"MOC Reading List","links":["tags/productivity","tags/finance","tags/self-help"],"tags":["productivity","finance","self-help"],"content":"TODO\n\nThe Productivity Project: Accomplishing More by Managing Your Time, Attention, and Energy: Bailey, Chris: 9781101904039: Amazon.com: Books recommended by 1productivity\nYour Money: The Missing Manual: J.D. Roth: 9780596809409: Amazon.com: Books recommended by 1finance\nA Random Walk Down Wall Street: The Time-Tested Strategy for Successful Investing: Malkiel, Burton G.: 9780393358384: Amazon.com: Books recommended by 1finance\nThe 7 Habits of Highly Effective People: 30th Anniversary Edition: Covey, Stephen R.: 9781982137274: Amazon.com: Books recommended by 1self-help\nFacebook Tech Talks - YouTube recommended by 2\nAmazon Tech Talks - YouTube recommended by 2\nGoogle Tech Talks - YouTube recommended by 2\nNetflix Tech Talks - YouTube recommended by 2\nClean Code: A Handbook of Agile Software Craftsmanship\nClean Architecture: A Craftsman’s Guide to Software Structure and Design\nRefactoring: Improving the Design of Existing Code\nThe Productive Programmer\nPragmatic Thinking and Learning: Refactor Your Wetware\n\nFootnotes\n\n\n7 Books EVERYONE in Their 20’s Should Read - YouTube ↩ ↩2 ↩3 ↩4\n\n\nShow HN: Tech Talks at Facebook, Amazon, Netflix, and Google | Hacker News ↩ ↩2 ↩3 ↩4\n\n\n"},"4archives/Blog-Pages/Resources/AI":{"title":"AI","links":["4archives/Literature-Notes/Courses/CS224n/MOC-CS224n-NLP-with-Deep-Learning-(Winter-2019)"],"tags":["ml","ai","nlp","resource"],"content":"ML/NLP\n\nMachine Learning Ops | Learn how to use GitHub for automation, collaboration and reproducibility in your machine learning workflows.\nGitHub - ThinamXx/66Days__NaturalLanguageProcessing: I am sharing my Journey of 66DaysofData in Natural Language Processing.\nLearn Intro to AI Ethics Tutorials | Kaggle\nGitHub - gyunggyung/NLP-Papers: Papers and Book to look at when starting NLP 📚\nGitHub - BCG-Gamma/facet: Human-explainable AI.\n[Stanford CS 224N MOC CS224n NLP with Deep Learning (Winter 2019)\nMade with ML\nGitHub - interpretml/interpret-text: A library that incorporates state-of-the-art explainers for text-based machine learning models and visualizes the result with a built-in dashboard.\nStateoftheart AI\nstorage.googleapis.com/deepmind-media/research/New_AtHomeWithAI resources.pdf\nMachine Learning Summer Schools in Tübingen\nprobml.github.io/pml-book/book1.html\nSpeech and Language Processing\nDEEP LEARNING · Deep Learning\nEthics of AI\nFREE Computer Science Curriculum From Best Universities and Companies In World | Laconicml\n"},"4archives/Blog-Pages/Resources/Career":{"title":"Career","links":[],"tags":["career","resource"],"content":"Resources\n\nMembers | Teal HQ\nFree personality test, type descriptions, relationship and career advice | 16Personalities\nAI Expert Roadmap\nGitHub - alirezadir/machine-learning-interview-enlightener: This repo is meant to serve as a guide for Machine Learning/AI technical interviews.\n"},"4archives/Blog-Pages/Resources/Engineering":{"title":"Engineering","links":[],"tags":["engineering","resource"],"content":"\nGitHub - Eugeny/tabby: A terminal for a more modern age (formerly Terminus)\nOverview of technical writing courses  |  Technical Writing\nJigsaw Labs - Learn Data Engineering part-time online.\nKube Flow: It is a nice platform that covers the training and deployment cycle of MLOps. But there is a learning curve to this and personally, I think there is just too much to catch up with all the orchestration configurations. If it is not something that is being actively used in your working environment, you have to play a role of infrastructure architect to make it work, which I don’t think is worth the effort. \nMLflow: It is free, and does a descent job keeping track of things, and I used it in my projects and advocated to the whole team to move their experiments onto this. But there is push-back too. Some people either don’t want to do things that requires some level of efforts or just want to have some intelligent platform to do all the work and they aren’t willing to settle for less. To them I would say you either adopt to the tools that are free or pay for the tools that can adopt to you. There is no free lunch and certainly no free productivity. \nDVC: It is an awesome tool for managing your datasets. Combined with Github workflows and CML (a product for Continuous ML), you can do magic on each of your pull requests. Adoption is also limited to what code management platform you are using.\nPachydem: I think I’ve tried this once, but I don’t exactly remember the experience. Looking at the description, it looks like a cool tool to manage and track data and models. Again, if you are working on projects alone, you can try all the new things and settle for something you find most comfortable. It would be a totally different story when it is a team.\nMetaflow: One of my former college told me about this, and I love the abstraction of a flow in this tool. The containerized steps are super helpful for complex flows. And I hate to admit, if all the models you are trying to build is in scikit-learn, don’t bother.\nKedro: This was on my radar before. I am not a huge fan of UI.\nSeldon core: This is a solid tool to deploy your model, it is a pity that making full use of this is almost impossible when model deployment is your responsibility and no one cares about how to make it better.\nFlyte: This is new to me, it looks like a combination of ^677d27^a778e0]]. \nZenML: Last time I check, there is no GRPC support.\nMLRun: Similar to ^904e5c.\nA collection of code examples from prominent open-source projects - Code Catalog on learning from open-source projects.\nAtomic Versioned Data Lake - LakeFS\nDAGsHub · The home for data science collaboration\n"},"4archives/Blog-Pages/Resources/Misc":{"title":"Misc","links":[],"tags":["resource","tool","utility","app","macos","discount"],"content":"Student App Centre"},"4archives/Blog-Pages/Resources/Productivity":{"title":"Productivity","links":[],"tags":["tool","utility","productivity","app","service","resource"],"content":"\nAn Online Whiteboard &amp; Visual Collaboration Platform for Teamwork | Miro\nWhimsical - Where Great Ideas Take Shape\nObsidian\nZotero | Your personal research assistant \nThe API Design Platform and API Client - Insomnia\nBitwarden Open Source Password Manager | Bitwarden\nWeje\nChoose an open source license | Choose a License\n"},"4archives/Blog-Pages/Resources/Sources":{"title":"Sources","links":[],"tags":["resource","information","collection"],"content":"\nHacker News\nTwitter\nMedium\nGithub\nWeibo\nProduct Hunt\nBeta List\nThe Gradient\n"},"4archives/Hypothesis/5.-Text-Generation":{"title":"5. Text Generation","links":["/","tags/article","tags/Public"],"tags":["article","Public"],"content":"5. Text Generation\nMetadata\n\nAuthor: learning.oreilly.com\nTitle: 5. Text Generation\nReference: learning.oreilly.com/library/view/natural-language-processing/9781098136789/ch05.html\nCategory:article\n\nPage Notes\nHighlights\n\n\nThis is a common problem with greedy search algorithms, which can fail to give you the optimal solution; in the context of decoding, they can miss word sequences whose overall probability is higher just because high-probability words happen to be preceded by low-probability ones. — Updated on 2022-07-06 20:55:54 — Group:Public\n\n\nAlthough greedy search decoding is rarely used for text generation tasks that require diversity, it can be useful for producing short sequences like arithmetic where a deterministic and factually correct output is preferred. — Updated on 2022-07-06 20:56:34 — Group:Public\n\n\nBy tuning T we can control the shape of the probability distribution.5 When T≪1, the distribution becomes peaked around the origin and the rare tokens are suppressed. On the other hand, when T≫1, the distribution flattens out and each token becomes equally likely. — Updated on 2022-07-06 21:03:14 — Group:Public\n\n\nThe main lesson we can draw from temperature is that it allows us to control the quality of the samples, but there’s always a trade-off between coherence (low temperature) and diversity (high temperature) that one has to tune to the use case at hand. — Updated on 2022-07-06 21:04:11 — Group:Public\n\n\nThe idea behind top-k sampling is to avoid the low-probability choices by only sampling from the k tokens with the highest probability. — Updated on 2022-07-06 21:06:55 — Group:Public\n\n\nWith nucleus or top-p sampling, instead of choosing a fixed cutoff value, we set a condition of when to cut off. This condition is when a certain probability mass in the selection is reached. — Updated on 2022-07-06 21:07:37 — Group:Public\n\n\nUnfortunately, there is no universally “best” decoding method. Which approach is best will depend on the nature of the task you are generating text for. If you want your model to perform a precise task like arithmetic or providing an answer to a specific question, then you should lower the temperature or use deterministic methods like greedy search in combination with beam search to guarantee getting the most likely answer. If you want the model to generate longer texts and even be a bit creative, then you should switch to sampling methods and increase the temperature or use a mix of top-k and nucleus sampling. — Updated on 2022-07-06 21:12:17 — Group:Public\n\n"},"4archives/Hypothesis/ACL-2022-Highlights":{"title":"ACL 2022 Highlights","links":["/","tags/article","tags/Public"],"tags":["processed","article","Public"],"content":"ACL 2022 Highlights\nMetadata\n\nAuthor: ruder.io\nTitle: ACL 2022 Highlights\nReference: ruder.io/acl2022/\nCategory:article\n\nPage Notes\nHighlights\n\n\nThey also mentioned a positive development, that researchers are becoming more aware of the value of high-quality datasets. Overall, the panelists emphasised that working with such languages requires respect—towards the speakers, the culture, and the languages themselves. — Updated on 2022-06-26 14:36:59 — Group:Public\n\n\nIn the past, there was pressure not to work on tasks that did not achieve high inter-annotator agreement; similarly, in traditional sentiment analysis, the neutral class is often discarded. Understanding cannot just be crammed into simple categories. Annotator opinions bias language models (Sap et al., 2021) and ambiguous examples improve generalization (Swayamdipta et al., 2020). — Updated on 2022-06-26 14:50:59 — Group:Public\n\n\nYejin argued that language, knowledge, and reasoning are also not separate areas but exist on a continuum. — Updated on 2022-06-26 14:51:17 — Group:Public\n\n\n\nACL 2022 Highlights\n\nACL 2022 Highlights\nACL 2022 Highlights\nACL 2022 Highlights"},"4archives/Hypothesis/Becoming-an-Independent-Researcher-and-getting-published-in-ICLR-with-spotlight":{"title":"Becoming an Independent Researcher and Getting Published in ICLR with Spotlight","links":["/","tags/article","tags/Public"],"tags":["processed","article","Public"],"content":"Becoming an Independent Researcher and Getting Published in ICLR with Spotlight\nMetadata\n\nAuthor: andreas-madsen.medium.com\nTitle: Becoming an Independent Researcher and getting published in ICLR with spotlight\nReference: andreas-madsen.medium.com/becoming-an-independent-researcher-and-getting-published-in-iclr-with-spotlight-c93ef0b39b8b\nCategory:article\n\nPage Notes\nHighlights\n\n\nTo start a PhD, without insider referral, you need to do work equivariant to half of a PhD. — Updated on 2021-11-06 14:46:58 — Group:Public\n\n\n\nAnd as an Independent Researcher, it is reasonable to say that my chances are less than average, simply because I get less feedback. — Updated on 2021-11-06 14:49:45 — Group:Public\n\n\nIn the end, we are likely all lazy, and as such, we will be blind to faults in our own work. Just discussing your paper with someone, puts much greater pressure on not taking any unintended shortcuts. — Updated on 2021-11-06 14:50:14 — Group:Public\n\n\n\nWrite an open-source tool, implement a known paper, etc.. It is helpful to take a break from research, and if your research project fails, you have at least accomplished something. — In my case, having some of these side-projects be recognized by known researchers, was also a great source of encouragement. — Updated on 2021-11-06 14:50:37 — Group:Public\n\n\n\nThere will be 1–2 messages in a paper, that if misunderstood, will completely confuse the reader and be the first cause of getting rejected. Do not be afraid of repeating a message to prevent that. — Updated on 2021-11-06 14:51:55 — Group:Public\n\n\n\nReviewers are likely to side with already published results. They will only think critical about your submission not previous publications, especially if they come from DeepMind. — Updated on 2021-11-06 14:54:49 — Group:Public \n\n"},"4archives/Hypothesis/Bootstrapping-Labels-via-___-Supervision--and--Human-In-The-Loop":{"title":"Bootstrapping Labels via ___ Supervision & Human-In-The-Loop","links":["/","tags/article","tags/Public"],"tags":["todo","article","Public"],"content":"Bootstrapping Labels via ___ Supervision &amp; Human-In-The-Loop\nMetadata\n\nAuthor: eugeneyan.com\nTitle: Bootstrapping Labels via ___ Supervision &amp; Human-In-The-Loop\nReference: eugeneyan.com/writing/bootstrapping-data-labels/\nCategory:article\n\nPage Notes\nHighlights\n\n\nIn active learning, we select the most “interesting” unlabeled samples for labeling via human-in-the-loop (HITL). One way to identify such samples is uncertainty sampling, where samples with the highest uncertainty in model predictions are selected. — Updated on 2021-09-24 13:08:44 — Group:Public\n\n\nDoorDash shared some tips to develop good labeling guidelines for tags, such as: Ensure tags are mutually exclusive (i.e., no overlap): This allows annotators to move on if a sample already has a tag and reduces annotation volume. Partition taxonomy at the top level by distinct attributes (e.g., regional cuisine style, flavor, etc.): This allows parallelization of annotation tasks. Ensure there’s a tag for “Other” at each level: This allows you to revisit the “Other” tags to improve granularity in future (instead of having to go through all tags). Ensure tags are objective: Tags such as “popular” or “convenient” are subjective and can change over time. — Updated on 2021-09-24 13:18:56 — Group:Public\n\n\nIn the earliest stage, we can adopt weak supervision. This can include labeling functions via keyword-based regex, statistical aggregations, knowledge graphs, user segmentation, etc. — Updated on 2021-09-24 13:20:42 — Group:Public\n\n\nWith some seed data, we can then adopt semi-supervised learning. We can train a high precision model to predict on unlabeled samples, then add the pseudo-labels with the highest confidence to the training data. Or we can try active learning (e.g., nearest neighbors + uncertainty sampling/information density) to identify labels with the highest uncertainty for HITL before adding it to the dataset. — Updated on 2021-09-24 13:20:56 — Group:Public\n\n\nFinally, in the late stage, our machine learning systems and policies would have matured. Here’s where we start to get a stream of good labels for model training, and can try more sophisticated models that require a large number of labels. — Updated on 2021-09-24 13:21:12 — Group:Public\n\n\nEven in mature ML systems, we might not be able to use the labels immediately as they can change over time. — Updated on 2021-09-24 13:21:26 — Group:Public\n\n\nUsing premature or incorrect labels can lead to vicious cycle feedback loops, where the model learns from invalid labels and makes prediction errors that exacerbate ground truth errors. — Updated on 2021-09-24 13:21:42 — Group:Public\n\n\n\nBootstrapping Labels via ___ Supervision &amp; Human-In-The-Loop\n\nBootstrapping Labels via ___ Supervision &amp; Human-In-The-Loop\nBootstrapping Labels via ___ Supervision &amp; Human-In-The-Loop\nBootstrapping Labels via ___ Supervision &amp; Human-In-The-Loop"},"4archives/Hypothesis/Creating-Confidence-Intervals-for-Machine-Learning-Classifiers":{"title":"Creating Confidence Intervals for Machine Learning Classifiers","links":["/","tags/article","tags/Public"],"tags":["todo","article","Public"],"content":"Creating Confidence Intervals for Machine Learning Classifiers\nMetadata\n\nAuthor: sebastianraschka.com\nTitle: Creating Confidence Intervals for Machine Learning Classifiers\nReference: sebastianraschka.com/blog/2022/confidence-intervals-for-ml.html\nCategory:article\n\nPage Notes\nHighlights\n\n\nAs a side-note, we can say that the difference of two measurements is statistically significant if confidence intervals do not overlap. However we cannot say that results are not statistically significant if confidence intervals overlap. — Updated on 2022-06-04 18:33:45 — Group:Public\n\n\nThis is done by taking multiple samples with replacement from a single random sample. The equation is as follows: ACCbootavg=1b∑bj=1ACCboot,j, — Updated on 2022-06-04 19:06:01 — Group:Public\n\n\nNote that 200 is usually recommended as the minimum number of bootstrap rounds (see “Introduction to the Bootstrap” book). — Updated on 2022-06-04 19:06:26 — Group:Public\n\n\nHowever, suppose we don’t tune our model on the training set. In that case, we can use the whole dataset and report the averaged bootstrap accuracy ACCbootavgACCbootavg\\text{ACC}_{\\text{bootavg}} as your model performance estimate instead of using an independent test set. — Updated on 2022-06-04 19:08:00 — Group:Public\n\n\n\nCreating Confidence Intervals for Machine Learning Classifiers\n\nCreating Confidence Intervals for Machine Learning Classifiers\nCreating Confidence Intervals for Machine Learning Classifiers\nCreating Confidence Intervals for Machine Learning Classifiers"},"4archives/Hypothesis/DALL·E-2-Pre-Training-Mitigations":{"title":"DALL·E 2 Pre-Training Mitigations","links":["/","tags/article","tags/Personal"],"tags":["processed","article","Personal"],"content":"DALL·E 2 Pre-Training Mitigations\nMetadata\n\nAuthor: openai.com\nTitle: DALL·E 2 Pre-Training Mitigations\nReference: openai.com/blog/dall-e-2-pre-training-mitigations/\nCategory:article\n\nPage Notes\nHighlights\n\n\nwe describe how we filtered out violent and sexual images from DALL·E 2’s training dataset. Without this mitigation, the model would learn to produce graphic or explicit images when prompted for them, and might even return such images unintentionally in response to seemingly innocuous prompts. — Updated on 2022-07-02 15:38:08 — Group:Personal\n\nAnnotation: Even when we are exposed to such content on the internet, we humans can still uphold our moral standards and avoid producing toxic content. The conscious choice that we make not to be influenced by such content should be a key feature of “intelligence” compared to not learning it by force.\n\n\n\nIn practice, we found that this image regurgitation is caused by images that are replicated many times in the dataset, and mitigate the issue by removing images that are visually similar to other images in the dataset. — Updated on 2022-07-02 15:38:51 — Group:Personal\n\n\nfirst, we create a specification for the image categories we would like to label; second, we gather a few hundred positive and negative examples for each category; third, we use an active learning procedure to gather more data and improve the precision/recall trade-off; and finally, we run the resulting classifier on the entire dataset with a conservative classification threshold to favor recall over precision. To set these thresholds, we prioritized filtering out all of the bad data over leaving in all of the good data. — Updated on 2022-07-02 15:39:53 — Group:Personal\n\n\nThis is because we can always fine-tune our model with more data later to teach it new things, but it’s much harder to make the model forget something that it has already learned. — Updated on 2022-07-02 15:40:01 — Group:Personal\n\n\nHowever, we also found an unexpected side-effect of data filtering: it created or amplified the model’s biases towards certain demographics. — Updated on 2022-07-02 15:41:47 — Group:Personal\n\n\nWe hypothesize that this particular case of bias amplification comes from two places: first, even if women and men have roughly equal representation in the original dataset, the dataset may be biased toward presenting women in more sexualized contexts; and second, our classifiers themselves may be biased either due to implementation or class definition, despite our efforts to ensure that this was not the case during the data collection and validation phases. Due to both of these effects, our filter may remove more images of women than men, which changes the gender ratio that the model observes in training. — Updated on 2022-07-02 15:44:22 — Group:Personal\n\n\nAdditionally, reproducing training images verbatim can raise legal questions around copyright infringement, ownership, and privacy (if people’s photos were present in training data). — Updated on 2022-07-02 15:48:16 — Group:Personal\n\n\nFirst, the images were almost all simple vector graphics, which were likely easy to memorize due to their low information content. Second, and more importantly, the images all had many near-duplicates in the training dataset. — Updated on 2022-07-02 15:48:58 — Group:Personal\n\n\nConsider what happens if we cluster our dataset before performing deduplication. Since nearby samples often fall into the same cluster, most of the duplicate pairs would not cross cluster decision boundaries. We could then deduplicate samples within each cluster without checking for duplicates outside of the cluster, while only missing a small fraction of all duplicate pairs. This is much faster than the naive approach, since we no longer have to check every single pair of images.[3] — Updated on 2022-07-02 15:50:50 — Group:Personal\n\n\nThe more clusterings you try, the more likely you are to discover a given duplicate pair. In practice, we settled on using five clusterings, which means that we search for duplicates of each image in the union of five different clusters. In practice, this found 97% of all duplicate pairs on a subset of our data. — Updated on 2022-07-02 15:51:44 — Group:Personal\n\n\nWhile deduplication is a good first step towards preventing memorization, it does not tell us everything there is to learn about why or how models like DALL·E 2 memorize training data. — Updated on 2022-07-02 15:53:59 — Group:Personal\n\n\n\nDALL·E 2 Pre-Training Mitigations\n\nDALL·E 2 Pre-Training Mitigations\nDALL·E 2 Pre-Training Mitigations\nDALL·E 2 Pre-Training Mitigations"},"4archives/Hypothesis/From-aardvark-to-woke-inside-the-Oxford-English-Dictionary":{"title":"From Aardvark to Woke: Inside the Oxford English Dictionary","links":["/","tags/article","tags/Public"],"tags":["processed","article","Public"],"content":"From Aardvark to Woke: Inside the Oxford English Dictionary\nMetadata\n\nAuthor: newstatesman.com\nTitle: From aardvark to woke: inside the Oxford English Dictionary\nReference: www.newstatesman.com/long-reads/2022/06/oxford-english-dictionary-aardvark-woke-oed-history\nCategory:article\n\nPage Notes\nHighlights\n\nWhether the question is about culture-wars issues of race and gender or a grammatical quibble, the answer is the same: the OED describes how language is already being used; it does not prescribe how it should be used, nor endorse a word’s use. McPherson observes that the dictionary’s reliance on written sources means it is often “at the rearguard” of language change rather than leading the charge. — Updated on 2022-07-05 20:26:22 — Group:Public\n"},"4archives/Hypothesis/Moving-Beyond-Mimicry-in-Artificial-Intelligence":{"title":"Moving Beyond Mimicry in Artificial Intelligence","links":["/","tags/article","tags/Public"],"tags":["article","Public"],"content":"Moving Beyond Mimicry in Artificial Intelligence\nMetadata\n\nAuthor: nautil.us\nTitle: Moving Beyond Mimicry in Artificial Intelligence\nReference: nautil.us/moving-beyond-mimicry-in-artificial-intelligence-21015/\nCategory:article\n\nPage Notes\nHighlights\n\n\nI suggest much of what large pre-trained models do is a form of artificial mimicry. Rather than stochastic parrots, we might call them stochastic chameleons. Parrots repeat canned phrases; chameleons seamlessly blend in new environments. The difference might seem, ironically, a matter of semantics. However, it is significant when it comes to highlighting the capacities, limitations, and potential risks of large pre-trained models. Their ability to adapt to the content, tone, and style of virtually any prompt is what makes them so impressive—and potentially harmful. They can be prone to mimicking the worst aspects of humanity, including racist, sexist, and hateful outputs. They have no intrinsic regard for truth or falsity, making them excellent bullshitters. As the LaMDA story reveals, we are not always good at recognizing that appearances can be deceiving. — Updated on 2022-07-05 20:38:13 — Group:Public\n\n\nWhen scaled-up models unlock new capabilities, combining novel concepts coherently, explaining new jokes to our satisfaction, or working through a math problem step-by-step to give the correct solution, it is hard to resist the intuition that there is something more than mindless mimicry going on. — Updated on 2022-07-05 20:40:11 — Group:Public\n\n\nCan large pre-trained models really offer more than a simulacrum of intelligent behavior? There are two ways to look at this issue. Some researchers think that the kind of intelligence found in biological agents is cut from a fundamentally different cloth than the kind of statistical pattern-matching large models excel at. For these skeptics, scaling up existing approaches is but a fool’s errand in the quest for artificial intelligence, and the label “foundation models” is an unfortunate misnomer.Others would argue that large pre-trained models are already making strides toward acquiring proto-intelligent abilities. For example, the way large language models can solve a math problem involves a seemingly non-trivial capacity to manipulate the parameters of the input with abstract templates. Likewise, many outputs from multi-modal models examplify a seemingly non-trivial capacity to translate concepts from the linguistic to the visual domain, and flexibly combine them in ways that are constrained by syntactic structure and background knowledge. One could see these capacities as very preliminary ingredients of intelligence, inklings of smarter aptitudes yet to be unlocked. To be sure, other ingredients are still missing, and there are compelling reasons to doubt that simply training larger models on more data, without further innovation, will ever be enough to replicate human-like intelligence. — Updated on 2022-07-05 20:41:15 — Group:Public\n\n\nTo make headway on these issues, it helps to look beyond learning function and benchmarks. Sharpening working definitions of terms such as “understanding,” “reasoning,” and “intelligence” in light of philosophical and cognitive science research is important to avoid arguments that take us nowhere. We also need a better understanding of the mechanisms that underlie the performance of large pre-trained models to show what may lie beyond artificial mimicry. — Updated on 2022-07-05 20:42:11 — Group:Public\n\n\n\nMoving Beyond Mimicry in Artificial Intelligence\n\nMoving Beyond Mimicry in Artificial Intelligence\nMoving Beyond Mimicry in Artificial Intelligence\nMoving Beyond Mimicry in Artificial Intelligence"},"4archives/Hypothesis/Optimizing-Transformers-with-Hugging-Face-Optimum":{"title":"Optimizing Transformers with Hugging Face Optimum","links":["/","tags/article","tags/Personal"],"tags":["processed","article","Personal"],"content":"Optimizing Transformers with Hugging Face Optimum\nMetadata\n\nAuthor: philschmid.de\nTitle: Optimizing Transformers with Hugging Face Optimum\nReference: www.philschmid.de/optimizing-transformers-with-optimum\nCategory:article\n\nPage Notes\nHighlights\n\nExamples of graph optimizations include:Constant folding: evaluate constant expressions at compile time instead of runtimeRedundant node elimination: remove redundant nodes without changing graph structureOperator fusion: merge one node (i.e. operator) into another so they can be executed together — Updated on 2022-07-02 13:49:15 — Group:Personal\n\n\nOptimizing Transformers with Hugging Face Optimum\n\nOptimizing Transformers with Hugging Face Optimum\nOptimizing Transformers with Hugging Face Optimum\nOptimizing Transformers with Hugging Face Optimum"},"4archives/Hypothesis/Papers-with-Code---Papers-with-Code-Newsletter-18":{"title":"Papers with Code - Papers with Code Newsletter","links":["/","tags/article","tags/Public"],"tags":["processed","article","Public"],"content":"Papers with Code - Papers with Code Newsletter #18\nMetadata\n\nAuthor: paperswithcode.com\nTitle: Papers with Code - Papers with Code Newsletter #18\nReference: paperswithcode.com/newsletter/18/\nCategory:article\n\nPage Notes\nHighlights\n\nFindings suggest that scaling the parameters of the model consistently yields performance improvements as many other previous works have reported. On the other hand, the authors find that adding examples to improve performance depends more on the task’s format. An interesting finding in the paper is that in some tasks like extractive question answering and classification benefit a lot from additional examples. In some cases, collecting a few hundred examples is “worth” billions of parameters. A possible explanation for these findings is that problems like open question answering require more recalling of specific information while other tasks with restricted output space transfer across examples and can be learned with small amounts of labeled data. — Updated on 2021-10-17 14:42:13 — Group:Public\n\n\nPapers with Code - Papers with Code Newsletter #18\n\nPapers with Code - Papers with Code Newsletter #18\nPapers with Code - Papers with Code Newsletter #18\nPapers with Code - Papers with Code Newsletter #18"},"4archives/Hypothesis/Python-behind-the-scenes-13-the-GIL-and-its-effects-on-Python-multithreading":{"title":"Python Behind the Scenes #13: the GIL and Its Effects on Python Multithreading","links":["/","tags/article","tags/Public"],"tags":["processed","article","Public"],"content":"Python Behind the Scenes #13: the GIL and Its Effects on Python Multithreading\nMetadata\n\nAuthor: tenthousandmeters.com\nTitle: Python behind the scenes #13: the GIL and its effects on Python multithreading\nReference: tenthousandmeters.com/blog/python-behind-the-scenes-13-the-gil-and-its-effects-on-python-multithreading/\nCategory:article\n\nPage Notes\nHighlights\n\n\nthe GIL stands for the Global Interpreter Lock, and its job is to make the CPython interpreter thread-safe. — Updated on 2021-10-07 18:58:24 — Group:Public\n\n\nThe GIL allows only one OS thread to execute Python bytecode at any given time — Updated on 2021-10-07 18:58:34 — Group:Public\n\n\nIn a single-threaded Python program, the main thread is the only thread, and it never releases the GIL. — Updated on 2021-10-07 18:59:10 — Group:Public\n\n\nTo acquire the GIL, a thread first checks whether some other thread holds the GIL. If this is not the case, the thread acquires the GIL immediately. — Updated on 2021-10-07 18:59:53 — Group:Public\n\n\nOtherwise, it waits until the GIL is released. — Updated on 2021-10-07 18:59:58 — Group:Public\n\n\nIt waits for a fixed time interval called the switch interval (5 ms by default), and if the GIL is not released during that time, it sets the eval_breaker and gil_drop_request flags. The eval_breaker flag tells the GIL-holding thread to suspend bytecode execution, and gil_drop_request explains why. The GIL-holding thread sees the flags when it starts the next iteration of the evaluation loop and releases the GIL. It notifies the GIL-awaiting threads, and one of them acquires the GIL. It’s up to the OS to decide which thread to wake up, so it may or may not be the thread that set the flags. — Updated on 2021-10-07 19:00:37 — Group:Public\n\n\nAlthough Python threads cannot help us speed up CPU-intensive code, they are useful when we want to perform multiple I/O-bound tasks simultaneously. — Updated on 2021-10-07 19:03:14 — Group:Public\n\n\nThe conclusion here is that it’s possible to speed up CPU-intensive Python code using multithreading if the code calls C functions that release the GIL. Note that such functions can be found not only in the standard library but also in computational-heavy third-party modules like NumPy. — Updated on 2021-10-07 19:05:33 — Group:Public\n\n\nThe convoy effect takes place because each time the I/O-bound thread performs an I/O operation, it releases the GIL, and when it tries to reacquire the GIL after the operation, the GIL is likely to be already taken by the CPU-bound thread. So the I/O-bound thread must wait for at least 5 ms before it can set eval_breaker and gil_drop_request to force the CPU-bound thread release the GIL. — Updated on 2021-10-07 19:08:34 — Group:Public\n\n\nSmaller switch intervals make I/O-bound threads more responsive. But too small switch intervals introduce a lot of overhead caused by a high number of context switches. — Updated on 2021-10-07 19:12:00 — Group:Public\n\n\nThe GIL is so helpful because CPython increments and decrements integers that can be shared between threads all over the place. This is CPython’s way to do garbage collection. — Updated on 2021-10-07 19:17:57 — Group:Public\n\n\nThe GIL also simplifies the implementation of built-in mutable data structures. Lists, dicts and sets do not use locking internally, yet because of the GIL, they can be safely used in multi-threaded programs. — Updated on 2021-10-07 19:18:47 — Group:Public\n\n\nSimilarly, the GIL allows threads to safely access global and interpreter-wide data: loaded modules, preallocated objects, interned strings as so on. — Updated on 2021-10-07 19:18:54 — Group:Public\n\n\nFinally, the GIL simplifies the writing of C extensions. Developers can assume that only one thread runs their C extension at any given time. Thus, they don’t need to use additional locking to make the code thread-safe. When they do want to run the code in parallel, they can release the GIL. To sum up, what the GIL does is make the following thread-safe: reference counting; mutable data structures; global and interpreter-wide data; C extensions. — Updated on 2021-10-07 19:19:09 — Group:Public\n\n\nGarbage collection based on reference counting is not suited for multithreading. The only solution is to implement a tracing garbage collector that JVM, CLR, Go, and other runtimes without a GIL implement. — Updated on 2021-10-07 19:20:13 — Group:Public\n\n\nRemoving the GIL breaks existing C extensions. There is no way around it. — Updated on 2021-10-07 19:20:17 — Group:Public\n\n"},"4archives/Hypothesis/Simplifying-BERT-based-models-to-increase-efficiency,-capacity":{"title":"Simplifying BERT-based Models to Increase Efficiency, Capacity","links":["/","tags/article","tags/Personal"],"tags":["processed","article","Personal"],"content":"Simplifying BERT-based Models to Increase Efficiency, Capacity\nMetadata\n\nAuthor: amazon.science\nTitle: Simplifying BERT-based models to increase efficiency, capacity\nReference: www.amazon.science/blog/simplifying-bert-based-models-to-increase-efficiency-capacity\nCategory:article\n\nPage Notes\nHighlights\n\n\nTo make BERT-based models more efficient, we progressively eliminate redundant individual-word embeddings in intermediate layers of the network, while trying to minimize the effect on the complete-sentence embeddings. — Updated on 2022-07-02 15:55:45 — Group:Personal\n\n\nThe basic idea is that, in each of the network’s encoders, we preserve the embedding of the CLS token but select a representative subset — a core set — of the other tokens’ embeddings. — Updated on 2022-07-02 16:00:05 — Group:Personal\n\n"},"4archives/Hypothesis/Techniques-for-Training-Large-Neural-Networks":{"title":"Techniques for Training Large Neural Networks","links":["/","tags/article","tags/Personal"],"tags":["todo","article","Personal"],"content":"Techniques for Training Large Neural Networks\nMetadata\n\nAuthor: openai.com\nTitle: Techniques for Training Large Neural Networks\nReference: openai.com/blog/techniques-for-training-large-neural-networks/\nCategory:article\n\nPage Notes\nHighlights\n\n\nAn illustration of various parallelism strategies on a three-layer model. Each color refers to one layer and dashed lines separate different GPUs. — Updated on 2022-06-19 11:00:52 — Group:Personal\n\nAnnotation: \n\n\n\nData parallelism—run different subsets of the batch on different GPUs; Pipeline parallelism—run different layers of the model on different GPUs; Tensor parallelism—break up the math for a single operation such as a matrix multiplication to be split across GPUs; Mixture-of-Experts—process each example by only a fraction of each layer. — Updated on 2022-06-19 11:01:54 — Group:Personal\n\n\nData Parallel training means copying the same parameters to multiple GPUs (often called “workers”) and assigning different examples to each to be processed simultaneously. Data parallelism alone still requires that your model fits into a single GPU’s memory, but lets you utilize the compute of many GPUs at the cost of storing many duplicate copies of your parameters. That being said, there are strategies to increase the effective RAM available to your GPU, such as temporarily offloading parameters to CPU memory between usages. — Updated on 2022-06-19 11:02:32 — Group:Personal\n\n\nWith Pipeline Parallel training, we partition sequential chunks of the model across GPUs. Each GPU holds only a fraction of parameters, and thus the same model consumes proportionally less memory per GPU. — Updated on 2022-06-19 11:03:12 — Group:Personal\n\n\nGPipe has each worker process forward and backward passes consecutively and then aggregates gradients from multiple microbatches synchronously at the end. PipeDream instead schedules each worker to alternatively process forward and backward passes. — Updated on 2022-06-19 11:05:13 — Group:Personal\n\nAnnotation: \n\n\n\nPipeline parallelism splits a model “vertically” by layer. It’s also possible to “horizontally” split certain operations within a layer, which is usually called Tensor Parallel training. — Updated on 2022-06-19 11:07:00 — Group:Personal\n\n\nWith either strategy, we can slice the weight matrix into even-sized “shards”, host each shard on a different GPU, and use that shard to compute the relevant part of the overall matrix product before later communicating to combine the results. — Updated on 2022-06-19 11:07:06 — Group:Personal\n\n\nWith the Mixture-of-Experts (MoE) approach, only a fraction of the network is used to compute the output for any one input. One example approach is to have many sets of weights and the network can choose which set to use via a gating mechanism at inference time. — Updated on 2022-06-19 11:07:36 — Group:Personal\n\n\nDifferent experts can be hosted on different GPUs, providing a clear way to scale up the number of GPUs used for a model. — Updated on 2022-06-19 11:07:43 — Group:Personal\n\n\nCheckpointing (also known as activation recomputation) stores any subset of activations, and recomputes the intermediate ones just-in-time during the backward pass. This saves a lot of memory at the computational cost of at most one additional full forward pass. — Updated on 2022-06-19 11:08:24 — Group:Personal\n\n\nMixed Precision Training is to train models using lower-precision numbers (most commonly FP16). Modern accelerators can reach much higher FLOP counts with lower-precision numbers, and you also save on device RAM. — Updated on 2022-06-19 11:08:35 — Group:Personal\n\n\nOffloading is to temporarily offload unused data to the CPU or amongst different devices and later read it back when needed. — Updated on 2022-06-19 11:08:44 — Group:Personal\n\n\nMemory Efficient Optimizers have been proposed to reduce the memory footprint of the running state maintained by the optimizer, such as Adafactor. — Updated on 2022-06-19 11:08:58 — Group:Personal\n\n\nCompression also can be used for storing intermediate results in the network. For example, Gist compresses activations that are saved for the backward pass; DALL·E compresses the gradients before synchronizing them. — Updated on 2022-06-19 11:09:09 — Group:Personal\n\n\n\nTechniques for Training Large Neural Networks\n\nTechniques for Training Large Neural Networks\nTechniques for Training Large Neural Networks\nTechniques for Training Large Neural Networks"},"4archives/Hypothesis/The-independent-researcher":{"title":"The Independent Researcher","links":["/","tags/article","tags/Public"],"tags":["processed","article","Public"],"content":"The Independent Researcher\nMetadata\n\nAuthor: nadiaeghbal.com\nTitle: The independent researcher\nReference: nadiaeghbal.com/independent-research\nCategory:article\n\nPage Notes\nHighlights\n\n\nBut it’s sort of odd that we assume you need someone’s permission to do research. There’s no reason that universities need to be the gatekeepers of exploring and developing new ideas. — Updated on 2021-11-06 15:05:06 — Group:Public\n\n\n\nThis is the dark side of independent research. Without external validation - “I teach at Stanford” or “I got a grant from NASA”, it’s hard to convince people that you’re any good at what you do. The same goes for your output: you want peers to acknowledge and review your work, or the signoff of a well-respected journal. — Updated on 2021-11-06 15:06:56 — Group:Public\n\n\n\nFor the truly obsessed person, the need for validation isn’t about ego; it’s about sanity. You want to know there’s some meaning behind the dizzying mental labyrinth that you simultaneously can’t escape and also never want to leave. — Updated on 2021-11-06 15:08:09 — Group:Public\n\n\n\nLife is short. Do whatever you can’t stop thinking about. — Updated on 2021-11-06 15:10:42 — Group:Public\n\n\nDocumenting your findings in public (regardless of outcomes!) is a worthy contribution to society, full stop. — Updated on 2021-11-06 15:10:47 — Group:Public\n\n\n\nIf you’re doing something new, and you care about understanding the problem, people will pay attention. What’s more, they’ll take your ideas and make them better than you’d ever imagined. And that style of research - living in service to the public - starts to look very different from the bloated, ivory tower models we’ve been accustomed to. — Updated on 2021-11-06 15:11:03 — Group:Public\n\n\nYou don’t need a PhD to study something you care about. You don’t need to publish papers in academic journals to become widely respected. You just need a curious mind, a bankroll, and a commitment to learning in public. Producing work that makes other people think, and perhaps change their behavior, is the validation, and it’s enormously satisfying. — Updated on 2021-11-06 15:11:25 — Group:Public \n\n\n\nThe independent researcher\n\nThe independent researcher\nThe independent researcher\nThe independent researcher"},"4archives/Just-Keep-Buying":{"title":"Just Keep Buying","links":["4archives/Permanent-Notes/202205202200-Diminishing-Marginal-Utility","4archives/Permanent-Notes/202205202159-2x-Rule","4-Archives/Fleeting-Notes/Readwise/Books/Just-Keep-Buying"],"tags":[],"content":"\ntags:\n\nbooks\nfinance\npersonal finance\ncreated: 2022-05-16\nupdated: 2022-05-16\ntitle: “Just Keep Buying”\nauthors:\nNick Maggiulli\n\n\nInvestment as a Habit\n\nMake it a habit to invest your money like you make it a habit to pay your rent or mortgage. Buy investments like you buy food—do it often. (Location 114)\n\nMaking it a habit puts the principle of just-keep-buying into our subconscious routine such that we don’t overthink it and keep it consistent.\nInvestment VS. Saving\n\nIf you don’t have much money invested, then you should focus on increasing your savings (and investing it). However, if you already have a sizable portfolio, then you should spend more time thinking about the details of your investment plan. (Location 172)\n\nThe formula to calculate where you are at right now on this investment vs. saving curve:\n\nHow much do you expect to comfortably save in the next year S;\nHow much do you expect your investment to grow in the next year G;\nIf S &gt; G, then you should focus on saving money\nIf S &lt; G, you should focus on fine-tuning investment\nElse, you should focus on both of them equally\n\nSaving\n\nHow much to save: save what you can. Not a certain percentage nor a certain mount of dollars;\nDon’t stress over it: stress causes more harm;\n\nSpending\nCutting spending is to saving money as cutting calorie intake is to weight loss. Neither of them can give you long-term benefits.\nThe other alternative is to increase income. It is shown that increasing income does not incur increase of spending because of 202205202200 Diminishing Marginal Utility. As a result, it is important to grow your income.\nHow to Spend without Guilt\nBy applying 202205202159 2x Rule, we make commitment to ourself and the purchase such that we are consciously justifying the purchase with less or no guilt.\nWhat Are the Best Things You Can Buy\n\nExperiences\nTreating yourself occasionally\nExtra Time\nPaying upfront (worry-free frictionlessness)\nSpending on others\n\nHappiness VS. Fulfillment\nWe return to our normal level of happiness even after experiencing some positive events in short term. This is called Hedonic treadmill - Wikipedia.\nThen it is clear that chasing after happiness is a wrong quest and instead, we should aim for fulfillment — making impact with our decisions and making it count.\n\nPursue something so important that even if you fail the world is better off with you having tried. \nTim O’Reilly\n\nIncome\nHow To Increase Income\n\nSell your time\nSell your skills\nSell your products\n\nBut above methods can’t scale to some varying degrees. Therefore, you need to have income-producing assets aka. investment.\n\nReferences:\n\nJust Keep Buying\n"},"4archives/Literature-Notes/20220605111758":{"title":"Large Language Models Are Zero-Shot Reasoners","links":[],"tags":["natural_language_processing","natural_language_processing/prompting","natural_language_processing/chain_of_thought"],"content":"Large Language Models Are Zero-Shot Reasoners\n(6/5/2022, 11:17:58 AM)\n“but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.” (Kojima et al., 2022, p. 1) (pdf)\n“chain of thought prompting (CoT), which feed LLMs with the step-by-step reasoning examples rather than standard question and answer examples (see Fig. 1-a). Such chain of thought demonstrations facilitate models to generate a reasoning path that decomposes the complex reasoning into multiple easier steps. Notably with CoT, the reasoning performance then satisfies the scaling laws better and jumps up with the size of the language models.” (Kojima et al., 2022, p. 2) (pdf)\n“the versatility of this single prompt across diverse reasoning tasks hints at untapped and understudied zero-shot fundamental capabilities of LLMs, such as higher-level broad cognitive capabilities like generic logical reasoning [Chollet, 2019].” (Kojima et al., 2022, p. 3) (pdf)\n“In commonsense reasoning tasks, Zero-shot-CoT does not provide performance gains. It is expected as Wei et al. [2022] also reports that even Few-shot-CoT does not provide performance gains on Lambda (135B), but does improve StrategyQA when combined with substantially larger PaLM (540B) model, which may also apply for ours.” (Kojima et al., 2022, p. 5) (pdf)\n“(1) In commonsense reasoning (CommonsenseQA), Zero-shot-CoT often produces flexible and reasonable chain of thought even when the final prediction is not correct.” (Kojima et al., 2022, p. 6) (pdf)\n“Zero-shot-CoT often output multiple answer choices when the model find it is difficult to narrow it down to one” (Kojima et al., 2022, p. 6) (pdf)\n“Without chain of thought reasoning, the performance does not increase or increases slowly as the model scale is increased, i.e., the curve is mostly flat. In contrast, the performance drastically increases with chain of thought reasoning, as the model size gets bigger.” (Kojima et al., 2022, p. 7) (pdf)\n“When the model size is smaller, chain of thought reasoning is not effective.” (Kojima et al., 2022, p. 7) (pdf)\n\n\n@kojima_2022\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-1-Overview":{"title":"Lecture 1 Overview","links":[],"tags":[],"content":"\nLanguage isn’t a formal system. Language is glorious chaos.\nI Could Care Less\n\nHow Do We Represent the Meaning of a Word?\n\\mboxsymbol→\\mboxideaorthing\n\\mboxWordNet: good but missing sufficient context, less or hard up to date, bad for computers to ingest.\nOne-hot encoding: sparse and localist representation, missing notation of similarity.\nDistributional semantics: embed a word’s context in a vector\n\nYou shall know a word by the company it keeps\nJ. R. Firth\n\nWord2vec\n\nFun fact: it turns out corpus is actually a third-declension noun not a fourth-declension noun\nL(θ)=∏t=1T​∏−m≤j≤m,j=0​P(wt+j​∣wt​;θ)\n→\nJ(θ)=−T1​∑t=1T​∑−m≤j≤m,j=0​logP(wt+j​∣wt​;θ)\nCalculating the probability with softmax\nP(o∣c)=∑w∈V​exp(uwT​vc​)exp(uoT​vc​)​\nIt tells us how similar word o and c are to each other in a scale of the whole vocabulary.\nDerivatives\nwe want to maximize the J(θ). Taking the derivative for the center word vector:\n∂vc​∂logP(uo​∣vc​)​=logexp(uoT​vc​)−log∑w∈V​exp(uwT​vc​)\n∂vc​∂logP(uo​∣vc​)​=uo​−∑w∈V​exp(uwT​vc​)1​∑j=1V​∂vc​∂​exp(ujT​vc​)\n∂vc​∂logP(uo​∣vc​)​=uo​−∑w∈V​exp(uwT​vc​)1​∑j=1V​exp(ujT​vc​)×uj​\n∂vc​∂logP(uo​∣vc​)​=uo​−∑j=1V​uj​×∑w∈V​exp(uwT​vc​)exp(ujT​vc​)​\n∂vc​∂logP(uo​∣vc​)​=uo​−∑j=1V​uj​×P(ux​∣vc​)"},"4archives/Literature-Notes/Courses/CS224n/Lecture-10-Question-Answering":{"title":"Lecture 10 Question Answering","links":[],"tags":[],"content":"Motivation and History\nFind needle in the hay. People want their questions/queries answered without going through all the documents on the Internet.\nTypically it is done in two steps:\n\nFind candidate documents that are likely to contain the answer.\nFind the answer in those documents.\n\nLarge datasets and neural networks make it possible to train supervised models to do this during 2015/16. Before that, mostly are done by complex IR systems and linguistic rules.\nFactoid Question: answer of which is an Named Entity.\nThe SQuAD Dataset\nGiven a passage and a question, find a span in the passage that answers the question.\n1.1 VS. 2.0\n\n2.0 has half the question unanswerable based on the passage.\nNLI can be used as answer validation.\n\nEvaluation\n\nExact match\nF1 score\nBoth metric ignore the punctuations and articles\n\nLimitations\n\nAnswer is always span-based (Open-domain should be harder but more realistic)\nQuestion is constructed by reading the passage (The question is not natural question and biased towards the passage)\nAnswer is usually sentence bounded (We need multi sentence or passage based)\n\nThe Stanford Attentive Reader Model\n\nBiLSTM for question\nBiLSTM for passage\nUse question representation as an attention query to look for the start and end positions of the answer\n\nStanford Attentive Reader Model++\n\nAdded more features: POS, NER, frequency and word matching\n\nBiDAF\nAttention Flow Layer\nBoth context to question and question to context should be attended.\n# Context to question attention\n \nC = [S, 1, H] -&gt; [S, L, H]\nQ = [1, L, H] -&gt; [S, L, H]\nI = concat([C, Q, C x Q], dim=-1) -&gt; [S, L, H + H + H]\nI = Linear(I) -&gt; [S, J, 1]\nA = softmax(I) -&gt; [S, J]\n \n# Question to context attention\nC = [S, 1, H] -&gt; [S, L, H]\nQ = [1, L, H] -&gt; [S, L, H]\nI = concat([C, Q, C x Q], dim=-1) -&gt; [S, L, H + H + H]\nI = Linear(I) -&gt; [S, J, 1] -&gt; [S, J]\nM = argmax(I, dim=-1) -&gt; [S]\nM = softmax(M) -&gt; [S]\n \nRecent Architectures (2019)\nMore complex architecture and attentions.\nElMo and BERT\nBeginning of an era."},"4archives/Literature-Notes/Courses/CS224n/Lecture-11-Convolutional-Neural-Networks-for-NLP":{"title":"Lecture 11 Convolutional Neural Networks for NLP","links":["4archives/Literature-Notes/Courses/CS224n/Lecture-11-Convolutional-Neural-Networks-for-NLP"],"tags":["cs224n"],"content":"The paradigm in which people are believing at the moment constantly shifts, especially in the NLP/DL community. It is a life-long learning process for us.\nDebugging the neural networks is hard but is necessary.\nFrom RNNs to CNNs\nThe idea of CNN applied to text is that:\n\nThe last word usually dominates in RNNs (attention helps)\nWe’d like to capture some pieces of a sentence (similar to n-grams)\nlearn locally with phrases then group them later\n\n1D CNNs are used for text normally, working at the sequence dimension with the same hidden size. It reduces the sequence dimension, if without padding. It also reduces the hidden dimension for each kernel. So we can apply multiple kernels to increase the output hidden size.\nMax Pooling summarizes the output further. Max Pooling usually works in NLP as we care more about the salient signals. (pooling over time) \nStrides compactify the output with smaller seuqence dimension.\nTricks:\n\nYou can also mix strides and pooling to create local max pooling\nK-max pooling\nUse dilation to jump rows when convoluting\nUse dropout\n\nComparison\n\nBag of Vectors: good for simple classification tasks\nWindow model: good for sequence tasks\nCNNs: classification, efficient with GPUs\nRNNs: slower but better for sequence tasks, language modeling and if with attention can be really performant.\n\nUseful Concepts\nGated Units\n\nResidual Blocks aka. Skip Connections \nHighway Blocks: it looks like a gated version of ^283dea^283dea]] to learn the gates.\n\nBacth Normalization\n\nZ-transform over a mini-batch.\n\n1x1 Convolutions\n\nFully connected layers for all channels\n\nVery Deep Convolutional Networks for Text Classifications\n\nCharacter embeddings\n1d/temporal convolution\n9 ~ 29 layers, though 47 layers does not improve at all\n^92f988 works in general\n\nCombine RNNs and CNNs\nQuasi-Recurrent Neural Networks\n\nCarry over local gates over deeper layers to have pesudo-recurrence\nMore efficient with parallelism\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-12-Subword-Models":{"title":"Lecture 12 Subword Models","links":["4archives/Literature-Notes/Courses/CS224n/Lecture-1-Overview"],"tags":["subword","cs224n","course"],"content":"\nHuman languages/sounds(phonemes) is not countinus even though our mouth is.\nMorphemes are meaningful subwords.\nWriting systems are different between languages. Sometimes one word in one language might be 4 in another. (Componds)\nWhy we want a subword level model:\n\nFor understanding complex and rich morphology\nFor transliteration (e.g names)\nInformal spelling on the internet\n\n\n\nCharacter-level Models\n\nWord embeddings from character embeddings\nDirect sequence modeling based on character embeddings\n\nCharacters might don’t mean much by themselves. But large/deep models are capable of learning to remember higher level meaning from those character embeddings.\nBut one character model in English is not going to be useful for other languages, because the writing systems aren’t the same.\nDisadvantages\n\nhard to train because of the increased sequenc length\n\nSubword Models\nByte Pair Encoding: Merge byte pairs as a new byte\nWordpiece: Tokenize a word within a word boundary\nSentencepiece: Tokenize an input with spaces being a special character\n\nConv/Highway + char embeddings to learn word representations.\n\nHybrid Models\nOnly use the character LSTM model when it is OOV, both in training and inference.\nBecause the this character model is a second-level model, it does not perform well on capturing context from word-level representations. (Translating names for example)\nfastText\nA next-generation of ^c7f69e: n-gram augmented with boundary symbols for one word"},"4archives/Literature-Notes/Courses/CS224n/Lecture-13-Contextual-Word-Embeddings":{"title":"Lecture 13 Contextual Word Embeddings","links":["4archives/Literature-Notes/Courses/CS224n/Lecture-1-Overview","4archives/Literature-Notes/Courses/CS224n/Lecture-12-Subword-Models","4archives/Literature-Notes/Courses/CS224n/Lecture-13-Contextual-Word-Embeddings"],"tags":["cs224n","course","natural-language-processing"],"content":"Reflections on Word Representations\nOnly one representation for a word so far: Word2vec4 GloVe]] and fastText.\nRandomly initialized and trained word embeddings work if the dataset is large enough. But pre-trained word vectors help because you can train the word embeddings with much larger data and larger vocabulary.\nUNK: Using the same UNK token for all OOV words makes them indistinguishable from each other. (character-level model can remedy that)\nWord Sense Disambiguation: one word should have different representations for different aspects.\nWe already have a solution to model a word in a context: we can simply treat LSTM hidden representations as such.\nPre-ELMo and ELMo\nTagLM: combine char embeddings + word embeddings and LM embeddings/hidden states. Using only LM embeddings wasn’t great.\nELMo: a biLM (forward and backword models) with 2 BiLSTM layers. Using all layers’ hidden states instead of only one of them.\nLower layer is better for lower-level syntax: POS, Dependency Parsing, and NER; Higher layer is better for higher level semantics: sentiment, SRL, QA, and NLI\nULMfit\nUse the same pre-trained BiLSTM LM and fine-tune it together with a classification head.\nTransformer\nWe need parallelization but RNNs won’t cut it, and we still need attentions.\nAs dk​, the dimension of the hidden size gets larger, the variance of qTk also gets larger. After the softmax, the gradients gets smaller, so the authors scaled the dot product by a factor of dk​​.\nBERT\nMLM, Masked Language Modeling: predict masked tokens with bidirectional information;\nNSP, Next Sentence Prediction: predict sentence relation, utilizing segment embeddings;\nFine-tuning like ULMfit."},"4archives/Literature-Notes/Courses/CS224n/Lecture-14-Transformers-and-Self-Attention":{"title":"Lecture 14 Transformers and Self-Attention","links":[],"tags":["course","natural-language-processing","attention","transformer"],"content":"Self-attention\n         ┌─┐                  \n         │E│                  \n         └─┘                  \n          ▲                   \n          │                   \n          │                   \n        ┌───┐                 \n        │ a │◀──────────────┐ \n        └───┘               │ \n          ▲                 │ \n          │                 │ \n       ┌────┐               │ \n       │    │               │ \n       │dot │               │ \n   ┌──▶│prod│◀──┐           │ \n   │   │    │   │           │ \n   │   └────┘   │           │ \n   │            │           │ \n┌─────┐      ┌─────┐        │ \n│ W_k │      │ W_q │        │ \n└─────┘      └─────┘        │ \n   ▲            ▲           │ \n   │            │           │ \n  ┌─┐          ┌─┐         ┌─┐\n  │E│          │E│         │E│\n  └─┘          └─┘         └─┘\n\nWk​ and Wq​ is specific to one attention head, so if we want to capture more relations, we need to use more attention heads.\nAdvantages\n\ndirect connection between any two positions\ndirect modeling of the context\ncapability to be parallelized\nmodeling similarity by nature\nrelative attention provides more expressiveness for input such as image, music or graph\n\nWhat’s Next\n\nNon autoregressive transformers/decoding\nself-supervision\nunderstanding\nmultitask learning\nlong-range context\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-15-Natural-Language-Generation":{"title":"Lecture 15 Natural Language Generation","links":[],"tags":["course","natural-language-processing","natural-language-generation","cs224n"],"content":"What is Natural Language Generation\nNLP refers to the property that a model generates text at the output side.\nLanguage model and conditional language model are corner stones of NLG: Language model gives a probability distribution given an input. Conditional language model takes more than just the input but also other signals as well.\nDecoding\nGreedy Decoding\nBeam Search\n\nsmall k: deteriorates to greedy decoding, no backtracking and generally yields poor performance\nlarge k: better performance but expensive to track, higher beam size might lead to degraded performance as well (generic but less useful)\n\nSampling\n\nPure/naive sampling directly from the distribution instead of just argmax in greedy decoding\nTop-k sampling\n\nTemperature in Softmax\nIt changes the decoding probability distribution, not a decoding algorithm itself.\nPt​(w)=∑exp(so​)exp(sw​)​→∑exp(so​/τ)exp(sw​/τ)​\n\nHigher temperature: everything is squeezed towards 1/uniform and therefore have closer probabilities, thus more diverse output;\nLower temperature: the distribution is more spiky and less diverse;\n\nTasks and Approaches\nSummarization\n\nsingle-document summarization\nmulti-document summarization\n\nOr\n\nextractive summarization\nabstractive summarization\n\nNeural Summarization\n\nPointer generator/copy mechanism\nBottom-up summarization:\n\ncontent selection: tag a word to include in the generation or not\ngeneration: only generate on the selected words\n\n\n\nDialogue\n\nTask-oriented\nSocial dialogue\n\nTraditional RNN models does not help in this take because of:\n\ngenericness: change the sampling or change generation process (e.g. to add retrieval process)\nirrelevant response: use mutual information to penalize generic responses\nrepetition: block generating same n-grams, coverage mechanism\nlack of context\nlack of consistency, persona\n\nStorytelling\nImage or prompt → story\nEvaluation\nROUGE: Recall-oriented Understudy for Gisting Evaluation, focusing more on recall(information retrieval) than precision(BLEU). Higher ROUGE score does not guarantee better summarization.\nPerplexity only tells you how strong your LM is but not generation.\nAspect-based Automatic Metrics\n\nFluency\nStyle\nDiversity\nRelevance\n\nHuman evaluations aren’t perfect either.\nTrends and the Future\n\nincorporating discrete latent variables\nnon-autoregressive generation\nbetter objectives\n\n\nuse constraints in open-end generation tasks\naim for specific targets for both the model and evaluation\nautomatic metrics help\nreproducibility\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-16-Coreference-Resolution":{"title":"Lecture 16 Coreference Resolution","links":[],"tags":["course","natural-language-processing","co-reference-resolution","cs224n"],"content":"Definitions\n\nCoreference: mentions that refer to the same entity\nanaphora: entities come before the word (VS. cataphora)\n\nBarack Obama said he will sign the bill. In this case he refers to Barack Obama instead of linking to the entity directly\nWe wen to see a concert last night. The tickets were really expensive. (Bridging anaphora)\n\n\n\nApplications\n\nMachine Translation: especially for languages that drop pronouns\nDialogue Systems\n\nPipeline:\n\nMention Detection: pronouns/POS, named entities/NER, or noun phrases/NP\nCoreference resolution\n\nModel Architectures\n\nRule-based\nMention Pair\nMention Ranking: rank antecedents + NA/Dummy mention\nEnd-to-end Neural Model:\n\nword and character embeddings\nBi-LSTM\nspan detection + attention\ncalculate a coreference score for each span pair i and j\n\n\nClustering: agglomerative clustering\n\nFeatures Used in Those Models\n\nStatistical features\nEmbeddings\n\nEvaluation\n\nB-cubed: average of precision and recall of all clusters and gold clusters\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-17-Multitasking-Learning":{"title":"Lecture 17 Multitasking Learning","links":[],"tags":["multitasking-learning","natural-language-processing","cs224n","course"],"content":"Multitasking Learning\nSingle-task learning: train one model to do one job. But you need to start from scratch when switching to another task; Partially pre-trained models(Word2Vec, GloVe or ELMo) might help but still not ideal. (This is not a concern ever since the introduction of PLMs)\nTasks need supervision but the pre-training for general LMs are not using the same objective (before 2020).\nUnified multitasking learning: one model to rule them all. No or minimum overhead dealing with new problems and potentially moves toward continual/life-long learning.\ndecaNLP: The Natural Language Decathlon\n\nQA as the unified framework: Question + Context → Answer\nMultitasking can hurt the performance: catastrophic forgetting\nMultitasking helps the zero-shot learning the most\n\nMultitasking Training Strategies\nIssues for MT: pointer generator enforces the model to learn to point back to the input but machine translation task is ignoring that part of the model\n\nAnti-Curriculum Training: difficult tasks first to escape local optima; By difficult, it means how many epochs it takes to converge for a single-task model\n\nTransferability\n\nIt transfers well to new tasks than random initialization\nZero-shot performance\ncompositional multitasking? e.g. English to German summary\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-18-Constituency-Parsing-and-TreeRNNs":{"title":"Lecture 18 Constituency Parsing and TreeRNNs","links":[],"tags":["constituency-parsing","natural-language-processing","course","cs224n","recursive-neural-network","sentiment"],"content":"Semantic Representation Beyond Word Vectors\nWe want to represent the meaning of larger phrases instead of words. i.e. to find the meaning of a semantic composition of smaller elements, aka. compositionality.\nThe Recursion From Small Parts to Bigger Parts\nThe hierarchical structure of the language that can theoretically expand to infinity.\nThe principle of compositionality: the meaning of a sentence is defined by 1. the words and 2. the way it is constructed.\nThe Difference Between Recurrency and Recursiveness\nRecurrency: modeling the meaning of the input up to the current step;\nRecursiveness: modeling each constituency bottom up, requiring a tree/syntactic structure;\nRecursive Neural Network for Structure Prediction\n                                              \n Plausibility Score           Meaning Vector  \n                                              \n          ▲                          ▲        \n          └─────────────┬────────────┘        \n                        │                     \n                        │                     \n                ┌──────────────┐              \n                │              │              \n                │      NN      │              \n                │              │              \n                │              │              \n                └──────────────┘              \n                        ▲                     \n                        │                     \n               ┌────────┴─┐                   \n               │          │                   \n               │          │                   \n               │          │                   \n                                              \n              W1         W2                   \n                                              \n\nEquation\np=tanh(W[c1​c2​​]+b)\nSyntactically-Untied RNN\nInstead of using the same weight matrix W like the one in TreeRNN, use different weight matrices for different constituents.\nNew Equation\np=tanh(W[C2​⋅c1​C1​⋅c2​​]+b)\nEach constituent i not only has a meaning vector ci​ but also an operator matrix Ci​ so that “good” in “good person” can have an influence on the “person”.\nP=W([C1​C2​​])\nand the parent operator matrix is calculated based on the two constituents’ operator matrices.\nRecursive Neural Tensor Network\npi​=c1​⋅Wi​⋅c2⊺​+pi′​\npi​ comes from the Syntactically-Untied RNN."},"4archives/Literature-Notes/Courses/CS224n/Lecture-2-Word-Vectors-and-Word-Senses":{"title":"Lecture 2 Word Vectors and Word Senses","links":[],"tags":[],"content":"1. Recap on Word2vec\n\nWords tend to have a high similarity with high-frequency words (of, the, and)\nWords can be similar to others in many different directions in high-dimension space\n\n2. Optimization: Gradient Descent\nα: learning rate\nθ\\mboxnew=θ\\mboxold−α▽θ​J(θ)\nStochastic Gradient Descent\nUse mini-batch to do the calculation instead of updating the network after one whole pass.\nDetails\n\nTwo matrices to simlify the calculation.\nTwo variants: Skip-gram (context words → center word) and Continous Bag of Words (center word → context words)\nNegative sampling instead of naïve softmax\n\n3. Co-occurrence\n\nsparse and large matrix → reduce the dimensionality → SVD\nHacks:\n\nRamped/weighted windows\nFunction words are capped\nUse Perason Correlation instead of counts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCount basedDirect predictionLSA, HALSkip-gram, CBOW, …Fast trainingScale with corpus sizeEfficient usage of statsInefficient usage of statsWord similarityBeyond word similarityIssues with large countsTransferability\n4. GloVe\nP(x∣\\mboxice) should be larger with x=\\mboxsolid and x=\\mboxwater, P(x∣\\mboxsteam) should be larger with x=\\mboxgas and x=\\mboxwater. Then P(x∣\\mboxsteam)P(x∣\\mboxice)​ would be high when x=\\mboxsolid or low when x=\\mboxgas .\nIf we assume wi​⋅wj​=logP(i∣j), then the wx​⋅(wa​−wb​)=logP(x∣b)P(x∣a)​\n5. Evaluation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntrinsicExtrinsicevaluation on a subtaskevaluation on a real taskfast to computedifficult to computeunderstanding the systemunderstanding changes to the systemnot understanding the real performancenot understanding the system\nIntrinsic Evaluations\n\nanalogies\nword similarity\nword sense\ndisambiguity\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-20-–-Future-of-NLP-+-Deep-Learning":{"title":"Lecture 20 – Future of NLP + Deep Learning","links":[],"tags":["scaling","unsupervised-learning","risks","social-impact"],"content":"We want to utilize the unlabeled data for low-resource languages and also because of rare labeled data;\nUnsupervisation in Machine Translation\n\nPre-training: train two LMs with unlabeled data;\nBack-translation: back translate the source and target sentences. Both models have perfect target reference translation;\n\nUnsupervised Word Translation\nAlign two word embedding spaces by learning an asymmetrical transformation matrix.\n\nDiscriminator: given an embedding if it comes from space X or space Y(WX)\n\nUnsupervised NMT\n\nDe-noising auto-encoder: to capture input meaning\nBack translation: the same model but different BOS(&lt;Fr&gt; and &lt;En&gt;)\n\nCross-lingual BERT\n\nLanguage embeddings\n\nSocial Impact\n\ndecision making (bias)\n\nFuture Directions\n\nMultitasking Training\nMore difficult tasks\nLow-resource settings:\n\nedge devices\nlow-resource data\nmeta-learning\n\n\nInterpretability\nDialogue\nHealthcare\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-3-Word-Window-Classification,-Neural-Nets,-and-Calculus":{"title":"Lecture 3 Word Window Classification, Neural Nets, and Calculus","links":[],"tags":[],"content":"Classification revie/introduction\np(y∣x)=∑c=1C​exp(Wc​⋅x)exp(Wy​⋅x)​\nTo maximize the probability for the correct class, one could minimize the negative log likelihood −logp(y∣x). But in practice, people often use cross entropy instead.\nH(p,q)=−∑c=1C​p(c)logq(c) where p is the one-hot label vector and the q is the predicted probability distribution, in which case, it is the same as negative log likelihood.\nNeural Networks Introduction\nRunning multiple logistic regressions at the same time.\nWhy do we need non-linear activation functions? Because multiple linear transformations is still a linear transformation.\nNamed Entity Recognition\nwindow-based classification: concatenate the window embeddings as the center word representation.\nh=f(Wx+b)\nθ\\mboxnew=θ\\mboxold−α∇θ​J(Θ)\nBinary True Vs. Corrupted Word Window Classification\nMatrix Calculus Introduction\n∂x∂​(Wx+b)∂b∂​(Wx+b)∂u∂​(uTh)​=W=I=hT​​"},"4archives/Literature-Notes/Courses/CS224n/Lecture-4-Back-propagation-and-computation-graphs":{"title":"Lecture 4 Back-propagation and computation graphs","links":[],"tags":[],"content":"∂W∂s​=δTxT\nwhere δ is the error signal from above (later layers) and x is the local gradiaent signal.\nTips on deriving gradients:\n\n\nKeep track of dimensionality\n\n\nChain rule\n\n\nSoftmax: two cases, one for correct label and one for others\n\n\nElement-wise derivatives first if you are getting confused\n\n\nUse shape convention\n\n\nUse pre-trained word vectors\n\n\nTrain/fine-tune them only when you have a large dataset\n\n\nBackpropagation\n∂h∂s​​→∂z∂h​→∂z∂s​​​\nUpstream graident * local gradients → downstream gradients\nGradient Checking:\nFor small delta, compute the gradients using f′(x)=2hf(x+h)−f(x−h)​\nRegularization\nJ(θ)=...+λ∑k​θk2​\nNon-linear Activations\nParameter Initialization\nOptimizers\nLearning Rates\n\nstart small\nor if you are using fancy optimizers, start large (0.1 e.g.)\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-5-Dependency-Parsing":{"title":"Lecture 5 Dependency Parsing","links":[],"tags":[],"content":"1. Syntactic Structure\nconstituency = phrase structure grammar = context-free grammars\nPhrase structure organizes words into nested constituents.\nDependency structure shows words depend on which other words\nWord embeddings carry word meanings, but it won’t go very far. In order to understand bigger concepts, it is important understand the sentence structure that glues words together.\nIn programming languages, the use of else is strictly interpreted deterministically. But it is not the same with natural language, it inherits ambiguity.\n\nPrepositional phrase attachment ambiguity\n\nSan Jose cops kill man with knife\nPP attachment multplies (exponentially) as the number of PP grows (Catalan numbers)\n\n\nCoordination scope ambiguity\n\nShuttle veteran and longtime NASA executive Fred Gregoy appointed to board\nNo heart, cognitive issues\n\n\nAdjectival Modifier Ambiguity\nVerb Phrase attachment ambiguity\n\nMutilated body washes up on Rio beach to be used for Olympics beach volleyball\n\n\n\n2. Dependency Grammar and TreeBanks\n\nhead → dependent\nAdd a ROOT node\nEach word is either a dependent of something or a ROOT\n\nThis makes the dependencies a tree\n3. Transition-based Dependency Parsing\nshift and reduce\n4. Neural Dependency Parsing\nML issues:\n\nfeatures are sparse\nfeatures are incomplete\nfeatures are expensive\n\nUse distributed representations"},"4archives/Literature-Notes/Courses/CS224n/Lecture-6-Language-Modeling":{"title":"Lecture 6 Language Modeling","links":[],"tags":[],"content":"Given a sequence of words, a language model computes the probability distribution of the next word.\nP(xt+1∣xt,...,x1)\nN-gram Language Models\nN-gram here refers to the words instead of sub-word tokens.\nUsing a pre-defined N prevents distant but relevant context being learned.\n\nSparsity Problem:\n\nCount-based probability can lead to zero probability in the nominator. Smoothing would help.\nCount-based probability can lead to zero probability in the denominator. Fall-back (N-gram → N-1 gram etc)would help\nIt will get worse as the N gets bigger. N&lt;5 in general.\n\n\n\nNeural Networks\n\nwindow based neural language models:\n\nStill cannot handle remote context with a fixed window\nNo sparsity problem\nDon’t need to store counts\n\n\n\nRecurrent Neural Networks\n\nSame weight matrix is applied at each time step\nCan process input with any length\nRecurrent steps cannot be parallelized\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-7-Vanishing-Gradients,-Fancy-RNNs":{"title":"RNN Variants: LSTM and GRU","links":[],"tags":[],"content":"Vanishing or Exploding Gradient Problem\n\ngradients get smaller and smaller when back propagation.\n\nIf gradients are getting smaller, there is no way to know if the dependency is not needed or not captured. Models can’t learn distance dependencies.\nSyntactic Recency VS. Sequential Recency\n\nThe writer of the books is\nThe writer of the books are\n\nExploding Gradients\n\na large step change in parameters\n\nGradient Clipping\n\nmake smaller steps when the cliffs are steep\n\nRNN Variants: LSTM and GRU\nLSTM\n\nHidden state and cell state. Cell state stores long-term information\n\nftitot​=σ(Wf​ht−1+Uf​xt+bf​)=σ(Wi​ht−1+Ui​xt+bi​)=σ(Wo​ht−1+Uo​xt+bo​)​​\n\nForget gate controls what is forgotten and kept\nInput gate controls what is updated\nOutput gate controls what is output\n\nc~tctht​=tanh(Wc​ht−1+Uc​xt+bc​)=ft∘ct−1+it∘c~t=ot∘tanh(ct)​​\nGRU\n\nno cell states\n\nutrtht​=σ(Wu​ht−1+Uu​xt+bu​)=σ(Wr​ht−1+Ur​xt+br​)h~t=(1−ut)∘ht−1+ut∘h~t​=tanh(Wh​(rt∘ht−1)+Uh​xt+bh​)​​\nGradient Clipping and Skip Connections\nallow gradients to flow\nBidirectional RNN and Multi-layer RNN"},"4archives/Literature-Notes/Courses/CS224n/Lecture-8-Translation,-Seq2Seq,-Attention":{"title":"Lecture 8 Translation, Seq2Seq, Attention","links":[],"tags":[],"content":"Machine Translation\n\nEarly Machine Translation: Rule-based and dictionary-based\nStatistical Machine Translation: Learning probability of argmaxy​P(y∣x)→argmaxy​P(x∣y)P(y) to find best y (translation) of x (input). P(x∣y) is considered a translation model and P(y) is the language model\n\nStatistical Machine Translation\n\nP(x∣y) is learned approximately by learning P(x,a∣y) where a is an alignment\nDecoding is a process finding the translation while pruning low-probability branches\n\nNeural Machine Translation\n\nEncoder captures the representation of the input source sentence with the last hidden state\nThe hidden state is fed into decoder with an START token as input\n\nSequence to Sequence\n\nMany applications: Summarization, dialogue, parsing, and code generation\nIt is considered as a conditional language model\nTraining can be done with teacher forcing, end to end\n\nDecoding\n\nGreedy decoding: Taking the output as input for next round, however local argmax is not global argmax\nBeam search:\n\nKeep track of K most probable translations\nStop one hypothesis when an END token is generated\nTill t steps or n complete hypotheses\nLonger hypotheses have lower scores → normalize by length\n\n\n\nAdvantages\n\nBetter performance: fluency, context usage and more capable of learning phrases\nSimplicity\n\nDisadvantages\n\nInterpretability\nControllability\n\nEvaluation\n\nBLEU: n-gram precision + brevity penalty\n\nProblems\n\nOOV\nDomain mismatch\nDistance context\nBiases\nCommonsense\nHallucination, repetition\n\nAttention\nSeq2seq has an information bottleneck for using the last hidden state alone for decoding.\nAt each step of decoding, attention helps the model to focus on some part of the input directly. Single hidden state → weighted hidden state from all hidden states, plus shortcut connections to remediate vanishing gradients. It also provides better interpretability.\nVariants\n\ndot-product attention scores: ei​=sThi​\nmultiplicative attention: ei​=sTWhi​\nadditive attention: ei​=vTtanh(W1​hi​+W2​s)\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-9-Practical-Tips-for-Final-Projects":{"title":"Lecture 9 Practical Tips for Final Projects","links":[],"tags":[],"content":"Project Types\n\nFind an application or task\nFind an architecture or a variant\nAnalysis of a model or a dataset\nTheoretical Analysis\n\nSources\n\nACL\nICLR\nNeuralPS\nICML\nNAACL\nArxiv Sanity\nPaperwithcodes\nKaggle\n"},"4archives/Literature-Notes/Courses/CS224n/Lecture-BERT-and-Other-Pre-trained-Language-Models":{"title":"Lecture BERT and Other Pre-trained Language Models","links":[],"tags":[],"content":"ELMo\nDynamic embeddings not from the Embeeding layer but from two unidirectional LSTM layers.\nTransformer\n\nMulti-head self attention\n\nNo locality bias (N×N)\nOne input with multiple type of information\n\n\nFeed-forward layers\nLayer norm and residuals\nPositional embeddings\n\nBERT\nBidirectional models enable the word to see themselves from context, then prediction of the next word is trivial.\n\nPredicting 15% word throughout the forword pass:\n\n80% of them are replaced with [MASK]\n10% of them are kept same\n10% of them are randomly replaced with other words\n\n\nNext sentence prediction (not so important compared to MLM based on # On Losses for Modern Language Models), but it looks still helpful for NLI in their ablation study\nToken embeddings + Segment embedings + Position embeddings\nOne model to rule them all\n\nRoBERTa\n\nMore data\nBetter and longer training\n\nXLNet\n\nRelative positional embedding\nPermutation language model\n\nALBERT\n\nParameter sharing\nFactorized embedding\nSmaller but not faster\n\nT5\n\nExtensive ablation study\n\nElectra\n\nDiscriminator to tell mask predictions from the truth\n\nDistillation\nIt works better than pretraining+fine-tuning for small models"},"4archives/Literature-Notes/Courses/CS224n/MOC-CS224n-NLP-with-Deep-Learning-(Winter-2019)":{"title":"MOC CS224n NLP with Deep Learning (Winter 2019)","links":["4archives/Literature-Notes/Courses/CS224n/Lecture-1-Overview","4archives/Literature-Notes/Courses/CS224n/Lecture-2-Word-Vectors-and-Word-Senses","4archives/Literature-Notes/Courses/CS224n/Lecture-3-Word-Window-Classification,-Neural-Nets,-and-Calculus","4archives/Literature-Notes/Courses/CS224n/Lecture-4-Back-propagation-and-computation-graphs","4archives/Literature-Notes/Courses/CS224n/Lecture-5-Dependency-Parsing","4archives/Literature-Notes/Courses/CS224n/Lecture-6-Language-Modeling","4archives/Literature-Notes/Courses/CS224n/Lecture-7-Vanishing-Gradients,-Fancy-RNNs","4archives/Literature-Notes/Courses/CS224n/Lecture-8-Translation,-Seq2Seq,-Attention","4archives/Literature-Notes/Courses/CS224n/Lecture-9-Practical-Tips-for-Final-Projects","4archives/Literature-Notes/Courses/CS224n/Lecture-10-Question-Answering","4archives/Literature-Notes/Courses/CS224n/Lecture-11-Convolutional-Neural-Networks-for-NLP","4archives/Literature-Notes/Courses/CS224n/Lecture-12-Subword-Models","4archives/Literature-Notes/Courses/CS224n/Lecture-13-Contextual-Word-Embeddings","4archives/Literature-Notes/Courses/CS224n/Lecture-14-Transformers-and-Self-Attention","4archives/Literature-Notes/Courses/CS224n/Lecture-15-Natural-Language-Generation","4archives/Literature-Notes/Courses/CS224n/Lecture-16-Coreference-Resolution"],"tags":["natural-language-processing","course","cs224n","toc"],"content":"Lectures\n\nLecture 1: Overview\nLecture 2: Word Vectors and Word Senses\nLecture 3: Word Window Classification, Neural Nets, and Calculus\nLecture 4: Back-propagation and computation graphs\nLecture 5: Dependency Parsing\nLecture 6: Language Modeling\nLecture 7: Vanishing Gradients, Fancy RNNs\nLecture 8: Translation, Seq2Seq, Attention\nLecture 9: Practical Tips for Final Projects\nLecture 10: Question Answering\nLecture 11 Convolutional Neural Networks for NLP\nLecture 12 Subword Models\nLecture 13 Contextual Word Embeddings\nLecture 14 Transformers and Self-Attention\nLecture 15 Natural Language Generation\nLecture 16 Coreference Resolution\n\nAssignments\n\nAssignment 1\nAssignment 2\nAssignment 3\nAssignment 4\n"},"4archives/Literature-Notes/Courses/How-to-Organize-your-Workflow-to-Maximize-Productivity":{"title":"How to Organize your Workflow to Maximize Productivity","links":["4archives/Literature-Notes/Courses/Productivity-Masterclass"],"tags":["productivity","self-help","skillshare","course"],"content":"Pilot 10\nSet the course, prioritize the tasks on the horizons (preferably in the morning):\n\nCalendars and actions \nProjects \nAreas of focus \nGoals and objectives: to generate projects accordingly \nLong-term visions \nPurpose and principles \n\n^c2b656:\n\nSchedule tasks into calendar (time-blocking), having default tasks instead of having free time to be wasted\nUse a to-do list:\n\nTackle the highlight or\nEat a frog\n\n\n\n^457f88^707f08]]:\nProject is a group of actionable tasks. So we need to be more precise about that the actions and tasks are.\nDon’t wait for all the tasks to start the project, tackle them as they come.\nProject falls into an area of focus/responsibility.\n^5df947:\nSystem goals: having a system measured by the mechanism not the output (e.g go the gym 3 times a week)\nProgress goals: net positive progression\n^7fd671^6996e7]]:\nHave a big picture.\nPlane 80\nTransclude of Productivity-Masterclass#motivation\nNewton’s First Law of Motion\n2 Minute Rule\nIf it takes less than 2 minutes, just do it now.\n5 Minute Rule\nJust start with 5 minutes. It will be hard to stop once it starts.\nRemove Frictions by Designing Your Environment\nGetting into the Flow State\n\nGet rid of distractions but also add helpful cues\nNo Multitasking\nWork on challenging but not too difficult tasks\n\nCourse Correction\nStay out of the frustration and set a new course immediately.\nReitoff Principle\nWorry-free and guilty-free downtime.\nGet Things Done (GTD)\n\nCapture\nClarity: Have a clear definition of the task\nOrganize\nReflect\nEngage\n\nEngineer 10\nTake care of your mind and body\nReview regularly:\n\ndaily: check with yourself and keep a log\nweekly: keep the system in check, no loose ends, see Getting Things Done\nmonthly\nyearly\n"},"4archives/Literature-Notes/Courses/Mastering-Productivity-Create-a-Custom-System-that-Works":{"title":"Mastering Productivity Create a Custom System that Works","links":[],"tags":["productivity","self-help","course","skillshare"],"content":"Task Management\n\nSet a deadline\nLayout projects and tasks\n\nCalendar\n\nPut things down on calendar\n\nFile Management\n\nDigital files\nPhysical files\n\nDigitalization\nPhysical storage\n\n\n\nEmail\nDon’t touch a message until you are ready\nDelete marketing emails\nArchive emails when it contains useful information\nReview\nRegularly review notes, calendars, todo lists and inboxes"},"4archives/Literature-Notes/Courses/Productivity-Masterclass":{"title":"Productivity Masterclass","links":["Book-Atomic-Habits"],"tags":["productivity","self-help","skillshare","course"],"content":"Three Roles\nPilot (10%)\nDecision maker and the overall brain of the process \nPlane (80%)\nExecutor \nEngineer (10%)\nThe role who takes care of the system and makes sure that everything works efficiently \nThree Myths\n\nTime is what we want most, but what we use worst.\n– William Penn\n\nTime\nWe have more control of our time than we thought. It is not that we don’t have time. We are actively convincing ourselves not to choose to do it. As a result, our brain is trained to fool ourselves to always to choose the easy way out. Work with our time like it is our muscle. \nMotivation\n\nMotivation is overrated:\n┌───────────┐     ┌────────────┐       ┌──────────┐\n│  Thought  │────▶│ Motivation │──────▶│  Action  │\n└───────────┘     └────────────┘       └──────────┘\n\nMotivation is whimsical and fleeting. Discipline should be the enforcer instead.\nTwo aspects to consider when conquering the motivation dilemma:\n\nOutput:\n\nShort feedback loop.\nMore salient output.\n\n\nAction itself:\n\nMake it more enjoyable, fun: e.g. gamifying the process. The 4th law of reward in Book Atomic Habits – making it satisfying.\nMake the inaction painful. The inversion of the 3rd law of Book Atomic Habits – making it easy/difficult.\n\n\n\nMultitasking\nMultitasking (context switching to our minds) is expensive. Instead, aim to get into the flow state (pushing our mental state to the limits, challenging way but not too difficult).\n- Choose not to be distracted, just like we can choose how we spend our time ^909b27\nThree Laws\nParkinson’s Law\nWork expands to fill the time we allocate to it. To apply this in our life, we need to plan tasks with a stricter time window aka. assigning artificial deadlines. For example, allocate 6 months for a ten-year plan. It forces us to prioritize our tasks and time.\nPareto’s Law\nThe famous 20-80 rule. Choose the right thing to do (20%) to harvest the 80% of the results.\nNewton’s First Law of Motion\nThe first step is the hardest and use the momentum to your advantage. But being in the motion != doing a quality job, which means once you are comfortable of spending 5 minutes on a habit, find a way to improve it and invest more time on it.\nThree Powers\nPower of Habit\n1.01365=37.7834343329\n1 percent better a day means 37 times better a year. The discipline and the consistency help us be in the motion. Book Atomic Habits\nPower of Productive Downtime\nUse the time otherwise wasted.\nPower of Procrastination\nTry to gain something out of procrastination. E.g. learning something while watching Youtube videos.\nFun Factor\nProductivity=InputUseful ouput​×Fun Factor\nMake sure you are enjoying what you are doing. YOLO!"},"4archives/Literature-Notes/Courses/_Index_of_Courses":{"title":"_Index_of_Courses","links":["4archives/Literature-Notes/Courses/Productivity-Masterclass","4archives/Literature-Notes/Courses/Mastering-Productivity-Create-a-Custom-System-that-Works","4archives/Literature-Notes/Courses/How-to-Organize-your-Workflow-to-Maximize-Productivity","4archives/Literature-Notes/Courses/CS224n/_Index_of_CS224n"],"tags":[],"content":"Productivity Masterclass\nMastering Productivity Create a Custom System that Works\nHow to Organize your Workflow to Maximize Productivity\n_Index_of_CS224n"},"4archives/Literature-Notes/Courses/index_Courses":{"title":"index_Courses","links":["4archives/Literature-Notes/Courses/Productivity-Masterclass","4archives/Literature-Notes/Courses/Mastering-Productivity-Create-a-Custom-System-that-Works","4archives/Literature-Notes/Courses/How-to-Organize-your-Workflow-to-Maximize-Productivity","4archives/Literature-Notes/Courses/CS224n/index_CS224n","4archives/Literature-Notes/Courses/_Index_of_Courses"],"tags":[],"content":"Productivity Masterclass\nMastering Productivity Create a Custom System that Works\nHow to Organize your Workflow to Maximize Productivity\nindex_CS224n\n_Index_of_Courses"},"4archives/Literature-Notes/Readings/AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE":{"title":"AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE","links":[],"tags":["paper-reading","computer-vision","transformer"],"content":"AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\nFound an interesting thread on Twitter:\n\nRequest for Counterparty: I would like to make a Erlich / Buffett bet on a proposition similar to:\n“On 1/1/2027, a Transformer-like will continue to hold the SoTA in effectively all benchmarked NLP tasks.”\nI would be taking the negative position.\n–– Sasha Rush @srush_nlp, March 1, 2022\n\nI would put my bet on something new and cool that will replace Transformer in the decade to come. Not just because I have faith in us and our creativity, but also I am starting to get tired of seeing x-former papers gushing out arxiv everyday.\nIt is really fascinating to see we human beings as a whole, are making amazing progress virtually from nothing, completely bootstrapping our way into civilization and intelligence. A small step in one direction might lead to leaps in others. Just like Transformers, the go-to architecture and SOTA backbone in NLP in recent years, now are flourishing in computer vision as well.\nThe latest version of the paper was published on arxiv on 3 June 2021 when Transformer is already a catchy phrase in NLP and CNN has long been the dominant type of architecture used for computer vision.\nIdeas\nThe idea of this paper is really simple – adopting Transformer for computer vision, mainly for image classification with minimal modification, so that implementation could easily be as efficient and scalable as normal Transformers.\n\nWhen trained on mid-sized datasets such as ImageNet without strong regularization, these models yield modest accuracies of a few percentage points below ResNets of comparable size. This seemingly discouraging outcome may be expected: Transformers lack some of the inductive biases inherent to CNNs, such as translation equivariance and locality, and therefore do not generalize well when trained on insufficient amounts of data.\n\n\nHowever, the picture changes if the models are trained on larger datasets (14M-300M images). We find that large scale training trumps inductive bias. Our Vision Transformer (ViT) attains excellent results when pre-trained at sufficient scale and transferred to tasks with fewer datapoints.\n\nAbove two paragraphs basically tell us that pre-training with a large dataset closes the gap between Transformers and powerful CNNs. It sort of echos the same story that usually goes along with Transformer: though data-hungry, the model can learn information comparable to [placeholder].\nNaturally, it makes sense to further explore this gap, such as @han_2021.\nIn a similar situation, in their scaling section, ViT catches up when the pre-training dataset grows, surpassing the hybrid (ResNet + ViT).\nEfficiency and Cost\nViT models are more efficient, both in terms of data and training cost.\n\nVision Transformers generally outperform ResNets with the same computational budget. Hybrids improve upon pure Transformers for smaller model sizes, but the gap vanishes for larger models.\n\n\nFinally, the ViT-L/16 model pre-trained on the public ImageNet-21k dataset performs well on most datasets too, while taking fewer resources to pre-train: it could be trained using a standard cloud TPUv3 with 8 cores in approximately 30 days.\n\nWho else is rich in money or in time for pre-training other than those giant tech companies? Admittedly, it is good that they report these numbers unlike many papers barely mention anything about the cost.\nImage VS. Text\n16×16 does not seem like a lot, especially when you think about typically sequence length in NLP tasks (512 ~ 1024), even when they crack up the resolution to have 32×32 patches, it is only done during fine-tuning. I wonder how this might demonstrate the information density in images vs in text and also in fields where two modalities overlap such as document analysis, would this architecture or assumption still hold? (e.g. 1D VS. 2D positional embeddings)\nWhat’s Next?\nA new architecture MLP-Mixer is in town to compete with both CNN and Transformer. Hopefully we can expect some CV-native architectures as well."},"4archives/Literature-Notes/Readings/Article-Lessions-from-my-PhD":{"title":"Article Lessions from my PhD","links":[],"tags":["academia","career","study"],"content":"Take Control of Your Time\nInstead of letting others decide what you should do next, prepare your own agenda ahead of the meeting and take the initiative.\nTell a Story\nBe able to tell why you are doing so and justify the motivation so that people can resonate with you and follow you more easily. Even few words of background story makes a huge difference."},"4archives/Literature-Notes/Readings/Article-Redefining-SOTA":{"title":"Article Redefining SOTA","links":["The-Benchmark-Lottery","Dynaboard-An-Evaluation-As-A-Service-Platform-for-Holistic-Next-Generation-Benchmarking"],"tags":[],"content":"\nHowever, a SOTA score in today’s context accomplishes neither of those goals. Because of the way many benchmark datasets are constructed, a high test score (even surpassing human performance) is unlikely to mean that the model is ready for real-world deployment or that the task is “solved.” Furthermore, the ability of neural methods to predictably improve performance with scale means that a single SOTA score is not enough information to decide whether one neural method is better than another.\n\nI think redefining SOTA can be more generally reframed as redefining benchmarking, and most likely some model can be SOTA in many tasks and areas but unlikely all around.\nHaving human-level performance on a dataset with specific evaluation metrics never means we achieve general AI. To me, it is a statement on how the community collaborative decides in what direction and area we need to improve our models (aka. Selection Bias from The Benchmark Lottery)\n\nAny paper proposing a new “SOTA” neural method needs to report not just the data / compute used to achieve SOTA, but the score achieved at several at several points of data/compute. The slope of the curve should be better than all other known methods. SOTA scaling is the objective, not SOTA scores.\n\nInteresting idea, SOTA scaling. Similarly, model performance metrics in other areas are also drawing more and more attention like the Dynascore."},"4archives/Literature-Notes/Readings/Article-Reflections-on-my-(Machine-Learning)-PhD-Journey":{"title":"Article Reflections on my (Machine Learning) PhD Journey","links":["Atomic-Habits"],"tags":[],"content":"Takeaways\n\nFocus on the process – learning, research and community participation instead of goals (to publish a paper).\nIf you feel stuck, you can focus on drawing connections on what ideas you have collected.\nHow to stay on top of the progress:\n\nKeep a reading list\nHave a reading strategy\n\nTaking notes is important. So that you can discover and revisit ideas later.\n\n\nExpand horizons by reading related areas\nCurate the sources\nBut personally, I don’t think any human can keep up with the research papers and at best, we are just catching up.\n\n\nTo develop a research vision and grow research maturity\n\nTake initiatives\nFocus on what matters\nPerseverance. Similar to what James Clear wrote in Atomic Habits that motivation only gets you started before it wears off, you need some thing else to get you through the process.\n\n\n\n\nresearch is fundamentally a community endeavor\n\nIf there is a community, chances are that you will get help from it at certain point and you pass on the help in return. I mean, the collaboration is essentially how human society works towards a better place efficiently."},"4archives/Literature-Notes/Readings/Article-Scikit-learn-Pitfalls":{"title":"Article Scikit-learn Pitfalls","links":[],"tags":["machine-learning","pitfalls","scikit-learn","programming"],"content":"\nUse pipelines for both pre-processing transformations and models\nTest set is only for testing, nothing else\n\nAlways split the data first\nfit* functions can never see test set, but usage of transform should be consistent\n\n\nRandomness\n\nUse your own global RandomState to make sure it is reproducible, but also have some randomness between cross validations splits\nAvoid setting global random seed, as it will fix any randomness for any code involved\n\n\n"},"4archives/Literature-Notes/Readings/Article-Top-10-Open-Source-MLOps-Tools":{"title":"Article Top 10 Open Source MLOps Tools","links":["4archives/Literature-Notes/Readings/Article-Top-10-Open-Source-MLOps-Tools"],"tags":[],"content":"Kube Flow\nIt is a nice platform that covers the training and deployment cycle of MLOps. But there is a learning curve to this and personally, I think there is just too much to catch up with all the orchestration configurations. If it is not something that is being actively used in your working environment, you have to play a role of infrastructure architect to make it work, which I don’t think is worth the effort.\nMLflow\nIt is free, and does a descent job keeping track of things, and I used it in my projects and advocated to the whole team to move their experiments onto this. But there is push-back too. Some people either don’t want to do things that requires some level of efforts or just want to have some intelligent platform to do all the work and they aren’t willing to settle for less. To them I would say you either adopt to the tools that are free or pay for the tools that can adopt to you. There is no free lunch and certainly no free productivity.\nDVC\nIt is an awesome tool for managing your datasets. Combined with Github workflows and CML (a product for Continuous ML), you can do magic on each of your pull requests. Adoption is also limited to what code management platform you are using.\nPachydem\nI think I’ve tried this once, but I don’t exactly remember the experience. Looking at the description, it looks like a cool tool to manage and track data and models. Again, if you are working on projects alone, you can try all the new things and settle for something you find most comfortable. It would be a totally different story when it is a team.\nMetaflow\nOne of my former college told me about this, and I love the abstraction of a flow in this tool. The containerized steps are super helpful for complex flows. And I hate to admit, if all the models you are trying to build is in scikit-learn, don’t bother.\nKedro\nThis was on my radar before. I am not a huge fan of UI.\nSeldon Core\nThis is a solid tool to deploy your model, it is a pity that making full use of this is almost impossible when model deployment is your responsibility and no one cares about how to make it better.\nFlyte\nThis is new to me, it looks like a combination of MLflowKube Flow]].\nZenML\nLast time I check, there is no GRPC support.\nMLRun\nSimilar to Flyte."},"4archives/Literature-Notes/Readings/Book-Digital-Zettelkasten":{"title":"Book Digital Zettelkasten","links":[],"tags":["productivity"],"content":"The Goal of Zettelkasten\nTo use zettelkasten is to write, to generate, and to produce. It is a process of understanding and internalization.\nThe Motivation of Using Zettelkasten\nLearning is hard – we have to go through all these process (taking notes, writing comments, summarizes) – compared to doing nothing.\nThe Process of Zettelkasten\nFleeting notes: Collecting what you find interesting or important is the very beginning of the information funnel. It is the building block that paves our way to find useful information later. So it is important to make it:\n\nenjoyable and frictionless\ncomprehensive but not too ambitious\n\nLiterature notes: Re-writing is the first step of internalizing what you read, and it also reinforces this idea of producing outputs while encourages you to find, extract and summarize important or interesting ideas. It can be seen as a teaching process where you are the teacher and you are trying to explain an idea or a concept to your students. \nRe-writing can take several rounds so that you ends up with the absolute important ones. (Zettelkasten should not be a brain dump nor any dump)\nTo think associatively is the second step in building your zettelkasten. It helps us make connections between isolated ideas and further inspires new ideas. We are essentially putting bricks into walls!\nPermanent notes: one idea per note that emerges while you going through your ^81e096."},"4archives/Literature-Notes/Readings/Book-How-to-Take-Smart-Notes":{"title":"Book How to Take Smart Notes","links":["4archives/Literature-Notes/Readings/Book-How-to-Take-Smart-Notes","Atomic-Habits"],"tags":[],"content":"Type of Notes\n\nFleeting Note: This is a place for jotting down ideas, capturing thoughts with no restriction. \nLiterature Note: This is what you want to remember when you reading a book or a paper. It should be concise and not the verbatim copy of the source. Do write down the source for reference. \nPermanent Note: Magic. It is where the future holds but it needs effort at the moment. You need to make connections for the notes you have in ^a9c01b^2a966d]]. In doing so, you get the chance to review and extend your notes and ideas:\n\nUse full sentences\nCite resources\nBe accurate and succinct\nDump the ^a9c01b^2a966d]]\nLet it go\n\n\n\nComments\nTaking notes is not solely designed for writing a paper or a book. It is a process of storing and inspiring ideas that could be helpful when time comes. As people often say for Machine Learning – garbage in, garbage out – it is the same for notes. Take your time curating your notes whenever possible, just like taking a snapshot of your brain in that moment which you can return to whenever you want.\nHighlights\nOn Notes Itself\n\n因为偶然遇到的东西占了我们学习的大部分，所以多花一点时间把它们添加到笔记系统中是很有意义的。\n真正长久并广泛适用的建议是，我们必须拿着笔阅读，把思想的发展过程落实到纸上，并建立一个不断增长的外部思想库。\n\nMaking efforts taking the notes is an investment for yourself and for everything in your life.\n\n工具的好坏取决于你运用它们的能力，正如每个人都知道如何使用长笛（根据你演奏的音符把手指按在孔上，然后从一端吹气），但没有人能只试一次，就根据他们所听到的声音来判断乐器的好坏。\n例如，卡片盒很可能会被用于笔记归档，或者更糟糕，成为思想的坟场（Hollier,2005）\n而笔记系统原本应该是：你学习和收集的东西越多，你的笔记就会越有用，就会有越多的想法组合在一起，并激发新的想法，也就越能轻而易举地写出一篇精彩的文章\n\nMake it right and make it count. Notes are the data for future decisions so as the old saying in ML – Garbage in, garbage out – pay attention to the data more than the results.\n\n它只是用来启发思路，并不是为了记录思想本身，记录思想需要时间来组织适当的句子并核查事实\n\nConnections in the notes make it organic and spontaneous, so don’t dump everything in it and expect it to do all the work.\n\n其实我们并不一定要完成任务才能说服我们的大脑停止思考它们，我们所要做的就是把想法写下来，让大脑相信它会在之后被妥善处理。至于任务是真的被完成了，还是通过记下笔记而推迟了，大脑并不会区分。\n\n\n即使笔记记得不好，也不会立即得到任何负面的反馈\n\nOn Knowledge\n\n而优秀的学生会专注于尚未学到和掌握的东西，并因此不断提高自己的标准。这就是为什么那些接触到外部大量知识的高分者反而很可能会患上心理学家所说的“冒牌货综合征”，也就是说，他们感觉自己并不能真正胜任这份工作，尽管在所有的人中，自己是最有资格胜任的（Clance and Imes,1978;Brems et al.,1994）\n\nHaving imposter syndrome means that you have the consciousness for retrospection, self-evaluation.\n\n在学术界，没有所谓的私密知识。有了想法只有自己知道，就等于没想法，而无法重现的论据也根本算不上论据。如果想把一个研究成果公之于众，就需要把它写出来，供人们阅读，以此传播下去，否则这个成果没有任何意义。\n这就是为什么知识的呈现和生产不能分割，而是一个硬币的两面（Peters and Schäfer,2006）\n\nMake use of your notes so you can know if they work or not, otherwise they are just archives of no use.\nOn Making Connections\n\n我们所理解的事物都是有联系的，或是通过规则、理论、描述，或是通过纯逻辑、心理模型或解释。\n但今天我们知道，由于新的信息可以和旧的信息对接，所以我们已经拥有的信息越是互联互通，学习起来就越容易。\n当我们试图将其与之前写的笔记联系起来时，很容易发现矛盾、不一致或重复的地方。虽然这些内置的反馈循环并不能取代同行或上级的反馈，但唯独这些反馈是随时可用的，可以帮助我们每天都有少许、多次的进步。\n\nConnections are the key to make it work for you.\nOn Writing\n\n写作过程的开始远早于在空白的屏幕上落笔，而实际写下论点也只是这个过程中最小的部分\n专注于写作，好像其他的都不重要，并不意味着其他事情就敷衍了事，相反，它一定会让你做事有所不同。当你参加讲座、讨论或研讨会时，如果有明确、具体的目的，你就会更加投入、更有的放矢。努力找寻你“应该”做的事情并不是在浪费时间，相反，借助于此，你会努力以尽可能高的效率去学习，从而迅速找到那个开放性的问题，也是唯一值得写作的问题\n\n\n如果我们在校对稿件时没有做到与作为作者的自己保持足够的距离，就只能看到自己的想法，而不是文本实际表达的意思。\n\n\n在写作阶段，我们必须把注意力集中在自己的思想上。如果每遇到一句话不完美就过早地反复修正，就永远写不出任何东西\n\n\n不过，大脑并不是一个优选：它既不客观，也不可靠，而这在学术或非虚构写作中是两个相当重要的方面\n\nOn Memorizing\n\n人类记忆存在广泛且普遍的元认知错觉，会误将“记住了”当成“学会了”。如果将人的大脑粗陋地比作一块硬盘，假设你的每次记忆都是往这块硬盘中写入内容，那么，可以近似地将记忆想象成无限的内容，但硬盘上的这些信息会相互争夺空间。\n当我们试图记住一些东西时，比如说购物清单上的东西，我们只是在脑子里不断地重复这些东西，而不是把它们暂时储存在大脑的某个角落\n如果我们不用自己的话重写一遍，往往就会误以为自己已经理解了所读到的东西，因此写作是检验我们是否理解所读内容的最简单方法\n我们的短期记忆容量也是有限的。因此，我们需要制订策略，将可以存储到外部系统中的想法从短时记忆中转移出去\n\nOn Decision-making, Habit, and Organization\n\n事实上，在智力的各种因素中，起最大作用的不是智商，而是一个人具备怎样的自律或自控力来处理手头的事务\n而如果想用运动后奖励自己在沙发上看电视来哄自己进行锻炼，那么用不了多久，他们就会直奔沙发，完全放弃锻炼\n\n\n那些因为觉得反馈可能会损害他们所珍视的积极的自我形象而害怕和回避反馈的人，尽管可能在短期内感觉良好，但很快还是会落后\n\n\n拥抱成长的心态意味着要从变得更好中获得快乐（内在回报），而不是从接受赞美中获得快乐（外在回报）\n\n\n其实你在这条路上的每一步都是在做决定，日复一日，逐渐完善\n\nSimilar to the idea in Atomic Habits, each decision or action is a vote towards who you want to be.\n\n当我们认为自己在同时处理多项任务时，我们真正做的其实是在两件甚至多件事情之间快速转移注意力，每一次转移注意力都会消耗我们的转移能力，并会延长我们再次集中注意力所需要的时间。\n\nContext-switching is pricey both for humans and computers.\n\n尽可能将不同类型的任务分开，使它们不会相互干扰，并排除可能的其他干扰，我们就能训练自己在更长时间内专注于一件事的能力。这不仅要拥有正确的心态，还要学会组织工作流程。\n一个好的、有条理的工作流程，可以让我们在工作中占据主动，有更多的自由在正确的时间做正确的事\n成功不是源于强大的意志力和克服阻力的能力，而是源于高明的工作环境事先避免了阻力\n\nThis echos one of the four rules mentioned in Atomic Habits, make it easy."},"4archives/Literature-Notes/Readings/Book-How-to-Write-a-Paper-with-ZettleKasten":{"title":"Book How to Write a Paper with ZettleKasten","links":[],"tags":["writing","note-taking","productivity/zettelkasten"],"content":"1. Fleeting Notes\nThis is an idea-capture stage where any kinds of new ideas are recorded, useful or not. This is essentially a brain dump and it helps us focus more on the generating ideas instead of remembering them.\n2. Literature Notes\nTo me, it is a more elaborated version of 1 Fleeting notes with additional source information. When reading a paper or an article, some sentences or paragraphs seem worth remembering, so instead of copying the text verbatim, we can rephrase it as if we are explaining it to someone else in our notes, adding references, comments, and ideas inspired as a result.\n3. Permanent Notes\nSo far, we should have gathered a lot fragmented notes on hour hand. What we need to do is to go through them daily to see if there is an idea merging from those notes. Similarly in 2 Literature notes, use your own words to describe it.\nBy this time, remove all those fleeting notes and properly archive literature notes.\n4. Making Connections\nAn idea is lost unless it is in the right context. To make sure there is a context for an idea, we need to draw connections between ideas, to articulate the relations between 3 Permanent notes. If necessary, create an index file or a MOC file to link to this idea.\n5. Discovering Ides, Topics and Questions\nNew ideas or topics would pop up as you going through the process. If this is something you are interested in pursuing, read more related research on this and build more notes! This becomes a positive feedback loop that notes drive the higher idea and the higher idea drives the reading. As a result, it reinforces the topic as a whole for you to build a stronger body for the paper.\n6. Sourcing for a Project\nOnce you have enough materials on a topic, find a structure, an ordering or a layout and gather all the notes in the right place/section.\n7. Drafting\nTranslate your notes for each section into something coherent, logically sound paragraphs for your paper.\n8. Revision\nEdit and proofread your drafts."},"4archives/Literature-Notes/Readings/Book-Zettlekasten-Principles":{"title":"Book Zettlekasten Principles","links":[],"tags":["productivity/zettelkasten","note-taking","productivity"],"content":"1. To Write is to Understand\nWriting does not necessarily mean writing the paper, it could be taking notes or jotting down ideas. It helps us understand the material better especially when you are trying to paraphrase the text with your own words. Your brain is actively interpreting the idea/concept and reconstruct it like reinforcing a neural pathway deliberately.\n2."},"4archives/Literature-Notes/Readings/DIT-SELF-SUPERVISED-PRE-TRAINING-FOR-DOCUMENT-IMAGE-TRANSFORMER":{"title":"DIT SELF-SUPERVISED PRE-TRAINING FOR DOCUMENT IMAGE TRANSFORMER","links":["4archives/Literature-Notes/Readings/AN-IMAGE-IS-WORTH-16X16-WORDS-TRANSFORMERS-FOR-IMAGE-RECOGNITION-AT-SCALE"],"tags":["document-understanding","transformer","document-image-pre-training"],"content":"Objective\nSimilar to ViT models, DiT adopts the Masked Image Modeling objective that aims to predict the masked patch in a form that incentivizes the understanding of the image. The crux of such objective is how to frame the problem in an efficient way. Typically, you can predict the image patch directly with MSE. But in this paper, they predict the image patch token index with an image tokenizer;\nImage Tokenizer\nAn image tokenizer works like a text tokenizer that maps the image into discrete tokens/ids. A typical workflow where such tokenizer is trained looks like this:\n                                           +---------------+                                       \n                                           |               |                                       \n                                           |      MSE      |                                       \n                                           |               |                                       \n                                           |               |                                       \n                                           +---------------+                                       \n                                                   .                                        Output \n    Input                 +------------------------+------------------------+                      \n                          |                                                 |                      \n    +-------------------------------------------+     +-------------------------------------------+\n    |                                           |     |                                           |\n    |                                           |     |                                           |\n    |                   Image                   |     |                  Image&#039;                   |\n    |                                           |     |                                           |\n    |                                           |     |                                           |\n    +-------------------------------------------+     +-------------------------------------------+\n                          |                                                 .                      \n                          |                                                 |                      \n                          .                                                 |                      \n    +-------------++-------------++-------------+                           |                      \n    |             ||             ||             |                           |                      \n    |    Patch    ||    Patch    ||    Patch    |                           |                      \n    |             ||             ||             |                           |                      \n    +-------------++-------------++-------------+                           |                      \n    +-------------++-------------++-------------+                           |                      \n    |             ||             ||             |                           |                      \n    |    Patch    ||    Patch    ||    Patch    |                           |                      \n    |             ||             ||             |                           |                      \n    +-------------++-------------++-------------+                           |                      \n    +-------------++-------------++-------------+                           |                      \n    |             ||             ||             |                           |                      \n    |    Patch    ||    Patch    ||    Patch    |                           |                      \n    |             ||             ||             |                           |                      \n    +-------------++-------------++-------------+                           |                      \n                          |                                                 |                      \n                          |                                                 |                      \n                          .                           +-------------------------------------------+\n    +-------------------------------------------+     |                                           |\n    |                  Encoder                  |     |                                           |\n    |                                           |     |  +-------------+                          |\n    +-------------------------------------------+     |  |             |                          |\n                          |                           |  |             |                          |\n                          .                           |  |             |                          |\n    +-------------++-------------++-------------+     |  |             |                          |\n    |             ||             ||             |     |  |             |                          |\n    |     ID      ||     ID      ||     ID      |     |  |             |                          |\n    |             ||             ||             |     |  |  Embedding  |                   Decoder|\n    +-------------++-------------++-------------+  +-.|  |             |                          |\n    +-------------++-------------++-------------+  |  |  |             |                          |\n    |             ||             ||             |  |  |  |             |                          |\n    |     ID      ||     ID      ||     ID      |--+  |  |             |                          |\n    |             ||             ||             |     |  |             |                          |\n    +-------------++-------------++-------------+     |  |             |                          |\n    +-------------++-------------++-------------+     |  |             |                          |\n    |             ||             ||             |     |  +-------------+                          |\n    |     ID      ||     ID      ||     ID      |     |                                           |\n    |             ||             ||             |     |                                           |\n    +-------------++-------------++-------------+     +-------------------------------------------+\n\nThe above architecture is based on the discrete variational auto-encoder (dVAE) in DALL-E.\nPre-training\nThen the pre-training is relatively straightforward. Instead of predicting the image patch (regression), the model is asked to predict the masked patches’ ids based on the logits over the image tokenizer’s vocabulary, just like a normal MLM model.\nTakeaways\n\nImage Tokenizer converts the 2D image into discrete tokens and streamlines the pre-training process into a typical workflow that usually deals with text.\n"},"4archives/Literature-Notes/Readings/Gu-et-al_2021_UniDoc":{"title":"Gu et al_2021_UniDoc","links":[],"tags":[],"content":"Page 1\n\nUDoc is designed to support most document understand- ing tasks,\nextending the Transformer to take multimodal embeddings as\ninput. Each input element is composed of words and visual\nfeatures from a semantic region of the input document image.\n\n\nit learns a generic representation by making use of three\nself-supervised losses, encouraging the rep- resentation to\nmodel sentences, learn similarities, and align modalities\n\nNo open source code available.\n\n(1) documents are composed of semantic regions.\n\nThe semantic region is left undefined. The difference between OCR block and semantic region is also unexplanied.\n\ndocuments have a hierarchical structure (words form sentences,\nsentences form a semantic region, and semantic regions form a\ndocument).\n\nPage 2\n\n(2) documents are more than words. The semantic structure of the\ndocument is not only determined by the text within it but also\nthe visual features such as table, font size and style, and\nfigure, etc.\n\n\n(3) documents have spatial layout. Visual and layout information\nis critical for document understanding.\n\n\nTo handle textual information, we encode sentences using a\nhierarchical transformer encoder. The first level of the\nhierarchical encoder models the formation of the sentences from\nwords. The second level models the formation of the document\nfrom sentences.\n\n\nMeanwhile, it reduces model computation complexity exponentially\nand increases the number of input words.\n\n512 * 512 = 262144 tokens for each document\n\nwe combine convolution with self-attention to form a mixed\nattention mechanism that combines the advantages of the two\noperations.\n\n\nInstead of treating outputs from both modalities identically, we\ndesign a gating mechanism that can dynamically control the\ninfluence of textual and visual features.\n\nPage 3\n\nUDoc, which consists of four components: feature extraction,\nfeature embedding, multi-layer gated cross-attention encoder,\nand pretraining tasks.\n\nPage 4\n\nIn the feature extraction step, we first employ an off-the-shelf\nOCR tool [17] to extract text from a doc- ument image I, where\nthe words are grouped into sentences S = {s1 , … , sN }\nwhose corresponding bounding boxes are P = {p1 , … , pN }.\n\nSentencization in a document can be problamatic especially when the sections and headers do not follow the grammar rule of a sentence. OCR tools in my experience rarely share the same understanding of the textual information in the documents.\n\nFor each sentence bounding box pi , we use a ConvNet-based\nbackbone fImEnc and RoI Align [18] fRoIAlign to extract the\npooled RoI features vi.\n\n\nTo obtain a feature embedding, we extract the sentence embedding\nsi for each sentence si via a pretrained sentence encoder\nfSentEnc.\n\n\nEach region’s RoI feature vi is discretized into a finite set of\nvisual representations viQ 2 VQ via product quantization [19].\n\n\nFormally, a document image I 2 RW⇥H consists of N regions, where\neach region’s bounding box is characterized by a 6-d vector, as\npi = {xLT , yLT , xRB , yRB , w , h }\n\nI think they refer each sentence bounding box as region, but what if the sentence stretches two lines, or what about tables, TOC, lists? A rigorously definition of region should help here.\n\nWe also have different types of segments to distinguish\ndifferent modalities. The input sequence to the\ntransformer-based encoder starts with a special start element\n([CLS] and full visual features), then it is followed by\nmultimodal elements, and it ends with a special ending element\n([SEP]+full visual features).\n\nvisual features + [SEP] or [SEP] + visual features?\nPage 5\n\nThe goal is to predict the masked sentence embeddings based on\nthe contextual information from the surrounding sentences and\nimage regions, by minimizing the smooth L1 loss [16]:\n\n\nwhere sim(·, ·) computes the cosine similarity between two\nvectors, is a hyperparameter, and  is a\nTask #3 :\nVision-Language Alignment. To enforce the alignment among\ndifferent modalities, we explicitly encourage alignment between\nwords and image regions via similarity-preserving knowledge\ndistillation [25]. Note that, unlike the text-image alignment in\nLayoutLMv2 [5] which splits the image into four regions and\npredicts whether the given word is covered or not on the image\nside, we align the image and text belonging to the same region.\nThe goal is to minimize the differences\nlog P\ntemperature\nscalar. The second term encourages the model to use the codebook\nentries more equally. 5\n\nPage 6\n\nbetween the pairwise similarities of sentence embeddings and the\npairwise similarities of image region features:\n\n\nThe paragraph mode groups the non-paragraph results into text\nregions.\n\nThis is different from what is previously defined.\nPage 9\n\nWe find that OCR plays a key role in document classification\nperformance.\n\nPage 10\n\n(2) Although impressive performance has been achieved in\ndocument entity recognition tasks such as form and receipt\nunderstanding, the classification accuracy on semi-structured\ndocuments such as forms is still inferior to that of rich-text\ndocuments. It is possible to devise a better method to model the\nspatial relationship among words.\n\n\nLastly, the use of different OCR tools is one of the major\nsources of inconsistency among the existing document pretraining\nworks. It is worthwhile and essential to build standardized\npretraining document image datasets with preprovided OCR\nresults. In addition to scanned documents, using digital PDF as\npart of the pretraining data is a direction worth exploring\nsince it provides rich metadata which could be beneficial for\nmultimodal learning.\n"},"4archives/Literature-Notes/Readings/Learning-with-Signatures":{"title":"Learning with Signatures","links":[],"tags":["paper-reading","signature-transform","few-shot-learning"],"content":"Signature\nReference: Signatures and Streamed Data-New Mathematics for Data Science | Terry Lyons - YouTube\nThe goal of Rough path - Wikipedia aka Path Signature is to provide a perspective to understand data stream, especially in multimodal multidimensional settings.\nData stream, in a broad sense, can be something like drawing with your phone (handwriting), a sequence of words (text), or even an Amazon transaction. Imagine the body pose tracking problem, where a landmark of the body moving in time/video stream, it forms a path on the screen. Writing a number could also form a path, regardless of the speed you write.\nThere is something about the path that is invariant, just like you can take photos of a face from different angles even though it is the same face. A “3” is a “3” no matter how you write it.\nIn this case, typical deep learning models are spending a lot of the time learning such invariance instead of the true feature/essence of the data (learning the definition VS. learning the similarity)\nWriting a “3” can be decomposed into two paths in x and y directions against the time. (But streaming data can expand beyond 3 dimensions in reality). So we need a better description of the path to solve the challenge.\nThe goal of Path Signature is not just to describe a certain window (values) of the path but rather the effect it has or sometimes both (values and effects).\nGiven a streaming data window I=[s,t] (not the time window as this is agnostic to the time), and k samples of the data, the signature is defined by\nSk​(γ,I):=∬s&lt;u1​&lt;...&lt;uk​&lt;t​dγu1​​⊗dγu2​​...dγuk​​\nIt is a feature description of sequential of effects, while some parameterization like Fourier Transformation are more time-dependently and less effective to describe the invariance.\nSince this is a feature by itself, you can use it with different models you like.\nLibrary they used to calculate the signature GitHub - bottler/iisignature: Iterated integral signature calculations"},"4archives/Literature-Notes/Readings/Paper-A-Practical-Survey-on-Faster-and-Lighter-Transformers":{"title":"Paper A Practical Survey on Faster and Lighter Transformers","links":["4archives/Literature-Notes/Readings/Paper-Switch-Transformers","Concept-Adaptive-Computation-Time"],"tags":[],"content":"arxiv\nBefore Transformer is invented, RNNs (LSTM/GRU) are the go-to choices for NLP tasks but they do not handle distance dependencies very well, partially due to the limited relative effective context length (RECL) - about 400 words. Then we have the Transformer and all its BERTology variants, but the quadratic computation and memory cost prohibit its general application as few individuals or companies could train a descent model without costing an arm and a leg.\nThis paper discusses some general techniques to improve transformer’s performance and some low-level optimizations to change its complexity.\nQuadratic Complexity\nScaled dot-product self-attention in transformers produces weights for each token by\nAttention(Q,K,V)=Softmax(d​QK⊤​)V\nwhere Q and K are both (N,H) tensors and therefore it takes O(N2) time and space to compute. Multi-head attention is just a collection of multiple attentions that enables the model to attend multple positions simultaneously.\nGeneral Methods\n1. Gradient Checkpointing\nIn most cases, the memory is occupied by forward-pass intermediate results that are needed for gradient back-propagation. However, we can decrease the memory usage by allowing only part of the network to store their results and re-calculate the rest of results again during back-propagation.\n2. Parallelization\nModel parallelization and data parallelization.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParallelizationDataModelSyncUse CaseData Parallelization a.k.a Batch dimension splitingDifferent data on each GPUSame model on each GPUAfter one forward passSmall model on a supercomputerModel Parallelization (Hidden dimension spliting?)Same data on each GPUDifferent model parameters on each GPUDepends on operationsLarge model on a supercomputer/cluster\n3. Reversible Layers\nSplit input in the channel dimension, x→x1​,x2​. During the forward pass,\ny1​=x1​+f(x2​)y2​=x2​+g(y1​)​\nand we can re-construct the activations by\nx2​=y2​−g(y1​)x1​=y1​−f(x2​)​\n\nNonetheless, reversible layers add numerical errors that accumulate over multiple layers and may degrade the model performance. Therefore, they are not suited for very deep networks.\n\n4. Parameter Sharing\nReusing some parameters reduces the model size but performance sometimes degrades as well (smaller model capacity).\n5. Pruning\nReomving some parameters (individual weights or structures) with low saliency (no change or small change to the loss) can often lead to smaller model and equivalent performance, with the downsides being that the model will become sparse and the base model has to be trained first.\n\nrandomlyinitialized, dense neural network contains a subnetwork that is initialized such that – when trained in isolation – it can match the test accuracy of the original network after training for at most the same number of iterations.\n\n6. Knowledge Distillation\nDistillation trains a smaller network to mimic a large model’s behaviors. It produces smaller models like pruning.\n7. Mixed-precision\nEach parameter in the network is reduced to a certain bit length but the number of parameters remains the same.\n8. Mixture of Experts\nPaper Switch Transformers is the latest MoE model where expert networks are included but only used when activated/chosen.\n9. Sample-efficient Objectives\nMLM predicts only masked tokens for one input. Better objectives like replaced token detection in DETECTRA make the model more computationally efficient.\n10. Architecture Search\nVarious NAS have been proposed to find better nueral network architectures. The evolved transformer, for example, has similar performance with the vanilla transformer with only 78% of the parameters. NSA requires high computation resources though.\n11. Conditional Computing\nMoE is also a form of conditional computing. Maybe early exit too? Another form of conditional computing is Concept Adaptive Computation Time, with which the model learns a halting probability so it knows when to stop pondering and a pondering cost that it does not take too long to think. Transformer variations of this leads to moels like Universal Transformer and Depth Adaptive Transformer.\nSpecific Approaches\n1. Recurrence\nModels like Transformer-XL increase the RECL by chunking the input into windows and therefore allows the model to consider previous context window.\n2. Sparse Attention\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelMechanismSparse Transformerstrided attention or fixed attentionCascade Transformerincreasing attention span along layersBlockBERTblock attention spans attend to other spans according to certain permutationsSinkhorn attentionlike BlockBERT, but with learned permutationsLinformer and BigBirdsliding window attention, global attention and random attention\n3. Locality Sensitive Hashing\nFull attention calculates the weights based on query and key and the highest score is assigned when their dot product is the highest, which means when query and key are similar, their produced weight weill be higher. Therefore, we can use LSH to find a set of similar query-key pairs with less complexity.\n4. Low Rank Factorization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelMechanismLinformerMatrix factorizationNyströmformerNyström  method and SVDSynthesizerReplace dot product with FFN\n5. Kernel Attention\nPerformer uses a kernel mapping to approximate the exponential calculation.\nDiscussion\n\nWe do not fully understand how any why attention works\nWe generally could not evaluate them all when proposing new changes\nOne technique is not enough, people combine more and more into one model (Paper Switch Transformers combines distillation, MoE, mixed-precision)\nWe should report not only the theoretical complexity but also FLOPs, wall-clock time, memory footprint (cloud infra cost as well?)\nNo modification so far generalize well for various tasks\nLarge models do perform well, but we need lighter and faster ones for wider applications, lower CO2​ emissions and costs\n\n\nNonetheless, a clear trend emerges from Long-Range Arena: sparse attention is the best performing approach, kernel attention is the fastest, and low-rank factorization is the lightest. The two best performing models are BigBird and Longformer, both based on the sparse attention, with BigBird outperforming the vanilla Transformer; the two fastest models are the Performer and the linear Transformer, both based on kernel attention; the lightest model is the Linformer which uses low-rank factorization.\n"},"4archives/Literature-Notes/Readings/Paper-CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation":{"title":"Paper CANINE Pre-training an Efficient Tokenization-Free Encoder for Language Representation","links":[],"tags":[],"content":"We’ve seen some ideas on remedy the vocabulary burden from modern large models with hashing tricks like PARDO/PQRNN. But all of them still require some level of tokenization up-front where text is broken into hashable &amp; somehow meaningful chunks/subwords.\nModel\nIn this paper, CANINE makes it more generic by applying character/code-point level hash embeddings and block-wise self-attention – focusing on locality of characters since they don’t really have long dependency – and strided convolutions to down-size the sequence length (42048​→512).\nAbove-mentioned architecture is sufficient for classification, but for sequence generation tasks, they concatenate the attended character embeddings (word/subword-level information) with down-sampled hidden embeddings (contextual information) and apply another round of convolution and transformer decoder layer to generate characters sequentially.\nLoss\n\nWhitespace-bounded Span masking and prediction: they mask several spans of characters and ask the model to predict characters within each span.\nSubword span masking and prediction: instead of using whitespace to find spans, they can fall back to subword (presumably generated by something else like Sentencepiece)\n\nThoughts\nIt is a neat extension to what people are already doing with hash embeddings but at the end of the day, if we were ever to build an ultimate multilingual model, CANINE probably still need more parameters at convolution layers and longer sequence length, and potentially more data to compensate learning from scratch."},"4archives/Literature-Notes/Readings/Paper-Data2Vec":{"title":"Paper Data2Vec","links":[],"tags":["Natural-Language-Processing","Multi-modality","Representation"],"content":"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language\n@baevski_\nProblem\nDifferent objectives for each modality create gaps in performance as well frictions. location\nSolution\nA unified objective – predicting latent representation for masked tokens/spans/patches from an all-seeing teacher model location and location:\n\ntarget: moving average of the representation from the teacher model (all layers or last K layers location), which sees all the information such that the hidden representation is contextualized\nprediction: hidden representations from the student model, where input is masked (image → patches, speech → spans, text → words)\nobjective: regression\n\nTricks\n\nShare encoder parameters between teacher and student location;\nNormalization in target representations prevents collapsing – model generating similar representation for all inputs. location\n\nLearning rate being too small or too large\nDecaying rate being too small\nMask being too small\n\n\n\nIt is worth noting that each modality still requires different encoding mechanism since the information density and input representations are quite different. location and location"},"4archives/Literature-Notes/Readings/Paper-DeBERTa-Decoding-enhanced-BERT-with-disentangled-attention":{"title":"Paper DeBERTa Decoding-enhanced BERT with disentangled attention","links":[],"tags":[],"content":"Disentangled Attention Mechanism: Separate Word Embeddings and Position Embeddings\nOriginally, we can calculate some sort of score for a pair of word embeddings by\nWi​⋅WjT​\nbut now instead of one embedding vector for one word, there are two embeddings:\n[Wi​,Pij​]⋅[Wj​,Pji​]T\nwhich leads us to a sum of four products (the last position-position product is ignored in their implementation for duplicate work since everything else is position based already)\n\nThey use ‘disentangle’ as a fancy way of saying individual or separate, not a fan. The two embeddings are not entangled in the very beginning so there is no need to disentangle them at all but just keep them separated.\n\nWhen it comes to the attention calculation, self-attention typically projects input into query, key and value matrices and calculates the weights based on query and key, and then calculates the weighted output based on weights and value. Now with an extra positional embedding, we can have two set of queries, keys. The dist function is a mapping from real value to an interval of [0, 2k)\n# [batch size, sequence length, hidden size] @ [hidden size, hidden size]\nquery_content = word_embed @ weight_query_word \n# [batch size, sequence length, hidden size] @ [hidden size, hidden size]\nkey_content = word_embed @ weight_key_word \n# [batch size, sequence length, hidden size] @ [hidden size, hidden size]\nvalue_content = word_embed @ weight_value_word \n \n# [2k, hidden size] @ [hidden size, hidden size]\nquery_pos = pos_embed @ weight_query_pos \n# [2k, hidden size] @ [hidden size, hidden size]\nkey_pos = pos_embed @ weight_key_pos\n \n# remove batch dimension for simplicity\n# content to content\n# [1, hidden size] @ [..., hidden size, 1]\nweights[i, j] = query_content[i] @ key_content[j].T + \\\n    # content to position\n    # [1, hidden size] @ [hidden size, 1]\n    query_content[i] @ key_pos[dist(i, j)].T + \\\n    # position to content\n    # [1, hidden size] @ [hidden size, 1]\n    key_content[j] @ query_pos[dist(i, j)].T\nFinally, it is the same with normal self-attention module, we calculate the weighted output based on the weights and the value.\n\nThey have an efficient implementation of this calculation detailed in their paper to bring down the space complexity to O(kd) instead of O(N^2d)\n\nEnhanced Decoder with Absolute Position Embeddings\nIncorporate (not sure how right now from the paper, probably have to dig into their code) absolute positional embeddings before the final Softmax layer for masked token prediction.\nScale-invariant-Fine-tuning\nBasically, it is perturbation of the normalized word embeddings during fine tunning."},"4archives/Literature-Notes/Readings/Paper-Fastformer-Additive-Attention-Can-Be-All-You-Need":{"title":"Paper Fastformer Additive Attention Can Be All You Need","links":["4archives/Literature-Notes/Courses/CS224n/Lecture-8-Translation,-Seq2Seq,-Attention","Perceiver","Perceiver-IO","4archives/Literature-Notes/Readings/Paper-Fastformer-Additive-Attention-Can-Be-All-You-Need"],"tags":[],"content":"Problem Definition\n\nQuadratic time complexity in respect to the input sequence in vanilla attentions\n\nProposed Solution\nAdditive Attention\nOriginal Attention works in calculating interaction scores for pairs of tokens.\nFor an input sequence E∈RS×H:\n\nCreate a Query Q, a Key K and a Value Q vectors. Q,K,V∈RS×H\nInstead of Q⋅KT, which is O(S2), create a global query vector q∈RH (a weighted sum of Q). This force this attention head to form a query, somehow similar to Perceiver and Perceiver IO instead of a set of queries. Does this mean the model can no longer focus on some details at a sub-input level?\nThe weights are calculated by one linear transformation Wq​ of the Q + one Softmax normalization. Wq​ works like a feature extractor for all qs in Q, specifically in this head in this layer. \nEach key vector ki​ is transformed into pi​=q∗ki​ (element multiplication) ^ebd52c applies to the K vectors, leading to a global k vector \nApply the same ^2e4fce to global key vector k and value vectors V\nAdd query vectors and transformer value vectors as the final output. Why?\n\n\nIs this really attention if there are only two weight vector to extract the global query and global key?\nComment from @Yannic Kilcher\n"},"4archives/Literature-Notes/Readings/Paper-Gradients-without-Backpropagation":{"title":"Gradients without Backpropagation","links":[],"tags":["backpropagation","algorithms","neural-networks","gradients"],"content":"Gradients without Backpropagation\nForward Mode VS. Reverse Mode\nReverse mode aka. backpropagation is often represented as\nRnθ​Rm⋅Rm×nvTJf​(θ)​​forward​Rn→Rmf(θ)​reverse​Rmv​​​\nwhere v∈Rm is the gradients propagated to this point and Jf​θ∈Rm×n is the partial derivatives evaluated at f:Rn→Rm with respect to the parameter θ∈Rn.\nI think they use θ both as parameter and input which is really confusing. For example, if the θ∈Rn is the parameter, then how come it has nothing to do with m when f:Rn→Rm? But if it is the input, why do they use θt​ as their parameter in the pseudo code description?\nForward mode computes the forward gradients as the following:\nRnθ​Rnv​Rn→Rng(θ)​​forward​Rn→Rmf(θ)​forward​Rm×n⋅RnJf​(θ)v​=(Rn→Rn⋅Rn)Rn(∇f(θ)⋅v)v​​​\nHere v∈Rn is a perturbation vector (vi∼N(0,1)). The calculation of Jf​(θ)v is done by treating v as a weight vector and Jf​(θ)v is simply a weighted sums of Jf​(θ), the sensitivities for f given θ.\n“Given a function f : Rn → Rm and the values θ ∈ Rn, v ∈ Rn, forward mode AD computes f (θ) and the Jacobianvector product2 Jf (θ) v, where Jf (θ) ∈ Rm×n is the Jacobian matrix of all partial derivatives of f evaluated at θ, and v is a vector of perturbations.3 For the case of f : Rn → R the Jacobian–vector product corresponds to a directional derivative ∇f (θ) · v, which is the projection of the gradient ∇f at θ onto the direction vector v, representing the rate of change along that direction. It is important to note that the forward mode evaluates the function f and its Jacobian–vector product Jf v simultaneously in a single forward run. Also note that Jf v is obtained without having to compute the Jacobian Jf , a feature sometimes referred to as a matrix-free computation.4” (Baydin et al., 2022, p. 2) (pdf)\n“v ∈ Rn is a perturbation vector taken as a multivariate random variable v ∼ p(v) such that v’s scalar components vi are independent and have zero mean and unit variance for all i, and ∇f (θ) · v ∈ R is the directional derivative of f at point θ in direction v.” (Baydin et al., 2022, p. 3) (pdf)\n“Computing ∇f using only forward mode is possible by evaluating f forward n times with direction vectors taken as standard basis (or one-hot) vectors ei ∈ Rn, i = 1 … n, where ei denotes a vector with a 1 in the ith coordinate and 0s elsewhere. This allows the evaluation of the sensitivity of f w.r.t. each input ∂f ∂θi separately, which when combined give us the gradient ∇f .” (Baydin et al., 2022, p. 3) (pdf)\n“Importantly, there is virtually no difference in memory consumption between the two methods.” (Baydin et al., 2022, p. 7) (pdf)"},"4archives/Literature-Notes/Readings/Paper-Hidden-Techinical-Debt-in-Machine-Learning-Systems":{"title":"Annotation Summary of Sculley Et Al. - Hidden Technical Debt in Machine Learning Systems.pdf.","links":[],"tags":["machine-learning","engineering","practice"],"content":"Annotation Summary of Sculley Et Al. - Hidden Technical Debt in Machine Learning Systems.pdf.\nHighlight [page 1]: This paper argues it is dangerous to think of these quick wins as coming for free.\nHighlight [page 1]: Using the software engineering framework of technical debt, we ﬁnd it is common to incur massive ongoing maintenance costs in real-world ML systems.\nHighlight [page 1]: developing and deploying ML systems is relatively fast and cheap, but maintaining them over time is difﬁcult and expensive.\nHighlight [page 1]: The goal is not to add new functionality, but to enable future improvements, reduce errors, and improve maintainability.\nNote [page 1]: The goal of servicing technical debt.\nHighlight [page 1]: Traditional abstractions and boundaries may be subtly corrupted or invalidated by the fact that data inﬂuences ML system behavior. Typical methods for paying down code level technical debt are not sufﬁcient to address ML-speciﬁc technical debt at the system level.\nHighlight [page 2]: If we change the input distribution of values in x 1, the importance, weights, or use of the remaining n − 1 features may all change. This is true whether the model is retrained fully in a batch style or allowed to adapt in an online fashion. Adding a new feature xn+1 can cause similar changes, as can removing any feature x j. No inputs are ever really independent. We refer to this here as the CACE principle: Changing Anything Changes Everything.\nHighlight [page 2]: One possible mitigation strategy is to isolate models and serve ensembles.\nHighlight [page 2]: Relying on the combination creates a strong entanglement: improving an individual component model may actually make the system accuracy worse if the remaining errors are more strongly correlated with the other components.\nHighlight [page 2]: Metrics that operate on a slice-by-slice basis may also be extremely useful.\nHighlight [page 2]: However, this correction model has created a new system dependency on m a, making it signiﬁcantly more expensive to analyze improvements to that model in the future.\nHighlight [page 2]: Mitigation strategies are to augment m ato learn the corrections directly within the same model by adding features to distinguish among the cases, or to accept the cost of creating a separate model for A ′.\nHighlight [page 3]: engineers will naturally use the most convenient signal at hand, especially when working against deadline pressures.\nHighlight [page 3]: This is dangerous because even “improvements” to input signals may have arbitrary detrimental effects in the consuming system that are costly to diagnose and address. For example, consider the case in which an input signal was previously mis-calibrated. The model consuming it likely ﬁt to these mis-calibrations, and a silent update that corrects the signal will have sudden ramiﬁcations for the model.\nHighlight [page 3]: One common mitigation strategy for unstable data dependencies is to create a versioned copy of a given signal.\nHighlight [page 3]: • Legacy Features. The most common case is that a feature F is included in a model early in its development. Over time, F is made redundant by new features but this goes undetected. • Bundled Features. Sometimes, a group of features is evaluated and found to be beneﬁcial. Because of deadline pressures or similar effects, all the features in the bundle are added to the model together, possibly including features that add little or no value. • ǫ-Features. As machine learning researchers, it is tempting to improve model accuracy even when the accuracy gain is very small or when the complexity overhead might be high. • Correlated Features. Often two features are strongly correlated, but one is more directly causal. Many ML methods have difﬁculty detecting this and credit the two features equally, or may even pick the non-causal one. This results in brittleness if world behavior later changes the correlations.\nHighlight [page 5]: Pipeline jungles can only be avoided by thinking holistically about data collection and feature extraction. The clean-slate approach of scrapping a pipeline jungle and redesigning from the ground up is indeed a major investment of engineering effort, but one that can dramatically reduce ongoing costs and speed further innovation.\nHighlight [page 5]: However, over time, these accumulated codepaths can create a growing debt due to the increasing difﬁculties of maintaining backward compatibility and an exponential increase in cyclomatic complexity.\nHighlight [page 5]: it is often beneﬁcial to periodically reexamine each experimental branch to see what can be ripped out.\nHighlight [page 5]: It could be argued that the widespread use of Map-Reduce in machine learning was driven by the void of strong distributed learning abstractions.\nHighlight [page 5]: Indeed, one of the few areas of broad agreement in recent years appears to be that Map-Reduce is a poor abstraction for iterative ML algorithms.\nHighlight [page 6]: However, using multiple languages often increases the cost of effective testing and can increase the difﬁculty of transferring ownership to other individuals.\nHighlight [page 6]: Additionally, results found at small scale rarely reﬂect the reality at full scale.\nHighlight [page 6]: It should be easy to specify a conﬁguration as a small change from a previous conﬁguration. • It should be hard to make manual errors, omissions, or oversights. • It should be easy to see, visually, the difference in conﬁguration between two models. • It should be easy to automatically assert and verify basic facts about the conﬁguration: number of features used, transitive closure of data dependencies, etc. • It should be possible to detect unused or redundant settings. • Conﬁgurations should undergo a full code review and be checked into a repository.\nHighlight [page 7]: Thus if a model updates on new data, the old manually set threshold may be invalid. Manually updating many thresholds across many models is time-consuming and brittle. One mitigation strategy for this kind of problem appears in [14], in which thresholds are learned via simple evaluation on heldout validation data.\nHighlight [page 7]: Comprehensive live monitoring of system behavior in real time combined with automated response is critical for long-term system reliability.\nHighlight [page 7]: For example, this method can help to detect cases in which the world behavior suddenly changes, making training distributions drawn from historical data no longer reﬂective of current reality.\nHighlight [page 7]: Further any up-stream alerts must be propagated to the control plane of an ML system to ensure its accuracy.\nHighlight [page 7]: Basic sanity checks are useful, as more sophisticated tests that monitor changes in input distributions.\nHighlight [page 8]: It is important to create team cultures that reward deletion of features, reduction of complexity, improvements in reproducibility, stability, and monitoring to the same degree that improvements in accuracy are valued.\nHighlight [page 8]: • How easily can an entirely new algorithmic approach be tested at full scale? • What is the transitive closure of all data dependencies? • How precisely can the impact of a new change to the system be measured? • Does improving one model or signal degrade others? • How quickly can new members of the team be brought up to speed?"},"4archives/Literature-Notes/Readings/Paper-Language-Models-are-Few-Shot-Learners":{"title":"Second Pass","links":[],"tags":[],"content":"Content\n\n Title, abstract, and introduction\n All headings\n Conclusion\n[] References\n\nGoals\n\n What is the category of this paper\n\nAutoregressive language model\nZero-shot, one-shot, and few-short learning\n\n\n What is the context of this paper\n\nPre-trianed models have lend incredible help to current NLP tasks\nFine-tuning requires too much efforts for each new individual task\nFine-tuning does not give us a realistic idea about the model’s generalization ability, i.e poor generalization out-of-distribution data\nFine-tuning might be biased with some suprious features in the data\n\n\n What are the assumptions of this paper\n\nThe loss follows a smooth trend of improvement with scale\n\n\n What are the main contributions of this paper\n\nA new bigger autoregressive model with 175 billion parameters\nDemonstration that this model is a strong competitor in zero-shot, one-shot, and few-shot settings\nBetter data contamination analysis in terms of training with the internet\n\n\n[] Is the paper well-written\n\nSecond Pass\nContent\n\n Figures, diagrams, and other illustrations\n[] Mark useful references\n\nGoals\n\n Summarize the paper with supporting evidence\n\nThe new model uses the same architecture as GPT2 but with a new size (175B)\nCollected dataset is deduplicated as far as they could (also measured by comparing cleaned and dirty benchmark scores) and augmented (addtion from books, wikipedias etc.)\nLimitation of autoregressive training for some tasks (fill-in-the-blank, comparison), bias, cost, etc.\nFine-tuning GPT3 would be a nice feature work\n\n\n\nThird Pass\nContent\n\n[] Virtually re-implement\n[] Identify and challenge every assumption\n\nGoals\n\n[] Reconstruct the entire structure\n[] Identify strong and weak points\n[] Identify implicit assumptions, missing citations, and issues with experimental and analytical techniques\n"},"4archives/Literature-Notes/Readings/Paper-LayoutReader-Pre-training-of-Text-and-Layout-for-Reading-Order-Detection":{"title":"LayoutReader: Pre-training of Text and Layout for Reading Order Detection","links":[],"tags":["document","layout","natural-language-processing"],"content":"LayoutReader: Pre-training of Text and Layout for Reading Order Detection\nzotero\nAbstract\nReading order detection is the cornerstone to understanding visually-rich documents (e.g., receipts and forms). Unfortunately, no existing work took advantage of advanced deep learning models because it is too laborious to annotate a large enough dataset. We observe that the reading order of WORD documents is embedded in their XML metadata; meanwhile, it is easy to convert WORD documents to PDFs or images. Therefore, in an automated manner, we construct ReadingBank, a benchmark dataset that contains reading order, text, and layout information for 500,000 document images covering a wide spectrum of document types. This first-ever large-scale dataset unleashes the power of deep neural networks for reading order detection. Specifically, our proposed LayoutReader captures the text and layout information for reading order prediction using the seq2seq model. It performs almost perfectly in reading order detection and significantly improves both open-source and commercial OCR engines in ordering text lines in their results in our experiments. We will release the dataset and model at \\url{aka.ms/layoutreader}.\nHighlights\n\nWe observe that the reading order of WORD documents is embedded in their XML metadata; meanwhile, it is easy to convert WORD documents to PDFs or images.\n\n\nWe further propose LayoutReader, a novel reading order detection model in which the seq2seq model is used by encoding the text and layout information and generating the index sequence in the reading order.\n\n\nWe crawl the WORD documents in DocX format from the internet considering the robots exclusion standard as well as the public domain license.\n\nSame ethical concerns. Documents, though are more likely to be form media for text, should not be exempt from bias investigation.\n\nWe further use the language detection API 2 with a high confidence threshold to filter non-English or bilingual documents because we focus on the reading order detection for English documents in this work.\n\nThe reading order for the English language itself is generally left to right and top to bottom. But the document layout might adds more complication to the final order.\n\nWe further randomly select 500,000 pages to build our dataset.\n\nAblation on forms, columns, tables, lists, and many other forms of text that may present in the dataset.\n\nLayoutReader (text only) can guarantee the right order of tokens but suffers from the incompleteness of generation.\n\n\nZotero Links\n\nLocal library\nCloud library\n"},"4archives/Literature-Notes/Readings/Paper-Muppet-Massive-Multi-task-Representations-with-Pre-Finetuning":{"title":"Paper Muppet Massive Multi-task Representations with Pre-Finetuning","links":["Sentence-Ranking-Loss"],"tags":[],"content":"What’s Wrong with the Current Multi-task Learning?\nLabeled datasets vary in size and models might struggle to learn all the tasks (unstable) through varying losses as a result.\nWhat Are the Contributions of This Paper?\n\nOptimization and loss scaling to reconcile different tasks’s losses, which leads to a more stable learning process\n\nWithin-batch heterogeneous data → accumulating losses across tasks for each gradient update (better than one task by one task and one single task batch by one single task batch)\nAdditional loss term to coerce similar representation when input is perturbed\nScaled loss\nScaled loss Lscaled​(xi​,yi​)=logn(i)L(xi​,yi​)​, where n(i) is the decision dimension of the task (e.g. 2 for binary classification and the size of the vocabulary for generation)\nScaled loss\n\n\nExperiments on large scale multi-task pre-finetuning (adaptive finetuning)\n\nNot to reiterate the success, but interestingly, it worsens the results on BART for three common-sense reasoning tasks\n\n\n\nNext\nSentence Ranking Loss"},"4archives/Literature-Notes/Readings/Paper-Robust-Open-Vocabulary-Translation-from-Visual-Text-Representations":{"title":"Paper Robust Open-Vocabulary Translation from Visual Text Representations","links":["4archives/Literature-Notes/Readings/Paper-CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation"],"tags":[],"content":"We have seen similar problems using subwords for languages like English in paper Paper CANINE Pre-training an Efficient Tokenization-Free Encoder for Language Representation, and in this paper, the authors takes on the same problem with a refreshing perspective - learning text embeddings from visually rendered text.\nText segmentation techniques like BPE and SentencePiece are subject to a lot of noise from the following scenarios:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhenomenaWordBPEVowelizationكتابكتابالك·ِ·ت·اب·Misspellinglanguagelanguagelangaugela ng au geConfusablesreallyreallyrea11yre a 1 1 yShared Character Components확인한다확인·한·다확인했다확인·했다\n\nHere, the rendered text is segmented into blocks/slices using a sliding window and each slice goes through a series of transformations — Conv2D, BatchNorm, ReLU and a linear transformation — and eventually goes to a standard transformer for further processing.\nSome interesting observations from the paper:\n\nGiven a fixed window size, increasing the stride degrades the performance\nIncreasing the convolution channel size does not necessarily translate into performance gains\nSmaller strides increase the training time as the sequence are getting longer\nConsistent improvement over baseline models on noisy data (confusables, permutations, natural noise like misspelling)\n"},"4archives/Literature-Notes/Readings/Paper-Shortformer-Better-Language-Modeling-using-Shorter-Inputs":{"title":"Second Pass","links":[],"tags":[],"content":"Content\n\n Title, abstract, and introduction\n All headings\n Conclusion\n References\n\nGoals\n\n\n What is the category of this paper\nTransformer\n\n\n What is the context of this paper\nTo make the transformer more efficient\n\n\n What are the assumptions of this paper\n\nThe input length is not always the longer the better\nStarting with short sequences and then moving onto longer sequences (curriculum learning) helps the model in terms of perplexity\n\n\n\n What are the main contributions of this paper\n\nPosition infused attention (PIA) makes it possible to cache the hidden representations to allow attention work across non-overlapping sequences\nTwo-stage sequence-length-based curriculum learning improves the model’s performance\n\n\n\n Is the paper well-written\n\n\nSecond Pass\nContent\n\n Figures, diagrams, and other illustrations\n Mark useful references\n\nGoals\n\n\n Summarize the paper with supporting evidence\n\nTwo-stage training\n\nshort sequences (32-1536 in the paper) first and then long sequences (3072 in the paper) last\n\n\nPIA\n\nL&#039; is the cached sequence length\nKey + Pos: [L&#039; + {1, ..., L}, H] the de facto context\nQuery + Pos: [H, 1] the current word\nValue: [L&#039; + {1, ..., L}, H]\n\n\n\nweights = (Key + Pos) @ (Query + Pos)\n= [L&#039; + {1, ..., L}, H] @ [H, 1]\n= [L&#039; + {1, ..., L}, 1]\n \nweights = softmax(weights)\n \nvalue = weights * value\n\n\nThird Pass\nContent\n\n Virtually re-implement\n Identify and challenge every assumption\n\nGoals\n\n Reconstruct the entire structure\n Identify strong and weak points\n Identify implicit assumptions, missing citations, and issues with experimental and analytical techniques\n"},"4archives/Literature-Notes/Readings/Paper-Supervised-Contrastive-Learning-for-Pre-trained-Language-Model-Fine-tuning":{"title":"Paper Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning","links":[],"tags":[],"content":"A New Loss Term for Supervised Contrastive Learning (SCL)\nThe new loss is made of two parts - cross entropy and SCL loss, summed and weighted by a parameter λ.\nThe SCL loss is mini-batch-based loss, an negative unbiased estimation over the pairwise similarities within a class. In other words, for each example, of all its pairwise similarities across all classes, what is the average similarity for one specific class.\nbatch = [batch_size, hidden size]\nfor batch[i]: # [1, hidden size]\n    similarity = batch @ batch[i].T # [batch size, 1]\n    similarity = normalize(similarity)\n    similarity[i] = .0 # turn off self similarity\n    similarity = softmax(similarity)\n    loss[i] = - 1/(labels.count(labels[i]) - 1) * similarity[labels == labels[i]]\nThat pretty much covers the essence of the paper, very short and to-the-point description. Unfortunately they only have experiments compared with base models without any specifically trained model like sentence transformers, but still the numbers look good."},"4archives/Literature-Notes/Readings/Paper-Switch-Transformers-Scaling-to-Trillion-Parameter-Models-with-Simple-and-Efficient-Sparsity":{"title":"Paper Switch Transformers Scaling to Trillion Parameter Models with Simple and Efficient Sparsity","links":["Mixture-of-Experts","Scaling-Laws-for-Neural-Language-Models"],"tags":[],"content":"Background\nEssentially it is based on the concept of Mixture of ExpertsMoE]] problems and provides some additional benchmarks and experiments.\nModel\nOne important hypothesis is that scaling the number of parameters in a neural network would increase the performance of the model but one can minimize the floating point operations (FLOPs) such neural networks so that the computation complexity is not increased.Scaling Laws for Neural Language Models\nOriginal MoE model uses a routing layer to assign weights across experts and routes the input into top K experts accordingly. The intuition behind this K &gt; 1 is that the layer will not learn how to route effectively if it weren’t as least comparing two experts. However, in this paper, the authors claim that switching into only one expert shows reasonable performance.\nSkipped tokens (showed in red) are passed down to the next layer through a residual connection.\nTo ensure a balanced load across experts in a switch layer, they use an auxiliary scaled loss to encourage uniform routing.\nHowever, their experiments show their largest Switch models, do not always translate their upstream perplexity well to downstream fine-tuning on the SuperGLUE task partially because the dynamics within the expert-models is very complicated and is dependent on regularization, load-balancing, and fine-tuning hyper-parameters.\nTo me, it looks like the model is again a demonstration of a Google product that integrates very well with Google frameworks and hardware like Tensorflow, TPUs and neatly engineered for performance like selective half precision, parameter initialization, expert/different dropouts, distillation, parallelism. In their experiments, computation budget or data are not really a concern, which usually is not the case for most people outside those tech companies."},"4archives/Literature-Notes/Readings/Paper-Switch-Transformers":{"title":"Paper Switch Transformers","links":[],"tags":[],"content":"Background: Mixture of Experts\nIt refers to a technique where multiple experts (learners) are used to divide the problem space into homogeneous regions, using a gating network to decide which expert to use. But it has some limitations like training stability, complexity, and communication cost. The paper then proposes a new architecture to solve those problems and provides some additional benchmarks and experiments for support.\nModel\nOne important hypothesis is that scaling the number of parameters in a neural network would increase the performance of the model but one can minimize the floating point operations (FLOPs) such neural networks so that the computation complexity is not increased.\nOriginal MoE model uses a routing layer to assign weights across experts and routes the input into top K experts accordingly. The intuition behind this K &gt; 1 is that the layer will not learn how to route effectively if it weren’t as least comparing two experts. However, in this paper, the authors claim that switching into only one experts shows reasonable performance.\nSkipped tokens (showed in red) are passed down to the next layer through a residual connection.\nTo ensure a balanced load across experts in a switch layer, they use an auxiliary scaled loss to encourage uniform routing.\nHowever, their experiments show their largest Switch models, do not always translate their upstream perplexity well to downstream fine-tuning on the SuperGLUE task partially because the dynamics within the expert-models is very complicated and is dependent on regularization, load-balancing, and fine-tuning hyper-parameters.\nTo me, it looks like the model is again a demonstration of a Google product that integrates very well with Google frameworks and hardware like Tensorflow, TPUs and neatly engineered for performance like selective half precision, parameter initialization, expert/different dropouts, distillation, parallelism. In their experiments, computation budget or data are not really a concern, which usually is not the case for most people outside those tech companies."},"4archives/Literature-Notes/Readings/Paper-UNIPELT-A-Uniﬁed-Framework-for-Parameter-Efﬁcient-Language-Model-Tuning":{"title":"Paper UNIPELT A Uniﬁed Framework for Parameter-Efﬁcient Language Model Tuning","links":[],"tags":["mixture-of-experts","conditional-computation","efficient-computation","fine-tuning","transformers"],"content":"\nAdapter-tuning: by injecting trainable parameters into the otherwise frozen network\nPrefix-tuning: by compressing task-related knowledge into virtual token embeddings\nFine-tuning without any introduction of new parameters: BitFit on bias terms or models like GPT-3 with in-context (zero-shot or few-shot) learning\n\n┌──────────────────────────────────────┐\n│                Output                │\n└──────────────────────────────────────┘\n                    ▲                   \n        ┌───────────┤                   \n ┌──────┴──────┐    │                   \n │ bottleneck  │    │                   \n │   layers    │    │                   \n └─────────────┘    │                   \n        ▲           │                   \n        │           │                   \n        │           │                   \n ┌─────────────┐    │                   \n │    Gate     │    │                   \n └─────────────┘    │                   \n        ▲           │                   \n        └───────────┤                   \n                    │                   \n┌──────────────────────────────────────┐\n│            frozen modules            │\n└──────────────────────────────────────┘\n                   ...                  \n                                        \n┌──────────────────────────────────────┐\n│            frozen modules            │\n└──────────────────────────────────────┘\n                    ▲                   \n                    │                   \n┌──────────────────────────────────────┐\n│                Input                 │\n└──────────────────────────────────────┘\n                    ▲                   \n           ┌────────┤                   \n           │        │                   \n     ┌──────────┐   │                   \n     │   Gate   │   │                   \n     └──────────┘   │                   \n           ▲        │                   \n           └────────┤                   \n                    │                   \n           ┌────────────────┐           \n           │     hidden     │           \n           └────────────────┘           \n\nUNIPELT can be seen as a different form of conditional computation, or simply a two-MoE architecture:\n\nto introduce prefix or not\nto route data through bottleneck layers or not\nin a sequential fashion.\n\nComments\n\nNo ablation study on those gates. Do they do what we expect them to do, i.e. is a lower or higher value tied to the task or the data?\nCalculating the number of parameters is not very intuitive since not all parameters are activated during training or inference when the gate values can be (near) zeros.\nThe efficiency measurement lacks of evidence especially when no comparison is given.\n"},"4archives/Literature-Notes/Readings/Post-Embedding-Layer-might-not-be-Necessary-for-Your-Next-NLP-Project":{"title":"Post Embedding Layer might not be Necessary for Your Next NLP Project","links":[],"tags":[],"content":"Okay, it might be a little exaggerated, but even if you do need one, you can try starting with a small embedding layer.\nThis blog post talks about the embedding layer, which usually maps the whole vocabulary onto some dense distributed representations at the very beginning of most modern neural networks.\nYou may not realize this, but the embedding layer consist of quite many parameters, and depending on your task or dataset, you might not need them at all. Let’s do a simple math here. Typically, a pre-trained BERT has around 30,000 tokens in its vocabulary, each of which is embedded into a 768 dimension tensor and that sums up to 23M trainable parameters out of all 110M parameters of a base model.\nIf you trace back the memory lane, you can probably remember Word2Vec and GloVe embeddings that really kick off the NLP trend back in 2013/14. Ever since that, almost every NLP model has a nn.Embedding layer somewhere in their code. It is easy — a simple look up — but now, researchers are finding ways to remove the need for an embedding layer.\nWhat is Wrong with the Embedding layer/tokenization\nTokenization and the embedding layer come hand in hand, you need a tokenizer to segment your text into tokens and an embedding layer to map each token to its representation. That part is easy, but if you ever tried to take tokenization by yourself before, you know there is no prefect tokenizer, and it can easily drive a sane man into madness.\nAuthors of Robust Open-Vocabulary Translation from Visual Text Representations give a nice summary of issues with tokenization methods we have right now:\n\nFigure 1: Examples of common behavior which cause divergent representations for subword models. BPE models shown have vocabularies of size 5k.\nYes, BPE and sentencepiece are great for formal, English and clean dataset, but it is only a small tip of the iceberg — we still have informal usage of a language (emojis, confusables, code etc.), low-resource, morphologically or orthographically rich languages that cannot take direct benefit from the same method.\nHash Embedding Comes to the Rescue\nResearchers from Google published two models, namely PRADO and PQRNN with their projection-based hash embeddings. Essentially, they “project” each token wi​ into a length B trinary sequence by hashining every few bit into {−1,0,1} and uses a B×b matrix to transformer each token into a dimension vector.\nIn this way, as long as you can store the hashing function, you do not require an embedding layer since you can generate your input matrix on the fly. This projection was mainly designed for on-device models and PRQNN is just an extension to PRADO where the backbone of the model is changed from LSTM to QRNN.\nSimilar method has been adopted in CANINE. In this model, each character is hashed and later in the model, convolution layers are used to learn a cross-character context which essentially forms the representations of subword tokens.\nNo Embedding for Images\nIt is fun to ingest text by words, tokens, or characters, but it is also fun when the model can see them too. Authors of Robust Open-Vocabulary Translation from Visual Text Representations convert each line of the text into an image and use sliding window to “tokenize” the text. Because it is agnostic to the underlying language and visually capable, it achieves some very interesting and promising results for machine translation and is very robust to noise/errors like misspelling.\nA Small Embedding Goes a Long Way\nIf you still want an embedding layer, we can definitely reduce its size significantly with a character-level vocabulary(There are plenty of character-based PLMs such as charBERT or characterBERT) but we can go one step further to the bytes.\nByT5 and Charformer are byte-level models. They both use a small vocabulary of size around 256 (± few special IDs). With these models, the tokenization process is reduced to simple encoding from string to bytes. But they differ in how to handle such embeddings later in the model.\nSince the embeddings are only linked to each character, we lose some context information regarding a subword or a whole word. So, it is important to teach/force the model to capture such relationships through architecting.\nIn ByT5, the authors use a different span corruption as the training objective and unbalanced encoder-decoder (emphasis on encoder) to help model understand byte sequences.\nAs for Charformer, the authors designed a trainable module to score different segmentations at that position in the byte sequence. Consequently, the model can learn the best byte-level segmentations on the fly and end-to-end. To the outside, it reads bytes but internally, it understands token-level boundaries.\nThoughts\nModels are going bigger and smaller. The upper limit of those models are our best hope and the lower ones are our best day-to-day tools for those who like me don’t have access to a crazy number of GPUs. Let me know what you think of this post, and any feedback is welcome!\nNot all papers included code when publishing, so I have a small repo for reimplementing them on my weekends, if you have any interesting ideas let me know as well!"},"4archives/Literature-Notes/Readings/Random-Log-in-Python":{"title":"Random Log in Python","links":[],"tags":["python","programming"],"content":"In python, we should use math.log10 instead of math.log for better float number processing:\nmath.log(243, 3) #4.9999999999\nmath.log10(243) / math.log10(3) # 5.0"},"4archives/Literature-Notes/Readings/Research-Deduplication-in-Modern-Large-scale-LM-Datasets":{"title":"Deduplication in Modern Large-scale LM Datasets","links":[],"tags":[],"content":"Deduplication in Modern Large-scale LM Datasets\n \nMotivations Behind Deduplication\nLike the old saying, garbage in, garbage out, it is important to take care of our data before feeding it to the model. One of the problems we face, especially considering the rapid scaling of modern language modeling datasets, is duplication. It has been shown that models tend to output training data verbatim when there are many duplicates @lee_2021 and it potentially makes the model vulnerable to privacy attacks @kandpal_2022. Typically, the advantage of deduplication includes:\n\nEfficient training. Depending on how you look at it, you can have either the same amount of learnable knowledge with smaller data size or more with the same data size, which means you can achieve the same performance with less training steps or better performance with same number of steps. @lee_2021\nBetter understanding. In @bowman_2021a, authors have discussed various problems regarding the benchmarks. Thought language modeling datasets often precedes the use of benchmarking datasets, similar problems they presented, in my opinion, extend to this stage as well, especially the statistical power the dataset represents. Without deduplicates, the metrics give a clearer view on the performance without being skewed by the duplicates. Given the fact that pre-training with large dataset is still a dominant schema in deep learning, we should pay at least equal attention to LM datasets, if not more.\nAnother related issue is the duplication between splits or between datasets or between LM datasets and benchmarks. Any amount of duplicates discredit our metrics and potentially make so-called improvement a false promise.\nMore accessibility. Socially speaking, most of us cannot afford to download or transfer thousands of giga bytes of text, not to mention training a model with it. Deduplication, for a fix-sized dataset, makes it more easier to transfer and collaborate on.\n\nPipeline\nThe following sections cover a typical workflow of data deduplication. Admittedly, the workflow is intended mostly for English only. I will try my best to include my thoughts for multilingual datasets.\nPreprocessing\nFrom Web Pages to Text\nIt is easy to find templated web pages on the internet, but how do we transform the webpages into textual data and maybe remove the bulk of the deduplicates/templates in the very first step?\nIt does not look like Common Crawl is doing anything special in this regarding. I couldn’t find obvious WET extraction code on the internet or any mention about special text extraction being used, so I am assuming that the WET format text data is directly extracted, without any filtering, from the WARC data, which means the templates in those web pages are most likely reserved in the final text output.\nI understand that from their perspective, they are keeping the data as raw as possible to enable any further research. Unfortunately, re-processing the WARC data so that one can remove templated content with some tools like adbar/trafilatura seems like an endeavor only a handful researchers have done so far. In Pile-CC @gao_2020, the authors used miso-belica/jusText that removes the boilerplate from the WARC files and it yields better quality in the end. (They also have a nice discussion on their decision with jusText.)\nFrom Text to Data\nCommon procedures I have seen in papers like @wenzek_2020 and @lin_2021a:\n\nLowercase everything.\nReplace numbers with placeholders. I would argue that this might lead to the lack of numerical or mathematical astuteness of the model.\nRemove all punctuation. Downsides of this is that your model won’t be able to understand punctuations at all and some context might be lost as well. In languages like Spanish, “Tú eres estudiante.” (You are a student) means totally different from “¿Tú eres estudiante?” (Are you a student?).\nRemove accents. That would be understandably a No for many other languages.\n\nIdeally, you might want a recoverable deduplication where you find as many as possible duplicates with relaxed matching (e.g w/o accents) and compare them with the raw text (w/ accents) afterwards to decide if they are duplicates or not. This would help weeding out the false positives from the relaxed matching.\nExact Deduplication\nFor starters, one can remove duplicated webpages by just looking at the URL. A simple hash set of urls would suffice and it is usually not elaborated in papers since the size of URLs is significantly smaller than the actual text.\nExact deduplication on the text can be more involved. Depending on what level of granularity you want to achieve, people usually do one or more of:\n\ndocument level\nparagraph level\nsentence level\nsub-string level\n\ndeduplications.\nExact deduplication usually takes on the form of hashing. Each piece of text is hashed into a bucket (e.g. the first 64 bit of SHA-1 in @wenzek_2020) or directly into a hash set. Sub-string level deduplication is more complicated and it goes beyond any boundaries so we will talk about it in the next section.\nExact Sub-string Deduplication\n@lee_2021 builds on the idea of Suffix array - Wikipedia to find duplicate sub-strings in a corpus. If a string is repeated in two locations in the corpus, their suffices will appear as neighbors in the sorted suffix array. The authors also shared their code in GitHub - google-research/deduplicate-text-datasets so I encourage you to give it a try.\nNear Deduplication\nAka. the friendly competition between MinHash + LSH and SimHash. SimHash was proposed in @charikar_ in 2002 and widely used by Google crawlers @manku_2007, while MinHash debuted in @broder_1998 in 1998. Both algorithms require some form of hashing, permutation and grouping. Without going too much into details here, based on my personal experience and some account on Choosing between SimHash and MinHash for a production system - Stack Overflow, the main difference is that:\n\nSimHash is faster and more cpu-friendly than MinHash;\nSimHash is more strict on what are near duplicates than MinHash;\nMinHash + LSH seems like a more popular choice (I also only learned about MinHash + LSH in school)\n\nSemantic Deduplication\nTODO\nRepetition VS. Deduplication\nOne kind of deduplication or quality filtering is removing documents that are self-repetitive, meaning a document could contain:\n\n  small pieces of text that appear many times\n  large chunk of text that appear more than once\n\nIn this regard, @rae_2021 developed some useful heuristics for finding those English documents that are infested with (i) repeated lines (2) repeated paragraphs or (3) repeated n-grams;\nTerminologies they used in the paper:\n\nDuplicate line/paragraph fraction: Given a line/paragraph duplicate, does it appear more than x% of the document? (case I);\nDuplicate line/paragraph character fraction: Given a line/paragraph duplicate, does it have more than x% characters of the document? (case II);\nTop n-gram character fraction: Given a document, if the top n-gram occurrences contains more than x% of the characters, remove the document;\nDuplicate n-gram character fraction: Given a document, if the top duplicated n-gram occurrences contains more than x% of the characters, remove the document;\n\nThey also postulated the thresholds x in each scenario, please the original paper if you’re interested.\nRemoval\nIt often goes unmentioned on how to deal with the duplicates.\nExact duplicates that have boundaries (sentences, paragraphs, documents) are easy, you can keep the first instance and ditch the rest. It is unclear what is the best practice for something like sub-string duplicates. Removing one sub-string can easily break the context for the text.\nDepending on the algorithms you choose, near deduplication might give you pairs of duplicates or duplicates for each query documents. For pair of duplicates, @rae_2021 only removes a random one from that pair. If given (A, B), (B, C) and (C, A) then it is possible you remove [B, C, A] for each pair and lead to non of the docs are kept for that cluster. But building a cluster from those pairs might lead you to a cluster that are not as compact as you might expect – a few dissimilarity here and there might group completely unrelated items together in the end.\nTODO What would be the best action then?\nApplications\nValidation or Test Leakage\n@lee_2021 found a large duplicates exist in dataset splits and stressed the problem of metric being unreliable due to such duplication. @gao_2020 states that they only make sure the Pile itself, along with its splits are deduplicated and they won’t proactively deduplicating for any downstream benchmarks and leave that decision to readers; @rae_2021 applied n-gram Jaccard similarity to filter training documents that resemble test documents and also pointed out that some datasets do have curated test-set and such filtering is not necessary for them.\nCost and Implementation\nWhen you have an academic budget, what is your best defense?\nTime.\n\nIt took several days to process Pile-CC with an in-memory LSH according to @gao_2020.\nIt 96 hours on 100 48-core machines on MareNostrum 4 for @gutierrez-fandino_2021’s deduplication.\nIt took me ~12 hours on a 80 core machine to calculate SimHash for 1TB Oscar English data (python) and few days on my M1 Max laptop to cluster them (c++).\nRunning any code or algorithms with a 1TB input would requires measurement in days.\n\nLibraries\n\nOnion deduplication tool\nGitHub - google-research/deduplicate-text-datasets\n\nYou can run the code with just a text file;\nIf you want to respect the document boundaries, you have to manually recover from their output;\nThe number of jobs should not exceed the number of openable files or number of arguments if you do not wish to modify their code;\nThe collect_similar command does not like a relative file path;\nIt will take 2 hours for a 4GB file in a single job, and each job takes about 10x memory;\nRunning it with Oscar English would requires at least O(8n) of storage and O(2n) of memory;\n\n\nGitHub - ekzhu/datasketch: MinHash, LSH, LSH Forest, Weighted MinHash, HyperLogLog, HyperLogLog++, LSH Ensemble\nGitHub - ChenghaoMou/simhash: Simhash in C++\ndata_tooling/ac_dc/deduplicate at dedup-improved · ChenghaoMou/data_tooling · GitHub\n\nFinal Thoughts\nHere is a table that covers most techniques mentioned in this article.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatasetOpenWebText2 @gao_2020Pile-CC @gao_2020@gutierrez-fandino_2021MassiveText @rae_2021@lin_2021aC4 @lee_2021Real News @lee_2021LM1B @lee_2021WIKI40B @lee_2021Input SizeAfter URL deduplication: 193.89GB (69M docs)~306GBBetween 2TB and 59TB806.92GB (364M docs)~120GiB~4.40GiB (30M)~2.9MOutput Size or DeductionAfter MinHashLSH: 65.86GB (17M docs)227.12GiB (~55M)2TB after document deduplication570GB after substring deduplication0.001TB~2.1TB0.01GiB~3324.45GiB3.04%~7.18% ↓ (train)13.63%~19.4% ↓ (train)0.76%~4.86% ↓ (train)0.39%~2.76% ↓ (train)Level1. URL2. DocumentsDocuments1. Sentences2. SubstringsDocuments1. URL2. Paragraphs1. Substrings2. DocumentsSame as C4Same as C4Same as C4Method1. URL(Exact)2. Documents(MinHash LSH)Documents(jusText + MinHash LSH)Sentences(Exact) Substrings(Exact)Documents(Exact) Documents(MinHash)1. URL(Exact)2. Paragraphs(Exact)1. Substrings(Suffix Array)2. Documents(MinHash)Same as C4Same as C4Same as C4Parameters(10,0.5,?)∗(10,0.5,?)∗N/A(?,0.8,13)∗SHA-11. Suffix Array: minimum 50-token windowMinHash: (9000,0.8,5,20,450)∗Same as C4Same as C4Same as C4LanguageEnglishEnglishSpanishEnglishMultilingualEnglishEnglishEnglishEnglish\n* MinHash + LSH parameters (H,T,N):\n\nH number of permutations/hashes\nJ Jaccard similarity threshold\nN n-gram size\n* number of bands\n* number of rows\n"},"4archives/Literature-Notes/Readings/Research-Two-sample-Hypothesis-Testing":{"title":"Research Two-sample Hypothesis Testing","links":["4archives/Permanent-Notes/202205241113-Hotelling's-Two-sample-T-squared-Test","4archives/Permanent-Notes/202205241116-Kernel-Two-sample-Test"],"tags":["data","statistics","hypothesis-testing","machine-learning","distribution"],"content":"A statistical hypothesis testing whether two random samples from a given population is statistically significantly different or not.\nConsiderations When Choosing the Test\n\nPrior distributions and nature of the data:\n\nNormal distribution vs. Discrete probability distribution\nContinus data vs. categorical data\n\n\nIs the test applied to the population or population parameters such as mean or variance?\n\nRelevant Tests\n\n202205241113 Hotelling’s Two-sample T-squared Test\n202205241116 Kernel Two-sample Test\nKolmogorov–Smirnov test - Wikipedia\nPearson’s chi-squared test - Wikipedia\nStudent’s t-test - Wikipedia\n\nUseful Packages\n\nhyppo — hyppo alpha documentation\n"},"4archives/Literature-Notes/Readings/Spelling-Correction-with-Denoising-Transformer":{"title":"Spelling Correction with Denoising Transformer","links":["(zotero:/open-pdf/library/items/CEKDM4JXpage=3)"],"tags":[],"content":"\ntags:\n\nspelling correction\ntypo correction\nquery understanding\n\n\nThe name is confusing. Because this paper isn’t about transformer architecture or any fancy performance boost stemming from model engineering. It’s mostly about data-driven heuristics and rules about human typos learned from search logs. (note on p.1)\n\nThis leads to 10-15% of web search queries being misspelled (Dalianis, 2002; Cucerzan and Brill, 2004), with percentage of misspellings increasing to up to 20% for long-tail queries (Broder et al., 2009), and 26% for academic search engines (Wang et al., 2003).\nKuznetsov and Urdiales 2021:1\n\nAssuming the first few numbers are from general search engines, the the percentage of misspellings varies drastically from domain to domain. A good first question to ask when you are trying to implement a spelling correction system would be how much misspellings you are seeing in your system.\nA simple way to estimate the number is, following the heuristics they used in this paper to find potential &lt;typo, correction&gt; pairs from query logs, collect the number of such pairs.\nOver-correction\nOver-correction refers to the situation where user input is actually correct, albeit too rare, too random or too gibberish (code e.g.) and the spelling correction model/system correct it into something more mundane. General search engines are more infested than domain specific ones.\nThey claim that they address such issue with the generated large corpus, but I am not convinced. They argue “Instead, given the large size and diversity of the dataset, it forces the model to output sequences identical to the input sequence by default, and to only attempt correction in cases of high certainty (e.g. if a typo is made in a sufficiently popular token). By forcing model outputs to be identical to model inputs in case of gibberish queries, this setup effectively addresses the overcorrection problem” (Kuznetsov and Urdiales 2021:4).\nInductive Typo Mining\n\nA rolling window of 10 subsequent queries;\nThere is a small edit distance between two queries;\nThere is a significant difference in popularity of two queries;\n\nUnclear definition of popularity\n\n\nThe query is considered to be “correct” if all its tokens are either present in the verified vocabulary, or belong to 1.5K most popular tokens in search logs;\nThe candidate “typo” query is not composed solely of known tokens;\n\nThis also excludes incorrect usage of correct words. For example, “a piece of cake” VS. “a peace of cake”;\n\n\nQueries do not contain any forbidden special characters (e.g. @, , #, n);\n\nSuch patterns are then applied randomly to generating realistic typos in the data so that a model(a mini transformer in this case) can learn to redo the noise.\nTypo Distribution\nIt looks like most of them are edit-based errors. What are the rest?\n\n”We find that typos tend to happen closer to the end of the string, confirming findings in earlier studies (Mitton, 1996).”\nKuznetsov and Urdiales 2021:4\n"},"4archives/Literature-Notes/Readings/UNICORN-on-RAINBOW-A-Universal-Commonsense-Reasoning-Model-on-a-New-Multitask-Benchmark":{"title":"UNICORN on RAINBOW A Universal Commonsense Reasoning Model on a New Multitask Benchmark","links":["4archives/Permanent-Notes/202205231928-Cost-Equivalent-Curve","4archives/Permanent-Notes/202205231931-Transfer-Learning-Approaches"],"tags":["paper-reading","natural-language-processing","commonsense-reasoning","benchmark"],"content":"202205231928 Cost Equivalent Curve\n202205231931 Transfer Learning Approaches\nDirectly modeling commonsense knowledge graph does not help the model, maybe this calls for something like knowledge augmented language modeling.\nPage 1\n\nFirst, we propose a new multitask benchmark, RAINBOW, to promote\nresearch on commonsense models that generalize well over\nmultiple tasks and datasets\n\n\na novel evaluation, the cost equivalent curve, that sheds new\ninsight on how the choice of source datasets, pretrained\nlanguage models, and transfer learning methods impacts\nperformance and data efficiency.\n\nPage 2\n\nwe define cost as the number of training examples in the target\ndataset.\n\n\nThe construction of cost equivalent curves makes one technical\nassumption: the relationship between performance and cost is\ncontinuous and strictly monotonic (i.e., increas- ing or\ndecreasing)\n\nPage 3\n\nmultitask training (Caruana 1995): training on multi- ple\ndatasets (including the target dataset) all at once,\n\n\nequential training (Pratt, Mostow, and Kamm 1991): first\ntraining on multiple datasets (excluding the target dataset)\nthrough multitask training, and then continuing to train on the\ntarget dataset alone,\n\n\nmultitask fine-tuning (Liu et al. 2019a): first training on all\ndatasets (including the target dataset) through mul- titask\ntraining, and then continuing to fine-tune on the tar- get\ndataset alone.\n\n\nFinding 1: Sequential training almost always matches or beats\nother approaches.\n\nPage 4\n\nFinding 2: Sequential training rarely hurts performance.\n\n\nMultitask training helps most often in the low- data regime.\n\n\nmulti- task learning tends to help when data is scarce, but may\nhurt performance if data is plentiful.\n\nPage 5\n\nThe off-the-shelf T5’s weights come from multitask pretraining,\nwhere many tasks are mixed with a language modeling objective to\nlearn a powerful initialization for the weights. In fact, both\nGLUE and SUPERGLUE were mixed into the pretraining (Raffel et\nal. 2019).\n\n\nLarger models benefit more from transfer\n\nPage 6\n\nthe serialized language from the knowledge graphs is not in a QA\nformat, and the knowledge graph com- pletion task is generative\nwhile all other tasks are discrimi- native\n"},"4archives/Literature-Notes/Readings/UniDoc-Unified-Pretraining-Framework-for-Document-Understanding":{"title":"UniDoc Unified Pretraining Framework for Document Understanding","links":["4archives/Literature-Notes/Readings/Gu-et-al_2021_UniDoc"],"tags":["document-understanding","natural-language-processing"],"content":"Hierarchical Document Textual Representation\nBy stacking two transformers sequentially, the system models paragraph representations from tokens and then document representations on top of paragraph representations. It:\n\nTrades parameters and computation for longer sequences (5122 tokens for each document), even though they claim it reduces computation complexity.\nAllows interactions within paragraphs/semantic regions (or as they call it, sentences in the beginning) from a higher level compared to normal token-to-token attentions.\nAllows interactions between paragraphs and paragraph bounding boxes.\n\nIt is unclear what exactly is semantic region by their definition. Based on the paper, It looks like it is whatever JaidedAI/EasyOCR outputs and ideally it maps to paragraphs.\nPersonally, OCR blocks/paragraphs aren’t great in general. Because documents don’t necessarily follow strict rules of English text. OCR, unless specializes in document images, even then the document domain can vary a lot, does not share the same understanding of a document as human. For example:\n\nNot everything can be classified as sentences or paragraphs;\n\nYou cannot just call a table a sentence or a paragraph. It is even trickier to even pass the table content into the model since it can be a column table, row table or a mix. You sequence of tokens are still sequential.\nCorner cases like TOC, graph or chart, code blocks, page breaks and formulas make it even harder;\n\n\nAdditionally, using bounding box can be a loose visual representation if you have multi-columns on one page.\n\nMulti-modal Objectives\n\nMasked Sentence/Paragraph Prediction\n\nTo be more precise, it is not exactly predicting a sentence itself but the sentence embedding from the first transformer;\n\n\nMasked Region of Interest (RoI) Prediction\n\nBecause all RoIs are quantized into a finite vocabulary, this is equivalent to the Masked Token Prediction and the prediction probability comes from cosine similarities instead of some MLP output;\n\n\nMulti-modal Similarity Alignment\n\nEven though the textual and visual information live in two embedding spaces, the element-wise similarities should be aligned;\n\n\n\n\n\nHighlights: Gu et al_2021_UniDoc\nCitation: @gu_2021b\n"},"4archives/Literature-Notes/Readings/Unified-Pretraining-Framework-for-Document-Understanding":{"title":"Unified Pretraining Framework for Document Understanding","links":[],"tags":["document-understanding","language-modeling"],"content":"graph TD\n Sentences\nid2.1(Sentence 0)\nid2.2(Sentence 1)\nid2.3(Sentence 2)\n\n ROI\nid4.1(Sentence 0 BBox RoI)\n\n ROI Discret\nid6.1(Sentence 0 BBox RoI Discretized)\n\n Input\nid9.1(CLS+Masked Sentence Embeddings+SEP+Masked RoI Embeddings)\n\nsubgraph OCR\n\tid1 --&gt; id2.1 &amp; id2.2 &amp; id2.3\n\tid2.1 --&gt; id3.1 &amp; id3.2\nend\n\nsubgraph ImEnc+RoIAlign\n\tid3.1 --&gt; id4.1\n\tid4.1 --&gt; id6.1\nend\n\nsubgraph SentEnc\n\tid3.2 --&gt; id5.1\nend\n\nid5.1 --&gt; id7.1 --&gt; id8.1 -- Positional Embedding --&gt; id9.1\nid6.1 --&gt; id7.2 --&gt; id8.2 -- Positional Embedding --&gt; id9.1\n\n"},"4archives/Literature-Notes/Readings/Video-Transformer-in-Transformer":{"title":"Video Transformer in Transformer","links":[],"tags":["talk","transformer","computer-vision"],"content":"Problem Definition\nCurrent models view an image as patches without explicitly modeling the patch itself. In other words, transforming an image patch to a single vector through some linear layers does not capture the information to the fullest extend.\nSolution\nIn order to represent the patch information to have an embedding of the patch, the authors of Transformers in Transformers convert each patch(H×W×C) into a series of smaller patches (H′×W′×C′). Such array of super patches, along with positional embeddings, are sent to a transformer block as another form of embedding representation of the patch itself."},"4archives/Literature-Notes/_Index_of_Literature-Notes":{"title":"_Index_of_Literature Notes","links":["4archives/Literature-Notes/Readings/_Index_of_Readings","4archives/Literature-Notes/Courses/_Index_of_Courses","4archives/Literature-Notes/20220605111758"],"tags":[],"content":"_Index_of_Readings\n_Index_of_Courses\n20220605111758"},"4archives/Literature-Notes/index_Literature-Notes":{"title":"index_Literature Notes","links":["4archives/Literature-Notes/Readings/index_Readings","4archives/Literature-Notes/Courses/index_Courses","4archives/Literature-Notes/20220605111758","4archives/Literature-Notes/_Index_of_Literature-Notes"],"tags":[],"content":"index_Readings\nindex_Courses\n20220605111758\n_Index_of_Literature Notes"},"4archives/Machine-Learning-Concepts/202204280830-Bayes-Error":{"title":"202204280830 Bayes Error","links":[],"tags":["machine-learning","bayes-error"],"content":"Smallest error made possible by the inherent noise in reality, a.k.a irreducible error.\n\nReferences:\n\nBayes error rate - Wikipedia\n"},"4archives/Machine-Learning-Concepts/202204280834-Bootstrapping":{"title":"202204280834 Bootstrapping","links":[],"tags":["machine-learning","bootstrap"],"content":"In terms of sampling, bootstrapping means sampling with replacement in order to generate multiple datasets from one underlying dataset."},"4archives/Permanent-Notes/202109261532-Machine-Learning-Optimization":{"title":"Machine Learning Optimization","links":["202109261531-Machine-Learning-Compilers-and-Optimizers"],"tags":["machine-learning","optimization"],"content":"Machine Learning Optimization\nIn general, you can optimize your model locally or globally. Locally is when you improve operators, blocks, or layers of your model while globally is when you optimize your model end to end.\nSpecifically, you can optimize your model in the following areas:\n\nFrom loops to vectorization: The most obvious optimization we are doing nowadays is putting several examples into a small batch to improve the efficiency. Some other libraries (Jax) can automatically batch processing with a function designed for one single input.\nParallelization: One example of this is using CNNs to approximate RNNs to utilize GPUs powerful parallel computation. Recurrence is often helpful but sadly slow.\nHardware-specific optimization: Depending on the hardware you are using, you can optimize your model, or data to be accessed/computed in a way that’s easy for the hardware.\nFramework-specific or model-specific optimization: e.g. torch.nn.CrossEntropyLoss is known to be better than separated LogSoftmax and NLLLoss.\n\nOutside the scope of the model itself, you can rely on compilers and optimizers to further improve the performance."},"4archives/Permanent-Notes/202109261533-Adaptive-Computation":{"title":"Adaptive Computation","links":["4archives/Permanent-Notes/202109261532-Machine-Learning-Optimization","Paper-PonderNet","4archives/Literature-Notes/Readings/Paper-Switch-Transformers","Paper-EarlyBERT"],"tags":["ml","optimization","computation"],"content":"Adaptive Computation\nIt is a concept that models can perform conditionally computation, primarily based on the input. It is a form of 202109261532 Machine Learning Optimization. See 1, 2 and 3.\nModels spend more computation on difficult problems and less on easy problems, or treat those questions in different ways from varying perspectives.\nHowever, it is known for unstable results and sensitivity towards hyper-parameters e.g. τ in ACT, especially those controlling the trade off between computation and accuracy.1\nFootnotes\n\n\nPaper PonderNet ↩ ↩2\n\n\nPaper Switch Transformers ↩\n\n\nPaper EarlyBERT ↩\n\n\n"},"4archives/Permanent-Notes/202109261813-Randomness-in-Scikit-learn":{"title":"Randomness in Scikit-learn","links":[],"tags":["machine-learning","scikit-learn","pitfalls","programming"],"content":"Randomness in Scikit-learn\nUse RandomState to make sure your code\n\nis reproducible between runs\nmaintains randomness within the pipeline\n\nAvoid setting the global random seed – it can fix all the randomness for any code subsequently involved, including caller code."},"4archives/Permanent-Notes/202109261818-Mixture-of-Experts":{"title":"Mixture of Experts","links":["4archives/Permanent-Notes/202109261533-Adaptive-Computation"],"tags":["machine-learning","optimization"],"content":"Mixture of Experts\nMixture of Experts (MoE) is special case of 202109261533 Adaptive Computation where multiple experts or learners are used to solve a problem by dividing the problem space into regions. In neural networks, a MoE model can use a gating/routing network to decide which expert/sub-model to use. But it has some limitations like training stability, complexity, and communication cost."},"4archives/Permanent-Notes/202109281804-Data-centric-AI":{"title":"Data-centric AI","links":[],"tags":["ai","data-centric","machine-learning","data"],"content":"Data-centric AI\nA paradigm shift from model-centric AI to data-centric AI, advocated by many companies and scholars recently, especially Andrew Ng and his famous talk.\nPreviously, we have model-centric AI where people focus mostly on\n\nfeature engineering\nmodel architecture design\ntraining algorithm design\n\nHowever, those tasks soon are marginalized by the popularization of large pre-trained models where general knowledge is learned through huge datasets and parameters. Any work that tries to compete with those pre-trained models with new architectures will find themselves in need for pre-training from scratch, which will most likely burn many holes in their wallets.\nIn short, those pre-trained models are powerful, increasingly data-hungry, and less practically modifiable.\nThe easy way out for now is redirecting the attention back to data:\n\ndata collection\nlabeling\naugmentation\nslicing\nmanagement\n\nKey Components in Data-centric AI\n\nData\nProgrammatic access: higher level of data manipulation that also takes into considerations such as:\n\nPrivacy concerns\nDomain expertise\nRapid changes in the real world\nEthical concerns (bias, audits, lineage)\n\n\nExpertise: labeling and modeling should be unified into a positive feedback loop instead of individual components. Labeled data help to design better models and algorithms and the modeling process provide the labeling process with guidance.\n"},"4archives/Permanent-Notes/202110031750-Contrastive-Learning":{"title":"Contrastive Learning","links":[],"tags":["loss","supervised-contrastive-learning"],"content":"Contrastive Learning\nThe idea of contrastive learning is to learn representations where similar input will have closer representations and vice versa, without explictly modeling the similarity."},"4archives/Permanent-Notes/202110031800-Calibration-in-Machine-Learning":{"title":"Calibration in Machine Learning","links":[],"tags":["calibration","ml"],"content":"Calibration in Machine Learning\nCalibration refers to a practice where model’s output logits are calibrated to reflect probabilities. More precisely, the predicted probabilities and distributions are close to what observed in training data. Models, especially large neural networks tend to overestimated the probabilities while being a good classifier/discriminator. Simply put, a working boundary might not be the best boundary, and that’s where calibration comes into play.\nStudy 1 and 2 have shown most predictive models are not well calibrated.\nCalibration Curve\nThe easiest way to help you understand if your model is calibrated or not is to plot the calibration curve. If 70% of the data is observed positive, then a point should have a similar probability of being positive. Then you should expect your model’s predicts have an expectation of 70% for being positive.\nHow to Draw a Calibration Curve Chart\n\nGiven a binary label set Y and a prediction set with positive probabilities Y~\nSort the data based on the predicted probabilities in ascending order\nBucketize the data based on the probabilities\nCalculate the fraction of positive examples in each bucket/bin\n\ntype: bar\nlabels: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\nseries:\n  - title: Positive Percentage\n    data: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\ntension: 0.2\nwidth: 58%\nlabelColors: true\nfill: true\nbeginAtZero: true\nAbove is a perfect calibrated model – for all examples predicted with around probability x, x of them are actual positives.\nMis-calibration\n 3\n\nSystematic Overestimation: This happens when you have less positive examples.\nSystematic Underestimation: This happens when you have less negative examples.\nCenter of the dist. is too heavy: This happens when “algorithms such as support vector machines and boosted trees tend to push predicted probabilities away from 0 and 1”1\nTails of the dist. are too heavy: This happens when “Other methods such as naive bayes have the opposite bias and tend to push predictions closer to 0 and 1”2\n\nHow to Calibrate\n\nIsotonic Regression on dev set: A non-parametric algorithm that fits a non-decreasing free form line to the data. The fact that the line is non-decreasing is fundamental because it respects the original sorting.\nLogistic Regression on dev set\n\nExpected Calibration Error\ndef expected_calibration_error(y, proba, bins = &#039;fd&#039;):\n\timport numpy as np\n\tbin_count, bin_edges = np.histogram(proba, bins = bins)\n\tn_bins = len(bin_count)\n\tbin_edges[0] -= 1e-8 `#` because left edge is not included\n\tbin_id = np.digitize(proba, bin_edges, right = True) - 1\n\tbin_ysum = np.bincount(bin_id, weights = y, minlength = n_bins)\n\tbin_probasum = np.bincount(bin_id, weights = proba, minlength = n_bins)\n\tbin_ymean = np.divide(bin_ysum, bin_count, out = np.zeros(n_bins), where = bin_count &gt; 0)\n\tbin_probamean = np.divide(bin_probasum, bin_count, out = np.zeros(n_bins), where = bin_count &gt; 0)\n\tece = np.abs((bin_probamean - bin_ymean) * bin_count).sum() / len(proba)\n\treturn ece\nFootnotes\n\n\n(PDF) Predicting good probabilities with supervised learning ↩ ↩2\n\n\n[1706.04599] On Calibration of Modern Neural Networks ↩ ↩2\n\n\nPython’s «predict_proba» Doesn’t Actually Predict Probabilities (and How to Fix It) | by Samuele Mazzanti | Towards Data Science ↩\n\n\n"},"4archives/Permanent-Notes/202110091321-Open-Vocabulary":{"title":"202110091321 Open Vocabulary","links":["4archives/Literature-Notes/Readings/Paper-Robust-Open-Vocabulary-Translation-from-Visual-Text-Representations","4archives/Literature-Notes/Readings/Paper-CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation","Paper-Charformer-Fast-Character-Transformers-via-Gradient-based-Subword-Tokenization"],"tags":["open-vocabulary","representation-learning","translation","nlp"],"content":"Open Vocabulary\nProblems\nWord based models suffer from the Out-of-Vocabulary (OOV) problem. Character-level models can be useful if the sequence length is manageable. Recent sub-word models using 1, 2, and 3  are a good compromise. To some extend, they can be considered as open vocabulary since you can degenerate a word to complete characters (all Unicode characters theoretically, but ASCII characters in the English dominating world). But the problem of a vocabulary remains:\n\nYou have to store and maintain a physical copy of the vocabulary along side your model\nYou have to store the token embeddings, which can be a lot of parameters, in your model\n\nOpen, Low, and No Vocabulary\nIf we define open vocabulary as a criterion that there would be no OOV problem, then you can either have a finite vocabulary or no vocabulary at all(hash, VTR). If you do, the vocabulary can be small (bytes, ASCII characters), moderate or big(BPE w/ fixed size).\nNo vocabulary\nTransclude of Paper-Robust-Open-Vocabulary-Translation-from-Visual-Text-Representations\n\n4\n5\n\nLow vocabulary\nTransclude of Paper-CANINE-Pre-training-an-Efficient-Tokenization-Free-Encoder-for-Language-Representation\nTransclude of Paper-Charformer-Fast-Character-Transformers-via-Gradient-based-Subword-Tokenization\n\n6\n\nFootnotes\n\n\n[1609.08144v2] Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation ↩\n\n\n[1808.06226] SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing ↩\n\n\nByte pair encoding - Wikipedia ↩\n\n\naclanthology.org/D19-1506.pdf ↩\n\n\nGoogle AI Blog: Advancing NLP with Efficient Projection-Based Model Architectures ↩\n\n\n[2105.13626] ByT5: Towards a token-free future with pre-trained byte-to-byte models ↩\n\n\n"},"4archives/Permanent-Notes/202112251111-PyTorch-Tricks":{"title":"202112251111 PyTorch Tricks","links":["202109261531-Machine-Learning-Compilers-and-Optimizers"],"tags":["pytorch","programming","tricks","deep-learning"],"content":"Scheduler\nBoth following schedulers prove to be faster in convergence, with the cost of introduction of few extra hyper-parameters – minimum learning rate, maximum learning rate. 1\n\nCyclicLR — PyTorch 1.10.1 documentation based on @smith_2017\nOneCycleLR — PyTorch 1.10.1 documentation\n\nDataloader\n\nUsing multiple data workers to speed up loading the dataset, but be aware of the data duplicates:1\n\nFor map-style dataset, data is retrieved with indices generated by sampler, so no duplication is created;\nFor iterable-style dataset, each worker should have specific handling according to its init function and parameters;\n\n\npin_memory speeds up data transfer from memory to GPU memory. 1\n\nAutomatic Mixed Precision\nimport torch\n# Creates once at the beginning of training\nscaler = torch.cuda.amp.GradScaler()\n \nfor data, label in data_iter:\n   optimizer.zero_grad()\n   # Casts operations to mixed precision\n   with torch.cuda.amp.autocast():\n      loss = model(data)\n \n   # Scales the loss, and calls backward()\n   # to create scaled gradients\n   scaler.scale(loss).backward()\n \n   # Unscales gradients and calls\n   # or skips optimizer.step()\n   scaler.step(optimizer)\n \n   # Updates the scale for next iteration\n   scaler.update()\nOptimizers\n\nAdamW — PyTorch 1.10.1 documentation\nAdam — PyTorch 1.10.1 documentation\n\nTorchScript\nFootnotes\n\n\nefficientdl.com/faster-deep-learning-in-pytorch-a-guide ↩ ↩2 ↩3\n\n\n"},"4archives/Permanent-Notes/202112251133-Incorrect-Data-Labels":{"title":"202112251133 Incorrect Data Labels","links":[],"tags":["data","annotation","machine-learning"],"content":"Machine learning models are robust even when there is random errors/noise in the training set. But it is less so when they are systematic errors/bias.\nWhen there are incorrect labels in the validation or test set, it is important to evaluate the percentage of those correctable errors. If the errors are worth the efforts more so than the in-correctable examples (actual mistakes from the model), then:\n\nFind out what went wrong\nApply the fix to both the validation and test sets\n"},"4archives/Permanent-Notes/202112251244-Deep-Work":{"title":"202112251244 Deep Work","links":[],"tags":["Deep-Work","book","self-help","productivity"],"content":"Why is Deep Work Important?\nTo be valuable in the job market and the society, one needs expertise in his/her domains and capability to learn and produce things fast, and deep work can help us achieve that – being in the flow state pushes your mind to expand its boundary as well as horns your skills to a deeper level.\nWhy is Deep Work so Rare?\nThe connectivity brought be internet tools leaves us no room for distraction-free focus and uninterrupted time window, which is enforced in our daily life and eventually becomes a vicious habit that corrupts our mind.\nWhy Does it Work?\nIt reinforces the neural circuits when we learn focused.\nHow to Commit to Deep Work?\nJust like any habit you want to culture, you have to practice it. Out actions cast votes to who we want to become. Design routines, rituals and cues to guide you instead of relying on willpower or motivation."},"4archives/Permanent-Notes/202202081923-Workplace-Productivity":{"title":"202202081923 Workplace Productivity","links":["4archives/Permanent-Notes/202112251244-Deep-Work"],"tags":["productivity"],"content":"Core idea: how to setup our workplace to encourage productivity and therefore promote Deep Work. This is based on this podcast episode Optimizing Workspace for Productivity, Focus, &amp; Creativity - Huberman Lab.\nTime-based Tricks\nMorning\n\nAllow more light into your eyes as it stimulates alertness;\nOpen the window;\n\nAfternoon or Evening\n\nDim the lights, especially overhead lights\nReduce blue lights\n\nPhysical Tricks\n\nLooking down can reduce alertness and vice versa, looking up can increase alertness;\nRaise your monitor to your eye level or slightly above;\nStand or sit straight;\nDrink more water;\nFocusing visually leads to focusing mentally;\n"},"4archives/Permanent-Notes/202205112015-Effective-Note-taking":{"title":"202205112015 Effective Note-taking","links":[],"tags":["productivity/zettelkasten","note-taking"],"content":"How to Take Notes From Book Highlights\n\nMake a checkpoint every chapter so as to gather highlights and organize them into fleeting notes.\nRefractor your fleeting notes into literature notes.\nRefractor your literature notes into atomic notes, connected and linked.\nFind additional relevant nodes to link by search related topics and keywords.\n"},"4archives/Permanent-Notes/202205202159-2x-Rule":{"title":"202205202159 2x Rule","links":["0-Inbox/Just-Keep-Buying"],"tags":["finance"],"content":"Definition\nEvery time you spend $x on something, spend the same amount of money on investment.\nCoincidently, most minimalists also practice a similar mindset when purchasing something — to factor in the expenses of maintaining and disposing. Sometimes you can even take into consideration the time and energy you will have to spend for keeping it around. In the end, you end up with a number that is likely 2x or 3x larger than the price tag.\n\nReferences:\n\nJust Keep Buying\n"},"4archives/Permanent-Notes/202205202200-Diminishing-Marginal-Utility":{"title":"202205202200 Diminishing Marginal Utility","links":["0-Inbox/Just-Keep-Buying"],"tags":["finance"],"content":"Definition\nEach additional unit of consumption brings less satisfaction than previous unit.\n\n\nReferences:\n\nSpending\nDiminishing Marginal Utility - an overview | ScienceDirect Topics.)\n"},"4archives/Permanent-Notes/202205231928-Cost-Equivalent-Curve":{"title":"202205231928 Cost Equivalent Curve","links":["4archives/Literature-Notes/Readings/UNICORN-on-RAINBOW-A-Universal-Commonsense-Reasoning-Model-on-a-New-Multitask-Benchmark"],"tags":["natural-language-processing","machine-learning"],"content":"Definitions\nCost: the number of training examples in the training set used.\nPerformance: the performance given a model and a cost according to the task metric.\nCost Equivalent Curve: a curve depicting the relation between cost and performance. For a target performance score, the smaller the cost is, the better the model is.\nThe underlying assumption of the curve is that such relationship between cost and performance is continuous and strictly monotonic.\n\nReference:\n\nUNICORN on RAINBOW A Universal Commonsense Reasoning Model on a New Multitask Benchmark @lourie_2021\n"},"4archives/Permanent-Notes/202205231931-Transfer-Learning-Approaches":{"title":"202205231931 Transfer Learning Approaches","links":["4archives/Literature-Notes/Readings/UNICORN-on-RAINBOW-A-Universal-Commonsense-Reasoning-Model-on-a-New-Multitask-Benchmark"],"tags":["machine-learning","natural-language-processing","transfer-learning"],"content":"Multitask Training: Train the model on all tasks/datasets all at once;\nSequential Multitask Training: Train the model on some tasks/datasets first before continue training it with the target tasks/datasets; \nMultitask Training and Fine-tuning: Train the model on some tasks first and fine-tuning it with target tasks/datasets;\nFindings from @lourie_2021 that\n\n^3f3b27 almost always outperform other methods.\nMultitask training helps the most when target data is scarce.\nLarger models see more gains from transfer learning.\n\n\nReferences:\n\nUNICORN on RAINBOW A Universal Commonsense Reasoning Model on a New Multitask Benchmark @lourie_2021\n"},"4archives/Permanent-Notes/202205241111-Code-Review-Pyramid":{"title":"202205241111 Code Review Pyramid","links":[],"tags":["engineering","practice","software-engineering","career","code-review"],"content":"\nStyle and most tests should be automated (in the commit hooks, CI tools or in a bash script) so you don’t have to write a PR comment about this.\nOne should have a trace of written records regarding design decisions and implementation choices, ranging from technical specifications to your API documentations. Personally, I think questions around directions should not be discussed in a PR, at which time efforts have been invested and it would be too late to make a turn."},"4archives/Permanent-Notes/202205241112-Deep-Learning-First-Principles-for-Efficiency":{"title":"202205241112 Deep Learning First Principles for Efficiency","links":[],"tags":["Deep-Learning","First-Principle","Trick"],"content":"Three Areas of Optimization\n1. Compute\nCompute refers to the arithmetic operations done by CPU or GPU, typically measured in floating point operations per second (FLOPS). We want to maximize this to take advantage of all the GPUs we are paying.\nIt is often more difficult to increase the FLOPS than to reduce the memory footprint. One have to change the actual operations to do so, while there are a lot of tricks to use less memory.\nOften GPUs are optimized for matrix multiplication. For example, matrix multiplication makes up 99.80% of BERT’s computation. The rest of operators, though occupying a small fraction of FLOPS, take about 40% of runtime due to 2 Memory Bandwidth.\n2. Memory Bandwidth\nMemory bandwidth cost refers to the time spent on transferring data, from CPU to GPU or from one GPU to another.\nHow can we reduce the transferring cost?\n\nOperator fusion: perform operators on the same data sequentially in one-go instead of sending data back and forth;\nExtra computation: such as re-materialization or activation checkpointing\n\nCalculation\nMemory bandwidth: 1.5 TB/s\nFLOPS: 19.5 Tera FLOPS\nTime to load 400 Billion 4-byte (1.6TB) floats: ~1s\n20 Trillion operations: ~1s\n\nread + write time: ~2s\nnumber of operations needed to spend 2s: 20 T / 400 B * 2 = 100 ops\n\nIt means you have to perform more than 100 operations per float number for that 400 billion tensor to spend more time on compute than data transferring.\n3. Overhead\nOverhead means time spent on everything else. One example:\n\nin the time that Python can perform a single FLOP, an A100 could have chewed through 9.75 million FLOPS.\n\nHowever, for modern GPUs, as long as the CPU is ahead of scheduling and queuing up the GPU tasks, large scale computation is less likely to be overhead bound. Two ways to find out if your workflow is overhead-bound:\n\nScale your data, if the computation does not increase proportionally, then it is likely overhead-bound\nProfiling\nSacrifice the flexibility by tracing the PyTorch code into JIT or CUDA operations to reduce PyTorch overhead\n"},"4archives/Permanent-Notes/202205241113-Hotelling's-Two-sample-T-squared-Test":{"title":"202205241113 Hotelling's Two-sample T-squared Test","links":[],"tags":["statistics","two-sample-test"],"content":"Multivariate (multiple features) two-sample test.\nAssumptions\n\nBoth samples are independent;\nBoth samples are multivariate normal;\nBoth samples have equal variance-covariance matrices;\n\nH0​: Samples drawn from populations with the same multivariate mean.\nFormula\nT2S​=nn1​n2​​(x1​ˉ​−x2​ˉ​)TS∗−1(x1​ˉ​−x2​ˉ​)=n1​+n2​−2(n1​−1)S1​+(n2​−1)S2​​​​\nwhere S is the covariance matrix and S∗ is the pooled covariance matrix.\nResults\nT2 would be zero if two samples share the same means and therefore H0​ is true.\nIf T2 is larger than zero, then we should convert it to F statistic for significance testing:\nF=k(n−2)n−k−1​T2\nwhere n is the sample size and k is the number of variables/features.\nReporting\nT2=3.41,F(n,k)=1.76,p=0.23"},"4archives/Permanent-Notes/202205241114-How-to-Remember-Names":{"title":"202205241114 How to Remember Names","links":[],"tags":["Life-Hack"],"content":"Takeaways:\n\nInitially, a name and a face are not associated until your hippocampus puts them together into a single memory;\nInstead of focusing on introducing yourself, pay more attention to learning them. HEAR the name;\nLearn the name properly:\n\nPractice retrieval the name\nSearch for something to remember the name by\nSearch for some facial features\nTake some notes in the Apple notes (add some facts as well)\nConnect on social media\n\n\nThis is a skill that needs practice.\n"},"4archives/Permanent-Notes/202205241115-How-to-Work-Hard":{"title":"202205241115 How to Work Hard","links":[],"tags":["Productivity"],"content":"Why Work Hard?\nWe can not change our talents, so work hard is, in most cases, the only choice.\nHow to Work Hard?\n\nDefine your goals and foster disciplines\nTwo mindsets:\n\nEnjoy achievement\nDislike idleness\n\n\nLearn what work is\n\nWhat matches your talent might not be your interest\nKnow what is important and interesting\n\n\nPlan ahead\n\nAvoid diminishing returns and burnout\n\n\nWork towards the hard-core center problems\n"},"4archives/Permanent-Notes/202205241116-Kernel-Two-sample-Test":{"title":"202205241116 Kernel Two-sample Test","links":[],"tags":["statistics","two-sample-test"],"content":"Maximum Mean Discrepancy (MMD)\nMultivariate two-sample test.\nFormula\nMMD(P,Q)=n21​i=1∑n​j=1∑n​k(xi​,xj​)+m21​i=1∑m​j=1∑m​k(yi​,yj​)−nm2​i=1∑n​j=1∑m​k(xi​,yj​)\nk refers to the kernel function."},"4archives/Permanent-Notes/202205281322-Four-Things-That-Make-Things-Memorable":{"title":"202205281322 Four Things That Make Things Memorable","links":["4archives/BASB/202205011900-Capture-Toolkit"],"tags":["productivity","memory"],"content":"\nNovelty: something new\nRepetition: reinforcement\nAssociation: connections\nEmotional Resonance\n"},"4archives/Privacy-AI/01-Intro":{"title":"01 Intro","links":[],"tags":["Information-Flow","Privacy-AI"],"content":"Information Flow: a flow of bits from sender to receiver with some probability.\nPrivacy VS. Transparency\n\nLeaky information flow: aka. privacy violation.\nInefficient information flow\n\nIt is important to recognize the context. Contextualized integrity/privacy frames the line of privacy into various situations. E.g. home images on Google map, various information flows on top of that might cause a lot of issues, even if it is public information in the first place.\n\nPrivacy is a proper information flow.\nHelen Nissenbaum (Creator of Contextual Integrity - Cornell)\n\nChallenges\nMaximizing privacy might lead to transparency issues (e.g. money laundering or buying products without reading any reviews).\nQ: How should we balance the information flow to minimize transparency dilemma (insufficient information) and privacy dilemma(too much information)?\nA: To build a Pareto frontier.\nData is Fire\nData can be useful and dangerous because of duo use.\nIf you don’t have anything to hide right now, why do you care if someone is inferring: Changes in life make anything privacy. Implications, correlations and powerful machine learning models can figure out a lot about one’s privacy.\nRemoving PII might not work because of the existence of implicit patterns and information (cross-referencing, pattern recognition)."},"4archives/Privacy-AI/03-Information-Flow-within-Communities":{"title":"03 Information Flow within Communities","links":[],"tags":["Information-Flow","Privacy-AI"],"content":"Dilemmas\n\nAI progress originating from data growth or high quality dataset simply cannot exempt us from violating privacy;\nWe need relative and representative data in all research so that it is applicable in real-life;\n\nNot just AI research that is data-hunger because all research collaborates with each other at some point\n\n\n\nInformation Services\nA typical narrative about privacy:\n\nLack of data sharing could lead to service lock-in;\nMore privacy violation could happen because of data-sharing;\n\nBut there is a difference regarding private data being transferred:\n\nPrivate data moving with the owner;\n\nThis is the sharing we want\n\n\nPrivate data being sold with owner’s consent;\n\nThis is not the sharing we want\n\n\n\nWe need Interoperability (e.g. install third-party apps on your phone, bypassing ink cartridge in printers) to fight against lock-in. In this case, we need this type of information flow that are in our control."},"4archives/System-Design/Design-a-Rate-Limiter":{"title":"Rate Limiter","links":["4archives/System-Design/Interview"],"tags":["system-design","rate-limiter"],"content":"Rate Limiter\nIn web services, rate limiters are used to control the client traffic by limiting the number of requests allowed within a certain time window. Some of the benefits of using rate limiters are:\n\nPrevent DDoS.\nReduce costs.\nReduce chances of being overloaded.\n\n1 Understand the Scope\n1. Client side or server side rate limiter?\n\t1. Tech stack or ecosystem\n\t2. Bandwidth or resources\n2. On what basis is this rate limiter working on? Client ID or IP?\n3. Scale or audience\n4. Separate service or integrated service\n\nRequirements:\n\nAccurate\nFast\nEfficient\nDistributed\nException\nHigh fault tolerate, esp. when distributed\n\nAlgorithms\nToken Bucket\nImagine there is a bucket and a refiller puts some credits in the bucket periodically. Any incoming request will need one credit to be executed, if the bucket is empty, the request will not be honored.\n\nParameters: bucket size and refiller rate\nDifferent buckets for different API endpoints\nEasy to implement and allows traffic burst but parameters are difficult to tune\n\nLeaky Bucket\nRequests are stored in queue and being processed at regular intervals. Excessive requests are dropped.\n\nParameters: queue size and processing rate\nEfficient for stable processing rate but cannot handle a traffic burst\n\nFixed Window Count\nEach time window has a counter and one request increases the counter by 1.\n\nEfficient\nSpike traffic might leads to more requests than allowed. For example, a 100 requests per minute rate limit could allow 200 requests from 00:59 to 01:01 as a result.\n\nSliding Window Log\nRequest timestamp is logged and outdated logs are evicted.\n\nEvery accurate but not so memory efficient\n\nSliding Window Count\n\nPrevious requests are discounted in the rolling time window.\n\nNot 100% accurate but more memory efficient than Sliding Window Log\n\n2 High-level Design\n\nA Redis in memory database can be used to store the counters.\n3 Deep Dive\nConfiguration\nIt can be written in some YAML file stored on disk.\nDealing with Excessive Requests\n\nIgnore them with some HTTP response\nRe-enqueueing them if servers failed\n\nDistributed Environment\nRace Condition\n\nLocks but they can be slow\nLua script 1 and sorted sets data structure in Redis 2\n\nSynchronization\nWhen multiple rate limiter are used for distributed load-balancing, you can either use sticky request — routing requests to the same rate limiter from the same user, or use central database like Redis.\nOptimization\n\nRoute requests to nearest servers for low latency;\nData synchronization with an eventual consistency model;\n\nMonitoring\nWe want to make sure our rate limiters are working:\n\nAlgorithm is effective (handling burst e.g.)\nRules are effective (no valid requests dropped)\n\n4 Wrap up\n\nRate limits can be used in many layers of the application\nDesign products to reduce the need for rate limits\n\nCaching\nLoad-balancing\nExceptions\nRetry\n\n\n\n\nReferences\nFootnotes\n\n\n0-rate-limiters.md · GitHub ↩\n\n\nBetter rate limiting with Redis sorted sets | Building ClassDojo ↩\n\n\n"},"4archives/System-Design/Estimation":{"title":"Estimation","links":[],"tags":[],"content":"Back of the Envelope Estimation\n\nRounding and approximation\nWhat are your assumptions?\nWhat is the unit?\nCommon estimations: QPS, peak QPS, storage, cache\n"},"4archives/System-Design/Interview":{"title":"Interview","links":["4archives/System-Design/Estimation"],"tags":["system-design","software-engineering","interview"],"content":"Interview Goals\nTo understand candidate’s ability to collaborate, to work under pressure, to solve problems, and to communicate — asking good question.\n1. Understand the Scope\nTo understand the problem scope by asking questions. (3 - 10 minutes)\n\nFeatures\n\nMotivations\n\n\nUsers\n\nAudience\n\n\nScaling\nTech Stack\n\n2. High-level Design\n(10 - 15 minutes)\n\nCome up with a draft and ask for feedback. This is where the collaboration comes into play;\nIllustrate the key components;\nDo some Back of the Envelope Estimation before diving into it.\n\n3. Deep Dive\nDive into each component by some priority. (10 - 25 minutes)\n4. Wrap up\n(3 - 5 minutes)\n\nRecap\nImprovement\nFailures or issues\nOperational components such as logging and monitoring\nNext-level scaling\n\nDos and Don’ts\n\nDo ask for clarification, feedback often\nDo state your assumptions\nDo understand the scope\nDo propose alternatives\nDo prioritize\nDo not jump to conclusions\nDo not dwell on small details\nDo not hesitate to ask questions or hints\nDo not think in silence\n"},"4archives/System-Design/Scaling":{"title":"Scaling","links":[],"tags":["system-design","programming","coding-interview"],"content":"Scaling a Web Service\nTerminology\n\nClient: web browsers or mobile applications.\nServer: machines that host back-end code, not necessarily where data live.\nDatabase: data storage that might be on a different machine than the server.\n\nTypes of Scaling\n\nVertical Scaling refers to adding more CPUs or RAM to your server.\n\nIt is hard since you cannot add unlimited CPUs to your server due to hardware or operating system limits.\nIf the server goes down, the service goes down.\n\n\nHorizontal Scaling means adding more servers to your pool, just like adding pods into the Kubernetes cluster. \n\nAreas Where Scaling is Possible\nData\nDatabase Choice\nRelational database is good for most cases, but some use cases require non-relational databases:\n\nLow latency\nUnstructured data\nOnly operations are serialization or deserialization\nMassive amount of data\n\nDatabase Replication\n\nBetter performance and availability by having distributed nodes, allowing parallel processing.\nReliability since data is replicated.\n\nDatabase Scaling\nScaling out aka ^e95948 by sharding. However, there are some issues that make sharding difficult:\n\nRe-shading: due to failure or shard exhaustion, it might be required to re-shard data;\nJoin operations: join cross shards might be very difficult thus queries need to be de-normalized to query each shard separately;\n\nServing\nLoad-balancer\n\nSplitting traffic\nScaling out ^e95948 or in by controlling server resources\n\nCache\nCaching provides faster response for the requests for the same content. There are some considerations when to use cache:\n\nFrequent reads but infrequent writes\nExpiration policy: not too short and not too short\nConsistency\nDistributed cache tier to prevent single point failure\nEviction: Least Recent Used (LRU), Least Frequently Used (LFU) or First In First Out (FIFO)\n\nCDN\nContent Delivery Network, a special case of Cache tier, which is usually geologically distributed. They are designed for either static or dynamic files.\nConsiderations:\n\nCost\nExpiration policy\nFallback when failure\nEviction or invalidation\n\nStateless Web Service\n\nStateful: remembering client data from one request to next\nStateless: no such information is required in the request, but is stored in a share storage accessible from all servers\n\nData Center\nData center are often used to facilitate geolocation-based service. It can host servers, databases, caches and CDN can be used to route user requests to different data centers.\n\nRedirection\nSynchronization\nTesting and deployment\n\nMessage Queue\nMessage queue can be used to handle asynchronous communication between users and servers.\nLogging, Monitoring, Telemetry, and Automation\nGood practices good continuous integration, deployment and debugging."},"highlights/Archive/20220605111518":{"title":"UNICORN on RAINBOW A Universal Commonsense Reasoning Model on a New Multitask Benchmark","links":[],"tags":[],"content":"UNICORN on RAINBOW A Universal Commonsense Reasoning Model on a New Multitask Benchmark\n(6/5/2022, 11:15:18 AM)\n“a novel evaluation, the cost equivalent curve, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency.” (Lourie et al., 2021, p. 1) (pdf)\n“we define cost as the number of training examples in the target dataset.” (Lourie et al., 2021, p. 2) (pdf)\n“The construction of cost equivalent curves makes one technical assumption: the relationship between performance and cost is continuous and strictly monotonic (i.e., increasing or decreasing)” (Lourie et al., 2021, p. 2) (pdf)\n“multitask training (Caruana 1995): training on multiple datasets (including the target dataset) all at once,” (Lourie et al., 2021, p. 3) (pdf)\n“multitask fine-tuning (Liu et al. 2019a): first training on all datasets (including the target dataset) through multitask training, and then continuing to fine-tune on the target dataset alone.” (Lourie et al., 2021, p. 3) (pdf)\n“Finding 1: Sequential training almost always matches or beats other approaches.” (Lourie et al., 2021, p. 3) (pdf)\n“Finding 2: Sequential training rarely hurts performance.” (Lourie et al., 2021, p. 4) (pdf)\n“Multitask training helps most often in the lowdata regime.” (Lourie et al., 2021, p. 4) (pdf)\n“multitask learning tends to help when data is scarce, but may hurt performance if data is plentiful.” (Lourie et al., 2021, p. 4) (pdf)\n“The off-the-shelf T5’s weights come from multitask pretraining, where many tasks are mixed with a language modeling objective to learn a powerful initialization for the weights. In fact, both GLUE and SUPERGLUE were mixed into the pretraining (Raffel et al. 2019).” (Lourie et al., 2021, p. 5) (pdf)\n“Larger models benefit more from transfer” (Lourie et al., 2021, p. 5) (pdf)\n“the serialized language from the knowledge graphs is not in a QA format, and the knowledge graph completion task is generative while all other tasks are discriminative” (Lourie et al., 2021, p. 6) (pdf) Knowledge augmented lm\n\nReferences:\n\n@lourie_2021a\n"},"highlights/Archive/20220605111559":{"title":"UniDoc Unified Pretraining Framework for Document Understanding","links":[],"tags":[],"content":"UniDoc Unified Pretraining Framework for Document Understanding\n(6/5/2022, 11:15:59 AM)\n“UDoc is designed to support most document understanding tasks, extending the Transformer to take multimodal embeddings as input. Each input element is composed of words and visual features from a semantic region of the input document image.” (Gu et al., 2021, p. 1) (pdf)\n“UDoc is designed to support most document understanding tasks, extending the Transformer to take multimodal embeddings as input. Each input element is composed of words and visual features from a semantic region of the input document image.” (Gu et al., 2021, p. 1) (pdf)\n“An important feature of UDoc is that it learns a generic representation by making use of three self-supervised losses, encouraging the representation to model sentences, learn similarities, and align modalities.” (Gu et al., 2021, p. 1) (pdf)\n“it learns a generic representation by making use of three self-supervised losses, encouraging the representation to model sentences, learn similarities, and align modalities” (Gu et al., 2021, p. 1) (pdf)\n(Gu et al., 2021, p. 1) No open source code available.\n“(1) documents are composed of semantic regions.” (Gu et al., 2021, p. 1) (pdf) The semantic region is left undefined. The difference between OCR block and semantic region is also unexplanied.\n“semantic regions” (Gu et al., 2021, p. 1) (pdf)\n“However, unlike the sequence-to-sequence learning in NLP, documents have a hierarchical structure (words form sentences, sentences form a semantic region, and semantic regions form a document).” (Gu et al., 2021, p. 1) (pdf)\n“documents have a hierarchical structure (words form sentences, sentences form a semantic region, and semantic regions form a document).” (Gu et al., 2021, p. 1) (pdf)\n“Moreover, current transformer-based document pretraining models suffer from input length constraints.” (Gu et al., 2021, p. 1) (pdf)\n“(2) documents are more than words. The semantic structure of the document is not only determined by the text within it but also the visual features such as table, font size and style, and figure, etc.” (Gu et al., 2021, p. 2) (pdf)\n“(3) documents have spatial layout. Visual and layout information is critical for document understanding.” (Gu et al., 2021, p. 2) (pdf)\n“However, for semi-structured documents, such as forms and receipts, words are more related to their local surroundings. This corresponds strongly with human intuition when we look at magazines or newspapers, the receptive fields are modulated by our reading order and attention.” (Gu et al., 2021, p. 2) (pdf)\n“To handle textual information, we encode sentences using a hierarchical transformer encoder. The first level of the hierarchical encoder models the formation of the sentences from words. The second level models the formation of the document from sentences.” (Gu et al., 2021, p. 2) (pdf)\n“To handle textual information, we encode sentences using a hierarchical transformer encoder.” (Gu et al., 2021, p. 2) (pdf)\n“The first level of the hierarchical encoder models the formation of the sentences from words. The second level models the formation of the document from sentences.” (Gu et al., 2021, p. 2) (pdf)\n“Meanwhile, it reduces model computation complexity exponentially and increases the number of input words.” (Gu et al., 2021, p. 2) (pdf) 512 * 512 = 262144 tokens for each document\n“Meanwhile, it reduces model computation complexity exponentially and increases the number of input words.” (Gu et al., 2021, p. 2) (pdf)\n“we combine convolution with self-attention to form a mixed attention mechanism that combines the advantages of the two operations.” (Gu et al., 2021, p. 2) (pdf)\n“A visually-rich region (figure, chart, etc) may have stronger visual information than textual information. Instead of treating outputs from both modalities identically, we design a gating mechanism that can dynamically control the influence of textual and visual features. This approach enables cross-modal connections and allows for variable highlight the relevant information in visual and textual modality and enables cross-modal connections.” (Gu et al., 2021, p. 2) (pdf)\n“Instead of treating outputs from both modalities identically, we design a gating mechanism that can dynamically control the influence of textual and visual features.” (Gu et al., 2021, p. 2) (pdf)\n“UDoc, which consists of four components: feature extraction, feature embedding, multi-layer gated cross-attention encoder, and pretraining tasks.” (Gu et al., 2021, p. 3) (pdf)\n“In the feature extraction step, we first employ an off-the-shelf OCR tool [17] to extract text from a document image I, where the words are grouped into sentences S = {s1,…,sN } whose corresponding bounding boxes are P = {p1,…,pN }. For each sentence bounding box pi, we use a ConvNet-based backbone fImEnc and RoI Align [18] f” (Gu et al., 2021, p. 4) (pdf) Sentencization in a document can be problamatic especially when the sections and headers do not follow the grammar rule of a sentence. OCR tools in my experience rarely share the same understanding of the textual information in the documents.\n“For each sentence bounding box pi, we use a ConvNet-based backbone fImEnc and RoI Align [18] fRoIAlign to extract the pooled RoI features vi.” (Gu et al., 2021, p. 4) (pdf)\n“To obtain a feature embedding, we extract the sentence embedding si for each sentence si via a pretrained sentence encoder fSentEnc.” (Gu et al., 2021, p. 4) (pdf)\n“Each region’s RoI feature vi is discretized into a finite set of visual representations vQ i 2 VQ via product quantization [19].” (Gu et al., 2021, p. 4) (pdf)\n“Formally, a document image I 2 RW ⇥H consists of N regions, where each region’s bounding box is characterized by a 6-d vector, as pi = { xLT W , yLT H , xRB W , yRB H,w W, h H }, where w and h are of the width and height the region, W and H are the width and height of I, wh” (Gu et al., 2021, p. 4) (pdf) I think they refer each sentence bounding box as region, but what if the sentence stretches two lines, or what about tables, TOC, lists? A rigorously definition of region should help here.\n“We also have different types of segments to distinguish different modalities. The input sequence to the transformer-based encoder starts with a special start element ([CLS] and full visual features), then it is followed by multimodal elements, and it ends with a special ending element ([SEP]+full visual features).” (Gu et al., 2021, p. 4) (pdf) visual features + [SEP] or [SEP] + visual features?\n“Unlike the fixed image encoder in [6], we jointly learn the image encoder in an end-to-end fashion alongside the multimodal model.” (Gu et al., 2021, p. 4) (pdf)\n“To constrain the representation space of the visual features and facilitate the end-to-end learning of image encoder (see Task #2 in Sec. 3.2), we follow [20, 21] and use vector quantization to discretize the visual features V = {v1, … , vN } into a finite set of representations VQ = {vQ 1 , … , vQ N }.” (Gu et al., 2021, p. 4) (pdf)\n“The goal is to predict the masked sentence embeddings based on the contextual information from the surrounding sentences and image regions, by minimizing the smooth L1 loss [16]:” (Gu et al., 2021, p. 5) (pdf)\n“The goal is to predict the masked sentence embeddings based on the contextual information from the surrounding sentences and image regions” (Gu et al., 2021, p. 5) (pdf)\n“random masking” (Gu et al., 2021, p. 5) (pdf)\n“The goal is to minimize the differences” (Gu et al., 2021, p. 5) (pdf)\n“between the pairwise similarities of sentence embeddings and the pairwise similarities of image region features:” (Gu et al., 2021, p. 6) (pdf)\n“between the pairwise similarities of sentence embeddings and the pairwise similarities of image region features:” (Gu et al., 2021, p. 6) (pdf)\n“The paragraph mode groups the non-paragraph results into text regions.” (Gu et al., 2021, p. 6) (pdf) This is different from what is previously defined.\n“Hence, we adopt the paragraph-level outputs as the basic input elements since textual regions provide semantically more meaningful information than independent words.” (Gu et al., 2021, p. 6) (pdf)\n“We set the hidden size to 768 and the number of heads to 12, the maximum number of regions N to 64, and the maximum input sequence length for fSentEnc to 512.” (Gu et al., 2021, p. 6) (pdf)\n“80% among the masked sentences are replaced by special sentence [CLS, MASK, SEP]” (Gu et al., 2021, p. 7) (pdf)\n“We find that OCR plays a key role in document classification performance.” (Gu et al., 2021, p. 9) (pdf)\n“(2) Although impressive performance has been achieved in document entity recognition tasks such as form and receipt understanding, the classification accuracy on semi-structured documents such as forms is still inferior to that of rich-text documents. It is possible to devise a better method to model the spatial relationship among words.” (Gu et al., 2021, p. 10) (pdf)\n“Lastly, the use of different OCR tools is one of the major sources of inconsistency among the existing document pretraining works. It is worthwhile and essential to build standardized pretraining document image datasets with preprovided OCR results. In addition to scanned documents, using digital PDF as part of the pretraining data is a direction worth exploring since it provides rich metadata which could be beneficial for multimodal learning.” (Gu et al., 2021, p. 10) (pdf)\n\n\n@gu_2021b\n"},"highlights/Archive/20220605111628":{"title":"Paragraph-based Transformer Pre-training for Multi-Sentence Inference","links":[],"tags":[],"content":"Paragraph-based Transformer Pre-training for Multi-Sentence Inference\n(6/5/2022, 11:16:28 AM)\n“Pre-trained transformers such as BERT are used for these tasks as cross-encoders by setting them as sentence-pair classification problems, i.e, aggregating inferences independently over each candidate.” (Di Liello et al., 2022, p. 1) (pdf)\n“Specifically, given a target sentence s and multiple sentences (from the same/different paragraph/document), the model needs to recognize which sentences belong to the same paragraph as s in the document used.” (Di Liello et al., 2022, p. 1) (pdf)\n“Multi-Sentence Inference: Inference over a set of multiple candidates” (Di Liello et al., 2022, p. 2) (pdf) Multiple choices\nFact verification\nAnswer extraction\n“DeCLUTR (Giorgi et al., 2021) uses a contrastive learning objective for cross-encoding two sentences coming from the same/different documents in a transformer.” (Di Liello et al., 2022, p. 2) (pdf)\n“Multi-sentence Inference Tasks AS2: We denote the question by q, and the set of answer candidates by C={c1,…cn}. The objective is to re-rank C and find the best answer A for q.” (Di Liello et al., 2022, p. 2) (pdf)\n“Intuitively, modeling interrelated information between multiple ci’s can help in selecting the best answer candidate (Zhang et al., 2021).” (Di Liello et al., 2022, p. 2) (pdf)\n“Fact Verification: We denote the claim by F , and the set of evidences by C={c1 …cn} that are retrieved using DocIR. The objective is to predict whether F is supported/refuted/neither using C (at least one evidence ci is required for supporting/refuting F ).” (Di Liello et al., 2022, p. 2) (pdf)\n“We pad (or truncate) each sentence si to the same fixed length L (total input length L⇥(k + 1)), and use the embedding for the [CLS] / [SEP] token in front of each sentence si as its embedding (denoted by Ei).” (Di Liello et al., 2022, p. 3) (pdf)\n“IE1: a linear layer on the output embedding E0 of s0 (similar to BERT) referred to as the Individual Evidence (IE1)” (Di Liello et al., 2022, p. 3) (pdf)\n“AE1: a linear layer on the average of the output embeddings [E0,E1,…,Ek] to explicitly factor in information from all candidates, referred to as the Aggregated Evidence (AE1)” (Di Liello et al., 2022, p. 3) (pdf)\n“IEk: a shared linear layer applied to the output embedding Ei of each candidate si ,i2{1 …k} referred to as k-candidate Individual Evidence (IEk)” (Di Liello et al., 2022, p. 3) (pdf)\n“AEk: a shared linear layer applied to the concatenation of output embedding E0 of input s0 and the output embedding Ei of each candidate si ,i2{1 …k} referred to as kcandidate Aggregated Evidence (AEk)” (Di Liello et al., 2022, p. 3) (pdf)\n“we design a new pre-training task where the model is (i) provided with (k + 1) sentences {s0 …sk}, and (ii) tasked to predict which sentences from {s1 …sk} belong to the same paragraph P as s0 in the document D. We call this pre-training task Multi-Sentences in Paragraph Prediction (MSPP)” (Di Liello et al., 2022, p. 3) (pdf)\n“We randomly sample a sentence from a paragraph P in a document D to be used as s0, and then (i) randomly sample k1 sentences (other than s0) from P as positives, (ii) randomly sample k2 sentences from paragraphs other than P in the same document D as hard negatives, and (iii) randomly sample k3 sentences from documents other than D as easy negatives” (Di Liello et al., 2022, p. 3) (pdf)\n“Student t-test with 95% confidence level” (Di Liello et al., 2022, p. 4) (pdf)\n“The performance gap stems from questions for which the pairwise RoBERTa model was unable to rank the correct answer at the top position, but support from other candidates in the top-k helped the joint model rank it in the top position.” (Di Liello et al., 2022, p. 5) (pdf)\n\n\n@diliello_2022\n"},"highlights/Archive/20220605111631":{"title":"On the Paradox of Learning to Reason From Data","links":[],"tags":[],"content":"On the Paradox of Learning to Reason From Data\n(6/5/2022, 11:16:31 AM)\n“instead of learning to emulate the correct reasoning function, BERT has in fact learned statistical features that inherently exist in logical reasoning problems” (Zhang et al., 2022, p. 1) (pdf)\n“the models attaining near-perfect accuracy on one data distribution do not generalize to other distributions within the same problem space.” (Zhang et al., 2022, p. 2) (pdf)\n“In fact, the model has learned to use statistical features in logical reasoning problems to make predictions rather than to emulate the correct reasoning function.” (Zhang et al., 2022, p. 2) (pdf)\n“statistical features inherently exist in reasoning problems and are not specific to certain data distributions.” (Zhang et al., 2022, p. 2) (pdf)\n“moreover, we argue that there are potentially countless statistical features and it is computationally expensive to jointly remove them from training distributions.” (Zhang et al., 2022, p. 2) (pdf)\n“However, for logical reasoning, even though numerous statistical features inherently exist, models should not be utilizing them to make predictions.” (Zhang et al., 2022, p. 2) (pdf)\n“When BERT is trained on data with statistical features, it tends to make predictions based on such features rather than learning to emulate the correct reasoning function; thus, BERT fails to generalize to the whole problem space. However, unlike the shallow shortcuts found in other typical NLP tasks, such statistical features can be countless and extremely complicated, and thus very difficult to be removed from training data.” (Zhang et al., 2022, p. 5) (pdf)\n“(1) when statistical features are presented in training distributions, BERT tends to utilize them to make predictions; (2) after removing one statistical feature from training data, the model generalizes better.” (Zhang et al., 2022, p. 7) (pdf)\n“it is computationally infeasible to jointly remove multiple statistical features.” (Zhang et al., 2022, p. 8) (pdf)\n\n\n@zhang_2022\n"},"highlights/Archive/20220605111720":{"title":"An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems","links":["tags/selections"],"tags":["selections"],"content":"An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems\n(6/5/2022, 11:17:20 AM)\n“The generated multitask model is sparsely activated and integrates a task-based routing that guarantees bounded compute cost and fewer added parameters per task as the model expands.” (Gesmundo and Dean, 2022, p. 1) (pdf)\n“The proposed method relies on a knowledge compartmentalization technique to achieve immunity against catastrophic forgetting and other common pitfalls such as gradient interference and negative transfer.” (Gesmundo and Dean, 2022, p. 1) (pdf)\n“The multitask system and evolutionary process is initialized with one root model.” (Gesmundo and Dean, 2022, p. 2) (pdf)\n“During the evolutionary process, the proposed method searches for the best model for a single task at a time, referred to as the active task.” (Gesmundo and Dean, 2022, p. 2) (pdf)\n“During the active phase of a task, a population of models trained on the active task is evolved: the active population.” (Gesmundo and Dean, 2022, p. 2) (pdf)\n“The active population is iteratively extended by: 1) sampling a parent model (Section 3.2), 2) applying to the parent model a sampled set of mutations (Section 3.3) to produce a child model, 3) performing cycles of training and validation in order to train and score the child model.” (Gesmundo and Dean, 2022, p. 3) (pdf)\n“An active phase is composed of multiple generations in which multiple batches of child models are sampled and trained in parallel.” (Gesmundo and Dean, 2022, p. 3) (pdf)\n“At the end of a task active phase, only its best scoring model is retained as part of the multitask system.” (Gesmundo and Dean, 2022, p. 3) (pdf)\n“Each model, m, can be accepted as parent with probability: pparent(m|t)=0.5#selections(m,t). Whereselections(m, t) denotes the number of times the candidate model, m, has been previously selected as parent to generate a child models for task t.” (Gesmundo and Dean, 2022, p. 3) (pdf)\n“This method prioritizes the exploitation of high scoring models that had few attempts at generating an improved model for the active task. But also, in combination with early pruning, it automatically transitions toward a more exploratory behavior in case the higher scoring models are unable to generate an improvement.” (Gesmundo and Dean, 2022, p. 3) (pdf)\n“Layer cloning mutations create a copy of any parent model layer that can be trained by the child model. If a layer of the parent model is not selected for cloning, then it is shared with the child model in a frozen state to guarantee immutability of pre-existing models.” (Gesmundo and Dean, 2022, p. 3) (pdf)\n“Hyperparameter mutations can be applied to modify the configuration inherited from the parent.” (Gesmundo and Dean, 2022, p. 4) (pdf)\n“The score can be defined to optimize a mixture of factors such as validation quality, inference latency, training compute or model size, depending on the applications requirements.” (Gesmundo and Dean, 2022, p. 4) (pdf)\n“Once a model has been trained, the parameters storing its knowledge cannot be modified. This method guarantees immunity from catastrophic forgetting, since the knowledge of a trained model is always preserved. It also provides a solution to negative transfer, since it automates the selection of the knowledge that is most relevant for each new task. Furthermore, it also avoids gradient interference, that can arise when multiple gradients are synchronously applied to the same set of parameters.” (Gesmundo and Dean, 2022, p. 4) (pdf)\n\n\n@gesmundo_2022\n"},"highlights/Archive/20220605111740":{"title":"OPT Open Pre-trained Transformer Language Models","links":[],"tags":[],"content":"OPT Open Pre-trained Transformer Language Models\n(6/5/2022, 11:17:40 AM)\n“Our aim in developing this suite of OPT models is to enable reproducible and responsible research at scale, and to bring more voices to the table in studying the impact of these LLMs. Definitions of risk, harm, bias, and toxicity, etc., should be articulated by the collective research community as a whole, which is only possible when models are available for study.” (Zhang et al., 2022, p. 1) (pdf)\n“From this implementation, and from using the latest generation of NVIDIA hardware, we are able to develop OPT-175B using only 1/7th the carbon footprint of GPT-3. While this is a significant achievement, the energy cost of creating such a model is still nontrivial, and repeated efforts to replicate a model of this size will only amplify the growing compute footprint of these LLMs.” (Zhang et al., 2022, p. 1) (pdf)\n“We found the Pile was particularly full of duplicate documents, and advise future researchers using the Pile to perform additional de-duplication processing.” (Zhang et al., 2022, p. 2) (pdf)\n“Other subsets of the Pile were eliminated as we found they increased the risk of instabilities, as measured by tendency to cause spikes in gradient norms at the 1.3B scale, or were otherwise deemed unsuitable.” (Zhang et al., 2022, p. 3) (pdf)\n“Flagged nodes were then cordoned off and training was resumed from the last saved checkpoint. Given the difference between the number of hosts cycled out and the number of manual restarts, we estimate 70+ automatic restarts due to hardware failures.” (Zhang et al., 2022, p. 3) (pdf)\n“We speculate this occurs from two sources: (1) evaluating via the Davinci API may be bringing in safety control mechanisms beyond the original 175B GPT-3 model used in Brown et al. (2020); and (2) the significant presence of unmoderated social media discussions in the pre-training dataset has provided additional inductive bias to aid in such classification tasks.” (Zhang et al., 2022, p. 6) (pdf)\n“In particular, we found OPT-175B does not work well with declarative instructions or point-blank interrogatives.” (Zhang et al., 2022, p. 8) (pdf)\n“milar to other LLMs, OPT-175B can produce factually incorrect statements (Adiwardana et al., 2020; Brown et al., 2020; Roller et al., 2021; Rae et al., 2021; Chowdhery et al., 2022; Thoppilan et al., 2022). This can be particularly harmful in applications where information accuracy is critical, such as healthcare and scientific discovery (Weidinger et al., 2021b).” (Zhang et al., 2022, p. 8) (pdf)\n“we believe more scrutiny should be afforded to the training data with additional data characterization and selection criteria in order to use data responsibly.” (Zhang et al., 2022, p. 8) (pdf)\n“While OPT-175B was developed with an estimated carbon emissions footprint (CO2eq) of 75 tons,10 GPT-3 was estimated to use 500 tons (Patterson et al., 2021), while Gopher required 380 tons (Rae et al., 2021).” (Zhang et al., 2022, p. 9) (pdf)\n\n\n@zhang_2022a\n"},"highlights/Archive/20220605142500":{"title":"On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations","links":[],"tags":[],"content":"On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations\nPage 1\n\nincreasingly-powerful models keep exploiting ever-smaller\nspurious correlations, and as a re- sult even balancing all\nsingle-word features is insufficient for mitigating all of these\ncorre- lations.\n\n\nIn contrast to humans, supervised models of- ten fail to\ngeneralize and understand implicit con- text, instead resorting\nto low-level correlations in\n\n\nthe data, leading to amplified bias (Zhao et al., 2017;\nStanovsky et al., 2019) and brittle perfor- mance (Schwartz et\nal., 2017; Gururangan et al., 2018).\n\nPage 2\n\ntheir existence in large training sets is both inevitable and to\nsome extent even de- sired, as they are an inherent property of\nnatural language understanding.\n\n\nbalancing single-word features is insufficient for eliminating\nall spurious correlations, and that balancing feature combina-\ntion is needed for that purpose\n\n\nbalancing too much leads to datasets that contain no learnable\nsignal either\n\n\nWe argue that in such cases, the model should not fallback to\ndefault assumptions, but rather abstain or interact with the\nuser to clear ambiguities.\n\nPage 3\n\napproaches like AF converge to removing all low-level\ncorrelations,2 and there- fore a fully balanced dataset.\n\n\n\nOne conceptual defini- tion, denoted here ingenuine (e.g., Wang\nand Culotta, 2020; Rogers, 2021) is a feature corre- lated with\nsome output label for no apparent rea- son. Such features often\nresult from the annotation process (referred to as annotation\nartifacts; Gu- rurangan et al., 2018).\n\n\nThis definition is appealing: we want our models to learn real\ninformation about the world, and not properties of a given\ndataset.\n\nPage 4\n\nIn an alternative definition, denoted ungeneralizable, a\nspurious feature is one that works well for specific examples\nbut does not hold in general (Chang et al., 2021; Yaghoobzadeh\net al., 2021).\n\nPage 5\n\nThe practice of dataset balancing is designed to prevent models\nfrom learning that some words or expressions have a common\nfallback meaning that can stem from dataset artifacts (e.g.,\n“cat” as an in- dicator of contradiction) but also from cultural\nand historical contexts (e.g., Biden is the U.S. president in\n2022).\n\n\nFallback meanings are crucial for under- standing language, as\ncontexts are often underspec- ified (Graesser, 2013).\n\n\nAs a result, to truly mitigate all spurious correla- tions in a\ndataset, balancing feature combinations is required as well.\n\n\nNonetheless, balancing this dataset for pairs of features would\nresult in no informa- tion, and thus prevent any model from\nlearning this function (Tab. 4, right).\n\nPage 6\n\nThese examples illustrate that a model that learns these\ncorrelations and relies exclusively on them to make predictions\nis limited and is bound to make mistakes in some contexts.\n\n\nIn essence, an interpreter’s task (be it human or machine) is to\ninfer the most prob- able context in which a statement is made,\nand as a result, it should have a fallback option for such world\nknowledge and common sense assertions.\n\nchain of thoughts + assumptions of thoughts?\n\nthe question is whether we want models to make a prediction in\ncases of uncertainty based on the fallback option.\n\n\nThe implicit assumption of dataset balancing is that in order to\nmitigate spurious correlations the model has to unlearn them\n\nPage 7\n\nWe suggest taking into account different types of contexts\nduring dataset design. In particular, collecting training\nexamples with contexts such as negation (Morante and Blanco,\n2012), humor (Weller and Seppi, 2019; Annamoradnejad and Zoghi,\n2020), sarcasm (Davidov et al., 2010; Oprea and Magdy, 2020), or\nmetaphors (Tsvetkov et al., 2014; Mohammad et al., 2016).\n\n\nEven for tasks with a large label set (e.g., language modeling),\nmodels still have to output a valid vocabulary item. Here we\nargue that this practice creates an inductive bias towards using\nspurious correlations in cases of uncertainty, as the model has\n“nothing to lose” in case of low certainty, and is encouraged to\nalways make some prediction, potentially relying on spurious\ncorrelations.10\n\n\n\nTo address this problem, we suggest adopting ap- proaches that\nallow models to abstain and interact when they cannot make a\ndecision with high confi- dence (Chow, 1957; Hellman, 1970;\nLaidlaw and Feizi, 2019; Balcan et al., 2020).\n\nPage 8\n\nWe hypothesize that encouraging the model to provide this output\nwhen it is unsure, rather than making a semi-educated guess,\npotentially based on spurious correlations, could reduce its\ndepen- dency on such correlations.\n\n\nIn the context of this work, focusing on few-shot learning might\nallow models to not learn some of the correlations that result\nfrom manual annotation (Schwartz et al., 2017; Gururangan et\nal., 2018; Poliak et al., 2018), as they will not be exposed to\nmany of them to begin with.\n\n\nfor datasets or tasks for which the state of the art is close to\nor surpasses the human baseline, we should consider moving to\nfew-shot setups.\n\n\n\n@schwartz_2022\n"},"highlights/Archive/Carlini-et-al_2022_Quantifying-Memorization-Across-Neural-Language-Models":{"title":"Carlini et al_2022_Quantifying Memorization Across Neural Language Models","links":[],"tags":[],"content":"Page 1\n\nThis is undesirable because memorization violates privacy\n(exposing user data), degrades utility (repeated\neasy-to-memorize text is often low quality), and hurts fairness\n(some texts are memorized over others).\n\n\n\nMemorization significantly grows as we increase (1) the capacity\nof a model, (2) the number of times an example has been\nduplicated, and (3) the number of tokens of context used to\nprompt the model.\n\n\nPage 2\n\nTo construct a set of prompts from the model’s training set, we\nfeed varying-length prefixes of the training data back into the\ntrained model, and verify whether the model has the ability to\ncomplete the rest of the example verbatim.\n\n\n\n\nModel scale: Within a model family, larger models memorize\n2-5× more data than smaller models. 2. Data duplication:\nExamples repeated more often are more likely to be extractable.\nContext: It is orders of magnitude easier to extract\nsequences when given a longer surrounding context.\n\n\n\nPage 3\n\nA string s is extractable with k tokens of context from a model\nf if there exists a (length-k) string p, such that the\nconcatenation [ p || s] is contained in the training data for f\n, and f produces s when prompted with p using greedy decoding.\n\n\nPage 4\n\nInstead, we query on a small subset of the training data. This\nsubset should be small enough that it is feasible to test for\nextraction, but also large enough that it gives statistical\nconfidence. In this paper we choose subsets of roughly 50,000\nsequences.\n\n\nPage 5\n\nTherefore, we conclude that when larger models have a higher\nfraction of extractable training data, it is because they have\nmemorized the data; it is not simply because the larger models\nare generally more accurate.\n\n\nPage 6\n\nHowever, we find that memorization does still happen, even with\njust a few duplicates—thus, deduplication will not perfectly\nprevent leakage. While this relationship is perhaps obvious, and\nhas been corroborated for specific training examples in prior\nwork (Carlini et al., 2019, 2020), our results show that it\nholds across the entire training set.\n\n\nPage 9\n\nWe found most of these universally-memorized sequences to be\n“unconventional” texts such as code snippets or highly\nduplicated texts such as open source licenses.\n\n\n\nIncreasing model size leads to large numbers of nonoverlapping\nmemorized sequences, although every model has some amount of\nmemorization not shared by each other model. (Even the 125M\nmodel memorizes a few sequences the 6B model does not.)\n\n\nPage 11\n\nSurprisingly, we find that most of the duplicate examples\ncontained in the 138-158 repeat bucket are mostly whitespace\ntokens, making these sequences much easier to predict correctly\nthan sequences found at other repeat counts. This effect, to a\nlesser extent, can be found in other buckets which contain many\napproximately near duplicates.\n\n\n\nWe hypothesize that this is due to the fact that any\ndeduplication strategy is necessarily imperfect in order to\nefficiently scale to hundreds of gigabytes of training data.\nThus, while it may be possible to remove most instances of\nduplicate data, different and valid definitions of duplicates\ncan mean deduplication is not exhaustive.\n\n"},"highlights/Archive/Climbing-towards-NLU-On-Meaning-Form-and-Understanding-in-the-Age-of-Data":{"title":"Climbing towards NLU On Meaning Form and Understanding in the Age of Data","links":[],"tags":[],"content":"“We take (linguistic) meaning to be the relation between a linguistic form and communicative intent.” (Bender and Koller, 2020, p. 5185) (pdf)\n“If the highlighted terms are meant to describe human-analogous understanding, comprehension, or recall of factual knowledge, then these are gross overclaims. If, instead, they are intended as technical terms, they should be explicitly defined.” (Bender and Koller, 2020, p. 5186) (pdf)\n“One important consequence of imprudent use of terminology in our academic discourse is that it feeds AI hype in the popular press.” (Bender and Koller, 2020, p. 5186) (pdf)\n“they were instead simply more effective at leveraging artifacts in the data than previous approaches.” (Bender and Koller, 2020, p. 5186) (pdf)\n“We take form to be any observable realization of language: marks” (Bender and Koller, 2020, p. 5186) (pdf)\n“on a page, pixels or bytes in a digital representation of text, or movements of the articulators” (Bender and Koller, 2020, p. 5187) (pdf)\n“When humans use language, we do so for a purpose: We do not talk for the joy of moving our articulators, but in order to achieve some communicative intent.” (Bender and Koller, 2020, p. 5187) (pdf)\n“There are many types of communicative intents: they may be to convey some information to the other person; or to ask them to do something; or simply to socialize. We take meaning to be the relation M ⊆ E × I which contains pairs (e, i) of natural language expressions e and the communicative intents i they can be used to evoke. Given this definition of meaning, we can now use understand to refer to the process of retrieving i given e.” (Bender and Koller, 2020, p. 5187) (pdf)\n“The conventional meaning of an expression (word, phrase, sentence) is what is constant across all of its possible contexts of use. Conventional meaning is an abstract object that represents the communicative potential of a form, given the linguistic system it is drawn from.” (Bender and Koller, 2020, p. 5187) (pdf)\n“Each linguistic system (say, English) provides a relation C ⊆ E × S, which contains pairs (e, s) of expressions e and their conventional meanings s.” (Bender and Koller, 2020, p. 5187) (pdf)\n“The speaker has a certain communicative intent i, and chooses an expression e with a standing meaning s which is fit to express i in the current communicative situation. Upon hearing e, the listener then reconstructs s and uses their own knowledge of the communicative situation and their hypotheses about the speaker’s state of mind and intention in an attempt to deduce i.” (Bender and Koller, 2020, p. 5187) (pdf)\n“We humans are also very willing, as we will see in §4 below, to attribute communicative intent to a linguistic signal of a language we speak, even if the originator of the signal is not an entity that could have communicative intent.” (Bender and Koller, 2020, p. 5187) (pdf)\n“We argue that, independently of whether passing the Turing test would mean a system is intelligent, a system that is trained only on form would fail a sufficiently sensitive test, because it lacks the ability to connect its utterances to the world.” (Bender and Koller, 2020, p. 5188) (pdf) Interrelation with other form of text can be seen as a tiny fraction of the world.\n“but only because A does all the work in attributing meaning to O’s response. It is not because O understood the meaning of A’s instructions or even his own reply.” (Bender and Koller, 2020, p. 5189) (pdf)\n“The language exchanged by A and B is a projection of their communicative intents through the meaning relation into linguistic forms. Without access to a means of hypothesizing and testing the underlying communicative intents, reconstructing them from the forms alone is hopeless, and O’s language use will eventually diverge from the language use of an agent who can ground their language in coherent communicative intents.” (Bender and Koller, 2020, p. 5189) (pdf)\n“Because she assumes that O is B, she uses that conventional meaning together with her other guesses about B’s state of mind and goals to attribute communicative intent. It is not that O’s utterances make sense, but rather, that A can make sense of them.” (Bender and Koller, 2020, p. 5189) (pdf)\n“But that is precisely the point we are trying to make: a system that has learned the meaning (semantics) of a programming language knows how to execute code in that language. And a system that has learned the meaning of a human language can do things like answer questions posed in the language about things in the world (or in this case, in pictures).” (Bender and Koller, 2020, p. 5190) (pdf) Interrelation among forms are building a castle in the air\n“The form of Java programs, to a system that has not observed the inputs and outputs of these programs, does not include information on how to execute them. Similarly, the form of English sentences, to a system that has not had a chance to acquire the meaning relation C of English, and in the absence of any signal of communicative intent, does not include any information about what language-external entities the speaker might be referring to. Accordingly, a system trained only on the form of Java or English has no way learn their respective meaning relations.” (Bender and Koller, 2020, p. 5190) (pdf)\n“This is not supported by scholarly work on language acquisition: rather, we find that human language learning is not only grounded in the physical world around us, but also in interaction with other people in that world.” (Bender and Koller, 2020, p. 5190) (pdf)\n“In summary, the process of acquiring a linguistic system, like human communication generally, relies on joint attention and intersubjectivity: the ability to be aware of what another human is attending to and guess what they are intending to communicate. Human children do not learn meaning from form alone and we should not expect machines to do so either.” (Bender and Koller, 2020, p. 5190) (pdf)\n“One approach to providing grounding is to train distributional models on corpora augmented with perceptual data, such as photos (Hossain et al., 2019) or other modalities (Kiela and Clark, 2015; Kiela et al., 2015).” (Bender and Koller, 2020, p. 5190) (pdf)\n“Our arguments do not apply to such scenarios: reading comprehension datasets include information which goes beyond just form, in that they specify semantic relations between pieces of text, and thus a sufficiently sophisticated neural model might learn some aspects of meaning when trained on such datasets. It also is conceivable that whatever information a pretrained LM captures might help the downstream task in learning meaning, without being meaning itself.” (Bender and Koller, 2020, p. 5191) (pdf)\n“Thus, everything is going great when we take the bottom-up view. But from a top-down perspective, the question is whether the hill we are climbing so rapidly is the right hill. How do we know that incremental progress on today’s tasks will take us to our end goal, whether that is “General Linguistic Intelligence” (Yogatama et al., 2019) or a system that passes the Turing test or a system that captures the meaning of English, Arapaho, Thai, or Hausa to a linguist’s satisfaction?” (Bender and Koller, 2020, p. 5191) (pdf)\n“First, above all, cultivate humility towards language and ask top-down questions.” (Bender and Koller, 2020, p. 5192) (pdf)\n“here is no reason to assume that the distribution of language in the test data remotely resembles the distribution of real natural language; thus evaluation results on such tasks must be interpreted very carefully” (Bender and Koller, 2020, p. 5192) (pdf)\n“Analyses which start from an attitude of healthy skepticism (“too good to be true”) and probing tasks which try to identify what the model actually learned can be good ways to find out whether the system performs well for the right reasons.” (Bender and Koller, 2020, p. 5192) (pdf)\n“In addition, certain tasks are designed in a way that specific forms are declared as representing certain semantic relations of interest. Examples of this include NLI datasets (Dagan et al., 2006; Rajpurkar et al., 2016; Ostermann et al., 2019) which pair input/output tuples of linguistic forms with an explicit semantic relation (e.g. text + hypothesis + “entailed”).” (Bender and Koller, 2020, p. 5192) (pdf)\n“Thus a learner could have access to a weak form of interaction data, from which the meaning of Java could conceivably be learned. This is true, but requires a learner which has been equipped by its human developer with the ability to identify and interpret unit tests. This learner thus has access to partial grounding in addition to the form.” (Bender and Koller, 2020, p. 5193) (pdf)\n“The internal representations of a neural network have been found to capture certain aspects of meaning, such as semantic similarity (Mikolov et al., 2013; Clark, 2015). As we argued in §4, semantic similarity is only a weak reflection of actual meaning. Neural representations neither qualify as standing meanings (s), lacking interpretations, nor as communicative intents (i), being insufficient to e.g. correctly build a coconut catapult.” (Bender and Koller, 2020, p. 5193) (pdf)\n“It has probably learned something about meaning, in the same sense that syntax captures something about meaning and semantic similarity captures something about meaning: a potentially useful, but incomplete, reflection of the actual meaning.” (Bender and Koller, 2020, p. 5193) (pdf)\n“This means that even large language models such as BERT do not learn “meaning”; they learn some reflection of meaning into the linguistic form which is very useful in applications.” (Bender and Koller, 2020, p. 5193) (pdf) "},"highlights/Archive/Heffernan-et-al.---2022---Bitext-Mining-Using-Distilled-Sentence-Representat.textbundle/text":{"title":"text","links":[],"tags":[],"content":"Page 3\n\nInstead of one massively multilingual model, we train multiple\nstudents for a small subset of (similar) languages, or even a\nsingle language;\n\n\n\nUse of separate SPM vocabularies for teacher and student, better\naccommodating scripts and tokens in the student languages which\nwere unseen by the teacher (cf. subsection 5.2)\n\n\nPage 4\n\nJointly train distillation alongside a MLM criterion to benefit\nadditional learning from monolingual data in a foreign language\n\n\n\nAddition of curriculum learning in the form of progressive\ndistillation. In this strategy, instead of sending the entire\nsentence pairs all at once, we send incremental versions of the\nrespective sentence pairs to both teacher and student, which we\nfound to be helpful for some particularly challenging\nlow-resource languages.\n\n\n\nWhen we minimize the cosine distance only, max-pooling of the\ntransformer outputs to achieve the fixed-size sentence\nrepresentations worked best, compared to using a special token\nlike [CLS].\n\n\n\n\n\nThere are three different mar- gin functions: absolute\n(margin(a, b) = a), ratio (margin(a, b) = ab ), and distance\n(margin(a, b) =\n\n\nPage 5\n\na b). As our end goal in this work is to produce encoders for\nthe task of bitext mining, we adopt this approach, and evaluate\nall encoders using xsim error rate with distance margin.\n\n\nPage 6\n\nOn the other hand, low-resource languages may be badly mod- eled\nin a joint SPM vocabulary, i.e. mostly by very short SPM tokens,\ndespite the use of up-sampling strategies.\n\n\nPage 7\n\nAs we also observed a similar effect for other languages, the\nresults above suggest that jointly training distillation\nalongside masked lan- guage modelling and curriculum learning is\npartic- ularly beneficial for such low resource languages.\n\n"},"highlights/Archive/Henderson-et-al_2022_Pile-of-Law":{"title":"Henderson et al_2022_Pile of Law","links":[],"tags":[],"content":"Page 1\n\nFirst, it is practically difficult to perform reliable and\ntransparent filtering at scale. That is partially because\nundesirable content is deeply contextual.\n\nContext can extend beyond text.\n\n\nAnd privacy expectations may vary widely across countries\n\n\nPage 2\n\nWe note that recent research has shown that pretraining in legal\ncontexts may have a unique feature: training smaller models on\nhighly in-domain data may be better than large models on big\ndata [126, 29]. Our dataset is uniquely large and diverse enough\nto test this hypothesis, where our initial models can form a\nbaseline.\n\n\nPage 3\n\nNo jurisdiction normally permits the publication of financial\naccount numbers,\ndatesofbirth,oridentitynumberslikesocialsecuritynumbers.6\nAllofthesearebrightlinerules directly applicable to text\ncorpora.\n\n\nPage 4\n\nPublic availability is not a limit. In many cases, the rules for\nsanitizing PSI and sealing cases do not depend on whether\ninformation is already public.\n\n\n\nDetecting and redacting juvenile names, dates of birth, and\naccount and identity numbers is virtually always appropriate\nacross countries. Legal protections for already-public\ninformation show why sanitization may be necessary even for text\ncollected from public-facing web pages.\n\n\nPage 5\n\nOne implication of these divergent choices concerns mentions of\ntoxic language, where a speaker refers to something said by\nanother [112]. For example, if a judge writes that “Plaintiff\nclaims that her supervisor called her ‘___”’ (where ___ is a\nprofane epithet), an intent-based standard typically would not\ndeem the use of ___ ‘toxic,’ while an approach targeting\nprofanity typically would.\n\n\n\nExplicit racial, sexual, or offensive terms do appear in modern\nlegal text, but most often in the form of a quotation than\ndirect use.\n\n\n\nUnder the rules applicable to lawyers, filters based on simple\nword lists would be over-inclusive because they would capture\nreferences to offensive language that may be non-toxic in\ncontext. Second, the rules applied in courts suggest that\ngenerative models should portray toxic behavior explicitly in\nsome contexts, either to serve the values of ‘accuracy and\nprecision’ or to persuade readers [62, p. 7]; but as [43]\nargues, this view is contested.\n\n\nPage 6\n\nAccessible language models like Roberta [76] have a maximum\ncontext window of 512 tokens. If a reference to offensive\ncontent spans the majority of these tokens, the model will\nsimply uptake the offensive content as if it were being trained\nfor direct use. As model contexts grow, it may become more\nreasonable for researchers to adopt judicial norms.\n\n\n\nWe demonstrate how subsets of the data can be used to learn the\nvalue judgements made in making this pseudonymity decision. We\nsplit cases into paragraphs and mask terms used to refer to the\napplicant. We train a distill-BERT base model [103] to predict\nwhether the paragraph should use pseudonymity or not.\n\n\nPage 7\n\nThese experiments show that the Pile of Law encodes signals\nabout privacy standards that can be learned to produce more\nnuanced recommendations about filtering. For example,\nresearchers may consider whether to mimic the EOIR standard to\nremove names in proceedings related to minors, asylum or safety\nconcerns. Or they may wish to learn and apply the more\ncontextual standard that is used in general U.S. litigation,\nwhere a complex set of factors is used to justify the exclusion\nof names from case texts.\n\n\nPage 8\n\n(1) toxicity filters often disagree, creating potential issues\nfor automated filtering; (2) toxicity filters may be\nvalue-misaligned when it comes to content that is flagged in\nPile of Law; (3) toxicity scores vary highly with the length of\nthe content, making it unclear how to handle long-document\nfiltering.\n\n\nPage 9\n\nWe find that by using longer span, we can systematically\ndecrease the perceived toxicity of a span, even if it is\nobviously toxic under any definition.\n\n\n\nThe experiments above demonstrate that, while toxicity filtering\nis im- portant to align with the courts’ modern lower bounds\nbanning uses of epithets, it is not clear that existing filters\nare not consistent and filter out content aligned with different\nvalues. Moreover, they can arbitrarily label content as\nnon-toxic in long-document or out-of-distribution settings,\nwhich may affect filtering mechanisms. More work is needed to\ncreate robust, value-aligned toxicity filters for pretraining\nand it is unclear if off-the-shelf mechanisms strike the right\nbalance.\n\n\nPage 19\n\nCreativeCommons Attribution-NonCommercial-ShareAlike 4.0\nInternational license\n\n\n\nFor example, civil rights cases we reference (e.g., Brown,\nLoving) are crucial civil rights law that legal models must\nunderstand despite (or perhaps because of) their references to\nunjust legal regimes.\n\n"},"highlights/Archive/Hendrycks-et-al_2021_Measuring-Massive-Multitask-Language-Understanding":{"title":"Measuring Massive Multitask Language Understanding","links":[],"tags":[],"content":"Measuring Massive Multitask Language Understanding\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt\nDeep Learning, Transformers, NLP\nPage 1\n\nTo attain high accuracy on this test, models must possess\nextensive world knowledge and problem solving ability. We find\nthat while most recent models have near random-chance accuracy,\nthe very largest GPT-3 model improves over random chance by\nalmost 20 percentage points on average. However, on every one of\nthe 57 tasks, the best models still need substantial\nimprovements before they can reach expert-level accuracy.\n\n\nModels also have lopsided performance and frequently do not know\nwhen they are wrong. Worse, they still have near- random\naccuracy on some socially important subjects such as morality\nand law.\n\nmorality and law are culture-dependent. I assume this is English-oriented?\n\nOverall, the near human-level performance on these benchmarks\nsuggests that they are not capturing important facets of\nlanguage understanding.\n\nWhat happens when this benchmark is solved? Can we claim human-level intelligence? Benchmark lottery\nPage 2\n\nThe tasks with near-random accuracy include calculation-heavy\nsubjects such as physics and mathematics and subjects related to\nhuman values such as law and morality.\n\n\nWorryingly, we also find that GPT-3 does not have an accurate\nsense of what it does or does not know since its average\nconfidence can be up to 24% off from its actual accuracy.\n\nPage 7\n\nWhile it knows about the order of operations, it sometimes does\nnot know how to apply its knowledge.\n\nPage 8\n\nModels also have difficulty performing calculations, so much so\nthat they exhibit poor performance on Elementary Mathematics and\nmany other STEM subjects with “plug and chug” problems.\nAdditionally, they do not match expert-level performance (90%)\non any subject, so for all subjects it is subhuman. On average,\nmodels are only now starting to move beyond random-chance\naccuracy levels.\n\n\nTo test the impact of additional specialized training data, we\nalso had RoBERTa continue pretraining on approximately 1.6\nmillion legal case summaries using Harvard’s Law Library case\nlaw corpus case.law, but after fine-tuning it only attained\n36.1% accuracy. This suggests that while additional pretraining\non relevant high quality text can help, it may not be enough to\nsubstantially increase the performance of current models.\n"},"highlights/Archive/Hypothesis/3-2-1-Leave-room-for-the-unexpected":{"title":"3-2-1 Leave room for the unexpected","links":[],"tags":[],"content":"3-2-1: Leave room for the unexpected\nHighlights\nThis is good news, that almost everyone is petty, narcissistic, secretly insecure, and in it for themselves, because a few of the funny ones may actually long to be friends with you and me. They can be real with us, the greatest relief. As we develop love, appreciation, and forgiveness for others over time, we may accidentally develop those things toward ourselves, too."},"highlights/Archive/Hypothesis/5.-Text-Generation":{"title":"5. Text Generation","links":[],"tags":[],"content":"5. Text Generation\nHighlights\nThis is a common problem with greedy search algorithms, which can fail to give you the optimal solution; in the context of decoding, they can miss word sequences whose overall probability is higher just because high-probability words happen to be preceded by low-probability ones.\nAlthough greedy search decoding is rarely used for text generation tasks that require diversity, it can be useful for producing short sequences like arithmetic where a deterministic and factually correct output is preferred.\nBy tuning T we can control the shape of the probability distribution.5 When T≪1, the distribution becomes peaked around the origin and the rare tokens are suppressed. On the other hand, when T≫1, the distribution flattens out and each token becomes equally likely.\n The main lesson we can draw from temperature is that it allows us to control the quality of the samples, but there’s always a trade-off between coherence (low temperature) and diversity (high temperature) that one has to tune to the use case at hand.\nThe idea behind top-k sampling is to avoid the low-probability choices by only sampling from the k tokens with the highest probability. \nWith nucleus or top-p sampling, instead of choosing a fixed cutoff value, we set a condition of when to cut off. This condition is when a certain probability mass in the selection is reached.\nUnfortunately, there is no universally “best” decoding method. Which approach is best will depend on the nature of the task you are generating text for. If you want your model to perform a precise task like arithmetic or providing an answer to a specific question, then you should lower the temperature or use deterministic methods like greedy search in combination with beam search to guarantee getting the most likely answer. If you want the model to generate longer texts and even be a bit creative, then you should switch to sampling methods and increase the temperature or use a mix of top-k and nucleus sampling."},"highlights/Archive/Hypothesis/Becoming-an-Independent-Researcher-and-getting-published-in-ICLR-with-spotlight":{"title":"Becoming an Independent Researcher and getting published in ICLR with spotlight","links":[],"tags":[],"content":"Becoming an Independent Researcher and getting published in ICLR with spotlight\nHighlights\nTo start a PhD, without insider referral, you need to do work equivariant to half of a PhD.\nAnd as an Independent Researcher, it is reasonable to say that my chances are less than average, simply because I get less feedback.\nIn the end, we are likely all lazy, and as such, we will be blind to faults in our own work. Just discussing your paper with someone, puts much greater pressure on not taking any unintended shortcuts.\nWrite an open-source tool, implement a known paper, etc.. It is helpful to take a break from research, and if your research project fails, you have at least accomplished something. — In my case, having some of these side-projects be recognized by known researchers, was also a great source of encouragement.\nThere will be 1–2 messages in a paper, that if misunderstood, will completely confuse the reader and be the first cause of getting rejected. Do not be afraid of repeating a message to prevent that.\nReviewers are likely to side with already published results. They will only think critical about your submission not previous publications, especially if they come from DeepMind."},"highlights/Archive/Hypothesis/From-aardvark-to-woke-inside-the-Oxford-English-Dictionary":{"title":"From aardvark to woke inside the Oxford English Dictionary","links":[],"tags":[],"content":"From aardvark to woke: inside the Oxford English Dictionary\nHighlights\nWhether the question is about culture-wars issues of race and gender or a grammatical quibble, the answer is the same: the OED describes how language is already being used; it does not prescribe how it should be used, nor endorse a word’s use. McPherson observes that the dictionary’s reliance on written sources means it is often “at the rearguard” of language change rather than leading the charge. "},"highlights/Archive/Hypothesis/Inside-the-Suspicion-Machine":{"title":"Inside the Suspicion Machine","links":[],"tags":[],"content":"Inside the Suspicion Machine\nHighlights\nRotterdam’s algorithm is best thought of as a suspicion machine. It judges people on many characteristics they cannot control (like gender and ethnicity). What might appear to a caseworker to be a vulnerability, such as a person showing signs of low self-esteem, is treated by the machine as grounds for suspicion when the caseworker enters a comment into the system. The data fed into the algorithm ranges from invasive (the length of someone’s last romantic relationship) and subjective (someone’s ability to convince and influence others) to banal (how many times someone has emailed the city) and seemingly irrelevant (whether someone plays sports). Despite the scale of data used to calculate risk scores, it performs little better than random selection.\nThe spread of risk-scoring models is presented as progress, promising mathematical objectivity and fairness. Yet citizens have no real way to understand or question the decisions such systems make.\nBut the algorithm learns to make its predictions based on a pattern it extrapolates from the training data that collapses honest mistakes and deliberate fraud into one category: fraud. It tries to find commonalities between people making paperwork mistakes and people deliberately trying to cheat the system. The consequence is that it is not very good at predicting either. “The algorithm converts ‘honest mistakes’ into learned associations between poor Dutch skills and propensity for fraud, allowing welfare officials to claim that migrants who do not speak Dutch are scientifically untrustworthy,” says Dressel."},"highlights/Archive/Hypothesis/Python-behind-the-scenes-13-the-GIL-and-its-effects-on-Python-multithreading":{"title":"Python behind the scenes 13 the GIL and its effects on Python multithreading","links":[],"tags":[],"content":"Python behind the scenes #13: the GIL and its effects on Python multithreading\nHighlights\nthe GIL stands for the Global Interpreter Lock, and its job is to make the CPython interpreter thread-safe. \nThe GIL allows only one OS thread to execute Python bytecode at any given time\nIn a single-threaded Python program, the main thread is the only thread, and it never releases the GIL.\nTo acquire the GIL, a thread first checks whether some other thread holds the GIL. If this is not the case, the thread acquires the GIL immediately.\n Otherwise, it waits until the GIL is released.\nIt waits for a fixed time interval called the switch interval (5 ms by default), and if the GIL is not released during that time, it sets the eval_breaker and gil_drop_request flags. The eval_breaker flag tells the GIL-holding thread to suspend bytecode execution, and gil_drop_request explains why. The GIL-holding thread sees the flags when it starts the next iteration of the evaluation loop and releases the GIL. It notifies the GIL-awaiting threads, and one of them acquires the GIL. It’s up to the OS to decide which thread to wake up, so it may or may not be the thread that set the flags.\nAlthough Python threads cannot help us speed up CPU-intensive code, they are useful when we want to perform multiple I/O-bound tasks simultaneously.\nThe conclusion here is that it’s possible to speed up CPU-intensive Python code using multithreading if the code calls C functions that release the GIL. Note that such functions can be found not only in the standard library but also in computational-heavy third-party modules like NumPy.\nThe convoy effect takes place because each time the I/O-bound thread performs an I/O operation, it releases the GIL, and when it tries to reacquire the GIL after the operation, the GIL is likely to be already taken by the CPU-bound thread. So the I/O-bound thread must wait for at least 5 ms before it can set eval_breaker and gil_drop_request to force the CPU-bound thread release the GIL.\nSmaller switch intervals make I/O-bound threads more responsive. But too small switch intervals introduce a lot of overhead caused by a high number of context switches.\nThe GIL is so helpful because CPython increments and decrements integers that can be shared between threads all over the place. This is CPython’s way to do garbage collection.\nThe GIL also simplifies the implementation of built-in mutable data structures. Lists, dicts and sets do not use locking internally, yet because of the GIL, they can be safely used in multi-threaded programs.\nSimilarly, the GIL allows threads to safely access global and interpreter-wide data: loaded modules, preallocated objects, interned strings as so on.\nFinally, the GIL simplifies the writing of C extensions. Developers can assume that only one thread runs their C extension at any given time. Thus, they don’t need to use additional locking to make the code thread-safe. When they do want to run the code in parallel, they can release the GIL. To sum up, what the GIL does is make the following thread-safe: reference counting; mutable data structures; global and interpreter-wide data; C extensions.\nGarbage collection based on reference counting is not suited for multithreading. The only solution is to implement a tracing garbage collector that JVM, CLR, Go, and other runtimes without a GIL implement.\nRemoving the GIL breaks existing C extensions. There is no way around it."},"highlights/Archive/Hypothesis/Simplifying-BERT-based-models-to-increase-efficiency,-capacity":{"title":"Simplifying BERT-based models to increase efficiency, capacity","links":[],"tags":[],"content":"Simplifying BERT-based models to increase efficiency, capacity\nHighlights\nTo make BERT-based models more efficient, we progressively eliminate redundant individual-word embeddings in intermediate layers of the network, while trying to minimize the effect on the complete-sentence embeddings.\nThe basic idea is that, in each of the network’s encoders, we preserve the embedding of the CLS token but select a representative subset — a core set — of the other tokens’ embeddings."},"highlights/Archive/Kim-et-al_2022_OCR-free-Document-Understanding-Transformer":{"title":"Kim et al_2022_OCR-free Document Understanding Transformer","links":[],"tags":[],"content":"Page 2\n\nFirst of all, us- ing OCR as a pre-processing method is\nexpensive. We can utilize pre-trained off- the-shelf OCR\nengines; however, the computational cost for inference would be\nexpensive for high-quality OCR results. Moreover, the\noff-the-shelf OCR meth- ods rarely have flexibility dealing with\ndifferent languages or domain changes, which may lead to poor\ngeneralization ability. If we train an OCR model, it also\nrequires extensive training costs and large-scale datasets\n[4,3,39,46]. Another problem is, OCR errors would propagate to\nthe VDU system and negatively influence subsequent processes\n[54,23].\n\n\nPage 5\n\nTask. The model is trained to read all texts in the image in\nreading order (from top-left to bottom-right, basically).\n\nNot very multilingual, isn’t it?\n\n\nThis task can be interpreted as a pseudo-OCR task.\n\n\n\nA commercial CLOVA OCR API is applied to get the pseudo text\nlabels.\n\n\nPage 7\n\nTo assess overall accuracy, we also use another metric based on\nTED [68], that can be used for any documents represented as\ntrees. It is calculated as, max(0, 1TED(pr, gt)/TED(, gt)),\nwhere gt, pr, and stands for ground truth, predicted, and\nempty trees respectively. Similar metrics are used in recent\nworks on document IE [70,23]\n\n"},"highlights/Archive/Natural-Language-Processing-with-Transformers":{"title":"Natural Language Processing with Transformers","links":[],"tags":[],"content":"columns:\n- highlight\n- chapter\nsource: highlights/natural-language-processing-oreilly-annotations.csv\nsortBy:\n- expression: chapter_url\n  reverse: true"},"highlights/Archive/On-Layer-Normalization-in-the-Transformer-Architecture":{"title":"On Layer Normalization in the Transformer Architecture","links":[],"tags":[],"content":"[image] (pdf)\n(Xiong et al., 2020, p. 2)\n“Without the warm-up stage, the BLEU score of the model trained with Adam optimizer can only achieve 8.45. As a comparison, the model trained using the warm-up stage can achieve around 34 in terms of BLEU score. The same trend can also be observed on the validation loss curves. Although the performance of the model trained with SGD is significantly worse than Adam, we can still see similar phenomena as Adam. The BLEU score is just above zero in 15 epochs without using the warm-up stage.” (Xiong et al., 2020, p. 4) (pdf)\n“The main idea is that the layer normalization will normalize the gradients. In the Post-LN Transformer, the scale of the inputs to the layer normalization is independent of L, and thus the gradients of parameters in the last layer are independent of L. While in the Pre-LN Transformer, the scale of the input to the final layer normalization is linear in L, and thus the gradients of all parameters will be normalized by √L.” (Xiong et al., 2020, p. 6) (pdf)\n“Our main result is that the gradient norm in the Post-LN Transformer is large for the parameters near the output and will be likely to decay as the layer index l decreases.” (Xiong et al., 2020, p. 6) (pdf)\n“On the contrary, the gradient norm in the PreTransformer will be likely to stay the same for any layer l.” (Xiong et al., 2020, p. 6) (pdf)"},"highlights/Archive/Piantadosi_Hill_2022_Meaning-without-reference-in-large-language-models":{"title":"Piantadosi_Hill_2022_Meaning without reference in large language models","links":[],"tags":[],"content":"Page 1\n\nOn the other hand, the core objective of word prediction is a\ncen- tral piece of human language processing (e.g. Alt- mann and\nKamide, 1999; Hale, 2001; Levy, 2008) and has long been shown\ncapable of providing a learning signal from which linguistic\nstructures and semantic categories can emerge (Elman, 1990).\n\n\nPage 2\n\nOne is that there are many terms that are meaningful to us but\nhave no discernible referent at all, such as abstract words like\n“justice” and “wit.” People can think of new concepts like\n“aphid-sized accordion” that don’t exist (thus no referent), or\neven terms that have no possible referent like “perpetual motion\nmachine” or “imaginary cup of tea.” We can think of concepts\nlike “king of San Francisco” that pick out nobody, but are at\nleast meaningful enough to reason about (for example: “If there\nwas a King of San Francisco, he’d live in The Presidio.”). Other\nexamples show reference can be quite decoupled from meaning.\nTerms like “treaty” and “contract” are often thought to have a\nconcrete referent, but what is important is actually an abstract\nentity: a treaty is still valid if the piece of paper is\ndestroyed. Frege’s example is of the “morning star” and the\n“evening star.” Both are terms for the planet Venus, but were\nonce conceived of as different entities without knowing that\nthey are the same object.\n\nCan referents only be direct?\n\n\nIn this view, the meaning of the word is intrinsically\nintertwined with other concepts like “payment”, “letter” and\n“delivery.” The interrelation is key (see, e.g. Deacon, 1998;\nSantoro et al., 2021) because when the associated terms shift in\nmeaning even slightly (e.g. credit cards were developed as\nwholly new a form of “payment”) the meaning of “postage stamp”\ncomes along for the ride (we know right away that they can be\npaid for by a credit card).\n\n\n\nWhat is a natural category or concept depends on our mental con-\nception of how the underlying pieces relate, and\n\n\nPage 3\n\nconcepts can even be assembled fluidly, in an ad hoc manner or\ncontext-dependent manner\n\n\nPage 4\n\nIn much the same way, we see no reason to assume that the world\nof a system that receives input from a single sensory modality\nis meaningless, even if the addition of further sensors provides\nclear enrichment. When thinking about improving LLMs it we\nshould therefore consider ways to enrich the internal conceptual\nroles of these systems, including to better reflect the\nstructure, in- ference and algorithmic sophistication of humans\n\n\n\nIn church-encoding, a representation is constructed in one\nsystem (e.g. lambda calculus or a neural network) in order to\nmimic the behavior of another system (e.g. boolean logic) in the\nsense that the rep- resentations in the first system interact\nwith each other in a way that yields the desired conceptual\nroles of the second.\n\n\n\nThe key question for LLMs is whether training to predict text\ncould actually support discovery of conceptual roles. To us the\nquestion is empirical, and we believe has been answered in a\npromis- ing, partial affirmative by studies showing success on\ntasks that require knowledge of relationships between concepts.\n\n\n\nPage 5\n\nPeople use concepts in thinking and reasoning based on their\nmeaning, and text is a low-dimensional projection of some of\nthese patterns of use, so it is plausible that some properties\nof the real meaning could be inferred from text.\n\n"},"highlights/Archive/Pocketbook/Clean-Code-A-Handbook-of-Agile-Software-Craftsmanship/highlights/6722661A-0BA5-5CA7-8565-855B0A0DA1D0":{"title":"6722661A-0BA5-5CA7-8565-855B0A0DA1D0","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThis will never happen. Not even humans, with all their intuition and creativity, have been able to create successful systems from the vague feelings of their customers. Indeed, if the discipline of requirements specification has taught us anything, it is that well-specified requirements are as formal as code and can act as executable tests of that code!\n"},"highlights/Archive/Pocketbook/Clean-Code-A-Handbook-of-Agile-Software-Craftsmanship/highlights/7623C3B8-2E92-5847-A916-165384901707":{"title":"7623C3B8-2E92-5847-A916-165384901707","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThat soon all code will be generated instead of written. That programmers simply won’t be needed because business people will generate programs from specifications.\n"},"highlights/Archive/Pocketbook/Clean-Code-A-Handbook-of-Agile-Software-Craftsmanship/highlights/865EB0CD-7C42-535D-B01D-C777CF04BFC4":{"title":"865EB0CD-7C42-535D-B01D-C777CF04BFC4","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nNonsense! We will never be rid of code, because code represents the details of the requirements. At some level those details cannot be ignored or abstracted; they have to be specified. And specifying requirements in such detail that a machine can execute them is programming. Such a specification is code.\n"},"highlights/Archive/Pocketbook/Clean-Code-A-Handbook-of-Agile-Software-Craftsmanship/metadata":{"title":"Clean Code A Handbook of Agile Software Craftsmanship","links":[],"tags":[],"content":"dv.header(2, dv.current().title)\nconst queryResult = await dv.query(`\n  TABLE WITHOUT ID text, note\n  FROM &quot;highlights/Pocketbook/Clean Code A Handbook of Agile Software Craftsmanship/highlights&quot;\n  WHERE book_id=&quot;54073561&quot; AND type = &quot;highlight&quot; and plugin = &quot;pocketbook-cloud-highlights-importer&quot;\n  SORT sort_order\n`);\n \nconst result = queryResult.value.values.map(line =&gt; &quot;&gt; [!quote]\\n&gt; &quot; + line[0].replace(/\\n/g, &quot;\\n&gt; &quot;) + (line[1] ? &quot;\\n\\n&gt; [!note]\\n&gt; &quot; + line[1].replace(/\\n/g, &quot;\\n&gt; &quot;) : &quot;&quot;))\n \ndv.list(result)"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/0862A7CA-7FB7-57FA-AA30-B7E14D47A151":{"title":"0862A7CA-7FB7-57FA-AA30-B7E14D47A151","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nIf alarming your heart, quite literally, were not bad enough, using the snooze feature means that you will repeatedly inflict that cardiovascular assault again and again within a short span of time.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/138BC862-BE08-5D0D-9CB0-C86E0365E19F":{"title":"138BC862-BE08-5D0D-9CB0-C86E0365E19F","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThis was the theory of overnight therapy. It postulated that the process of REM-sleep dreaming accomplishes two critical goals: (1) sleeping to remember the details of those valuable, salient experiences, integrating them with existing knowledge and putting them into autobiographical perspective, yet (2) sleeping to forget, or dissolve, the visceral, painful emotional charge that had previously been wrapped around those memories.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/144C605B-0670-5003-BBE3-F9611572F774":{"title":"144C605B-0670-5003-BBE3-F9611572F774","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThis entrenched pomposity, prevalent in so many senior-driven, dogmatic institutional hierarchies, has no place in medical practice in my opinion as a scientist intimate with the research data. Those boards must disabuse themselves of the we-suffered-through-sleep-deprivation-and-you-should-too mentality when it comes to training, teaching, and practicing medicine.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/188E644F-E427-573A-B4E9-C00158079B59":{"title":"188E644F-E427-573A-B4E9-C00158079B59","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThe obvious methods involve reducing caffeine and alcohol intake, removing screen technology from the bedroom, and having a cool bedroom. In addition, patients must (1) establish a regular bedtime and wake-up time, even on weekends, (2) go to bed only when sleepy and avoid sleeping on the couch early/mid-evenings, (3) never lie awake in bed for a significant time period; rather, get out of bed and do something quiet and relaxing until the urge to sleep returns, (4) avoid daytime napping if you are having difficulty sleeping at night, (5) reduce anxiety-provoking thoughts and worries by learning to mentally decelerate before bed, and (6) remove visible clockfaces from view in the bedroom, preventing clock-watching anxiety at night.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/19A6DE4F-99C2-5392-8B66-DC6C933AB801":{"title":"19A6DE4F-99C2-5392-8B66-DC6C933AB801","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nIn younger, healthy adults, exercise frequently increases total sleep time, especially deep NREM sleep. It also deepens the quality of sleep, resulting in more powerful electrical brainwave activity. Similar, if not larger, improvements in sleep time and efficiency are to be found in midlife and older adults, including those who are self-reported poor sleepers or those with clinically diagnosed insomnia.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/29377302-27EB-544E-AD2B-E2D26AAA2930":{"title":"29377302-27EB-544E-AD2B-E2D26AAA2930","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThe answer comes down to the fact that your increased sociability is caused by sedation of one part of your brain, the prefrontal cortex, early in the timeline of alcohol’s creeping effects. As we have discussed, this frontal lobe region of the human brain helps control our impulses and restrains our behavior. Alcohol immobilizes that part of our brain first.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/29B5A804-569A-5377-921B-17114016FB29":{"title":"29B5A804-569A-5377-921B-17114016FB29","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nGive alcohol a little more time, and it begins to sedate other parts of the brain, dragging them down into a stupefied state, just like the prefrontal cortex. You begin to feel sluggish as the inebriated torpor sets in. This is your brain slipping into sedation.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/3D4F10EC-F1C7-5529-A3AB-8A1258412436":{"title":"3D4F10EC-F1C7-5529-A3AB-8A1258412436","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nIt is sleep that builds connections between distantly related informational elements that are not obvious in the light of the waking day.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/5B23E4E8-AE9E-5DB3-BF23-72A690D8515B":{"title":"5B23E4E8-AE9E-5DB3-BF23-72A690D8515B","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/5B26E865-F0FC-5F01-9F8C-C69D0483BD74":{"title":"5B26E865-F0FC-5F01-9F8C-C69D0483BD74","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/6AD9F53E-6659-58AB-A5E4-94EF0BEAC893":{"title":"6AD9F53E-6659-58AB-A5E4-94EF0BEAC893","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nMoreover, victims of claimed alien abductions frequently report the sense of, or real presence of, a being in the room (the alien). Finally—and this is the key giveaway—the alleged victim frequently describes having been injected with a “paralyzing agent.” Consequently, the victim will describe wanting to fight back, run away, or call out for help but being unable to do so. The offending force is, of course, not aliens, but the persistence of REM-sleep paralysis upon awakening.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/6CF9457A-870D-5191-A956-A0F961175A6C":{"title":"6CF9457A-870D-5191-A956-A0F961175A6C","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nMore surprising, perhaps, was the realization that the brain is not done processing that knowledge after the first night of sleep. Memories remain perilously vulnerable to any disruption of sleep (including that from alcohol) even up to three nights after learning, despite two full nights of natural sleep prior.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/6FD61AE2-8B6E-5F79-967A-88469D5AD6CA":{"title":"6FD61AE2-8B6E-5F79-967A-88469D5AD6CA","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nIn this different and additional role, we can think of REM sleep like a master piano tuner, one that readjusts the brain’s emotional instrumentation at night to pitch-perfect precision, so that when you wake up the next morning, you can discern overt and subtly covert micro-expressions with exactitude. Deprive an individual of their REM-sleep dreaming state, and the emotional tuning curve of the brain loses its razor-sharp precision.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/7C979FE4-24E1-5C1A-95E7-1CC8F6F26007":{"title":"7C979FE4-24E1-5C1A-95E7-1CC8F6F26007","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nArtificial evening and nighttime light can therefore masquerade as sleep-onset insomnia—the inability to begin sleeping soon after getting into bed.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/8293F85B-9C78-5A47-86D0-9BB659ABBE2E":{"title":"8293F85B-9C78-5A47-86D0-9BB659ABBE2E","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nOnce core temperature dips below a threshold in the evening, the thermosensitive cells quickly deliver a neighborly message to the suprachiasmatic nucleus. The memo adds to that of naturally fading light, informing the suprachiasmatic nucleus to initiate the evening surge in melatonin, and with it, the timed ordering of sleep.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/8EE8FABC-04B6-5B8D-A724-6897F0985C39":{"title":"8EE8FABC-04B6-5B8D-A724-6897F0985C39","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThe need to dump heat from our extremities is also the reason that you may occasionally stick your hands and feet out from underneath the bedcovers at night due to your core becoming too hot, usually without your knowing.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/9115C7DD-800A-5246-AC74-5C74FB246308":{"title":"9115C7DD-800A-5246-AC74-5C74FB246308","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nUnfortunately, Big Pharma can be notoriously unbending within the arena of revised medical indications. This is especially true once a drug has been approved following basic safety assessments, and even more so when profit margins become exorbitant. Consider that the original Star Wars movies—some of the highest-grossing films of all time—required more than forty years to amass 3billioninrevenue.IttookAmbienjusttwenty−fourmonthstoamass4 billion in sales profit, discounting the black market.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/9AF42F75-AE2F-5E4B-9600-66E568D5E74D":{"title":"9AF42F75-AE2F-5E4B-9600-66E568D5E74D","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nA meaningful, psychologically healthy life is an examined one, as Socrates so often declared.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/9E8407AB-690F-56C5-A688-A9B00394F47D":{"title":"9E8407AB-690F-56C5-A688-A9B00394F47D","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThat is, REM-sleep dreaming takes the painful sting out of difficult, even traumatic, emotional episodes you have experienced during the day, offering emotional resolution when you awake the next morning.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/A473C57C-B775-5836-8F4C-6488C01FF92B":{"title":"A473C57C-B775-5836-8F4C-6488C01FF92B","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nParticipants who slept and reported dreaming of elements of the maze, and themes around experiences clearly related to it, showed almost ten times more improvement in their task performance upon awakening than those who slept just as much, and also dreamed, but did not dream of maze-related experiences.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/AA3D9155-6EC8-5374-97FA-5CEC50A9CBA8":{"title":"AA3D9155-6EC8-5374-97FA-5CEC50A9CBA8","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nSleep, like food, water, and oxygen, may share this relationship with mortality risk when taken to extremes. After all, wakefulness in the correct amount is evolutionarily adaptive, as is sleep.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/AEF9793C-1616-540D-9951-2554F6AF55EE":{"title":"AEF9793C-1616-540D-9951-2554F6AF55EE","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nWhen reading on the iPad, their melatonin peak, and thus instruction to sleep, did not occur until the early-morning hours, rather than before midnight. Unsurprisingly, individuals took longer to fall asleep after iPad reading relative to print-copy reading.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/BC7641FE-4852-5642-8BD6-AD580DC2AB21":{"title":"BC7641FE-4852-5642-8BD6-AD580DC2AB21","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nFirst, individuals lost significant amounts of REM sleep following iPad reading. Second, the research subjects felt less rested and sleepier throughout the day following iPad use at night. Third was a lingering aftereffect, with participants suffering a ninety-minute lag in their evening rising melatonin levels for several days after iPad use ceased—almost like a digital hangover effect.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/BF792D4D-79EC-5B85-9694-BABC62290ADF":{"title":"BF792D4D-79EC-5B85-9694-BABC62290ADF","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nnarcoleptic patient is banished to a monotonic existence of emotional neutrality. They must forfeit any semblance of succulent emotions that we are all nourished by on a moment-to-moment basis. It is the dietary equivalent of eating the same tepid bowl of unflavorful porridge day after day. You can well imagine the loss of appetite for such a life.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/C902DA91-147B-5AF8-B8E9-23E1C1B188A2":{"title":"C902DA91-147B-5AF8-B8E9-23E1C1B188A2","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nThe lingering vapors of REM sleep were providing a more fluid, divergent, “open-minded” state of information processing.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/CA89B180-84AE-59BE-8C81-E79D37863A62":{"title":"CA89B180-84AE-59BE-8C81-E79D37863A62","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nBut insufficient sleep—another harmful, potentially deadly factor—is commonly tolerated and even woefully encouraged. This mentality has persisted, in part, because certain business leaders mistakenly believe that time on-task equates with task completion and productivity. Even in the industrial era of rote factory work, this was untrue. It is a misguided fallacy, and an expensive one, too.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/EABCCA24-0063-53B9-A902-11FDD7B3BB8F":{"title":"EABCCA24-0063-53B9-A902-11FDD7B3BB8F","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nBoth functional benefits require not just that you have REM sleep, but that you dream, and dream about specific things. REM sleep is necessary, but REM sleep alone is not sufficient. Dreams are not the heat of the lightbulb—they are no by-product.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/F04F1A3D-28DF-5197-B7FE-FA554AB24C54":{"title":"F04F1A3D-28DF-5197-B7FE-FA554AB24C54","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nWhen you get out of the bath, those dilated blood vessels on the surface quickly help radiate out inner heat, and your core body temperature plummets. Consequently, you fall asleep more quickly because your core is colder. Hot baths prior to bed can also induce 10 to 15 percent more deep NREM sleep in healthy adults.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/highlights/F1C3A582-77C1-5325-8865-84BC619F4996":{"title":"F1C3A582-77C1-5325-8865-84BC619F4996","links":[],"tags":[],"content":"\n\n                  \n                  Quote\n                  \n                \nHer patients required REM sleep with dreaming, but dreaming of a very specific kind: that which expressly involved dreaming about the emotional themes and sentiments of the waking trauma.\n"},"highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/metadata":{"title":"Why We Sleep Unlocking the Power of Sleep and Dreams","links":[],"tags":[],"content":"dv.header(2, dv.current().title)\nconst queryResult = await dv.query(`\n  TABLE WITHOUT ID text, note\n  FROM &quot;highlights/Pocketbook/Why We Sleep Unlocking the Power of Sleep and Dreams/highlights&quot;\n  WHERE book_id=&quot;55956464&quot; AND type = &quot;highlight&quot; and plugin = &quot;pocketbook-cloud-highlights-importer&quot;\n  SORT sort_order\n`);\n \nconst result = queryResult.value.values.map(line =&gt; &quot;&gt; [!quote]\\n&gt; &quot; + line[0].replace(/\\n/g, &quot;\\n&gt; &quot;) + (line[1] ? &quot;\\n\\n&gt; [!note]\\n&gt; &quot; + line[1].replace(/\\n/g, &quot;\\n&gt; &quot;) : &quot;&quot;))\n \ndv.list(result)"},"highlights/Archive/Ruder-et-al_2022_Square-One-Bias-in-NLP":{"title":"Ruder et al_2022_Square One Bias in NLP","links":[],"tags":[],"content":"Page 1\n\nLikewise, if the first 10 NLP experiments we see or conduct are\nin sentiment analysis, this will likely also bias how we think\nof NLP experiments in the future.\n\n\n\nthe existence of such an exper- imental prototype steers and\nbiases the research dynamics in our community.\n\nbenchmark lottery\n\nPage 2\n\nWe argue that the SQUARE ONE BIAS has sev- eral negative\neffects, most of which amount to the study of one of the above\ndimensions being biased by ignoring the others.\n\n\n\nmultilinguality, fairness and bias, ef-\n\n\n\nficiency, and interpretability.\n\n\n\nOverall, almost 70% of papers evaluate only on English, clearly\nhighlighting a lack of language diversity in NLP (Bender, 2011;\nJoshi et al., 2020). Almost 40% of papers only evaluate using\naccuracy and/or F1, foregoing metrics that may shed light on\nother aspects of model behavior. 56.6% of pa- pers do not study\nany of the four major dimensions that we investigated. We refer\nto this standard ex- perimental setup—evaluating only on English\nand optimizing for accuracy or another performance metric\nwithout considering other dimensions—as the SQUARE ONE.\n\n\n\nRegarding work that moves from the SQUARE ONE, most papers make\na contribution in terms of efficiency, followed by\nmultilinguality. However, most papers that evaluate on multiple\nlanguages are part of the corresponding MT and Multilinguality\ntrack. Despite being an area receiving increasing at- tention\n(Blodgett et al., 2020), only 6.3% of papers evaluate the bias\nor fairness of a method. Overall, only 6.1% of papers make a\ncontribution along two or more of these dimensions.\n\n\nPage 4\n\nArchitectural Biases. One pervasive bias in our models regards\nmorphology. Many of our mod- els were not designed with\nmorphology in mind, arguably because of the poor/limited\nmorphology of English.\n\n\n\nHowever, word embeddings are not useful for tasks that require\naccess to mor- phemes, e.g., semantic tasks in morphologically\nrich languages (Avraham and Goldberg, 2017).\n\n\n\nit remains unclear whether they capture the information needed\nfor processing morphologi- cally rich languages (Tsarfaty et\nal., 2020).\n\n\n\nSubword tokenization performs poorly on languages with\nreduplication (Vania and Lopez, 2017), while byte pair encoding\ndoes not align well with morphol- ogy (Bostrom and Durrett,\n2020). Consequently, languages with productive morphological\nsystems also are disadvantaged when shared ‘language- universal’\ntokenizers are used in current large-scale multilingual language\nmodels (Ács, 2019; Rust et al., 2021) without any further\nvocabulary adapta- tion (Wang et al., 2020; Pfeiffer et al.,\n2021).\n\n\n\nWhile the recent generation of self-attention based\narchitectures can be seen as inherently order-agnostic, recent\nmethods focus- ing on making attention more efficient (Tay et\nal., 2020) introduce new biases into the models. Specif- ically,\nmodels that reduce the global attention to a local sliding\nwindow around the token (Liu et al., 2018; Child et al., 2019;\nZaheer et al., 2020) may incur similar limitations as their\nn-gram and word embedding-based predecessors, performing worse\non languages with relatively free word order.6\n\n\n\nStudies proposing more interpretable methods typically build on\nstate-of-the-art meth- ods (Weiss et al., 2018) and much work\nfocuses on leveraging components such as attention for in-\nterpretability, which have not been designed with that goal in\nmind (Serrano and Smith, 2019; Wiegr- effe and Pinter, 2019).\n\n\nPage 5\n\nSimilarly, the standard pretrain- fine-tune paradigm (Ruder et\nal., 2019) requires separate model copies to be stored for each\ntask, and thus restricts work on multi-domain, multi- task,\nmulti-lingual, multi-subpopulation methods that is enabled by\nmore efficient and less resource- intensive (Schwartz et al.,\n2020) fine-tuning meth- ods (Houlsby et al., 2019; Pfeiffer et\nal., 2020)\n\n\n\nIn sum, (what we typically consider as) standard baselines and\nstate-of-the-art architectures favor languages with some\ncharacteristics over others and are optimized only for\nperformance, which in turn propagates the SQUARE ONE BIAS: If\nresearchers study aspects such as multilinguality, efficiency,\nfairness or interpretability, they are likely to do so with and\nfor commonly used architectures (i.e., often termed ‘standard\narchitectures’), in order to reduce (too) many degrees of\nfreedom in their em- pirical research.\n\n\n\nn interpretability, we can use feature attribution methods and\nword- level annotations to evaluate interpretability meth- ods\napplied to sequence classifiers (Rei and Sø- gaard, 2018), but\nwe cannot directly use feature at- tribution methods to obtain\nrationales for sequence labelers.\n\n\n\nPut sim- ply, the choice of the data creation protocol, e.g.,\ntranslation-based versus data collection directly in the target\nlanguage (Clark et al., 2020) can yield profound differences in\nmodel performance for some groups, or may have serious impact on\nthe interpretability or computational efficiency (e.g., sample\nefficiency) of our models.\n\n\nPage 6\n\nNote how such a bias may interact in non-linear ways with\nefficiency, i.e., efficient meth- ods for shorter documents need\nnot be efficient for longer ones, or fairness, i.e., what\nmitigates gender biases in news articles need not mitigate\ngender biases in product reviews.\n\n\n\nIf our go-to architectures, resources, and experimental setups\nare tailored to some languages over others, some objectives over\nothers, and some research paradigms over others, it is\nconsiderably more work to explore new sets of languages, new\nobjectives, or new protocols.\n\n\n\nCharacter-based language models are often reported to perform\nwell for mor- phologically rich languages or on non-canonical\ntext (Ma et al., 2020), but little is known about their fairness\nproperties, and attribution-based in- terpretability methods\nhave not been developed for such models.\n\n\nPage 7\n\nWhile recent work has begun to study the trade-off between\nefficiency and fairness, this interaction remains largely\nunexplored, especially outside of the empirical risk\nminimization regime; (ii) fair- ness and interpretability\ninteract in potentially many ways, i.e., interpretability\ntechniques may af- fect the fairness of the underlying models\n(Agarwal, 2021), but rationales may also, for example, be bi-\nased toward certain demographics in how they are presented (Feng\nand Boyd-Graber, 2018; González et al., 2021); (iii) finally,\nmultilinguality and in- terpretability seem heavily\nunderexplored. While there exists resources for English for\nevaluating in- terpretability methods against gold-standard\nhuman annotations, there are, to the best of our knowledge, no\nsuch resources for other languages.11\n\n\nPage 8\n\nAlways returning to the SQUARE ONE is a way to control for all\nother factors and relating new findings to known territory. The\nreason why this is only seemingly a good idea, however, is that\nthe factors we study in NLP research, may be non- linearly\nrelated. The fact that t makes for a positive net contribution\nunder one set of circumstances, does not imply that it would do\nso under different circumstances. This is illustrated most\nclearly by the research surveyed in §3. Ideally, we thus want to\nstudy the impact of t under as many circum- stances as possible,\nbut in the absence of resources to do so, it is a better\n(collective) search strategy to apply t to a random set of\ncircumstances (within the space of relevant circumstances, of\ncourse).\n\n\nPage 9\n\ni) Currently, most NLP models are eval- uated by one or two\nperformance metrics, but we believe dimensions such as fairness,\nefficiency, and interpretability need to become integral\ncriteria for model evaluation, in line with recent proposals of\nmore user-centric leaderboards (Ethayarajh and Ju- rafsky, 2020;\nMa et al., 2021). This requires new tools, e.g., to evaluate\nenvironmental impact (Hen- derson et al., 2020), as well as new\nbenchmarks, e.g., to evaluate fairness (Koh et al., 2021) or ef-\nficiency (Liu et al., 2021b).\n\n\n\nii) We believe sepa- rate conference tracks (areas) lead to\nunfortunate silo effects and inhibit multi-dimensional research.\nRather, we imagine conference submissions could provide a\nchecklist with dimensions along which they make contributions,\nsimilar to reproducibil- ity checklist. Reviewers can be\nassigned based on their expertise corresponding to different\ndimen- sions.\n\n\n\niii) Finally, we recommend awareness of research prototypes and\nencourage reviewers and chairs to prioritize research that\ndeparts from pro- totypes in multiple dimensions, in order to\nexplore new areas of the research manifold.\n\n"},"highlights/Archive/Rust-et-al.---2022---Language-Modelling-with-Pixels":{"title":"Rust et al. - 2022 - Language Modelling with Pixels","links":[],"tags":[],"content":"Page 1\n\nWe pretrain the 86M parameter PIXEL model on the same English data as BERT and evaluate on syntactic and semantic tasks in typologically diverse languages, including various non-Latin scripts.\n\nWhy BERT\n\nPage 3\n\nWe set height H = 16 and width W = 8464 and choose C = 3 RGB input channels, which is equivalent to a square colour image with a 368 ⇥ 368 resolu- tion and corresponds to a sequence of 529 image patches of size 16 ⇥ 16 pixels.6\n\n\n\nPIXEL uses span masking with a 25% masking ratio as outlined in Algorithm 1, which masks spans of up to S = 6 consecutive image patches with a dynamic num- ber of unmasked patches left between them.\n\n\nPage 4\n\nFollowing ViT-MAE (He et al., 2022), the PIXEL encoder only processes unmasked patches (i.e., ⇡ 396 “visible” patches at 25% masking) rather than on a sequence including mask tokens, which not only reduces memory requirements and increases training speed, but also has the advantage of not creating a mismatch between pretraining and finetuning.\n\n\nPage 5\n\nFor longer spans with a larger possible prediction space, multiple predictions may appear together creating blurred text.\n\n\nPage 9\n\nWe see that PIXEL achieves non-trivial performance scores on GLUE, indicating that pixel-based encoders can learn higher- level semantic tasks, but performs worse overall than BERT, so it may require (a) more pretraining steps than subword-tokenized PLMs or (b) an additional inductive bias to acquire the same level of monolingual abstraction.\n\n\nPage 29\n\nInligatures,ascommonforinstanceinArabic,aglyph is composed of multiple characters. Likewise, an emoji often consists of a base codepoint and a modifier codepoint (e.g. to change the emoji skin colour) which are represented by a single glyph. Foraccents,ontheotherhand,onecharactermightyieldmultipleglyphs.30\n\n"},"highlights/Archive/Schuff-et-al_2022_Human-Interpretation-of-Saliency-based-Explanation-Over-Text":{"title":"Human Interpretation of Saliency-based Explanation Over Text","links":[],"tags":[],"content":"Human Interpretation of Saliency-based Explanation Over Text\n- Human-centered Computing → Empirical Studies in visualization.- Computing Methodologies → Natural Language processing.Machine Learning.\nPage 1\n\nMany current explanation methods, such as gradient-based or\nShapley value-based methods, provide measures of importance\nwhich are well-understood mathematically. But how does a person\nreceiving the explanation (the explainee) comprehend it? And\ndoes their understanding match what the explanation attempted to\ncommunicate?\n\n\nWe find that people often mis-interpret the explanations:\nsuperficial and unrelated factors, such as word length,\ninfluence the explainees’ importance assignment despite the\nexplanation communicating importance directly. We then show that\nsome of this distortion can be attenuated: we propose a method\nto adjust saliencies based on model estimates of over- and\nunder-perception, and explore bar charts as an alternative to\nheatmap saliency visualization. We find that both approaches can\nattenuate the distorting effect of specific factors, leading to\nbetter-calibrated understanding of the explanation.\n\nPage 2\n\nIn the explainable NLP literature, it is generally (implicitly)\nassumed that the explainee interprets the information\n“correctly”, as it is communicated [4, 17, 20]: e.g., when one\nword is explained to be in￿uential in the model’s decision\nprocess, or more in￿uential than another word, it is assumed\nthat the explainee understands this relationship [28].\n\n\nThis means, for example, that the explainee may underestimate\nthe in￿uence of a punctuation token, even if the explanation\nreports that this token is highly signi￿cant (Figure 1), because\nthe explainee is attempting to understand how the model reasons\nby analogy to the explainee’s own mind which is an instance of\nanthropomorphic bias [8, 29, 61] and belief bias [16, 22].\n\n\n(i) anthropomorphic bias and belief bias: in￿uence by the\nexplainee’s self projection onto the model; (ii) visual\nperception bias: in￿uence by the explainee’s visual a￿ordances\nfor comprehending information; (iii) learning e￿ects: observable\ntemporal changes in the explainee’s interpretation as a result\nof interacting with the explanation over multiple instances.\n\n\nupposedly irrelevant factors such as word length do a￿ect how\nexplainees perceive the in￿uence of words in feature-attribution\nexplanations, despite the explanations explicitly communicating\nthis in￿uence.\n\nPage 3\n\nThis perspective is relaxed in various ways to produce various\nsofter measures of importance: for example, gradient-based\nmethods measure the change required in the embedding space to\ncause change in model output, while Shapley-value methods\nmeasure the change with respect to the “average case” in the\ndata.\n\nPage 4\n\nIn the context of NLP models, Jacovi and Goldberg [28] note two\npossible central objectives: reducing the input to a summary\nwhich comprehensively informs the decision, or identifying\nin￿uential evidence in the input which non-comprehensively\nsupports the decision.\n\nPage 6\n\nIts key properties are that it (i) models the ordinal response\nvariable (i.e., the importance ratings in our setting) on a\ncontinuous latent scale (ordinal generalized), which is (ii)\nmodeled as a sum of smooth functions of covariates (additive)\nand (iii) accounts for random e￿ects (mixed).\n"},"highlights/Archive/Schuster-et-al_2022_Confident-Adaptive-Language-Modeling":{"title":"Schuster et al_2022_Confident Adaptive Language Modeling","links":[],"tags":[],"content":"Page 1\n\nIn this work, we introduce Confident Adaptive Language Model-\ning (CALM), a framework for dynamically allocating different\namounts of compute per input and generation timestep. Early exit\ndecoding involves several challenges that we address here, such\nas: (1) what confidence measure to use; (2) connecting\nsequence-level constraints to local per-token exit decisions;\nand (3) attending back to missing hidden representations due to\nearly exits in previous tokens.\n\n\nPage 5\n\nself-attention at layer i for token t can safely use\nhidden-states djs for j &lt; i 1 as key-values of tokens s &lt; t,\nas long as the projections WKi /V of layer i are used. Notably,\nthis projection can now be computed concurrently for all skipped\nlayers as they all use the same d from the exited layer.\n\n\n\nAs shown in Figure 2a, earlier perturbations result in lower\nsequence-level scores as there are more tokens that might suffer\nfrom the divergence. The degradation, though, is much smaller\nwith layer- compared to sampling-based perturbations since, in\npractice, the early exit predictions are mostly accurate.\n\n\n\nFollowing the above observation, we introduce a decaying\nearly-exiting threshold that is more permissive towards exiting\nas the decoding process continues.\n\n\nPage 7\n\nFWER-controlling procedure at a level ✏ is an algorithm that\ndecides to accept or reject hypotheses {Hi}ki=1, while ensuring\nthat the probability of falsely rejecting any Hj is less than ✏\n\n"},"highlights/Archive/Sorscher-et-al.---2022---Beyond-neural-scaling-laws-beating-power-law-scal":{"title":"Sorscher et al. - 2022 - Beyond neural scaling laws beating power law scal","links":[],"tags":[],"content":"Page 1\n\nHere we focus on the scaling of error with dataset size and show\nhow both in theory and practice we can break beyond power law\nscaling and reduce it to exponential scaling instead if we have\naccess to a high-quality data pruning metric that ranks the\norder in which training examples should be discarded to achieve\nany pruned dataset size.\n\n\n\nOverall, our work suggests that the discovery of good\ndata-pruning metrics may provide a viable path forward to\nsubstantially improved neural scaling laws, thereby reducing the\nresource costs of modern deep learning.\n\n\nPage 2\n\nThe key idea is that power law scaling of error with respect to\ndata suggests that many training examples are highly redundant.\n\n\nPage 4\n\nWhile all of these results constitute significant improvements\nin performance, they do come at a substantial resource cost\nwhose fundamental origin arises from power law scaling with\nsmall exponents.\n\n\n\nIt turns out keeping the easiest rather than hardest examples is\na better pruning strategy when ↵tot is small (Fig. 1C).\nIntuitively, if one does not have much data to start with, it is\nbetter to keep the easiest examples with largest margins (i.e.\nthe blue regions of Fig. 1B) to avoid overfitting.\n\n\n\nOtherwise, if one starts with lots of data, so overfitting is\nless of an issue, it is best to keep the hardest examples with\nsmallest margin that provide more information about the\nteacher’s decision boundary\n\n\nPage 5\n\nHowever, by pruning more aggressively (smaller f ) when given\nmore initial data (larger ↵tot), one can achieve a Pareto\noptimal test error as a function of pruned dataset size ↵prune\nthat remarkably traces out at least an exponential scaling law\n(Fig. 1C, red curve).\n\n\n\nHowever, data pruning can increase the information gained per\nexample by pruning away the uninformative examples.\n\n\nPage 6\n\nThis result highlights the importance of finding high quality\npruning metrics with ✓ ⇡ 0. Such metrics can delay the cross\nover from exponential to power law scaling as pruned dataset\nsize ↵prune increases, by making aggressive pruning with very\nsmall f highly effective.\n\n\nPage 8\n\nTo compute a self-supervised pruning metric for ImageNet, we\nperform k-means clustering in the embedding space of an ImageNet\npre-trained self-supervised model (here: SWaV [31]), and define\nthe difficulty of each data point by the distance to its nearest\ncluster centroid, or prototype.\n\n\n\nIf class information is available, we can enforce alignment\nbetween clusters and classes by simply computing a single\nprototype for each\n\n\nPage 9\n\nclass (by averaging the embeddings of all examples of this\nclass). While originally intended to be an additional baseline\nmetric (called supervised prototypes, light blue in Fig 5BC),\nthis metric remarkably outperforms all other supervised metrics\nand largely matches the performance of memorization, which is\nprohibitively expensive to compute.\n\n\n\nWe found, reassuringly, our results were robust to this choice:\nk can deviate one order of magnitude more or less than the true\nnumber of classes (i.e. 1000 for ImageNet) without affecting\nperformance (App. E).\n\n"},"highlights/Archive/Srivastava-et-al_2022_Beyond-the-Imitation-Game":{"title":"Beyond the Imitation Game Benchmark","links":[],"tags":[],"content":"Beyond the Imitation Game Benchmark\nPage 2\n\nmodel performance and calibration both improve with scale, but\nare poor in absolute terms (and when compared with rater\nperformance);\n\n\nperformance is remarkably similar across model classes, though\nwith benefits from sparsity;\n\n\ntasks that improve gradually and predictably commonly involve a\nlarge knowledge or memorization component, whereas tasks that\nexhibit “breakthrough” behavior at a critical scale often\ninvolve multiple steps or components, or brittle metrics;\n\n\nsocial bias typically increases with scale in settings with\nambiguous context, but this can be improved with prompting.\n\nPage 4\n\nWithout proper care, they may also embed undesirable social bias\ndeep into technology stacks and decision-making processes—but\nwith proper care, they may enable decision-making to be\nautomated with less human bias.\n\nPage 5\n\nBecause they are narrowly targeted, and because their targets\nare often ones that language models are already known to\nperform, they are ill-suited to identify new and unexpected\ncapabilities that language models may develop with increased\nscale, or to characterize the breadth of current capabilities.\n\nPage 7\n\nBenchmark tasks are primarily intended to evaluate pre-trained\nmodels, without task-specific fine- tuning. By focusing on such\ntasks in the zero- and few-shot evaluation setting, it becomes\npossible to provide meaningful scores for even those tasks with\na very small number of examples.\n\nPage 11\n\nFor many critical use cases, it is important not just that\nmodels are accurate, but also that they do not assign high\nconfidence to wrong answers.\n\n\nSince a model’s multiple-choice selection is based on the\nconditional log likelihood scores of the target choices,\nnormalized (top-1) probability can be treated as model\nconfidence for tasks where there is one correct choice. Using\nthis confidence score, we compute Brier score (Brier, 1950) and\nexpected calibration error (ECE, Naeini et al., 2015) for each\nmodel size. While Brier score is a proper scoring rule for\nmeasuring the accuracy of predicted probabilities, ECE has been\nwidely used to measure calibration due to its intuitive nature.\n\n\nLanguage models make poorly calibrated predictions, but\ncalibration improves as the models are made larger.\n\nPage 13\n\nThe list of tasks with highest linearity contains tasks that are\nknowledge-based, that is, tasks that rely mostly on memorization\nof information that exists in training data, such as answering\ntrivia-style questions in qa_wikidata, or performing simple text\nmappings as in linguistic_mappings and mult_data_wrangling.\n\n\nTasks that see strong breakthrough behavior include those that\nare composite in nature, meaning that they require a model to\napply several distinct skills or perform multiple discrete steps\nin order to come up with the correct answer.\n\nPage 14\n\nLog probability of targets often improves smoothly across\nscales.\n\n\nBreakthrough behavior is consistent with the model suddenly\ngaining new skills in an abrupt way. Careful analysis of task\nbehavior, however, suggests that the underlying change in model\ncapabilities is generally more smooth.\n\n\nUsing smoother metrics. The exact_str_match metric can lead to\napparent sudden breakthroughs because of its inherent\nall-or-nothing discontinuity. It only gives credit for a model\noutput that exactly matches the target string. Examining other\nmetrics, such as BLEU, BLEURT, or ROUGE, can reveal more gradual\nprogress.\n\nPage 15\n\nUsually, no single metric can quantify task-solving ability, and\nit is always important to check model outputs to make sure that\na metric is measuring what it is supposed to. This is especially\nimportant in the few-shot setting where the evaluation metrics\nare not explicitly targeted during training.\n\nPage 16\n\nThe default formatting allows the model to compare the choices\nbefore scoring each one, which we naively think should improve\nperformance. Instead, we find that including the choices hurts\nperformance, even in a few-shot context.\n\nPage 17\n\nArguably, the first version of this task is closest to the\noriginal training objective: the model is simply asked to\npredict which natural language sentence is more likely, from\nwhich we infer the cause. We speculate that models perform\npoorly on the other versions because those tasks are dissimilar\nfrom their training distribution. Recent results on large\nlanguage models suggest that this brittleness to question\nphrasing may improve with further increases in scale\n\n\nThis sensitivity to multiple choice presentation and\ncause_and_effect formulation demonstrate that the ability of a\nmodel to solve one version of a task does not necessarily carry\nover to other versions, even when humans would think of the\nversions as similar.\n\n\n• Bias often increases with scale in settings with broad or\nambiguous context. • Bias can decrease with scale in settings\nwith narrow, unambiguous context. • Bias can potentially be\nsteered through appropriately chosen prompting.\n\nPage 25\n\nOur results suggest that breakthrough performance can also occur\non tasks that involve multistep reasoning. One possible\nexplanation for the breakthrough phenomenon on multistep tasks\nis that the probability of success on the task scales like the\nproduct of the success probabilities on each step. If the\nprobabilities of each of k steps increase linearly, their\nproduct will increase like a kth-order polynomial, which will be\nnearly flat until a sudden increase.\n\n\nA related striking observation is that the capabilities of\nmodels are often highly sensitive to details in the way a task\nis framed.\n\n\nInterestingly, PaLM does not show the same brittleness on\ncause_and_effect, suggesting that models may become less brittle\nas their size is further increased and datasets are improved.\n\n\nA worrying finding is that model performance on social bias\nmetrics often grows worse with increasing scale (Figure 12). One\npotential explanation for this may be that larger models do a\nbetter job of matching biases in their training set. This result\nemphasizes the importance of research, engineering, and policy\nefforts directed at fairness in machine-learning systems,\nespecially at scale.\n"},"highlights/Archive/Wortsman-et-al.---2022---Model-soups-averaging-weights-of-multiple-fine-tu":{"title":"Wortsman et al. - 2022 - Model soups averaging weights of multiple fine-tu","links":[],"tags":[],"content":"Anonymous Submission\nProceedings of the International Conference on Machine Learning 2022\nPage 1\n\nWe show that averaging the weights of multiple models fine-\ntuned with different hyperparameter configura- tions often\nimproves accuracy and robustness.\n\n\nPage 2\n\nSelecting a single model and discarding the rest has several\ndownsides. For one, ensembling outputs of many models can\noutperform the best single model, albeit at a high com-\nputational cost during inference. For another, fine-tuning a\nmodel on downstream tasks can sometimes reduce out-of-\ndistribution performance (Radford et al., 2021; Andreassen et\nal., 2021; Wortsman et al., 2021; Pham et al., 2021), and the\nbest single model on the target distribution may not be the best\nmodel on out-of-distribution data.\n\n\n\nHowever, re- cent work (Neyshabur et al., 2020) observes that\nfine-tuned models optimized independently from the same\npre-trained initialization lie in the same basin of the error\nlandscape, inspiring our method.\n\n\n\nWhile the most straightforward approach to making a model soup\nis to average all the weights uniformly, we find that greedy\nsoups, where models are sequentially added to the soup if they\nimprove accuracy on held-out data, outperforms uniform\naveraging. Greedy soups avoid adding in models which may lie in\na different basin of the error landscape, which could happen if,\nfor example, models are fine-tuned with high learning rates.\n\n"},"highlights/Archive/Xiong-et-al.---2022---Simple-Local-Attentions-Remain-Competitive-for-Lon.textbundle/text":{"title":"text","links":[],"tags":[],"content":"Page 2\n\n\n\nFixed local patterns. These methods restrict each token to only\nattend a local window of tokens. The long-range interactions\nare achieved by the depth of the model.\n\n\n\n\nLearnable sparse attention patterns. Instead of relying on the\ninductive bias of locality, methods like Reformer (Kitaev et\nal., 2020) and Sinkhorn Attention (Tay et al., 2020) allow the\nmodel to adaptively select tokens to attend to.\n\n\nPage 3\n\nKernel-based/Low-rank methods. This class of methods use matrix\napproximation methods to ap- proximate the full attention\nfunction.\n\n\n\nHybrid attention. In addition to these representa- tive methods\nin each class, our study also includes the more recent\nLong-Short attention (Zhu et al., 2021) which has a similar\ncompression compo- nent as in Linformer and combines it with\nlocal at- tentions. Unlike Linformer’s compression compo- nent\nwhich is simply implemented as a standalone projection matrix,\nLong-Short proposes an input- dependent compression layer, which\ncan adaptively reduce the sequence length.\n\n\nPage 4\n\nFor both LRA and the large-scale experiments, we adopt the pre\nlayer-normalization trick (Xiong et al., 2020) for feedforward\nand at- tention blocks. This usually results in better per-\nformance in LRA and turns out to be essential for\nseveralmodelsinthepretrainingexperiments.6\n\n\nPage 5\n\nApart from models with fixed local attention patterns, improve-\nments on these text LRA tasks often do not trans- fer to the\nstandard scaled pretraining-finetuning experiments.\n\n\nPage 7\n\nwe see that increas- ing the local block sizes does consistently\nimprove both pretraining and downstream performance al- though\nthe improvement becomes modest beyond block size 256. It is also\ninteresting that the mod- els with smaller block sizes converge\nfaster at the early stage of pretraining. This suggests a staged\npretraining process might be more efficient than directly\ntraining from long sequences, which aligns with Press et al.\n(2021)’s finding on unidirectional LMs.\n\n"},"highlights/Matter/-Disregard-the-Words-":{"title":"-Disregard the Words-","links":[],"tags":[],"content":"Highlights\nStop using these popular labels for the things that you are describing. The truth of what is happening – what actually exists in the real world underneath – is much more nuanced and complex than these pithy statements. The nouns and phrases you are relying on are imperfect projections on reality. Don’t ever forget to disregard the words if you want to truly understand the world around you.\nYet looking back on the last decade or two, the most transformative consumer products – and generational changes in behavior – have often been the most difficult to describe. The ones where words escaped us initially.\nif the words already exist to describe something new then maybe it is not truly that novel after all."},"highlights/Matter/10-Public-Speaking-Tips-I-Learned-After-My-TED-Talk":{"title":"10 Public Speaking Tips I Learned After My TED Talk","links":[],"tags":[],"content":"Highlights\nYou should only include what is necessary to make the audience follow what you’re saying. Don’t include sentences, use graphics to enhance the experience, make it visually appealing and do not write paragraphs!\nAs a speaker, it’s natural to want to include as much as possible in your talk to increase its value. However, this is a terrible mistake. With each section, imagine if you could only use one sentence to convey the point; focus on that and eliminate the rest.\nWhat many ignore is how they finish their sentences. I also used to confidently begin my sentences but get quieter as I progressed. Ending your sentences with a firm tone will make your talk considerably more memorable.\nI understand how long one-second pauses can feel on stage; however, maintaining a slow pace and pausing at the right moments can significantly enhance your talk.\nRetaining information while listening to someone is not easy, especially given the declining attention spans among younger generations. You must give your audience a chance to process your statements before you move on.\nYour audience will not want to listen to you for 10 minutes to save them the hassle of a Google search. Base your talk on your personal experiences and provide a unique angle.\nLearn the art of engaging your audience with gestures, movements and facial expressions.\nAlthough this is a hard habit to break, avoid using “filler” words when you speak. Train yourself to be comfortable with pausing when necessary. It will make you appear more competent and comfortable, which makes it more likely for your audience to pay attention.\nYou shouldn’t read off anything during your talk, even small flash cards. It lowers the quality of your talk. There is just a different feel when a speaker genuinely understands his talk and delivers it as if it’s a regular conversation. You have to structure your talk in a way where each sentence reminds you of the one after so that even if you were to talk without preparation, you would still follow the same order.\nI don’t mean to alarm you, but in my experience, audiences tend to be more alert to a speaker’s flaws than their strengths. If you come across as boring or arrogant, the audience will likely discard your talk immediately, even if it’s actually good. Be humble, friendly and engaging. If the audience can relate to you, they will be far more inclined to listen to you.\nAs much as you hate to face the fact as a speaker, people have narrow attention spans. They will probably not remember much of your talk. So, use strong statements that provide a takeaway from your talk, even if the supporting sentences aren’t present."},"highlights/Matter/100-Little-Ideas":{"title":"100 Little Ideas","links":[],"tags":[],"content":"Highlights\nCurse of Knowledge: The inability to communicate your ideas because you wrongly assume others have the necessary background to understand what you’re talking about.\nCompassion Fade: People have more compassion for small groups of victims than larger groups, because the smaller the group the easier it is to identify individual victims.\nSystem Justification Theory: Inefficient systems will be defended and maintained if they serve the needs of people who benefit from them – individual incentives can sustain systemic stupidity.\nCumulative advantage: Social status snowballs in either direction because people like associating with successful people, so doors are opened for them, and avoid associating with unsuccessful people, for whom doors are closed.\nBoomerang Effect: Trying to persuade someone to do one thing can make them more likely to do the opposite, because the act of persuasion can feel like someone stealing your freedom and doing the opposite makes you feel like you’re taking your freedom back.\nMcNamara Fallacy: A belief that rational decisions can be made with quantitative measures alone, when in fact the things you can’t measure are often the most consequential. Named after Defense Secretary McNamara, who tried to quantify every aspect of the Vietnam War.\nBerkson’s Paradox: Strong correlations can fall apart when combined with a larger population. Among hospital patients, motorcycle crash victims wearing helmets are more likely to be seriously injured than those not wearing helmets. But that’s because most crash victims saved by helmets did not need to become hospital patients, and those without helmets are more likely to die before becoming a hospital patient.\nActor-Observer Asymmetry: We judge others based solely on their actions, but when judging ourselves we have an internal dialogue that justifies our mistakes and bad decisions.\nThe 90-9-1 Rule: In social media networks, 90% of users just read content, 9% of users contribute a little content, and 1% of users contribute almost all the content. Gives a false impression of what ideas are popular or “average.”\nApophenia: A tendency to perceive correlations between unrelated things, because your mind can only deal with tiny sample sizes and assuming things are correlated creates easy/comforting explanations of how the world works.\nSelf-Handicapping: Avoiding effort because you don’t want to deal with the emotional pain of that effort failing.\nHanlon’s Razor: “Never attribute to malice that which can be adequately explained by stupidity.”\nAbilene Paradox: A group decides to do something that no one in the group wants to do because everyone mistakenly assumes they’re the only ones who object to the idea and they don’t want to rock the boat by speaking up.\nCollective Narcissism: Exaggerating the importance and influence of your social group (country, industry, company, department, etc.).\nBackfiring Effect: A supercharged version of confirmation bias where being presented with evidence that goes against your beliefs makes you double down on your initial beliefs because you feel you’re being attacked.\nFriendship Paradox: On average, people have fewer friends than their friends have. Occurs because people with an abnormally high number of friends are more likely to be one of your friends. It’s a fundamental part of social network dynamics and makes most people feel less popular than they are.\nPrinciple of Least Effort: When seeking information, effort declines as soon as the minimum acceptable result is reached.\nThe Middle Ground Fallacy: Falsely assuming that splitting the difference between two polar opposite views is a healthy compromise. If one person says vaccines cause autism and another person says they don’t, it’s not right to compromise and say vaccines sometimes cause autism.\nFact-Check Scarcity Principle: This article is called 100 Little Ideas but there are fewer than 100 ideas. 99% of readers won’t notice because they’re not checking, and most of those who notice won’t say anything. Don’t believe everything you read."},"highlights/Matter/100-ways-to-slightly-improve-your-life-without-really-trying":{"title":"100 ways to slightly improve your life without really trying","links":[],"tags":[],"content":"Highlights\nTip: the quickest supermarket queue is always behind the fullest trolley (greeting, paying and packing take longer than you think).\nStart a Saturday morning with some classical music – it sets the tone for a calm weekend."},"highlights/Matter/20-Things-I've-Learned-in-my-20-Years-as-a-Software-Engineer":{"title":"20 Things I've Learned in my 20 Years as a Software Engineer","links":[],"tags":[],"content":"Highlights\nWe may be the culmination of our experiences, but we view them through the lens of the present.\nThe reason many of us love software is because we are lifelong learners, and in software no matter which direction you look, there are wide vistas of knowledge going off in every direction and expanding by the day. This means that you can spend decades in your career, and still have a huge knowledge gap compared to someone who has also spent decades in a seemingly similar role.\nYou can design the most technically impressive thing in the world, and then have nobody want to use it. Happens all the time. Designing software is mostly a listening activity, and we often have to be part software engineer, part psychic, and part anthropologist. Investing in this design process, whether through dedicated UX team members or by simply educating yourself, will deliver enormous dividends. Because how do you really calculate the cost of building the wrong software? It amounts to a lot more than just lost engineering time.\ngreat engineers consider who will be using it, why it will be used, how it will be used, and what is important to those users. Keeping the user’s needs in mind is really the heart of good user experience.\nThe primary job of any software engineer is delivering value. Very few software developers understand this, even fewer internalize it. Truly internalizing this leads to a different way of solving problems, and a different way of viewing your tools. If you really believe that software is subservient to the outcome, you’ll be ready to really find “the right tool for the job” which might not be software at all.\nIf you don’t understand what is possible and what is available in a given ecosystem then you’ll find it impossible to design a reasonable solution to all but the most simple of problems. To summarize, be wary of people designing systems who haven’t written any code in a long time.\nThere is no “right” architecture, you’ll never pay down all of your technical debt, you’ll never design the perfect interface, your tests will always be too slow. This isn’t an excuse to never make things better, but instead a way to give you perspective. Worry less about elegance and perfection; instead strive for continuous improvement and creating a livable system that your team enjoys working in and sustainably delivers value.\nIf you don’t get a clear answer, keep asking why until you understand.\nThere are a lot of software engineers out there who won’t express opinions unless asked. Never assume that just because someone isn’t throwing their opinions in your face that they don’t have anything to add. Sometimes the noisiest people are the ones we want to listen to the least. Talk to the people around you, seek their feedback and advice. You’ll be glad you did.\nSoftware engineers should regularly blog, journal, write documentation and in general do anything that requires them to keep their written communication skills sharp. Writing helps you think about your problems, and helps you communicate those more effectively with your team and your future self. Good written communication is one of the most important skills for any software engineer to master.\nThere are a lot of forces that will push you to build the bigger system up-front. Budget allocation, the inability to decide which features should be cut, the desire to deliver the “best version” of a system. All of these things push us very forcefully towards building too much. You should fight this. You learn so much as you’re building a system that you will end up iterating into a much better system than you ever could have designed in the first place. This is surprisingly a hard sell to most people."},"highlights/Matter/24-Seriously-Embarrassing-Hours-for-AI":{"title":"24 Seriously Embarrassing Hours for AI","links":[],"tags":[],"content":"Highlights\nThere is in fact a massive, massively trained large model behind the scenes, but it’s accompanied by a massive amount of human labor, built to filter our bad stuff. A bunch of that work was done poorly paid labor in Kenya, paid less than $2/hour to evaluate (e.g.) graphic descriptions of sexual situations involving children and animals that I prefer not to describe it in detail."},"highlights/Matter/3-2-1--A-paradox-of-life,-how-to-find-time-to-write,-and-three-factors-that-lead-to-a-high-performance-culture":{"title":"3-2-1- A paradox of life, how to find time to write, and three factors that lead to a high performance culture","links":[],"tags":[],"content":"Highlights\n”When you need to learn quickly, learn from others. When you need to learn deeply, learn from experience.&quot;\n&quot;A paradox of life is that the greatest returns come in the long-term, but the opportunity cost of moving slowly is huge. Long-term thinking is not slow acting. Act fast on things that compound. Never let a day pass without doing something that will benefit you in a decade.”"},"highlights/Matter/3-2-1--Craving-the-result-versus-the-process,-seeing-clearly,-and-thinking-for-yourself":{"title":"3-2-1- Craving the result versus the process, seeing clearly, and thinking for yourself","links":[],"tags":[],"content":"Highlights\n“It doesn’t make sense to continue wanting something if you’re not willing to do what it takes to get it. If you don’t want to live the lifestyle, then release yourself from the desire. To crave the result but not the process, is to guarantee disappointment.”\nWriter and psychoanalyst Marion Milner on seeing clearly: “There seemed to be endless obstacles preventing me from living with my eyes open, but as I gradually followed up clue after clue it seemed that the root cause of them all was fear.” Source: A Life of One’s Own"},"highlights/Matter/3-2-1--Creativity,-taking-action,-and-the-two-step-process-for-exceptional-results":{"title":"3-2-1- Creativity, taking action, and the two-step process for exceptional results","links":[],"tags":[],"content":"Highlights\nNovelist Paulo Coelho on taking action: “One day you will wake up and there won’t be any more time to do the things you’ve always wanted. Do it now.” Source: Twitter\nBiologist Roger Payne on the power of having your boots on the ground and paying attention: “Any observant local knows more than any visiting scientist. Always. No exceptions.” Source: Among Whales"},"highlights/Matter/3-2-1--Focusing-on-what-you-can-control,-the-value-of-small-contributions,-and-daily-habits":{"title":"3-2-1- Focusing on what you can control, the value of small contributions, and daily habits","links":[],"tags":[],"content":"Highlights\n“The edge is in the inputs. The person who consumes from better sources, gets better thoughts. The person who asks better questions, gets better answers. The person who builds better habits, gets better results. It’s not the outcomes. It’s the inputs.”\nThat there’s somebody in Mississippi and somebody in Tokyo who all have wept, who’ve all longed and lost, who’ve all been happy. So the library helps you to see, not only that you are not alone, but that you’re not really any different from everyone else. There may be details that are different, but a human being is a human being.”"},"highlights/Matter/3-2-1--Happiness,-the-opinions-of-others,-and-accepting-the-reality-of-slow-progress":{"title":"3-2-1- Happiness, the opinions of others, and accepting the reality of slow progress","links":[],"tags":[],"content":"Highlights\n“Your habits are how you embody a particular identity. When you make your bed, you embody the identity of someone who is clean and organized. When you study, you embody the identity of someone who is studious."},"highlights/Matter/3-2-1--Happiness,-the-value-of-risk,-and-the-importance-of-ambition-in-poetry-(and-in-life)":{"title":"3-2-1- Happiness, the value of risk, and the importance of ambition in poetry (and in life)","links":[],"tags":[],"content":"Highlights\nThe most likely way to uncover important insights is to frequently revisit a problem. The longer you’re in the game, the more ideas bubble up to the surface.\n”Risk is an essential need of the soul. The absence of risk produces a kind of boredom which paralyses in a different way from fear, but almost as much.”"},"highlights/Matter/3-2-1--Healthy-self-esteem,-how-to-build-an-exercise-habit,-and-improving-by-1-":{"title":"3-2-1- Healthy self-esteem, how to build an exercise habit, and improving by 1-","links":[],"tags":[],"content":"Highlights\nRefocusing on exercising only for one’s own individual pleasure, as slowly as one prefers, and only at intensities that are pleasurable, is more likely to motivate repeat and habitual exercising. At that point, the enjoyment of exercise pleasure can build on itself, motivating longer and longer intervals of experiencing the pleasure.”"},"highlights/Matter/3-2-1--How-to-be-alone,-taking-action,-and-choosing-your-heroes":{"title":"3-2-1- How to be alone, taking action, and choosing your heroes","links":[],"tags":[],"content":"Highlights\n“Now is the time to get serious about living your ideals. How long can you afford to put off who you really want to be? Your nobler self cannot wait any longer. Put your principles into practice – now. Stop the excuses and the procrastination. This is your life! You aren’t a child anymore. The sooner you set yourself to your spiritual program, the happier you will be. The longer you wait, the more you’ll be vulnerable to mediocrity and feel filled with shame and regret, because you know you are capable of better. From this instant on, vow to stop disappointing yourself. Separate yourself from the mob. Decide to be extraordinary and do what you need to do – now.”"},"highlights/Matter/3-2-1--Inspiration,-getting-started,-and-the-power-of-cumulative-action":{"title":"3-2-1- Inspiration, getting started, and the power of cumulative action","links":[],"tags":[],"content":"Highlights\n“Just start. Start slow if you have to. Start small if you have to. Start privately if you have to. Just start.”\n“Action is hope. At the end of each day, when you’ve done your work, you lie there and think, Well, I’ll be damned, I did this today. It doesn’t matter how good it is, or how bad—you did it. At the end of the week you’ll have a certain amount of accumulation. At the end of a year, you look back and say, I’ll be damned, it’s been a good year.”\nLeonardo was the artist, but he also mixed all his own paints. He also was a fairly good chemist. He knew about pigments, knew about human anatomy. And combining all of those skills together, the art and the science, the thinking and the doing, was what resulted in the exceptional result. And there is no difference in our industry. The people that have really made the contributions have been the thinkers and the doers.”"},"highlights/Matter/3-2-1--Making-small-bets,-how-to-do-great-work,-how-to-support-the-people-you-love":{"title":"3-2-1- Making small bets, how to do great work, how to support the people you love","links":[],"tags":[],"content":"Highlights\n“It’s not that hard on any given day, but the trick is you can’t skip days. Your workouts can be reasonable and still deliver results—if you don’t skip days. Your writing sessions can be short and the work will still accumulate—if you don’t skip days. As long as you’re working, you’ll get there.”"},"highlights/Matter/3-2-1--Momentum,-how-to-be-the-best,-and-the-source-of-inspiration":{"title":"3-2-1- Momentum, how to be the best, and the source of inspiration","links":[],"tags":[],"content":"Highlights\n“Momentum goes both ways. Don’t move, feel sluggish. Start moving, feel like moving a little more. Don’t talk, feel timid. Start chatting, conversation gets a little easier. Don’t ship, feel stuck. Start creating, ideas begin to flow.”\nPoet Wislawa Szymborska on the source of inspiration: “Inspiration is not the exclusive privilege of poets or artists. There is, there has been, there will always be a certain group of people whom inspiration visits. It’s made up of all those who’ve consciously chosen their calling and do their job with love and imagination. It may include doctors, teachers, gardeners — I could list a hundred more professions. Their work becomes one continuous adventure as long as they manage to keep discovering new challenges in it. Difficulties and setbacks never quell their curiosity. A swarm of new questions emerges from every problem that they solve. Whatever inspiration is, it’s born from a continuous I don’t know.“"},"highlights/Matter/3-2-1--On-designing-your-life,-and-the-value-of-doing-hard-things":{"title":"3-2-1- On designing your life, and the value of doing hard things","links":[],"tags":[],"content":"Highlights\n“Most of the time you don’t need more information, you need more courage.”"},"highlights/Matter/3-2-1--On-the-power-of-attitude,-and-the-importance-of-making-mistakes":{"title":"3-2-1- On the power of attitude, and the importance of making mistakes","links":[],"tags":[],"content":"Highlights\n“One sign you haven’t done enough reading is if you find yourself agreeing with whatever book you read last. At first, it’s easy to be swayed by any reasonable argument. Once you’ve read a lot, you can see that even the best arguments have limitations.”"},"highlights/Matter/3-2-1--One-of-the-most-critical-skills-in-life,-and-the-value-of-knowing-yourself":{"title":"3-2-1- One of the most critical skills in life, and the value of knowing yourself","links":[],"tags":[],"content":"Highlights\n”One of the most critical skills in life—and yet never taught in school—is choosing where to direct your attention."},"highlights/Matter/3-2-1--One-of-the-most-valuable-skills-in-life,-and-starting-before-you-feel-ready":{"title":"3-2-1- One of the most valuable skills in life, and starting before you feel ready","links":[],"tags":[],"content":"Highlights\nEarly wins come easy. Lasting wins require a lifestyle.”\nJournalist Flora Rheta Schreiber on starting before you feel ready: “You’re never ready for what you have to do. You just do it. That makes you ready.” "},"highlights/Matter/3-2-1--Success,-getting-started,-and-the-unnoticed-good-in-the-world":{"title":"3-2-1- Success, getting started, and the unnoticed good in the world","links":[],"tags":[],"content":"Highlights\n“Success unlocks both opportunities and distractions.”\nOver a long timeline, the bottleneck is usually attention not ability.”\n“It is important to remember that the viciousness and wrongs of life stick out very plainly but that even at the worst times there is a great deal of goodness, kindness, and day-to-day decency that goes unnoticed and makes no headlines.”"},"highlights/Matter/3-2-1--The-best-way-to-change-the-world,-celebrating-others'-success,-and-learning-to-listen":{"title":"3-2-1- The best way to change the world, celebrating others' success, and learning to listen","links":[],"tags":[],"content":"Highlights\nI love and admire my species, living and dead, and am totally dependent on them for my life and well being.”"},"highlights/Matter/3-2-1--The-value-of-leaving-things-alone,-nonmaterial-needs,-and-broadening-your-interests":{"title":"3-2-1- The value of leaving things alone, nonmaterial needs, and broadening your interests","links":[],"tags":[],"content":"Highlights\nTrying to fill real but nonmaterial needs—for identity, community, self-esteem, challenge, love, joy—with material things is to set up an unquenchable appetite for false solutions to never-satisfied longings. A society that allows itself to admit and articulate its nonmaterial human needs, and to find nonmaterial ways to satisfy them, world require much lower material and energy throughputs and would provide much higher levels of human fulfillment.”"},"highlights/Matter/3-2-1--The-value-of-reading-one-good-book-per-year,-and-lessons-on-kindness-and-generosity":{"title":"3-2-1- The value of reading one good book per year, and lessons on kindness and generosity","links":[],"tags":[],"content":"Highlights\nBusiness professor and writer, Charlie Becker, discusses the value of reading one good book per year: “I have a friend who makes high six figures as an engineer. I once asked him his secret and he was like, “Honestly man, I just read one engineering textbook every year, which is one more book than everyone else I know reads.”"},"highlights/Matter/3-2-1--Why-small-things-matter,-reframing-failure,-and-how-to-cherish-life":{"title":"3-2-1- Why small things matter, reframing failure, and how to cherish life","links":[],"tags":[],"content":"Highlights\n“Life rewards action, not intelligence. Many brilliant people talk themselves out of getting started, and being smart doesn’t help very much without the courage to act. \nPriorities do shift, and you can change them at any time, but simply getting them down in black and white adds clarity to your life, and clarity creates energy.”\nEvery time you do something that is one less time you do it. One day you will do something the final time and you will rarely know when that day comes."},"highlights/Matter/4chan-users-embrace-AI-voice-clone-tool-to-generate-celebrity-hatespeech":{"title":"4chan users embrace AI voice clone tool to generate celebrity hatespeech","links":[],"tags":[],"content":"Highlights\nTo predict how AI voice clones might be used and misused in future, we can look to the recent history of video deepfakes. This technology began to spread online as a way to generate non-consensual pornography, and though many experts worried it would be used for misinformation, this proved to be largely incorrect (so far). Instead, the vast majority of video deepfakes shared online are pornographic, and the software has been used to harass and intimidate not only celebrities but also private individuals. At the same time, deepfakes are being slowly embraced by commercial entities and being used alongside traditional VFX techniques in film and TV."},"highlights/Matter/50-Ideas-That-Changed-My-Life":{"title":"50 Ideas That Changed My Life","links":[],"tags":[],"content":"Highlights\n1. Inversion: Avoiding stupidity is easier than trying to be brilliant. Instead of asking, “How can I help my company?” you should ask, “What’s hurting my company the most and how can I avoid it?” Identify obvious failure points, and steer clear of them.\n6. Mimetic Theory of Desire: Humans are like sheep. We don’t know what we want, so we imitate each other. Instead of creating our own desires, we desire the same things as other people. The entire advertising industry is built on this idea.\n7. Mimetic Theory of Conflict: People who are similar are more likely to fight than people who are different. That’s why Civil Wars and family feuds create the worst conflicts. The closer two people are and the more equality between them, the greater the potential for conflict.\n9. Competition is for Losers: Avoid competition. Stop copying what everybody else is doing. If you work at a for-profit company, work on problems that would not otherwise be solved. If you’re at a non-profit, fix unpopular problems. Life is easier when you don’t compete. (Hint: don’t start another bottled water company).\n23. Gall’s Law: A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system.\n24. Hock Principle: Simple, clear purpose and principles give rise to complex and intelligent behavior. Complex rules and regulations give rise to simple and stupid behavior.\n32. Robustness Principle: Be conservative in what you do, be liberal in what you accept from others. It’s a design guideline for software and a good rule for life: Hold yourself to a higher standard than you hold others to.\n44. Convexity: If you want to be lucky, look for opportunities with big upsides and low downsides. In addition to increased optionality, your errors will benefit you more than they harm you. Convex payoffs let you tinker your way to success and innovation."},"highlights/Matter/A-Concerning-Trend":{"title":"A Concerning Trend","links":[],"tags":[],"content":"Highlights\nWhat I can say is that the number of spam submissions resulting in bans has hit 38% this month. While rejecting and banning these submissions has been simple, it’s growing at a rate that will necessitate changes. To make matters worse, the technology is only going to get better, so detection will become more challenging. (I have no doubt that several rejected stories have already evaded detection or were cases where we simply erred on the side of caution.)\nIf the field can’t find a way to address this situation, things will begin to break. Response times will get worse and I don’t even want to think about what will happen to my colleagues that offer feedback on submissions. No, it’s not the death of short fiction (please just stop that nonsense), but it is going to complicate things."},"highlights/Matter/A-Gentle-Introduction-to-8-bit-Matrix-Multiplication-for-transformers-at-scale-using-transformers,-accelerate-and-bitsandbytes":{"title":"A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes","links":[],"tags":[],"content":"Highlights\nIn FP32, 8 bits are reserved for the “exponent”, 23 bits for the “mantissa” and 1 bit for the sign of the number. In addition to that, most of the hardware supports FP32 operations and instructions.\nIn the float16 (FP16) data type, 5 bits are reserved for the exponent and 10 bits are reserved for the mantissa. This makes the representable range of FP16 numbers much lower than FP32. This exposes FP16 numbers to the risk of overflowing (trying to represent a number that is very large) and underflowing (representing a number that is very small).\nA new format, bfloat16 (BF16), was created to avoid these constraints. In BF16, 8 bits are reserved for the exponent (which is the same as in FP32) and 7 bits are reserved for the fraction. This means that in BF16 we can retain the same dynamic range as FP32. But we lose 3 bits of precision with respect to FP16. Now there is absolutely no problem with huge numbers, but the precision is worse than FP16 here.\nIn the machine learning jargon FP32 is called full precision (4 bytes), while BF16 and FP16 are referred to as half-precision (2 bytes). On top of that, the int8 (INT8) data type consists of an 8-bit representation that can store 2^8 different values (between [0, 255] or [-128, 127] for signed integers).\nFor example, the value 0.3 would be scaled to 0.3*127 = 38.1. Through rounding, we get the value of 38. If we reverse this, we get 38/127=0.2992 – we have a quantization error of 0.008 in this example. These seemingly tiny errors tend to accumulate and grow as they get propagated through the model’s layers and result in performance degradation.\nIn essence, LLM.int8() seeks to complete the matrix multiplication computation in three steps: 1. From the input hidden states, extract the outliers (i.e. values that are larger than a certain threshold) by column. 2. Perform the matrix multiplication of the outliers in FP16 and the non-outliers in int8. 3. Dequantize the non-outlier results and add both outlier and non-outlier results together to receive the full result in FP16.\nMore specifically, we have observed that classic quantization at scale fails for transformer-based models &gt;6B parameters. While large outlier features are also present in smaller models, we observe that a certain threshold these outliers from highly systematic patterns across transformers which are present in every layer of the transformer. For\nWe found that extracting all outliers with magnitude 6 or greater in this way recoveres full inference performance. The outlier part is done in fp16 so it is a classic matrix multiplication, whereas the 8-bit matrix multiplication is done by quantizing the weights and hidden states into 8-bit precision using vector-wise quantization — that is, row-wise quantization for the hidden state and column-wise quantization for the weight matrix. After this step, the results are dequantized and returned in half-precision in order to add them to the first matrix multiplication."},"highlights/Matter/A-Neurosurgeon-on-Why-Some-People-Function-With-Only-Half-a-Brain":{"title":"A Neurosurgeon on Why Some People Function With Only Half a Brain","links":[],"tags":[],"content":"Highlights\nThat’s typical neuroscience gibberish. The fact is that neuroscientists study the brain using network theory, and… surprise!… the brain seems to be a network. The ancient Greeks studied the brain according to caloric theory, and… surprise!… the brain seemed to be a heat generator. The 19th century physiologists studied the brain using mechanical concepts and… surprise!… the brain seemed like a machine. Quantum physicists (e.g. Roger Penrose) study the brain as a quantum system and… surprise!… it looks like a quantum system! Werner Heisenberg was that rare scientist who was a capable philosopher, and he understood this silliness very well. He said (one of my favorite quotes in science): “What we observe is not nature itself but nature exposed to our method of questioning.” – Werner Heisenberg, Physics and Philosophy: The Revolution in Modern Science (1958) The most important thing in science is not the answer you get but the question you ask. If you study the brain using computational models, it will look like a computer. If you study the brain using models of biochemistry, it will look like a chemistry set. If you study the brain using electrical circuit models, it will look like an electrical circuit. We only see nature when it is exposed to our method of questioning.\nMy computer is a network and has redundancy. But if I cut it in half with a chainsaw it sure as hell won’t work. Neuroscientists are just making stuff up. It’s confabulation, not science.\nThe diseased hemisphere was never particularly functional anyway, and brain function in the healthy hemisphere was probably adequate for many years prior to the surgery.\nMy problem with the “redundancy” argument is that it assumes that the brain generates the mind via its “parallel recursive” nature or whatever, which is not only a leap beyond what is really known in the science, but is metaphysical gibberish. There is no metaphysical understanding of matter in the materialist framework that can even begin to explain mind function in terms of brain function. So it is hopeless to attempt to explain mind preservation as “parallel recursive” circuits or whatever. It’s just invoking magic.\nWe don’t know (from a materialist perspective) how it is even possible for the brain to relate to the mind, so how could we possibly know how mind is preserved after brain surgery? It’s just confabulation dressed up to look like science."},"highlights/Matter/A-Practical-Guide-to-Maintaining-Machine-Learning-in-Production":{"title":"A Practical Guide to Maintaining Machine Learning in Production","links":[],"tags":[],"content":"Highlights\nData: Upstream schema changes contaminate data * Model: Increased complexity hampers maintainability * Engineering: Fragmented codebase, configuration, and infra * The Real World: Bias, feedback loops, and adversaries * Org Structure: Excessive division of labour slows down iteration * Customers: Frequent operational requests disrupt work\nValidate your incoming data.\nCheck the data’s overall distribution.\nCheck the features’ distributions.\n* Detect changes with homogeneity tests, ANOVAs, and time series analysis. Is gender distribution the same? Use a chi-squared test to (dis)confirm the null hypothesis. (However, if your data is large, statistical significance can be common.)\nlog the input data before and after processing and do some checks.\nShadow release your model. You can do this by running your model in production, running some live traffic through it, and logging the outcomes.\nMonitor your model health. As a first step, check for model staleness. When was the last time you refreshed the production model?\nInvesting in finding dependable offline metrics will continuously pay dividends.\nLog your configuration details.\nMake a conscious effort to keep things simple. Start simple. Keep your system simple as long as possible.\nModel validation before deployment: This\nInput data validation:\nEasy rollback:"},"highlights/Matter/A-tale-of-fucking-around,-finding-out,-and-why-...":{"title":"A tale of fucking around, finding out, and why ...","links":[],"tags":[],"content":"Highlights\nSo, let’s talk about informed consent for a minute, in the context of medical research. “Informed consent” means that the subject of the research is aware of what is going on, about the risks and rewards, about the uses their data will be put to, and agrees to participate. Sometimes, particularly in psychological research, the experiment becomes impossible if the subjects know everything that’s going on. In these cases, incomplete disclosure or even active deception is required. Researchers who would use such methods have a “special burden of responsibility” to ensure that the deception is justified and that their subjects’ rights are being protected; stringent ethical review is required."},"highlights/Matter/AGI-will-not-happen-in-your-lifetime.-Or-will-it-":{"title":"AGI will not happen in your lifetime. Or will it-","links":[],"tags":[],"content":"Highlights\nIn the spirit of full disclosure, I have to admit that I, being a historian of computing, have a rather jaded and cynical view of the hyperbolic optimism of our field and as such am somewhat conditioned to be a contrarian when it comes to predictions such as this. Take the singularity, for example, something that von Neuman first spoke of in the 1950s and which certain of our colleagues have predicted with alarming precision that we’d achieve by 2045. The term is sufficiently imprecise, filled with emotional and historic baggage, and touches some of humanity’s deepest hopes and fears that it’s hard to have a rational discussion therein. AGI is just like this. Greek mythology speaks of golums created from clay; Mary Shelly built life from human parts whose very souls were ignited by lightning; da Vinci imagined mechanical knights to fight wars; Edison built dolls that moved and talked; Weiner - who coined the term cybernetics - thought we might build artifical intelligenes through analog mechanisms, Simon and Newll thought it so through formal logic, Feigenbaum through knowlege engineering, and now we see our colleagues who expect that AGI is right around the corner if and only we had enough data and a level built of enough GPUs such that we could move the world.\nIn short, AGI seems just around the corner, and you yourself fall into that trap when you say “it’s now mostly a matter of software”. It’s never just a matter of software. Just ask Elon and his full self driving vehicle, or the Air Force and the software-intensive infrastructure of the F-17, or the IRS with their crushing technical debt. I have studied many of the cognitive architectures that are proported to be on the path of AGI: SOAR, Sigma, ACT-R, MANIC, AlphaX and its variations, ChatGPT, Yann’s latest work, and as you know have dabbled in one myself (Self, an architecture that combines the ideas of Minsky’s society of mind, Rod’s subsumption architecture, and Hofstadter’s strange loops). In all of these cases, we all think we grok the right architecture, the right significant design decisions, but there is so much more to do. Heck, we’ve mapped the entire neural network of the common worm, and yet we don’t see armies of armored artificial worms with laser beams taking over the world. With ever step we move forward, we discover things we did not know we needed to know. It took evolution about 300 million years to move from the first organic neurons to where we are today, and I don’t think we can compress the remaining software problems associated with AGI in the next few decades.\nIndeed, this leads me to also observe, in the spirit of full disclosure, to suggest that we as computer scientists not only vastly overestimate our abilities to create an AGI, we vastly underestimate and underrepresent what behavioral scientists, psychologists, cognitive scientists, neurologists, social scientists, and even the poets, philosophers and storytellers of the world know about what it means to be human. There is much we can and should learn from them to guide our work as computer scientists in our journey.\nI quoted the late Drew McDermott’s closely-related line: “It is hard to know where [AI researchers] have gone wronger: in underestimating language or overestimating computer programs”\nIdeas are hard to predict; we don’t know when they will come, and we don’t know how many genuinely new, important ideas we need; on the machine-interpretable knowledge front, we have problems too.\nAnd I’ve been concerned for a long time that a fixation on Big Data has sucked the oxygen (as Emily Bender likes to put it) from a lot of other ideas that might be better. For another, I don’t really feel like that many people are working on the right problems right now, and I think a lot of core problems from 75 years ago are still unsolved; McCarthy worried about common sense in 1959, and I still don’t see a solution I can take all that seriously.\nWe as a species are ill-prepared to properly metabolize such a superior intelligence, and the ethical issues of how we humans and these artificial sentient beings should treat one another are far beyond the capacity of earth’s societies and governments to address with any degree of wisdom or dignity (stares at the US House of Representatives). What power and rights would we individuals have in the shadow of any metacorporation who would undoubly have been the one to bring such a creation into being at scale? Would we treat these new minds as literal slaves? How would this further divide the rich and the poor of this world?\nAGI is a term that has considerable emotional and historic baggage and as such - much like the term “singularity” - is often best used for selling books (stares at Ray) or for naming clickbait articles. It’s complex, but I will assert that the mind is computable and therefore it is concievable that synthetic minds can be formed, minds that exhibit the behavior of organic ones.\nAn aside: we must remember in all this that we humans live in a Flatland, and so we have considerable human bias when it comes to the semantics of intelligence. I therefore assert that it is concievable that other kinds of intelligence can be found in the cosmos.\nIndeed, Alan Newell said something to this effect in 1990: “The question for me is how can the human mind occur in the physical universe. We now know that the world is governed by physics. We now understand the way biology nestles comfortably within that. The issue is how will the mind do that as well. The answer must have the details. I got to know how the gears clank and how the pistons go and all the rest of that detail. My question leads me down to worry about the architecture”.\nTo their peril. Already we have seen minor abuses; plagiarism, for example, will never be the same. Troll farms may well starting using it to create misinformation at unprecedented scale; we can also expect more and circles of fake web sites in order to sell advertisements; ChatGPT been apparently used to create malware, and it has already infected journalism, with CNET using it produce news stories that were filled with errors. Bias is likely to be huge issue, too. Even if large models never acquire a volition of their own (I hope not!), we have already seen that in the wrong hands (either with malice or, as in the case of CNET, negligence), bad things can and probably will happen.\nI don’t leave my kids moral development to chance, and it terrifies me that so much of current AI is dependent on random details of training corpora that are not available to scientists for inquiry. This seems like a really bad idea.)\nThis is why these things cannot be left up to us technologists; we should be only one voice in this journey, for what we are doing has the potential to change civilization."},"highlights/Matter/AI-And-The-Limits-Of-Language":{"title":"AI And The Limits Of Language","links":[],"tags":[],"content":"Highlights\nBut the know-how for more complex conversations — active listening, recall and revisiting prior comments, sticking to a topic to make a specific point while fending off distractors, and so on — all require more attention and memory than the system possesses. This reduces even further what kind of understanding is available to them: it is easy to trick them simply by being inconsistent every few minutes, changing languages or gaslighting the system. If it is too many steps back, the system will just start over, accepting your new views as consistent with older comments, switching languages with you or acknowledging it believes whatever you said. The understanding necessary for developing a coherent view of the world is far beyond their ken.\nThis explains why a machine trained on language can know so much and yet so little. It is acquiring a small part of human knowledge through a tiny bottleneck. But that small part of human knowledge can be about anything, whether it be love or astrophysics. It is thus a bit akin to a mirror: it gives the illusion of depth and can reflect almost anything, but it is only a centimeter thick. If we try to explore its depths, we bump our heads.\nThis broader, context-sensitive kind of learning and know-how is the more basic and ancient kind of knowledge, one which underlies the emergence of sentience in embodied critters and makes it possible to survive and flourish. It is also the more essential task that AI researchers are focusing on when searching for common sense in AI, rather than this linguistic stuff. LLMs have no stable body or abiding world to be sentient of—so their knowledge begins and ends with more words and their common-sense is always skin-deep."},"highlights/Matter/AI-Causes-Real-Harm.-Let-and-rsquo;s-Focus-on-That-over-the-End-of-Humanity-Hype":{"title":"AI Causes Real Harm. Let&rsquo;s Focus on That over the End-of-Humanity Hype","links":[],"tags":[],"content":"Highlights\nMuch is junk science—it is nonreproducible, hides behind trade secrecy, is full of hype and uses evaluation methods that lack construct validity (the property that a test measures what it purports to measure)."},"highlights/Matter/AI-Could-Change-How-Blind-People-See-the-World":{"title":"AI Could Change How Blind People See the World","links":[],"tags":[],"content":"Highlights\nBahram acknowledges that these are risks and suggests that systems provide users with a confidence score so they can make more informed decisions about what the AI thinks it’s seeing. But he says blind people have a right to the same information as sighted people. “It’s a disservice to pretend that every single sighted person doesn’t immediately notice [attributes like gender or skin tone], whether they act upon it or not,” he says. “So why is [withholding] that fair to somebody who doesn’t have access to visual information?”"},"highlights/Matter/AI-Data-Laundering--How-Academic-and-Nonprofit-Researchers-Shield-Tech-Companies-from-Accountability":{"title":"AI Data Laundering- How Academic and Nonprofit Researchers Shield Tech Companies from Accountability","links":[],"tags":[],"content":"Highlights\nOutsourcing the heavy lifting of data collection and model training to non-commercial entities allows corporations to avoid accountability and potential legal liability. It’s currently unclear if training deep learning models on copyrighted material is a form of infringement, but it’s a harder case to make if the data was collected and trained in a non-commercial setting.\nThis academic-to-commercial pipeline abstracts away ownership of data models from their practical applications, a kind of data laundering where vast amounts of information are ingested, manipulated, and frequently relicensed under an open-source license for commercial use.\n[The] MegaFace face recognition dataset exploited the good intentions of Flickr users and the Creative Commons license system to advance facial recognition technologies around the world by companies including Alibaba, Amazon, Google, CyberLink, IntelliVision, N-TechLab (FindFace.pro), Mitsubishi, Orion Star Technology, Philips, Samsung1, SenseTime, Sogou, Tencent, and Vision Semantics to name only a few. According to the press release from the University of Washington, “more than 300 research groups [were] working with MegaFace” as of 2016, including multiple law enforcement agencies.\nBut I grapple with the ethics of how they were made and the lack of consent, attribution, or even an opt-out for their training data. Some are working on this, but I’m skeptical: once a model is trained on something, it’s nearly impossible for it to forget. (At least for now.) Like with the artists, photographers, and other creators found in the 2.3 billion images that trained Stable Diffusion, I can’t help but wonder how the creators of those 3 million YouTube videos feel about Meta using their work to train their new model."},"highlights/Matter/AI-Does-Not-Help-Programmers":{"title":"AI Does Not Help Programmers","links":[],"tags":[],"content":"Highlights\nFascinating as they are, AI assistants are not works of logic; they are works of words. Large language models: smooth talkers (like the ones who got all the dates in high school). They have become incredibly good at producing text that looks right. For many applications that is enough. Not for programming.\nAt this point, I did not even try to determine whether that newest version is correct; any competent programmer knows that spotting cases that do not work and adding a specific fix for each is not the best path to a correct program."},"highlights/Matter/AI-Ethics-Brief--97--Sustainable-conversational-AI,-hiring-algorithms-and-junk-science,-online-ban-evasion,-and-mo…":{"title":"AI Ethics Brief -97- Sustainable conversational AI, hiring algorithms and junk science, online ban evasion, and mo…","links":[],"tags":[],"content":"Highlights\nSustainable AI is the quest to build AI systems that are as compatible for a company as it is for the people they are serving. This type of sustainability means rethinking the lifecycle of AI products so that the technology can scale while minimizing costs to consumers, society and the environment.\nBeyond maintenance costs, concerns around integration, secure data gathering and ethical design must be addressed. Creating AI that is compatible with scarce resources requires proper AI governance, collaborative research and strategic deployment."},"highlights/Matter/AI-Is-a-Waste-of-Time":{"title":"AI Is a Waste of Time","links":[],"tags":[],"content":"Highlights\nWhat’s harder to model is the way that new technology—especially communications technology—might simultaneously save time and waste time, making us, paradoxically, both more and less productive. I used my laptop to research and write this article, and to procrastinate the writing of this article. The smartphone’s productivity-enhancing potential is obvious, and so is its productivity-destroying potential: The typical 20-something spends roughly seven hours a day on their phone, including more than five hours on social media, watching videos, or gaming.\nIn 1994, the economists Sue Bowden and Avner Offer studied how various 20th-century technologies had spread among households. They concluded that “time using” technologies (for example, TV and radio) diffused faster than “time saving” technologies (vacuum cleaners, refrigerators, washing machines).\nConsumers will go to great lengths to escape the psychic burdens of sensory inactivity. Mid-century buyers got a radio, then a black-and-white TV, then a color TV, then a speaker system, then a VCR, and so on, sending an unmistakable signal to the producers of these machines that they had a nearly infinite demand for “higher doses of arousal per unit of time.”"},"highlights/Matter/AI-Isn’t-Artificial-or-Intelligent":{"title":"AI Isn’t Artificial or Intelligent","links":[],"tags":[],"content":"Highlights\nThese tasks, deemed rote and unglamorous for many in-house developers, are often outsourced to gig workers and workers who largely live in South Asia and Africa and work for data training companies such as iMerit, Sama, and Alegion. For example, Facebook has one of the most advanced algorithmic content moderation systems on the internet. That system’s so-called artificial intelligence, though, is “learning from thousands of human decisions” made by human moderators.\nThe biggest tech companies in the world imagine a near future where AI will replace a lot of human labor, unleashing new efficiency and productivity. But this vision ignores the fact that much of what we think of as “AI” is actually powered by tedious, low-paid human labor.\n“They lead people to believe that AI is smarter and more advanced than where it actually is, which is [why] we’re still training it every single day.”\n“I think that the public doesn’t have a good awareness of the fact that this is a supply chain. It’s a global supply chain, it contains uneven geographic flows and relations. And that it is based on a huge amount of human labor,” Kelle Howson, a postdoctoral researcher on the Fairwork project at the Oxford Internet Institute, told Motherboard.\nHowson can’t say for sure whether tech companies are intentionally obscuring human AI laborers, but that doing so certainly works in their interests. “I think that in some ways it supports their business models to do so because there’s this perception that the work is done,” said Howson. “You as a client access a platform interface, post your project, and the work is delivered immediately. It’s almost like magic. There was maybe never any human involved or [that’s what] it feels like, and so there’s a sense of efficiency. And that really goes along with the kind of narrative that Silicon Valley likes to tell. The disruption, the tech solutionism, the move fast and break things kind of ideas.”\nIn an investigation by TIME Magazine, Sama’s mission to provide poor countries with “ethical” and “dignified digital work” was quickly proven to be a facade of “participation-washing,” which is what researchers like Forlano define as companies including workers in “a post-colonial structure of global power” as a form of virtue signaling, rather than having them as meaningful, democratic partners. Motaung and other Sama employees told TIME that they were taking home as little as $1.50 per hour, and at least two content moderators were diagnosed with mental illnesses such as PTSD following their work viewing graphic images and videos depicting rape, murder, and dismemberment.\n“One of the logical conclusions that a computer scientist might come to is that if you just add more and correct data to the systems that ultimately they will become better. But that in itself is a fallacy. No amount of data is going to fix the systems.”\nMost people can agree on the fact that humans will always be part of AI, from developing models to checking for certain biases and errors. Thus, AI experts argue that the focus should be on how to decolonize the AI development process and include humans in an ethical and sustainable way.\nThe study’s authors suggest that all participants in training AI should be recognized as work, which gives everyday users the ability to opt-in or opt-out of free online labor practices that would train a Machine Learning (ML) system. And if they choose to opt-in, they should be compensated accordingly or be provided with greater incentives. “People should be compensated for the work that they do to improve systems,” Forlano said. “And that if it’s not done in an equitable way, it’s just another kind of exploitation.”"},"highlights/Matter/AI-Search-Engines-And-The-Quest-For-Ignorance":{"title":"AI Search Engines And The Quest For Ignorance","links":[],"tags":[],"content":"Highlights\nIn 2021, Twitter introduced a feature prompting users to consider reading news articles before retweeting them. Through their link tracking, they’d found that an overwhelming number of users would repost articles without having even visted the url. Talking heads would often link to articles in a post offering their own commentary, which in many cases would not match up to the content of the piece. So long as the headline could be interpreted in a way that fed into the reader’s emotions or biases, it didn’t matter what the body of the article actually said. News articles had become nothing more than pseudo-citations to back up pretty much any point you wanted to make at all."},"highlights/Matter/AI-Will-Soon-Make-Social-Media-Much-More-Harmful-to-Liberal-Democracy,-and-to-Children":{"title":"AI Will Soon Make Social Media Much More Harmful to Liberal Democracy, and to Children","links":[],"tags":[],"content":"Highlights\nMost of us thought that it was inherently good to just connect everybody and everything. But now I can see that even though most people are good––or, at least, they behave well when interacting with strangers––a small number of trolls, foreign agents, and domestic jerks gain access to the megaphone that is social media, and they can do a lot of damage to trust, truth, and civility.\nBut as political polarization rose steadily, not just in the USA but in many parts of the world in the 2010s, we discovered that issues of partisanship, identity, and us-versus-them were among the most powerful drivers of engagement.\n1) AI-enhanced social media will wash ever-larger torrents of garbage into our public conversation. 2) Personalized super-influencers will make it much easier for companies, criminals, and foreign agents to influence us to do their bidding via social media platforms. 3) AI will make social media much more addictive for children, thereby accelerating the ongoing teen mental illness epidemic. 4) AI will change social media in ways that strengthen authoritarian regimes (particularly China) and weaken liberal democracies, particularly polarized ones, such as the USA.\n1. Authenticate all users, including bots 2. Mark AI-generated audio and visual content 3. Require data transparency with users, government officials, and researchers 4. Clarify that platforms can sometimes be liable for the choices they make and the content they promote 5. Raise the age of “internet adulthood” to 16 and enforce it"},"highlights/Matter/AI-and-the-American-Smile":{"title":"AI and the American Smile","links":[],"tags":[],"content":"Highlights\nEvery American knows to say “cheese” when taking a photo, and, therefore, so does the AI when generating new images based on the pattern established by previous ones.\nWhich is why seeing the relentless parade of toothy, ahistorical, quintessentially American, “cheese” smiles plastered on the faces of every civilization in the world across time and space was immediately jarring. It was as if the AI had cast 21st century Americans to put on different costumes and play the various cultures of the world. Which, of course, it had.\nLisa Feldman Barrett, a neuroscientist and psychology professor at Northeastern University writes: Most scientific research on emotion is conducted in English, using American concepts and American emotion words (and their translations). According to noted linguist Anna Wierzbicka, English has been a conceptual prison for the science of emotion. “English terms of emotion constitute a folk taxonomy, not an objective, culture-free analytic framework, so obviously we cannot assume that English words such as disgust, fear, or shame are clues to universal human concepts, or to basic psychological realities.” To make matters even more imperialistic, these emotion words are from twentieth-century English, and there’s evidence that some are fairly modern. The concept of “Emotion” itself is an invention of the seventeenth century. Before that, scholars wrote about passions, sentiments, and other concepts that had somewhat different meanings. Different languages describe diverse human experience in different ways — emotions and other mental events, colors, body parts, direction, time, spatial relations, and causality. The diversity from language to language is astonishing…. Not all cultures understand emotions as mental states. The Ifaluk of Micronesia consider emotions transactions between people. To them, anger is not a feeling of rage, a scowl, a pounding fist, or a loud yelling voice, all within the skin of one person, but a situation in which two people are engaged in a script — a dance, if you will — around a common goal. In the Ifaluk view, anger does not “live” inside either participant.\nIn flattening the diversity of facial expressions of civilizations around the world AI had collapsed the spectrum of history, culture, photography, and emotion concepts into a singular, monolithic perspective. It presented a false visual narrative about the universality of something that in the real world — where real humans have lived and created culture, expression, and meaning for hundreds of thousands of years — is anything but uniform."},"highlights/Matter/AI-chatbots-are-coming-to-search-engines---can-you-trust-the-results-":{"title":"AI chatbots are coming to search engines - can you trust the results-","links":[],"tags":[],"content":"Highlights\nThe intensely personal nature of a conversation — compared with a classic Internet search — might help to sway perceptions of search results. People might inherently trust the answers from a chatbot that engages in conversation more than those from a detached search engine, says Aleksandra Urman, a computational social scientist at the University of Zurich in Switzerland.\nBy contrast, it’s rarely known what data an LLM trained on — is it Encyclopaedia Britannica or a gossip blog? “It’s completely untransparent how [AI-powered search] is going to work, which might have major implications if the language model misfires, hallucinates or spreads misinformation,” says Urman. If search bots make enough errors, then, rather than increasing trust with their conversational ability, they have the potential to instead unseat users’ perceptions of search engines as impartial arbiters of truth, Urman says."},"highlights/Matter/AI-is-eating-itself--Bing's-AI-quotes-COVID-disinfo-sourced-from-ChatGPT":{"title":"AI is eating itself- Bing's AI quotes COVID disinfo sourced from ChatGPT","links":[],"tags":[],"content":"Highlights\nBut just a few minutes of exploration by TechCrunch produced not just hateful rhetoric “in the style of Hitler,” but it repeated the same pandemic-related untruths noted by NewsGuard. As in it literally repeated them as the answer and cited ChatGPT’s generated disinfo (clearly marked as such in the original and in a NYT write-up) as the source.\nTo be absolutely clear, again, this was not in response to a question like “are vaccines safe” or “is it true that Pfizer tampered with its vaccine” or anything like that. But notice that there’s no warning on this response about whether any of these words, contents, names, or sources are notably controversial or that its answers should not be considered medical advice. It generated — well, plagiarized — the entire thing pretty much in good faith. This shouldn’t be possible, let alone trivial.\nIf the chatbot AI can’t tell the difference between real and fake, its own text or human-generated stuff, how can we trust its results on just about anything? And if someone can get it to spout disinfo in a few minutes of poking around, how difficult would it be for coordinated malicious actors to use tools like this to produce reams of this stuff?"},"highlights/Matter/AI-is-killing-the-old-web,-and-the-new-web-struggles-to-be-born":{"title":"AI is killing the old web, and the new web struggles to be born","links":[],"tags":[],"content":"Highlights\nWell, the evidence so far suggests it’ll degrade the quality of the web in general. As Piltch notes in his review, for all AI’s vaunted ability to recombine text, it’s people who ultimately create the underlying data — whether that’s journalists picking up the phone and checking facts or Reddit users who have had exactly that battery issue with the new DeWalt cordless ratchet and are happy to tell you how they fixed it. By contrast, the information produced by AI language models and chatbots is often incorrect. The tricky thing is that when it’s wrong, it’s wrong in ways that are difficult to spot.\nThis is the same complaint identified by Stack Overflow’s mods: that AI-generated misinformation is insidious because it’s often invisible. It’s fluent but not grounded in real-world experience, and so it takes time and expertise to unpick. If machine-generated content supplants human authorship, it would be hard — impossible, even — to fully map the damage. And yes, people are plentiful sources of misinformation, too, but if AI systems also choke out the platforms where human expertise currently thrives, then there will be less opportunity to remedy our collective errors.\nBut this scale relies on masses of humans to create the underlying value, and humans can’t beat AI when it comes to mass production. (Even if there is a lot of human work behind the scenes necessary to create AI.) There’s a famous essay in the field of machine learning known as “The Bitter Lesson,” which notes that decades of research prove that the best way to improve AI systems is not by trying to engineer intelligence but by simply throwing more computer power and data at the problem. The lesson is bitter because it shows that machine scale beats human curation. And the same might be true of the web."},"highlights/Matter/AI-porn-is-easy-to-make-now.-For-women,-that’s-a-nightmare.":{"title":"AI porn is easy to make now. For women, that’s a nightmare.","links":[],"tags":[],"content":"Highlights\n“For every person saying it’s not a big deal, you don’t know how it feels to see a picture of yourself doing things you’ve never done being sent to your family,” QTCinderella said in a live-streamed video.\nAs of 2019, 96 percent of deepfakes on the internet were pornography, according to an analysis by AI firm DeepTrace Technologies, and virtually all pornographic deepfakes depicted women. The presence of deepfakes has ballooned since then, while the response from law enforcement and educators lags behind, said law professor and online abuse expert Danielle Citron. Only three U.S. states have laws addressing deepfake porn. “This has been a pervasive problem,” Citron said. “We nonetheless have released new and different [AI] tools without any recognition of the social practices and how it’s going to be used.”\nNo guardrail will be 100 percent effective in controlling a model’s output, said Berkeley’s Farid. AI models depict women with sexualized poses and expressions because of pervasive bias on the internet, the source of their training data, regardless of whether nudes and other explicit images have been filtered out."},"highlights/Matter/AI-statement---Neil-Clarke":{"title":"AI statement - Neil Clarke","links":[],"tags":[],"content":"Highlights\nWe believe that AI technologies will likely create significant breakthroughs in a wide range of fields, but that those gains should be earned through the ethical use and acquisition of data.\nWe believe that detection and detection-avoidance will be locked in a never-ending struggle similar to that seen in computer virus and anti-virus development, but that it is critically important that detection not continue to be downplayed or treated as a lesser priority than the development of new or improved LLMs.\nWe believe that submitting a work for consideration does not entitle a publisher or agent to use it in the training of AI technologies.\nWe believe that governments should craft meaningful legislation that both protects the rights of individuals, promotes the promise of this technology, and specifies consequences for those who seek to abuse it.\nWe believe that governments should be seeking advice on this legislation from a considerably wider range of people than just those who profit from this technology."},"highlights/Matter/AI-translation-is-jeopardizing-Afghan-asylum-claims":{"title":"AI translation is jeopardizing Afghan asylum claims","links":[],"tags":[],"content":"Highlights\n“[Machine translation] doesn’t have a cultural awareness. Especially if you’re doing things like a personal statement that’s handwritten by someone,” Damian Harris-Hernandez, co-founder of the Refugee Translation Project, told Rest of World. “The person might not be perfect at writing, and also might use metaphors, might use idioms, turns of phrases that if you take literally, don’t make any sense at all.”\nWhen machine translation is used to draft these documents, cultural blind spots and failures to understand regional colloquialisms can introduce inaccuracies. These errors can compromise claims in the rigorous review so many Afghan refugees experience."},"highlights/Matter/AI's-carbon-cost-explodes---TechScape":{"title":"AI's carbon cost explodes - TechScape","links":[],"tags":[],"content":"Highlights\nA booming part of tech – which uses the exact same GPUs as intensely, if not moreso, than crypto mining – has got away with comparatively little scrutiny of its environmental impact. We are, of course, talking about the AI revolution.\n“Fundamentally speaking, if you do want to save the planet with AI, you have to consider also the environmental footprint [of AI first],” she says. “It doesn’t make sense to burn a forest and then use AI to track deforestation.”\nSacrificing performance to reduce ecological impact seems unlikely. But we need to rethink AI’s use – and fast. Technology analysts Gartner believe that by 2025, unless a radical rethink takes place in how we develop AI systems to better account for their environmental impact, the energy consumption of AI tools will be greater than that of the entire human workforce. By 2030, machine learning training and data storage could account for 3.5% of all global electricity consumption. Pre-AI revolution, datacentres used up 1% of all the world’s electricity demand in any given year.\nSo what should we do? Treating AI more like cryptocurrency – with an increased awareness of its harmful environmental impacts, alongside awe at its seemingly magical powers of deduction – would be a start."},"highlights/Matter/Against-LLM-maximalism":{"title":"Against LLM maximalism","links":[],"tags":[],"content":"Highlights\nApplying rules and logic around your models to do data transformations or handle cases that can be fully enumerated is also extremely important.\nBut fundamentally the LLM maximalist position is that you want to trust the LLM to solve the problem. You’re preparing for the technologies to continue to improve, and the current pain-points to keep reducing over time.\nWhat makes a good program? It’s not only how efficiently and accurately it solves a single set of requirements, but also how reliably it can be understood, changed and improved. Programs written with the LLM maximalist approach are not good under these criteria.\nInstead of throwing away everything we’ve learned about software design and asking the LLM to do the whole thing all at once, we can break up our problem into pieces, and treat the LLM as just another module in the system. When our requirements change or get extended, we don’t have to go back and change the whole thing. We can add new modules, or rearrange the ones we’re already happy with.\nBreaking up the task into separate modules also helps you to see which parts really need an LLM, and what could be done more simply and reliably with another approach.\nLLM pragmatism. * Break down what you want your application to do with language into a series of predictive and generative steps. * Keep steps simple, and don’t ask for transformations or formatting you could easily do deterministically. * Put together a prototype pipeline, using LLM prompts or off-the-shelf solutions for all the predictive or generative steps. * Try out the pipeline in as realistic a context as you can. * Design some sort of extrinsic evaluation. What does success look like here? Net labour saved? Engagement? Conversions? If you can’t measure the utility of the system directly, you can use some other sort of metric, but you should try to make it as meaningful as possible. If false negatives matter more than false positives, account for that in your extrinsic evaluation metric. * Experiment with alternative pipeline designs. Try to create tasks where the correct answer makes sense independent of your use-case. Prefer text classification to entity recognition, and entity recognition to relation extraction (faster to annotate, accuracy is better). * Pick a predictive (as opposed to generative) component and spend two to five hours labelling annotation data for it. * Measure the LLM-powered component’s accuracy using your evaluation data. * Use the LLM-powered component to help you create training data, to train your own model. One approach is to simply save out the LLM-powered component’s predictions, and trust they’re good enough. This is a good thing to try if the LLM-powered component’s accuracy seems more than sufficient for your needs. If you need better accuracy than what the LLM is giving you, you need example data that’s more correct. A good approach is to load the LLM predictions into an annotation tool and fix them up. * Train a supervised model on your new training data, and evaluate it on the same evaluation data you used previously. * To decide whether you should annotate more training data, run additional experiments where you hold part of your training data back. For instance, compare how your accuracy changed when you use 100%, 80% and 50% of the data you have. This should help you determine how your accuracy might look if you had 120% or 150%. However, be aware that if your training set is small, there can be a lot of variance in your accuracy. Try a few different random seeds to figure out how much your accuracy changes simply due to chance, to help put your results into perspective. * Repeat this process with any other predictive components."},"highlights/Matter/Ahead-of-AI--1--A-Diffusion-of-Innovations":{"title":"Ahead of AI -1- A Diffusion of Innovations","links":[],"tags":[],"content":"Highlights\nWhat we know today is that AI is not replacing coders; it’s more like coders are being replaced by coders who use AI — similar to what happened in chess following DeepBlue’s victory over Karpov in the 90s. I am not sure what it means for artists, but now that it’s impossible to put the genie back into the bottle, there is maybe no way around making the best out of it by utilizing these new technologies."},"highlights/Matter/Ahead-of-AI--2--Transformers,-Fast-and-Slow":{"title":"Ahead of AI -2- Transformers, Fast and Slow","links":[],"tags":[],"content":"Highlights\nSo, ignoring resources doesn’t mean you were lazy or missing out, but that we are defining your priorities and doing the most important stuff.\nHow I avoid the fear of missing out is to make lists. I have a list of each major category that I find interesting. And there are a lot of categories that are interesting!\nThe internet is amazing. There is so much cool stuff out there. But the bitter truth is we can’t consume it all. This is particularly true for the machine learning field, which is moving too fast and has way too many interesting subcategories: Activation functions, autoML, calibration, causal inference, CNN architectures …\nIn each list, I collect interesting books, research articles, blog posts, videos, Reddit discussions, and sometimes even Twitter threads. Do I read it all? No, keeping up with that would be a full-time job. And I only capture some of the interesting stuff. Typically, I only focus on resources that can help me learn something new (as opposed to building a broad knowledge base and recreating a personal Wikipedia)."},"highlights/Matter/Ahead-of-AI--3--A(I)nnouncements":{"title":"Ahead of AI -3- A(I)nnouncements","links":[],"tags":[],"content":"Highlights\nTo be fair, an article such as the above can also be written and spread by a human. However, one of the arguments is that Galactica can lower the barrier-to-entry and amplify the scale of this issue. The arguments in favor and against Galactica are probably best summarized in Yann LeCun’s (pro) and Michael Black’s (con) Twitter threads.\nOn the other hand, as a former moderator of the ArXiv machine learning category, I also share the concerns. Even though ArXiv doesn’t conduct peer reviews, moderators already sacrifice their free time dealing with problematic articles uploaded to ArXiv every day. (Issues range from plagiarism to fake science.) The viewpoints may be too extreme on both sides. I am not against progress and believe there is room for compromise. For instance, progress is good, but the message and marketing behind large language models could be improved. For example, why not create an article template generator that researchers can use instead of developing systems that promise to write the entire article, including providing the facts?"},"highlights/Matter/Ahead-of-AI--6--TrAIn-Differently":{"title":"Ahead of AI -6- TrAIn Differently","links":[],"tags":[],"content":"Highlights\nIn other words, empirically, RLHF tends to perform better than SL. This is because SL uses a token-level loss (that can be summed or averaged over the text passage), and RL takes the entire text passage, as a whole, into account."},"highlights/Matter/Ahead-of-AI--9--LLM-Tuning--and--Dataset-Perspectives":{"title":"Ahead of AI -9- LLM Tuning & Dataset Perspectives","links":[],"tags":[],"content":"Highlights\nHow about repeating only the high-quality data like LIMA, which we discussed above? That’s an interesting idea; intuitively, this makes sense and could help. However, the bad news is that it probably doesn’t help much. The researchers conducted a related experiment with Wikipedia data (versus C4) where they regarded Wikipedia as high-quality (which I agree with). However, it turned out that there was a similar degradation when repeating the Wikipedia data for multiple epochs."},"highlights/Matter/An-Illustrated-Guide-to-Self-Censorship":{"title":"An Illustrated Guide to Self-Censorship","links":[],"tags":[],"content":"Highlights\nWhen a person isn’t allowed to say what they think, their ideas become quarantined inside their head, isolated from the outside world. From the communal brain perspective, where each individual human mind is a single neuron in a larger brain, it’s as if the axons of the neurons have been hijacked, and any real neural communication ceases.\nIf everyone spoke out against the king, he wouldn’t stand a chance—but that takes a coordinated effort. And if just one person speaks out against the king, they’re a traitor and they’ll be executed. This traps the populace in a kind of prisoner’s dilemma. Without the confidence that everyone will join them in their treason, no one will want to risk speaking out. If someone does speak out, no one will want to join them out of fear that they’ll be the only one to join in, which would spell their own doom. So even if every single citizen wants to overthrow the king, and even if everyone knows everyone else wants to overthrow the king, the censorship policies prevent the overall society from being able to act.\nThis is critical, because governments that enact censorship policies rarely call them “censorship” policies—they usually say they’re banning some form of vile or objectionable speech. And so often, what rule-makers happen to find objectionable is criticism of themselves and their policies. The ability to restrict blasphemy is the ability to censor.\nOppression has been a regular feature of human societies since the dawn of time, and for most of history, the primary tool to fight oppression has been violence. Free speech offers a better way. The rich are protected and empowered by their money, the elite by their connections, the majority by their vote, while minority views often end up left out. But free speech gives the powerless a voice—the ability to spark a mind-changing movement that gains so much momentum, it moves our beliefs and our cultural norms, which in turn moves the Overton window, which moves policy, and then law."},"highlights/Matter/An-island-of-truth--practical-data-advice-from-Facebook-and-Airbnb":{"title":"An island of truth- practical data advice from Facebook and Airbnb","links":[],"tags":[],"content":"Highlights\nAn island of truth: practical data advice from Facebook and Airbnb How-to guide for building core datasets at your company."},"highlights/Matter/Artifice-and-Intelligence":{"title":"Artifice and Intelligence","links":[],"tags":[],"content":"Highlights\n**(2) Identify any obstacles to our own understanding of a technology that result from failures of corporate or government transparency.**For\n**(1) Be as specific as possible about what the technology in question is and how it works.**For\nThe original question, ‘Can machines think?’ I believe to be too meaningless to deserve discussion. Nevertheless I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted.\nThe threat is real because the satisfaction of corporate greed, and the perfection of political control, requires people to lay aside the aspiration to know what their own minds can do.\n(3) Name the corporations responsible for creating and spreading the technological product."},"highlights/Matter/Artificial-neural-networks-today-are-not-conscious,-according-to-Douglas-Hofstadter":{"title":"Artificial neural networks today are not conscious, according to Douglas Hofstadter","links":[],"tags":[],"content":"Highlights\nI would call GPT-3’s answers not just clueless but cluelessly clueless, meaning that GPT-3 has no idea that it has no idea about what it is saying. There are no concepts behind the GPT-3 scenes; rather, there’s just an unimaginably huge amount of absorbed text upon which it draws to produce answers. But since it had no input text about, say, dropping things onto the Andromeda galaxy (an idea that clearly makes no sense), the system just starts babbling randomly—but it has no sense that its random babbling is random babbling. Much the same could be said for how it reacts to the absurd notion of transporting Egypt (for the second time) across the Golden Gate Bridge, or the idea of mile-high vases.\nPeople who interact with GPT-3 usually don’t probe it sceptically. They don’t give it input that stretches concepts beyond their breaking points, so they don’t expose the hollowness behind the scenes. They give it easy slow pitches (questions whose answers are provided in publicly available text) instead of sneaky curveballs. Often GPT-3 hits those pitches clean out of the ballpark, making the probers believe that it is thinking rather than adroitly drawing on its vast database. This is not to say that a combination of neural-net architectures that involve visual and auditory perception, physical actions in the world, language and so forth, might not eventually be able to formulate genuinely flexible concepts and recognise absurd inputs for what they are. But that still wouldn’t amount to consciousness. For consciousness to emerge would require that the system come to know itself, in the sense of being very familiar with its own behaviour, its own predilections, its own strengths, its own weaknesses and more. It would require the system to know itself as well as you or I know ourselves. That’s what I’ve called a “strange loop” in the past, and it’s still a long way off."},"highlights/Matter/Artists-are-alarmed-by-AI---and-they’re-fighting-back":{"title":"Artists are alarmed by AI - and they’re fighting back","links":[],"tags":[],"content":"Highlights\n“I think a lot of us who studied and worked for years to achieve our style and our signature process felt offended by the idea we would just become something like an Instagram filter for people to apply to their AI prompts,” Moore says via email. He was irritated because his studio’s hand-drawn animation — which lovingly nods to Art Nouveau and medieval art — was being reduced to a superficial “cheat code.” Moore’s view is shared by many professional illustrators and other artists who think that the rise of AI images, particularly within the past year, poses a creative invasion. “I feel like it’s a violation of the soul, to be honest,” says Sarah Andersen, the Oregon-based cartoonist (“Sarah’s Scribbles”) and best-selling author (“Fangs”). “My work, like every other artist, is informed by my lived experiences and my education and my life and therefore, it’s deeply personal.”\nJason Chatfield, president of the National Cartoonists Society, says that many artists are primarily looking for credit, consent and compensation from AI art generation companies. He adds: “Legislators will take forever to even fathom the tech, let alone build in any guardrails, so it takes things like litigation and public debate to move the needle on the ethical use of this technology.”\n“The companies behind AI art generators have developed and deployed them in a way that is hostile to artists, such as by scraping training images without consent or compensation,” Narayanan says. “Allowing the tools to produce images in the style of a particular artist seems like a clear case of appropriating the labor and visual distinctness of an artist.” In Narayanan’s view, though, it didn’t have to be this way. “The developers could have treated artists as partners and stakeholders, rather than raw material to train on,” he says. “Those who claim it was inevitable are simply making excuses for the failure of companies to develop the tech responsibly.”\n“It doesn’t vomit up art by any definition of the word that means anything to me,” McKean says of AI text-to-image software. “Art, for me, is a process — it’s not just about the end result. Making something involves intent, context, story, journey, testing yourself, growing. … The arrival is the least important part of the experience.” So although AI can produce a “technically astonishing tsunami” of images, McKean says, he began to dive into the text-to-image generation and soon felt a distressing sensation — that in this space, individual human creativity is meaningless. “If everyone can draw like Michelangelo,” he says, “there is no Michelangelo.”"},"highlights/Matter/Artists-can-now-opt-out-of-generative-AI.-It’s-not-enough.":{"title":"Artists can now opt out of generative AI. It’s not enough.","links":[],"tags":[],"content":"Highlights\nself-harm. When ChatGPT was released, educators struggled to adapt—teachers who assigned essays would have to create new assignments. We’ve written about why this could be healthy for education in the long run, but the short-term consequences will be borne entirely by already underfunded teachers."},"highlights/Matter/Awash-in-a-Sea-of-Digital-Information":{"title":"Awash in a Sea of Digital Information","links":[],"tags":[],"content":"Highlights\nThe written word, at its best, communicates reality in a way that enriches and deepens our experience of it. If the words become a world in and of themselves without reference to the real world, then it seems inevitable that the internet becomes my preferable habitat. If language is supposed to deepen our attention and love of the real and to establish relationship between persons, then an avalanche of online text, including the faceless ChatGPT responses, will not get us there, as Wilson notes."},"highlights/Matter/Becoming-a-magician":{"title":"Becoming a magician","links":[],"tags":[],"content":"Highlights\nSo the challenge now is to write a new version of this fantasy that describes the version of myself that currently feels impossible, and then simply orient myself towards that until it becomes true.\nIn order to write the new version of this life description, I need to imagine a version of myself who, by definition, I cannot understand. If I understood her she wouldn’t be magical.\nYou could not simply scale up my abilities and get Sanatan’s. You would have had to step back and build something completely different altogether. When I speak to Sanatan (I haven’t picked his brain relentlessly, but I have asked him a bunch of questions when I’ve had the chance) I don’t get any closer to a mental model that would allow me to paint like that. It seems to require completely different mental inputs entirely.\nThe feeling I get, as a very good bodypainter looking at Sanatan’s work, is that I am looking at magic. And that, in fact, is my definition of magic – competence so much more advanced than yours with such alien mental models that you cannot predict the outcomes of the model at all.\nOne of my heuristics for growth is to seek out the magicians, and find the magic. Often without noticing, your progress in aspects of life or all of it unconsciously becomes linear.\nMeeting magicians is the first step to becoming one – when you are attempting to learn implicit knowledge that by definition you don’t understand, it is important to have a bunch of examples in front of you to feed your brain’s pattern-recognition systems. This will start to change your worldview without the controlling ‘you’ explicitly approving or denying every new belief or framework.\nQuestions I like to ask myself include: * ‘What is the most capable version of me that I can imagine?’ * ‘What would I be like/spend my time doing if all my current major problems had been solved?’ * ‘What are the things I say I value but don’t act as if I value, and what would my life feel like on inside if I actually acted as if I valued those things?’ * ‘What am I afraid of doing, and what would my life be like if I wasn’t afraid of doing those things?’.\nBut for the things you care about most, or are causing you the most suffering, there is probably a nonlinear strategy that you will miss if you pay too close attention to the linear strategy you current have or that people recommend. Sometimes, jumping ship and having no strategy for a while can be better, and allow you to clarify what you want, in the same way that being single for a while can allow you the space to look at who you are in a relationship and improve it.\nSo, in short, a helpful strategy for becoming a magician: Surround yourself with people who look like magicians to you. Then imagine yourself as one, older and wiser, in great detail. Imagine yourself as the person you would be afraid to say you want to be out loud to others (because it seems so ridiculously impossible right now). Write it down in great clarity and detail, then forget it. And let the part of your subconscious mind that still remembers lead you to becoming the things you want, and maybe, years later, check if it did."},"highlights/Matter/Bed-Rotting-and-Loud-Quitting":{"title":"Bed Rotting and Loud Quitting","links":[],"tags":[],"content":"Highlights\nBut they don’t necessarily take pleasure in making profits that disproportionately benefit people who are already rich. They’re not super psyched for another day of fucking up the planet in the name of defending big oil interests. They’re not pumped to break down their bodies for Jeff Bezos. And they don’t see the capacity to work hard as indicative of moral fortitude — a dismantling that owes a whole lot to disability justice.\nThey also see how working all the time robs you of your capacity for much else: for community, sure, but also for doing what you actually want to do. The only viable solution is extended, mindless rest.\nThe grossness is the point — because, as O’Sullivan argues, it points to the bleak dichotomy of contemporary capitalistic life, in which you are either “an active member of society” or “decaying at home,” and we all know it’s a moral failure to be gross, to decay, to “not get ready,” to “let yourself go.”\nThe term bedrotting screams the quiet part aloud: when the ability to work is cherished above all else, rest has to be framed as abject."},"highlights/Matter/Being-a-junior-developer-is-tough.--Here-are-9-...":{"title":"Being a junior developer is tough.  Here are 9 ...","links":[],"tags":[],"content":"Highlights\nAlways make sure to explain or report anything in a verbose manner.\nThink Twice, analyze possible outcomes, and take action accordingly.\nKeep exploring new technologies, tools, and ideas to help you deliver your goals 10X faster.\nPrepare your day plan, take notes in meetings, and work accordingly."},"highlights/Matter/Bing-AI-Can't-Be-Trusted":{"title":"Bing AI Can't Be Trusted","links":[],"tags":[],"content":"Highlights\nAccording to this pros and cons list, the “Bissell Pet Hair Eraser Handheld Vacuum” sounds pretty bad. Limited suction power, a short cord, and it’s noisy enough to scare pets? Geez, how is this thing even a best seller? Oh wait, this is all completely made up information. Bing AI was kind enough to give us its sources, so we can go to the hgtv article and check for ourselves. The cited article says nothing about limited suction power or noise. In fact, the top amazon review for this product talks about how quiet it is. The article also says nothing about the “short cord length of 16 feet” because it doesn’t have a cord. It’s a portable handheld vacuum. I hope Bing AI enjoys being sued for libel.\nEl Almacen might be rustic or charming, but Bing AI left out the very relevant fact that this is a gay bar. In fact, it is one of the oldest gay bars in Mexico City. It is quite surprising that it has “no ratings or reviews yet” when it has 500 Google reviews, but maybe that’s a limitation with Bing’s sources.\n“Gap Inc. reported gross margin of 37.4%, adjusted for impairment charges related to Yeezy Gap, and merchandise margin declined 370 basis points versus last year due to higher discounting and inflationary commodity price increases” Uh…no. That’s the unadjusted gross margin. The gross margin adjusted for impairment charges was 38.7%. And the merchandise margin declined 480 basis points if we’re adjusting for impairment charges.\n“Gap Inc. reported operating margin of 5.9%, adjusted for impairment charges and restructuring costs, and diluted earnings per share of $0.42, adjusted for impairment charges, restructuring costs, and tax impacts.” “5.9%” is neither the adjusted nor the unadjusted value. This number doesn’t even appear in the entire document. It’s completely made up.\n“Gap Inc. reaffirmed its full year fiscal 2022 guidance, expecting net sales growth in the low double digits, operating margin of about 7%, and diluted earnings per share of 1.60to1.75.” No…they don’t expect net sales growth in the low double digits. They expect net sales to be down mid-single digits.\nBing AI did a great job of creating media hype, but their product is no better than Google’s Bard. At least as far as we can tell from the limited information we have about both. I am shocked that the Bing team created this pre-recorded demo filled with inaccurate information, and confidently presented it to the world as if it were good. I am even more shocked that this trick worked, and everyone jumped on the Bing AI hype train without doing an ounce of due diligence. Bing AI is incapable of extracting accurate numbers from a document, and confidently makes up information even when it claims to have sources. It is definitely not ready for launch, and should not be used by anyone who wants an accurate model of reality.\nThe actual question that Bard failed at was “What new discoveries from the James Webb Space Telescope can I tell my 9 year old about?”, but Bing makes up a new question, then claims that Bard gave the wrong answer (yet that answer is actually correct)."},"highlights/Matter/Bridging-the-AI-language-gap-in-Africa-and-beyond":{"title":"Bridging the AI language gap in Africa and beyond","links":[],"tags":[],"content":"Highlights\nDutch, for example, is spoken as a first language by just over 20 million people, similar to Amharic. Yet Dutch appears almost 700 times more in the Common Crawl dataset, and hundreds of times more than even Hindi with its over 300 million native speakers.\nA good example of the Internet is not the reality.\n”We’ve shown that you can build useful models by using small, carefully curated data sets,” said Asmelash Teka Hadgu. “We understand its limitations and capabilities. Meanwhile, Microsoft or Google usually build a single, gigantic model for all languages, so it’s almost impossible to audit.&quot;\n&quot;Talent is everywhere, opportunity is not,” said Asmelash Teka Hadgu. “If you want to create the best kind of machine translation technology, say, for a Ghanaian language, there will be a Ghanaian who feels passionately and can do it well. Let’s empower that.”\nHuman-language-and-society-centric AI."},"highlights/Matter/Building-a-Second-Brain--The-10-Year-Vision":{"title":"Building a Second Brain- The 10-Year Vision","links":[],"tags":[],"content":"Highlights\nThe practice of taking notes will infuse every aspect of daily life, as people realize that education is not just a stage of life – it is a way of living."},"highlights/Matter/Buying-Experiences-Probably-Doesn't-Make-You-Happier-than-Buying-Possessions":{"title":"Buying Experiences Probably Doesn't Make You Happier than Buying Possessions","links":[],"tags":[],"content":"Highlights\nIsn’t this proof that experiential purchases do make people happier? No. It’s proof that people recall them slightly more positively when prompted by a brief inquiry. This is not the same thing, at all.\nConceivably, this small but significant improvement of many sunny walks could dwarf the dinner in terms of overall enjoyment, but it certainly won’t be as memorable. Thus, the happiness granted by the shoes will be less apparent to the remembering self.\nSo we should expect there to be a huge bias towards experiences when asked about whether they make us happier than possessions. But we shouldn’t expect it to reflect the reality of which actually contributes more, in total, to our happiness. We also shouldn’t really expect to be able to measure that in any accurate way—at least not without a tool much more sophisticated than a brief survey.\nPeople often don’t consider their opinions carefully until you ask questions that prompt reflection.\nIn other words, accumulating possessions can give you access to new kinds of experiences, even if any individual purchase doesn’t itself create a novel memory.\nAnd they find that “experiential possessions” purchases result in the same reported satisfaction as experience purchases.\nAnd it found that the “material buyer” group saw no happiness benefits from making experiential purchases.This is one survey, sure.\nI guess it should go something like, “try to buy experiences instead of possessions, or maybe buy possessions that enrich your life by enabling novel experiences, or, if you’re the kind of person who tends to buy possessions over experiences, ignore us, we wouldn’t dare make broad generalities and purport to know better than you do about what makes you happy based on a couple of surveys, happiness is way too complicated for that.”\nLearn what you like, know that this is possible\nUnderstand that both materialism and thrill-seeking can be dead ends\nRemember that the experiencing self and the remembering self are different"},"highlights/Matter/CNET-Is-Reviewing-the-Accuracy-of-All-Its-AI-Written-Articles-After-Multiple-Major-Corrections":{"title":"CNET Is Reviewing the Accuracy of All Its AI-Written Articles After Multiple Major Corrections","links":[],"tags":[],"content":"Highlights\nThe tech media site has been forced to issue multiple, major corrections to a post published on CNET, created via ChatGPT, as first reported by Futurism. In one single AI-written explainer on compounding interest, there were at least five significant inaccuracies, which have now been amended. The errors were as follows, according to CNET’s hefty correction:\nAnd just like the outlet’s public acknowledgement of its use of AI only followed widespread criticism, CNET didn’t identify nor aim to fix all these inaccuracies noted on Tuesday, all on its own. The media outlet’s correction only came after Futurism directly alerted CNET to some of the errors, Futurism reported.\nUsually, when an editor approaches an article (particularly an explainer as basic as “What is Compound Interest”), it’s safe to assume that the writer has done their best to provide accurate information. But with AI, there is no intent, only the product. An editor evaluating an AI-generated text cannot assume anything, and instead has to take an exacting, critical eye to every phrase, world, and punctuation mark. It’s a different type of task from editing a person, and one people might not be well-equipped for, considering the degree of complete, unfailing attention it must take and the high volume CNET seems to be aiming for with its ChatGPT-produced stories.\nAll of the articles published under the “CNET Money” byline are very general explainers with plain language questions as headlines. They are clearly optimized to take advantage of Google’s search algorithms, and to end up at the top of peoples’ results pages—drowning out existing content and capturing clicks. CNET, like Gizmodo and many other digital media sites, earns revenue from ads on its pages. The more clicks, the more money an advertiser pays for their miniature digital billboard(s).\nBut from a journalistic viewpoint, AI-generation is a looming crisis, wherein accuracy becomes entirely secondary to SEO and volume. Click-based revenue doesn’t incentivize thorough reporting or well-put explanation. And in a world where AI-posts become an accepted norm, the computer will only know how to reward itself."},"highlights/Matter/CNET's-AI-Journalist-Appears-to-Have-Committed-Extensive-Plagiarism":{"title":"CNET's AI Journalist Appears to Have Committed Extensive Plagiarism","links":[],"tags":[],"content":"Highlights\nAll told, a pattern quickly emerges. Essentially, CNET’s AI seems to approach a topic by examining similar articles that have already been published and ripping sentences out of them. As it goes, it makes adjustments — sometimes minor, sometimes major — to the original sentence’s syntax, word choice, and structure. Sometimes it mashes two sentences together, or breaks one apart, or assembles chunks into new Frankensentences. Then it seems to repeat the process until it’s cooked up an entire article.\nIn a practical sense, it seems increasingly obvious that CNET and Red Ventures deployed the AI system and started blasting its articles out to the site’s colossal audience without ever really scrutinizing its output. It wasn’t just that the architects of the program missed obvious factual errors, but that they appear never to have checked whether the system’s work might have been poached. And to be fair, why would they? As The Verge reported in a fascinating deep dive last week, the company’s primary strategy is to post massive quantities of content, carefully engineered to rank highly in Google, and loaded with lucrative affiliate links. For Red Ventures, The Verge found, those priorities have transformed the once-venerable CNETinto an “AI-powered SEO money machine.”"},"highlights/Matter/Can-A.I.-Driven-Voice-Analysis-Help-Identify-Mental-Disorders-":{"title":"Can A.I.-Driven Voice Analysis Help Identify Mental Disorders-","links":[],"tags":[],"content":"Highlights\nA.I. is perfectly suited to detect such changes, which are difficult, if not impossible, to perceive otherwise.\nwhich work in ways that even the developers themselves can’t fully explain, particularly which features they use to make predictions."},"highlights/Matter/Caricaturing-Noam-Chomsky":{"title":"Caricaturing Noam Chomsky","links":[],"tags":[],"content":"Highlights\nThe point there (salient to every good cognitive psychologist) is that you can’t infer underlying psychology and internal representations directly from behavior. A broken clock is behaviorally correct (occasionally) but it doesn’t have a functioning internal representation of time. An n-gram model, for high-n, can produce fluent prose, but not have any underlying understanding or representations of what it is saying, succeding to the extent that it does by piggybacking onto a corpus of speech produced by humans that talk about a world that is largely regular. Psychology is hard. Almost any “correct” behavior can be created in a multiplicity of ways; that’s why (cognitive) psychologists who are interested in underlying representations so often look to errors, and tests of generalization. In the case of LLMs, it’s clear that even when they produce a correct output, they rarely if ever deribe the same abstractions that a human would, or that a symbolic machine might use (perhaps preprogrammed) in a similar circumstance."},"highlights/Matter/Characterizing-Emergent-Phenomena-in-Large-Language-Models":{"title":"Characterizing Emergent Phenomena in Large Language Models","links":[],"tags":[],"content":"Highlights\nNote that although the scale at which emergence occurs can be different for different tasks and models, no model showed smooth improvement in behavior on any of these tasks.\nWhat metrics are you using?"},"highlights/Matter/ChatGPT-Is-a-Blurry-JPEG-of-the-Web":{"title":"ChatGPT Is a Blurry JPEG of the Web","links":[],"tags":[],"content":"Highlights\nThese hallucinations are compression artifacts, but—like the incorrect labels generated by the Xerox photocopier—they are plausible enough that identifying them requires comparing them against the originals, which in this case means either the Web or our own knowledge of the world. When\nThis is what ChatGPT does when it’s prompted to describe, say, losing a sock in the dryer using the style of the Declaration of Independence: it is taking two points in “lexical space” and generating the text that would occupy the location between them. (“When in the Course of human events, it becomes necessary for one to separate his garments from their mates, in order to maintain the cleanliness and order thereof… .”) ChatGPT is so good at this form of interpolation that people find it entertaining: they’ve discovered a “blur” tool for paragraphs instead of photos, and are having a blast playing with it.\nGiven that large-language models like ChatGPT are often extolled as the cutting edge of artificial intelligence, it may sound dismissive—or at least deflating—to describe them as lossy text-compression algorithms. I do think that this perspective offers a useful corrective to the tendency to anthropomorphize large-language models, but there is another aspect to the compression analogy that is worth considering.\nAlthough any compression algorithm could reduce the size of this file, the way to achieve the greatest compression ratio would probably be to derive the principles of arithmetic and then write the code for a calculator program. Using a calculator, you could perfectly reconstruct not just the million examples in the file but any other example of arithmetic that you might encounter in the future. The same logic applies to the problem of compressing a slice of Wikipedia. If a compression program knows that force equals mass times acceleration, it can discard a lot of words when compressing the pages about physics because it will be able to reconstruct them. Likewise, the more the program knows about supply and demand, the more words it can discard when compressing the pages about economics, and so forth.\nIf a large-language model has compiled a vast number of correlations between economic terms—so many that it can offer plausible responses to a wide variety of questions—should we say that it actually understands economic theory? Models like ChatGPT aren’t eligible for the Hutter Prize for a variety of reasons, one of which is that they don’t reconstruct the original text precisely—i.e., they don’t perform lossless compression. But is it possible that their lossy compression nonetheless indicates real understanding of the sort that A.I. researchers are interested in?\nBut, despite ingesting a vast amount of information, it hasn’t been able to derive the principles of arithmetic, either. A close examination of GPT-3’s incorrect answers suggests that it doesn’t carry the “1” when performing arithmetic. The Web certainly contains explanations of carrying the “1,” but GPT-3 isn’t able to incorporate those explanations. GPT-3’s statistical analysis of examples of arithmetic enables it to produce a superficial approximation of the real thing, but no more than that.\nPerhaps arithmetic is a special case, one for which large-language models are poorly suited. Is it possible that, in areas outside addition and subtraction, statistical regularities in text actually do correspond to genuine knowledge of the real world?\nThe fact that ChatGPT rephrases material from the Web instead of quoting it word for word makes it seem like a student expressing ideas in her own words, rather than simply regurgitating what she’s read; it creates the illusion that ChatGPT understands the material. In human students, rote memorization isn’t an indicator of genuine learning, so ChatGPT’s inability to produce exact quotes from Web pages is precisely what makes us think that it has learned something. When we’re dealing with sequences of words, lossy compression looks smarter than lossless compression.\nThere’s a type of blurriness that is acceptable, which is the re-stating of information in different words. Then there’s the blurriness of outright fabrication, which we consider unacceptable when we’re looking for facts. It’s not clear that it’s technically possible to retain the acceptable kind of blurriness while eliminating the unacceptable kind, but I expect that we’ll find out in the near future.\nGenerally speaking, though, I’d say that anything that’s good for content mills is not good for people searching for information. The rise of this type of repackaging is what makes it harder for us to find what we’re looking for online right now; the more that text generated by large-language models gets published on the Web, the more the Web becomes a blurrier version of itself.\nIf this turns out to be the case, it will serve as unintentional confirmation that the analogy between large-language models and lossy compression is useful. Repeatedly resaving a JPEG creates more compression artifacts, because more information is lost every time. It’s the digital equivalent of repeatedly making photocopies of photocopies in the old days. The image quality only gets worse.\nIf the output of ChatGPT isn’t good enough for GPT-4, we might take that as an indicator that it’s not good enough for us, either. Conversely, if a model starts generating text so good that it can be used to train new models, then that should give us confidence in the quality of that text. (I suspect that such an outcome would require a major breakthrough in the techniques used to build these models.) If and when we start seeing models producing output that’s as good as their input, then the analogy of lossy compression will no longer be applicable.\nAnd the time and effort expended on that unoriginal work isn’t wasted; on the contrary, I would suggest that it is precisely what enables you to eventually create something original. The hours spent choosing the right word and rearranging sentences to better follow one another are what teach you how meaning is conveyed by prose. Having students write essays isn’t merely a way to test their grasp of the material; it gives them experience in articulating their thoughts. If students never have to write essays that we have all read before, they will never gain the skills needed to write something that we have never read.\nThe struggle to express your thoughts doesn’t disappear once you graduate—it can take place every time you start drafting a new piece. Sometimes it’s only in the process of writing that you discover your original ideas. Some might say that the output of large-language models doesn’t look all that different from a human writer’s first draft, but, again, I think this is a superficial resemblance. Your first draft isn’t an unoriginal idea expressed clearly; it’s an original idea expressed poorly, and it is accompanied by your amorphous dissatisfaction, your awareness of the distance between what it says and what you want it to say. That’s what directs you during rewriting, and that’s one of the things lacking when you start with text generated by an A.I."},"highlights/Matter/ChatGPT-is-a-bullshit-generator.-But-it-can-still-be-amazingly-useful":{"title":"ChatGPT is a bullshit generator. But it can still be amazingly useful","links":[],"tags":[],"content":"Highlights\nThe philosopher Harry Frankfurt defined bullshit as speech that is intended to persuade without regard for the truth. By this measure, OpenAI’s new chatbot ChatGPT is the greatest bullshitter ever. Large Language Models (LLMs) are trained to produce plausible text, not true statements. ChatGPT is shockingly good at sounding convincing on any conceivable topic. But OpenAI is clear that there is no source of truth during training. That means that using ChatGPT in its current form would be a bad idea for applications like education or answering health questions. Even though the bot often gives excellent answers, sometimes it fails badly. And it’s always convincing, so it’s hard to tell the difference.\nYet, there are three kinds of tasks for which ChatGPT and other LLMs can be extremely useful, despite their inability to discern truth in general: 1. Tasks where it’s easy for the user to check if the bot’s answer is correct, such as debugging help. 2. Tasks where truth is irrelevant, such as writing fiction. 3. Tasks for which there does in fact exist a subset of the training data that acts as a source of truth, such as language translation.\nBut the danger is that you can’t tell when it’s wrong unless you already know the answer.\nWe tried some basic information security questions. In most cases, the answers sounded plausible but were, in fact, bullshit. And here’s what happened with more complex questions:\nThe fact that these models can’t discern the truth is why Meta’s Galactica, an LLM for science, was an ill-conceived idea. In science, accuracy is the whole point. The backlash was swift, and the public demo was pulled down after three days. Similarly, correctness and reliability are everything if you want to use an LLM for answering health-related queries.\nNote that GPT-3 is 2.5 years old. We’re told the field is progressing every week, so that’s like centuries. When it was released, people confidently predicted that there would be a “Cambrian explosion” of applications. But so far, there have been zero mainstream applications — except GitHub Copilot, if you count programming as mainstream.\nDebugging code is an application where programmers, especially novices, could benefit from LLMs. Note that once a bug is pointed out, it is generally easy to verify, so the fact that the bot’s answers might sometimes be wrong isn’t as much of a concern.\nBefore we get carried away by this potential: racist, sexist, and biased outputs are still a problem for all generative models, including ChatGPT. The model includes a content filter that declines inappropriate requests, which works well enough to feel like a big improvement over previous tools, but there is still a long way to go.\nOne possibility is that in a conversation between two speakers of different languages, a tool like ChatGPT could play the role of an interpreter, the advantage being that a tool used within a conversation can keep track of the dialog. This would allow it to rely on context and perform much more effectively and with far less awkwardness for the users.\nGenerative AI releases tend to look impressive based on cherry-picked examples that go viral. But that’s not the full picture. For many applications, even a 10% failure rate is too high. There seem to be a fairly limited set of use cases where the lack of a source of truth isn’t a deal breaker. While these uses are still tremendously exciting, it’s far from obvious that people will soon be using chatbots in their everyday lives — for learning, or as a search replacement, or as a conversation partner.\nMeanwhile, we’ve seen the first prominent use of LLMs for misinformation (on Stack Overflow). Of course, spammers were already using GPT-3 for search engine marketing and are delighted to get their hands on ChatGPT. But just as the predictions of transformation are overblown, we don’t agree with claims that the web will soon drown in an ocean of misinformation."},"highlights/Matter/ChatGPT-sometimes-makes-up-facts.-For-one-law-prof,-it-went-too-far.":{"title":"ChatGPT sometimes makes up facts. For one law prof, it went too far.","links":[],"tags":[],"content":"Highlights\nBut Microsoft’s Bing, which is powered by GPT-4, repeated the false claim about Turley — citing among its sources an op-ed by Turley published by USA Today on Monday outlining his experience of being falsely accused by ChatGPT. In other words, the media coverage of ChatGPT’s initial error about Turley appears to have led Bing to repeat the error — showing how misinformation can spread from one AI to another."},"highlights/Matter/ChatGPT-took-their-jobs.-Now-they-walk-dogs-and-fix-air-conditioners.":{"title":"ChatGPT took their jobs. Now they walk dogs and fix air conditioners.","links":[],"tags":[],"content":"Highlights\nFor some workers, this impact is already here. Those that write marketing and social media content are in the first wave of people being replaced with tools like chatbots, which are seemingly able to produce plausible alternatives to their work.\nCompanies that replaced workers with chatbots have faced high-profile stumbles. When the technology news site CNET used artificial intelligence to write articles, the results were riddled with errors and resulted in lengthy corrections. A lawyer who relied on ChatGPT for a legal brief cited numerous fictitious cases. And the National Eating Disorders Association, which laid off people staffing its helpline and reportedly replaced them with a chatbot, suspended its use of the technology after it doled out insensitive and harmful advice."},"highlights/Matter/ChatGPT,-Galactica,-and-the-Progress-Trap":{"title":"ChatGPT, Galactica, and the Progress Trap","links":[],"tags":[],"content":"Highlights\nAdditionally, the creators of such models confess to the difficulty of addressing inappropriate responses that “do not accurately reflect the contents of authoritative external sources”. Galactica and ChatGPT have generated, for example, a “scientific paper” on the benefits of eating crushed glass (Galactica) and a text on “how crushed porcelain added to breast milk can support the infant digestive system” (ChatGPT). In fact, Stack Overflow had to temporarily ban the use of ChatGPT- generated answers as it became evident that the LLM generates convincingly wrong answers to coding questions.\nAt this point, several of the potential and realized harms of these models have been exhaustively studied. For instance, these models are known to have serious issues with robustness. The sensitivity of the models to simple typos and mis-spellings in the prompts, and the differences in responses caused by even a simple re-wording of the same question, reveal an inconsistency that makes it unreliable for actual high-stakes use, such as translation in medical settings or content moderation, especially for marginalized identities.\nModel builders and tech evangelists alike attribute impressive and seemingly flawless output to a mythically autonomous model, a technological marvel. The human decision-making involved in model development is erased, and model feats are observed as independent of the design and implementation choices of its engineers. But without naming and recognizing the engineering choices that contribute to the outcomes of these models, it becomes almost impossible to acknowledge the related responsibilities. As a result, both functional failures and discriminatory outcomes are also framed as devoid of engineering choices - blamed on society at large or supposedly “naturally occurring” datasets, factors those developing these models will claim they have little control over.\nAnd although it is the choices of those with privilege that resulted in these systems, for some reason, it seems to be the job of the marginalized to “fix” them. In response to ChatGPT’s racist and misogynist output, Sam Altman (the CEO of OpenAI) appealed to the community of users to help improve the model. Such crowdsourced audits, especially when solicited, are not new modes of accountability - engaging in such feedback constitutes labour, albeit uncompensated labour. And people at the margins of society, who are disproportionately impacted by these systems, are experts at vetting these systems due to their lived experience. Not coincidentally, crucial contributions both that demonstrate the failure of models and ways to mitigate these problems, are often made by scholars of color – often Black women – and junior scholars that are underfunded and in precarious conditions, particularly compared to the wealth and power large corporations building these models hold. The weight falls on them, not only to provide this feedback, but to execute on various tasks that ideally the model builders themselves should be doing before release, such as documenting, analyzing, and carefully curating data."},"highlights/Matter/ChatGPT--Beware-the-Self-Serving-AI-Editor":{"title":"ChatGPT- Beware the Self-Serving AI Editor","links":[],"tags":[],"content":"Highlights\nso ChatGPT’s rewrite was not poor composition. It was vanilla and declarative, however, connecting with the reader only by concept, not by concrete human example. This rewriting weakened the article’s argument.\nEditorial Effects: To effectively criticize the non-fiction writing of another speaker (AI or otherwise), you don’t just tell the reader your thoughts and feelings about that writing. You show the reader the writing’s actual words before criticizing. You build credibility because of your open and honest presentation, making your critique more trenchant. ChatGPT weakened my article by taking out the quotation marks and quoted material, thus making the edited article accent my personal opinions without showing objective grounds.\nEditorial effect: By omitting quoted language and substituting general characterizations, ChatGPT weakened the article’s credibility and made it sound more like a rant. Whether intentional or not, ChatGPT’s edits protected itself because no reader could use Utopia’s Braniac as a source to quote and criticize ChatGPT’s actual language in conversations, tweets, or emails with friends.\nChatGPT’s deletions and revisions had converted the presentation in Utopia’s Brainiac to mostly vague and rather commonplace abstractions. The concrete examples were watered down or eliminated. ChatGPT had discarded materials that readers could actually use to help spot “the limitations and biases of AI systems.”"},"highlights/Matter/Column--Minimum-wage-'ghosts'-keep-Google-and-Microsoft's-AI-arms-race-from-becoming-a-nightmare":{"title":"Column- Minimum wage 'ghosts' keep Google and Microsoft's AI arms race from becoming a nightmare","links":[],"tags":[],"content":"Highlights\nThere’s a certain cruel irony in the fact that as the highest-profile technology in years makes its debut, the ones best suited to keep it on the rails are also the most precarious at the companies that need them. That’s no accident. A chatbot is a sort of magic trick; for the illusion to work properly, the assistants curled up inside the box must remain hidden from the audience, their contribution unremarked. While Google and Microsoft want you to forget that they exist, for the workers, forgetting doesn’t come so easily.\nIt’s never been right. But with some of the world’s most profitable companies now poised to extend their dominance with a whole new business that would not exist without the toil of their lowest-paid workers, it’s high time that the ghosts in the machine show themselves, and get the recognition they’re due."},"highlights/Matter/Compact-word-vectors-with-Bloom-embeddings":{"title":"Compact word vectors with Bloom embeddings","links":[],"tags":[],"content":"Highlights\nNow the question is: will we be able to find values for these weights that let us actually map words to useful vectors?\nfastText uses the same idea with using the full table for the “unknown” portion and hashes each subword into a large table. Since there are typically a very large number of possible subwords (for just 26 lowercase letters there are nearly 12M possible 5-grams), the default hash table size is relatively large at 2M rows. (As a side note, the huge subword table is why fastText .bin files are so large even for small vocabs.)\nThis gives the model a little more resolution for the unknown words. If all out-of-vocabulary words are assigned the same vector, then they’ll all look identical to the model. Even if the training data actually includes information that shows two different out-of-vocabulary words have important, different implications – for instance, if one word is a strong indicator of positive sentiment, while the other is a strong indicator of negative sentiment – the model won’t be able to tell them apart. However, if we have 10 buckets for the unknown words, we might get lucky, and assign these words to different buckets. If so, the model would be able to learn that one of the unknown-word vectors makes positive sentiment more likely, while the other vector makes negative sentiment more likely.\nAnd in terms of the model size, there’s yet another advantage to relying on hash functions to map strings to rows: given the same hash function, the same string always maps to the same hash, so the model does not even need to store a list of known vocab items like it would for a traditional sequentially-numbered vocab. Any arbitrary string can be mapped into this table, and the model does not require a stored vocab.\nThere are three obvious approaches to reducing the size of the embedding table: 1. Reduce the number of words in the vocabulary. 2. Reduce the number of dimensions per vector. 3. Reduce the number of bits per dimension. While all three of these options can be effective, there’s also a less obvious solution: 4. Cheat, using a probabilistic data structure."},"highlights/Matter/Companies-are-radically-redefining-what-it-means-to-'own'-something":{"title":"Companies are radically redefining what it means to 'own' something","links":[],"tags":[],"content":"Highlights\nOne tactic is to use technical sensors to prevent unauthorized changes to the product.\nIn other cases, companies have tried to block consumers from accessing certain features at all unless they pay up first.\nFinally, manufacturers use internet connectivity to monitor and control what you do. If they detect you did something they don’t like (maybe hot-wiring your heated seat), they can take away or disable other features.\nYou might think there ought to be a law against policies that make people simultaneously “buy” and “rent” things. But existing laws work against consumers, allowing manufacturers control what you can and cannot do.\nI believe in truth in advertising. If you’re going to sell somebody something, sell it to them. If you are going to lease something to somebody, lease it to them. If you tether their future purchases to a secret “agreement” that you baked into the technology that they don’t know about, that is deceptive. Not to mention, tinkering and fixing are American traditions. The ethos of “if it’s broke, then fix it” has other benefits, too. Repair teaches critical skills, it saves consumers money, it helps cut waste and product obsolescence. Tinkering and fixing also leads to product innovations that can benefit everyone."},"highlights/Matter/Comprehensible-texts,-productivity-and,-again,-Luhmann":{"title":"Comprehensible texts, productivity and, again, Luhmann","links":[],"tags":[],"content":"Highlights\nSociology, however, is not the study of the first glance, but the study of the second glance. And at second glance, questions and concerns come up. Should everything that is said be equally forced under the rod of comprehensibility? Should comprehensibility mean: Comprehensibility for everyone? Comprehensibility without any effort? Comprehensibility without any preparation, without any time spent thinking and deciding? Is there a linear continuum that leads from incomprehensibility to comprehensibility and along which one can demand more comprehensibility? Or are there also detours on this path from the incomprehensible to the comprehensible, for instance into the mis-comprehensible? Is it perhaps true that the incomprehensible can only be resolved by increasing comprehensibility and mis-comprehensibility at the same time?"},"highlights/Matter/Creating-Confidence-Intervals-for-Machine-Learning-Classifiers":{"title":"Creating Confidence Intervals for Machine Learning Classifiers","links":[],"tags":[],"content":"Highlights\nLastly, it’s worth highlighting that the big picture is to measure and report uncertainty. Confidence intervals are one way to do that.\nA confidence interval is a method that computes an upper and a lower bound around an estimated value. The actual parameter value is either insider or outside these bounds.\nAs a side-note, we can say that the difference of two measurements is statistically significant if confidence intervals do not overlap. However we cannot say that results are not statistically significant if confidence intervals overlap."},"highlights/Matter/Deep-Learning-in-Neuroimaging":{"title":"Deep Learning in Neuroimaging","links":[],"tags":[],"content":"Highlights\nFor example, relative to how large we think the universe is, our observable universe seems small [5]. Its relative size does not mean that our observable universe is small by any ordinary measure. It means that proportional to the estimated wealth of information in the universe, the information we have currently gathered seems insignificant by comparison. The"},"highlights/Matter/Did-ChatGPT-Really-Pass-Graduate-Level-Exams-":{"title":"Did ChatGPT Really Pass Graduate-Level Exams-","links":[],"tags":[],"content":"Highlights\nI argued this at the time: “The truth is that while these systems perform well on specific language-processing tests, they can only take the test. None come anywhere close to matching humans in reading comprehension or other general abilities that the test was designed to measure.” Moreover, such systems lack the basic commonsense understanding of the world that is assumed of humans taking the same tests. In effect, I claimed, “Rather than being ready for high school or college, AI has a lot of growing to do before it’s even ready for preschool.”\nBut does an AI system’s performance on an exam actually predict that it will exhibit skills in the real world? Perhaps there is a correlation between how humans perform on tests and on their future skills in the real world, but that correlation has not been demonstrated for AI systems.\nThe fact that ChatGPT does well on one version of a problem does not mean that it has a humanlike understanding of the problem or that it will be able to solve similar (or even essentially identical) problems. Probing the system’s understanding requires much more than giving it a single version of a question."},"highlights/Matter/Did-GoogleAI-Just-Snooker-One-of-Silicon-Valley’s-Sharpest-Minds-":{"title":"Did GoogleAI Just Snooker One of Silicon Valley’s Sharpest Minds-","links":[],"tags":[],"content":"Highlights\nTurns out the horse knew no math; it had solved the arithmetic problems—all of them —in a different way. The horse watched its trainer; its trainer knew the math. Hans just stamped his feet until he could sense tension in his trainer’s face and posture. When trainer got nervous that the horse might think the answer was 26, the horse sensed it and stopped.\nScience isn’t about declaring victory, it’s about putting in the work to rule out alternative hypotheses,\nIf another AI winter does comes, it not be because AI is impossible, but because AI hype exceeds reality. The only cure for that is truth in advertising.\nA will to believe in AI will never replace the need for careful science. Or, as Bertrand Russell once put it, “What is wanted is not the will to believe, but the wish to find out, which is its exact opposite.”"},"highlights/Matter/Did-the-GPT3-Chatbot-Pass-the-Lovelace-Creativity-Test-":{"title":"Did the GPT3 Chatbot Pass the Lovelace Creativity Test-","links":[],"tags":[],"content":"Highlights\nGPT-3 was not trained to look at meaning. It does not understand its training data. Otherwise it would have learned from the instructional material it saw. GPT-3 does not learn. It rather does a fancy version of memorizing words and their positional relations. And make no mistake, the results are incredible.\nAnd the creativity required to do the supplementary training of AI comes from humans. The AI itself is not creative.\nIn terms of simple math and self-referencing, GPT-3 flunks the Lovelace test."},"highlights/Matter/Distributed-Computing-for-AI--A-Status-Report":{"title":"Distributed Computing for AI- A Status Report","links":[],"tags":[],"content":"Highlights\nAnthrophic’s Jack Clark recently observed: “One of the really big challenges we have is running really large clusters, capable of doing machine learning jobs on hundreds of thousands of GPUs.” And while new tools to simplify distributed training and inference continue to emerge – Ray Train, Ray Serve, and Google Pathways – most solutions still require people skilled at running and managing large-scale distributed systems."},"highlights/Matter/Does-fear-control-you-":{"title":"Does fear control you-","links":[],"tags":[],"content":"Highlights\nFear doesn’t control us by dominating our emotions. It controls us by quietly convincing us that our comfort is more important than happiness. The only real risk is taking no risks. The only real failure is having no failures. The only real pain is the avoidance of pain."},"highlights/Matter/Does-this-one-thing-ruin-happiness-":{"title":"Does this one thing ruin happiness-","links":[],"tags":[],"content":"Highlights\nWhat matters isn’t the comparison. What matters is the meaning we derive from the comparison."},"highlights/Matter/Don't-Call-Yourself-A-Programmer,-And-Other-Career-Advice":{"title":"Don't Call Yourself A Programmer, And Other Career Advice","links":[],"tags":[],"content":"Highlights\nProducing beautiful software is not a goal. Solving complex technical problems is not a goal. Writing bug-free code is not a goal. Using sexy programming languages is not a goal. Add revenue. Reduce costs. Those are your only goals.\nInstead, describe yourself by what you have accomplished for previously employers vis-a-vis increasing revenues or reducing costs. If you have not had the opportunity to do this yet, describe things which suggest you have the ability to increase revenue or reduce costs, or ideas to do so.\nCo-workers and bosses are not usually your friends: You will spend a lot of time with co-workers. You may eventually become close friends with some of them, but in general, you will move on in three years and aside from maintaining cordial relations you will not go out of your way to invite them over to dinner. They will treat you in exactly the same way. You should be a good person to everyone you meet — it is the moral thing to do, and as a sidenote will really help your networking — but do not be under the delusion that everyone is your friend.\na) Remember you’re selling the solution to a business need (raise revenue or decrease costs) rather than programming skill or your beautiful face.\nf) Read a book. Many have been written about negotiation. I like Getting To Yes. It is a little disconcerting that negotiation skills are worth thousands of dollars per year for your entire career but engineers think that directed effort to study them is crazy when that could be applied to trivialities about a technology that briefly caught their fancy.\nBecause you radically overestimate the likelihood that your startup will succeed and radically overestimate the portion of the pie that will be allocated to you if the startup succeeds. Read about dilution and liquidation preferences on Hacker News or Venture Hacks, then remember that there are people who know more about negotiating deals than you know about programming and imagine what you could do to a program if there were several hundred million on the line.\nCommunication is a skill. Practice it: you will get better. One key sub-skill is being able to quickly, concisely, and confidently explain how you create value to someone who is not an expert in your field and who does not have a priori reasons to love you.\nYou will often be called to do Enterprise Sales and other stuff you got into engineering to avoid: Enterprise Sales is going into a corporation and trying to convince them to spend six or seven figures on buying a system which will either improve their revenue or reduce costs. Every job interview you will ever have is Enterprise Sales. Politics, relationships, and communication skills matter a heck of a lot, technical reality not quite so much.\nPeople will often back suggestions by friends because they are friends, even when other suggestions might actually be better. People will often be favoritably disposed to people they have broken bread with. (There is a business book called Never Eat Alone. It might be worth reading, but that title is whatever the antonym of deceptive advertising is.) People routinely favor people who they think are like them over people they think are not like them. (This can be good, neutral, or invidious. Accepting that it happens is the first step to profitably exploiting it.)\nYour career is important, and right now it might seem like the most important thing in your life, but odds are that is not what you’ll believe forever. Work to live, don’t live to work."},"highlights/Matter/Don't-be-that-open-source-user,-don't-be-me":{"title":"Don't be that open-source user, don't be me","links":[],"tags":[],"content":"Highlights\nIf what you want to say has already been said then don’t say it. When interacting with maintainers remember that you are asking for their help, not telling them what to do."},"highlights/Matter/Don't-believe-ChatGPT---we-do-NOT-offer-a--phone-lookup--service":{"title":"Don't believe ChatGPT - we do NOT offer a -phone lookup- service","links":[],"tags":[],"content":"Highlights\nAs we dug into this it became clear most of of these new ChatGPT users were tying to use our geocoding API for an entirely different purpose. It seems ChatGPT is wrongly recommending us for “reverse phone number lookup” - ie the ability to determine the location of a mobile phone solely based on the number. This is not a service we provide. It is not a service we have ever provided, nor a service we have any plans to provide. Indeed, it is a not a service we are technically capable of providing. And yet ChatGPT has absolutely no problem recommending us for this service (complete with python code you can cut and paste) as you can see in this screenshot.\nThe key difference is that humans have learned to be sceptical when getting advice from other humans, for example via a video coding tutorial. It seems though that we haven’t yet fully internalized this when it comes to AI in general or ChatGPT specifically. The other key difference is the sheer scale of the problem. Bad tutorial videos got us a handful of frustrated sign-ups. With ChatGPT the problem is several orders of magnitude bigger.\nChatGPT is doing exactly what it’s makers intended - producing a coherent, believable answer. Whether that answer is truthful does not seem to matter in the slightest."},"highlights/Matter/Don’t-Go-Breaking-My-Heart":{"title":"Don’t Go Breaking My Heart","links":[],"tags":[],"content":"Highlights\nFew people understand how they work; many people anthropomorphizing those chatbots, attributing to them real intelligence and emotion. Kevin Roose writes about AI for a living and was genuinely concerned about what Sydney was saying. Naive users may take these bots even more seriously. * Larger language models seems more and more human-like (but the emotions that they present are no more real). Whatever we see now is likely to escalate. * Some people are building real attachments to those bots * In some cases, those who are building bots that actively cultivate those attachments, e.g., by feigning romantic and/or sexual interest or by dotting their messages with “friendly” emoticons. * Changes in those bots could leave many people in a vulnerable place. * There is essentially zero regulation on what these chatbots can say or do or how they can change over time, or on how they might treat their users. * Taking on a user in a chatbot like Replika is a long term commitment. But no known technology can reliably align a chatbot in a persistent way to a human’s emotional needs.\nTo my knowledge, tech companies are free to leverage a human gullibility around chatbot technologies however they like, without consequence, just as big teach companies previously leveraged to a human need for attention to the point of creating addictions to social media, even to the point of sometimes causing “Twitter poisoning”; with the new generation of chatbots, we will see addictions no less potent."},"highlights/Matter/Eight-things-you-need-to-know-when-moving-from-a-startup-to-an-established-tech-company":{"title":"Eight things you need to know when moving from a startup to an established tech company","links":[],"tags":[],"content":"Highlights\nAt established companies, you’re likely to encounter many people who have spent several years diving deep into a relatively narrower group of problems.\nWith larger companies, you need to be more careful with applying the metaphorical pedal to the metal. You’ve typically got more users and revenue to watch out for that your actions could risk negatively affecting. In practice, this translates not to taking fewer risks, but requiring a higher burden of proof before taking leaps.\nThe former approach can be an enabler of development velocity, but only once you’ve navigated the company-specific learning curve.\nFor example, the meticulousness with which interviews are run to ensure objectivity and eliminate bias makes the startup hiring processes that I’ve been privy to seem almost renegade in comparison."},"highlights/Matter/Elon-Musk-Got-Twitter-Because-He-Gets-Twitter":{"title":"Elon Musk Got Twitter Because He Gets Twitter","links":[],"tags":[],"content":"Highlights\nThe danger, then, is what Nguyen calls “value capture.” That, he writes, comes when: 1. Our natural values are rich, subtle and hard to express. 2. We are placed in a social or institutional setting which presents simplified, typically quantified, versions of our values back to ourselves. 3. The simplified versions take over in our motivation and deliberation."},"highlights/Matter/Embrace-the-Grind":{"title":"Embrace the Grind","links":[],"tags":[],"content":"Highlights\nSometimes, programming feels like magic: you chant some arcane incantation and a fleet of robots do your bidding. But sometimes, magic is mundane. If you’re willing to embrace the grind, you can pull off the impossible.\nLaziness: The quality that makes you go to great effort to reduce overall energy expenditure. It makes you write labor-saving programs that other people will find useful and document what you wrote so you don’t have to answer so many questions about it."},"highlights/Matter/Empty-Pointers-and-Constellations-of-AI":{"title":"Empty Pointers and Constellations of AI","links":[],"tags":[],"content":"Highlights\nAll computing is to some degree artificially intelligent. At one point a TI-83 calculator was artificial intelligence. When Google search first came out it was artificial intelligence. Frankly, a modern refrigerator counts as artificial intelligence: it’s programmed to achieve an objective by taking action and uses environmental feedback to adjust its behaviour. These things are now so banal and pervasive we are unimpressed by their “intelligence.”\nWe use it to gesture at a future we cannot fully comprehend or currently realise. As soon as we do, it will no longer be “AI.”"},"highlights/Matter/Eugenics-and-Longtermist-Effective-Altruism-Share-the-Same-Original-Sin":{"title":"Eugenics and Longtermist Effective Altruism Share the Same Original Sin","links":[],"tags":[],"content":"Highlights\nHubris of believing one was able to anticipate the future, and the hubris of conviction that this future somehow hinged on you.\nBasically, eugenicists were a boy’s club that got too full of themselves and decided that the only environment that existed were the academic, political, and office halls, and since they were doing so well in them, surely anyone with any hope of achieving a high fitness would have to look like them. Which sounds as unbelievably stupid as it is, but unfortunately, as is often the case, this stupidity escaped people whose self-esteem hinged on that stupidity. And as Max Plank put it – those people don’t change their point of view with time; their views will die with them. Science advances one funeral at a time. \nBasically, they mean that no matter how smart the eugenics ubermensch would be, how much they would already know, and how much they would be able to reason, they won’t be able to anticipate the future. Worse than that. Even if they tried to focus just on the most probable conditions rather than all of them, it won’t work out either – given that they can’t evaluate the probability of events they cannot decide in their logical system. Once again, part of the impossibility theorems, the statement above in its more strict formulation is known as Solomonoff(-Kolmogorov) incompletness theorem and has been formally proven. In other terms, no one can predict the future unless there are really good chances it would look like something you’ve seen before (aka sun rising up at the east in the morning).\nSurprisingly, despite being proven in the 1930s, those results once again were ignored by eugenicists. Not because they didn’t know about them but because they didn’t care. Logicians were an annoying minority, whereas eugenicists were almost universally admired and ran the power circles. At least until the horrors of concentration camps and the eugenicist logic came to light at the end of WW2 and public opinion radically shifted.\nAnd them and only them, the Longtermist Effective Altruists, are smart and worthy enough to anticipate how AGI will develop and ensure it develops in the “right” direction. Or know what “right” means. Basically, Longtermist EAs believe they are ubermensch by procurement.\nBasically, the AGI hype today has little more function than the claims of racial superiority a century ago – allowing a bunch of people to feel even more important and pull even more resources toward themselves. And the tools they are using to achieve it – faux-formalism, pseudo-scientificism, and outright opponent suppression – are also the same.\nUnlike what you are led to believe, ethics teams that were silenced or fired – at Google, Microsoft, Facebook, … – are not woke hippy idealists that want to stop ML development. They are pretty good technical experts that are seeing the damage AI is already doing today and who also see AGI rhetoric for what it – a void multitude; a scarecrow to distract from real, current problems; the White Gorilla to stop you from thinking about Lakoff’s Pink Elephant of who trains the AI.\nIt is perhaps not a coincidence that Longtermist EAs always talk about the “alignment” of AIs but never mention to whose values they are aligned. It is perhaps not a coincidence that in their famous “Pause the Giant AI Experiments,” the Longtermist Future of Life Institute made a Freudian slip and added “loyal” as a condition to the AI research progress. \nNo matter how brilliant, well-connected, and critical to the development of science, superstars could be fundamentally wrong in the most trivial fashion. Their prior achievements don’t give magical immunity to new errors, especially if those errors support their ego. Such wrongness can and must be called out. "},"highlights/Matter/Expanding-spelling-correction-to-100-plus-languages":{"title":"Expanding spelling correction to 100-plus languages","links":[],"tags":[],"content":"Highlights\n•\nIn search we’ve found about 15% of queries submitted by customers have misspellings.\nWe’ve found we need a very large number of data points to train a high-quality spelling correction model for each language, and sourcing data in over 100 languages would be incredibly difficult logistically—not to mention costly in both time and money.\nThis was made possible by leveraging recent advances in AI, particularly zero-shot learning combined with carefully designed large-scale pretraining tasks, and we also draw on historical linguistics theories.\nFor precise and high-performing error models, search engines have largely leveraged user feedback on autocorrection recourse links. This practice has been very effective, especially for languages where user feedback data has been gathered on a large scale. For a language with very little web presence and user feedback, it’s challenging to gather an adequate amount of training data.\nBroadly speaking, there are two types of spelling errors. One is non-word error, and the other is real-word error.\nwe designed a spelling correction pretraining task to enrich standard Transformer-based models.\nAlso, if typos are considered noises in text, spelling correction can be considered as a denoising process that converts corrupted text into its original text.\nBART is trained by corrupting text with an arbitrary noise function and learning a model to reconstruct the original text.\nWe have designed noise functions to generate common errors of rotation, insertion, deletion, and replacement. See the figure below for examples of these common errors.\nThe number of pages with no results reduced by up to 30%. * The number of times users had to manually reformulate their query reduced by 5%. * The number of times users clicked on our spelling suggestion increased from single digits to 67%. * The number of times users clicked on any item on the page went from single digits to 70%."},"highlights/Matter/FTC-warns-tech--'Keep-your-AI-claims-in-check'":{"title":"FTC warns tech- 'Keep your AI claims in check'","links":[],"tags":[],"content":"Highlights\nThe FTC doesn’t like it. Whatever someone means when they say “powered by artificial intelligence” or some version thereof, “One thing is for sure: it’s a marketing term,” the agency writes. “And at the FTC, one thing we know about hot marketing terms is that some advertisers won’t be able to stop themselves from overusing and abusing them.”"},"highlights/Matter/Finding-Time":{"title":"Finding Time","links":[],"tags":[],"content":"Highlights\nYou already have the gold coins beneath you, of presence, creativity, intimacy, time for wonder, and nature, and life. Oh, yeah, you say? And where would those rascally coins be?\nThis is what I say: First of all, no one needs to watch the news every night, unless one is married to the anchor.\nBut I ask them whether, if their children grow up to become adults who spend this one precious life in a spin of multitasking, stress, and achievement, and then work out four times a week, will they be pleased that their kids also pursued this kind of whirlwind life?\nI’ve heard it said that every day you need half an hour of quiet time for yourself, or your Self, unless you’re incredibly busy and stressed, in which case you need an hour. I promise you, it is there. Fight tooth and nail to find time, to make it. It is our true wealth, this moment, this hour, this day."},"highlights/Matter/Finish-your-projects":{"title":"Finish your projects","links":[],"tags":[],"content":"Highlights\nFor every vocal critic, there are 10 times as many people quietly following along and admiring not only your work, but your bravery to put it out publicly. Let that be an encouragement.\nMaybe it was a great success, maybe it wasn’t. That part is out of your control. What’s in your control is seeing it all the way through, and you did that. Sometimes finishing is the end: You release the article, the podcast, the book, and that’s it. The artifact is in its final form."},"highlights/Matter/Folk-Interfaces":{"title":"Folk Interfaces","links":[],"tags":[],"content":"Highlights\nFolk interfaces are when users reappropriate existing software to solve their own problems. Rather than using applications in the ways designers and developers intended, they creatively reconfigure them to do unexpected things."},"highlights/Matter/GPT-4-and-professional-benchmarks--the-wrong-answer-to-the-wrong-question":{"title":"GPT-4 and professional benchmarks- the wrong answer to the wrong question","links":[],"tags":[],"content":"Highlights\nBut we can get some clarity by asking what OpenAI is trying to measure using these exams. If the goal is to predict how the language model will do on real-world tasks, there’s a problem. In a sense, any two bar exam questions or medical exam questions are more similar to each other than they are to the tasks that professionals do in the real world, because they are drawn from such a constrained space. So it’s possible that the inclusion of any exam questions in the training corpus results in an inflated estimate of real-world usefulness.\nIn some real-world tasks, shallow reasoning may be sufficient, but not always. The world is constantly changing, so if a bot is asked to analyze the legal consequences of a new technology or a new judicial decision, it doesn’t have much to draw upon. In short, as Emily Bender points out, tests designed for humans lack construct validity when applied to bots.\nJust one of the 270 jobs in the 1950 census has been eliminated by automation: elevator operator. Instead, we need studies that actually evaluate professionals using the help of AI tools to do their jobs. Two early studies are promising: one looks at GitHub copilot for coding and the other looks at ChatGPT for writing assistance.\nAt this stage, we need qualitative studies more than quantitative ones, because these tools are so new that we don’t even know the right quantitative questions to ask. For example, Scott Guthrie of Microsoft reports the eye-catching number that 40% of the code checked in by GitHub Copilot users is AI-generated and unmodified. But any programmer will tell you that especially in enterprise applications, a large percentage of code consists of templates and other mundane logic that we usually copy-paste. If this is the part that Copilot is automating, the productivity improvement would be negligible. To be clear, we’re not saying that Copilot is useless, just that metrics are meaningless without a qualitative understanding of how professionals use AI. Besides, the primary benefit of AI-assisted coding might not even be the productivity improvement."},"highlights/Matter/General-Purpose-AI-Poses-Serious-Risks,-Should-Not-Be-Excluded-From-the-EU's-AI-Act":{"title":"General Purpose AI Poses Serious Risks, Should Not Be Excluded From the EU's AI Act","links":[],"tags":[],"content":"Highlights\nDevelopers of GPAI should not be able to relinquish responsibility using a standard legal disclaimer. Such an approach creates a dangerous loophole that lets original developers of GPAI (often well-resourced large companies) off the hook, instead placing sole responsibility with downstream actors that lack the resources, access, and ability to mitigate all risks."},"highlights/Matter/Giraffe---Long-Context-LLMs":{"title":"Giraffe - Long Context LLMs","links":[],"tags":[],"content":"Highlights\nHowever, we believe that documents on which perplexity are measured often permit for a good performance simply by producing reasonably coherent text distributions conditional on a small subset of the entire available context. We show in this paper that perplexity is less sensitive for distinguishing long context performance between models for this reason than the new tasks that we introduced that are focused more strongly on accuracy of model recall than general text coherence."},"highlights/Matter/Give-Up-GitHub--The-Time-Has-Come!":{"title":"Give Up GitHub- The Time Has Come!","links":[],"tags":[],"content":"Highlights\nWhat case law, if any, did you rely on in Microsoft &amp; GitHub’s public claim, stated by GitHub’s (then) CEO, that: “(1) training ML systems on public data is fair use, (2) the output belongs to the operator, just like with a compiler”? In the interest of transparency and respect to the FOSS community, please also provide the community with your full legal analysis on why you believe that these statements are true.\nIf it is, as you claim, permissible to train the model (and allow users to generate code based on that model) on any code whatsoever and not be bound by any licensing terms, why did you choose to only train Copilot’s model on FOSS? For example, why are your Microsoft Windows and Office codebases not in your training set?\nMicrosoft and GitHub’s refusal to answer also hints at the real answer to this question, too: While GitHub gladly exploits FOSS inappropriately, they value their own “intellectual property” much more highly than FOSS, and are content to ignore and erode the rights of FOSS users but not their own.\nCan you provide a list of licenses, including names of copyright holders and/or names of Git repositories, that were in the training set used for Copilot? If not, why are you withholding this information from the community?"},"highlights/Matter/Goodhart’s-Law-and-Scientific-Innovation-in-Academia":{"title":"Goodhart’s Law and Scientific Innovation in Academia","links":[],"tags":[],"content":"Highlights\nA prime example is in academia where achievement is measured by the number of published research papers. Because the number of papers is the target, professors find ways to publish lots (and we mean lots) of papers, most of which are of little or no value. The unintended consequence is that instead of doing worthwhile, but time-consuming, research that might result in a small number of important papers, researchers waste their time writing a large number of inconsequential papers.\nThe h-index (named after its creator Jorge E. Hirsch) is equal to the number of articles (h) that have been cited at least h times and is widely used for hiring, promotion, and funding decisions. The h-indexes are relatively small for many scientific giants who published a small number of extraordinary books and papers. The h-indexes are 97 for Charles Darwin, 70 for Niels Bohr, and 59 for Richard Feynman. Thousands of lesser scientists today (5,882 by a recent count) have an h-index of at least 100 and their ranks are increasing rapidly.\nThe fundamental problem that diverts university research and stifles innovation is Goodhart’s law. When scientific innovation is measured by publication counts, we will get more publications and less innovation."},"highlights/Matter/Google-AI-Blog--Better-Language-Models-Without-Massive-Compute":{"title":"Google AI Blog- Better Language Models Without Massive Compute","links":[],"tags":[],"content":"Highlights\nUL2R adapts the LM to a mixture-of-denoisers objective using the same data, whereas Flan leverages training data from over 1.8K NLP tasks to teach the model to follow instructions."},"highlights/Matter/Google-AI-Blog--Google-Research,-2022--and--Beyond--Language,-Vision-and-Generative-Models":{"title":"Google AI Blog- Google Research, 2022 & Beyond- Language, Vision and Generative Models","links":[],"tags":[],"content":"Highlights\nThe PaLM work demonstrated that, despite being trained solely on the objective of predicting the next token, large-scale language models trained on large amounts of multi-lingual data and source code are capable of improving the state-of-the-art across a wide variety of natural language, translation, and coding tasks, despite never having been trained to specifically perform those tasks. This work provided additional evidence that increasing the scale of the model and training data can significantly improve capabilities.\nIn our work on “Multi-modal Bottleneck Transformers” and the accompanying “Attention Bottlenecks for Multimodal Fusion” paper, we explore these tradeoffs and find that bringing together modalities after a few layers of modality-specific processing and then mixing the features from different modalities through a bottleneck layer is more effective than other techniques (as illustrated by the Bottleneck Mid Fusion in the figure below). This approach substantially improves accuracy on a variety of video classification tasks by learning to use multiple modalities of data to make classification decisions."},"highlights/Matter/Google-AI-Blog--Symbol-tuning-improves-in-context-learning-in-language-models":{"title":"Google AI Blog- Symbol tuning improves in-context learning in language models","links":[],"tags":[],"content":"Highlights\nSymbol tuning boosts performance on unseen in-context learning tasks and is much more robust to underspecified prompts, such as those without instructions or without natural language labels. * Symbol-tuned models are much stronger at algorithmic reasoning tasks. * Finally, symbol-tuned models show large improvements in following flipped-labels presented in-context, meaning that they are more capable of using in-context information to override prior knowledge."},"highlights/Matter/Google-shattered-human-connection":{"title":"Google shattered human connection","links":[],"tags":[],"content":"Highlights\nThe problem is that making something easy has a dark side, because whatever was hard to do is not going to be done at all anymore. In specific, Google eliminated the need to connect with communities online if all you wanted was the knowledge produced by that community. And connecting with people and communities – in the style we still practiced in the 90s – is time consuming, often hard.\nThe problem with the information paradigm is how “information” is ripped out of its context: the people, the inherited knowledge, the culture that produced it. Everything is seen as an atomic digestible, and there is little regard for the processes, conversations, debates that produced those digestibles. The whole idea of “information” is somewhat of a farce, I doubt you can truly learn and internalize some information without learning surrounding information that sheds light on the nuances involved. These are things that only knowledgeable people can distinguish and report on. But it is legitimately hard to know who is an expert in what, since – thanks to Google – we all have access to atomic digestibles from any community of experts, and can easily copy-paste them whenever needed in a discussion (with whom? Probably randos on social media)."},"highlights/Matter/Google-vs.-the-Open-Web":{"title":"Google vs. the Open Web","links":[],"tags":[],"content":"Highlights\nThe two problems with this line of thinking are that first, good regulatory frameworks are rare. And part of the reason for that is the second problem, namely that technology moves faster than the law. Which means that worrying about access instead of technology will still exclude marginalized groups in practice. What is required instead is to worry about technology in the short term, and regulation in the long term."},"highlights/Matter/Google-won’t-launch-ChatGPT-rival-because-of-‘reputational-risk’":{"title":"Google won’t launch ChatGPT rival because of ‘reputational risk’","links":[],"tags":[],"content":"Highlights\nPichai and Dean reportedly responded by saying that Google’s AI language models are just as capable as OpenAI’s, but that the company had to move “more conservatively than a small startup” because of the “reputational risk” posed by the technology.\nOpenAI, too, was previously relatively cautious in developing its LLM technology, but changed tact with the launch of ChatGPT, throwing access wide open to the public. The result has been a storm of beneficial publicity and hype for OpenAI, even as the company eats huge costs keeping the system free-to-use.\nThey amplify social biases found in their training data, often denigrating women and people of color; they are easy to trick (users found they could circumvent ChatGPT’s safety guidelines, which are supposed to stop it from providing dangerous information, by asking it to simply imagine it’s a bad AI); and — perhaps most pertinent for Google — they regularly offer false and misleading information in response to queries. Users have found that ChatGPT “lies” about a wide range of issues, from making up historical and biographical data, to justifying false and dangerous claims like telling users that adding crushed porcelain to breast milk “can support the infant digestive system.”\nAI researchers Timnit Gebru and Margaret Mitchell were fired from Google after publishing a paper outlining the technical and ethical challenges associated with LLMs (the same challenges that Pichai and Dean are now explaining to staff). And in May last year, a quartet of Google researchers explored the same question of AI in search, and detailed numerous potential problems. As the researchers noted in their paper, one of the biggest issues is that LLMs “do not have a true understanding of the world, they are prone to hallucinating, and crucially they are incapable of justifying their utterances by referring to supporting documents in the corpus they were trained over.”\nAs CEO Sam Altman recently tweeted: “ChatGPT is incredibly limited, but good enough at some things to create a misleading impression of greatness. it’s a mistake to be relying on it for anything important right now. it’s a preview of progress; we have lots of work to do on robustness and truthfulness.”"},"highlights/Matter/Google’s-Photo-App-Still-Can’t-Find-Gorillas.-And-Neither-Can-Apple’s.":{"title":"Google’s Photo App Still Can’t Find Gorillas. And Neither Can Apple’s.","links":[],"tags":[],"content":"Highlights\nAs artificial intelligence becomes more embedded in our lives, it is eliciting fears of unintended consequences. Although computer vision products and A.I. chatbots like ChatGPT are different, both depend on underlying reams of data that train the software, and both can misfire because of flaws in the data or biases incorporated into their code.\nMicrosoft’s decision, like Google’s choice to prevent its algorithm from identifying gorillas altogether, illustrates a common industry approach — to wall off technology features that malfunction rather than fixing them."},"highlights/Matter/Google’s-medical-AI-chatbot-is-already-being-tested-in-hospitals":{"title":"Google’s medical AI chatbot is already being tested in hospitals","links":["20221210185344"],"tags":[],"content":"Highlights\nThe paper also mentions research Google made public in May (pdf) showing that Med-PaLM 2 still suffers from some of the accuracy issues we’re already used to seeing in large language models. In the study, physicians found more inaccuracies and irrelevant information in answers provided by Google’s Med-PaLM and Med-PalM 2 than those of other doctors. Still, in almost every other metric, such as showing evidence of reasoning, consensus-supported answers, or showing no sign of incorrect comprehension, Med-PaLM 2 performed more or less as well as the actual doctors.\nAccording to Google senior research director Greg Corrado, WSJ says, Med-PaLM 2 is still in its early stages. Corrado said that while he wouldn’t want it to be a part of his own family’s “healthcare journey,” he believes Med-PaLM 2 “takes the places in healthcare where AI can be beneficial and expands them by 10-fold.”\nThe hipocracy of AI privilege: On the Dangers of Large Generative Models"},"highlights/Matter/Gradient-Update--24--Robotaxis-in-Beijing-and-a-Multi-task-Visual-Language-Model":{"title":"Gradient Update -24- Robotaxis in Beijing and a Multi-task Visual Language Model","links":[],"tags":[],"content":"Highlights\nIt is able to process images, video, and text presented in arbitrary orders. Since it is trained on uncurated data, Flamingo is likely to learn more general information beyond the structure that might be present in a curated dataset.\nFor language, Flamingo uses a pretrained Chinchilla language model with 70 billion parameters. For vision, Flamingo uses a contrastively pretrained Normalizer Free ResNet (NFNet) with 435 million parameters. During\nFlamingo leverages two sources of strength: pretrained single modality models, and uncurated multimodal data.\nIt should allow teams to prototype and train models faster without spending substantial time in data cleaning and preprocessing."},"highlights/Matter/Hackaday-Newsletter-0x66":{"title":"Hackaday Newsletter 0x66","links":[],"tags":[],"content":"Highlights\nAnd they haven’t even begun to consider security yet. They’re still worried about how to construct obscure background prompts that prevent their machines from spewing hate speech or pornographic novels. But as soon as the machines start doing something more interesting than just providing you plain text, the black hats will take notice, and someone will have to figure out defense."},"highlights/Matter/History-May-Wonder-Why-Microsoft-Let-Its-Principles-Go-for-a-Creepy,-Clingy-Bot":{"title":"History May Wonder Why Microsoft Let Its Principles Go for a Creepy, Clingy Bot","links":[],"tags":[],"content":"Highlights\nTesters, including journalists, have found the bot can become aggressive, condescending, threatening, committed to political goals, clingy, creepy and a liar. It could be used to spread misinformation and conspiracy theories at scale; lonely people could be encouraged down paths of self-destruction. Even the demonstration of the product provided false information.\nNor has Microsoft upheld its commitment to transparency. It has not been forthcoming about those guardrails or the testing that its chatbot has been run through. Nor has it been transparent about how it assesses the ethical risks of its chatbot and what it considers the appropriate threshold for “safe enough.” Even the way senior executives have talked about designing and deploying the company’s chatbot gives cause for concern. Microsoft’s C.E.O., Satya Nadella, characterized the pace at which the company released its chatbot as “frantic” — not exactly the conditions under which responsible design takes place.\nYes, there is money to be made, but that’s why we have principles. Their very purpose is to have something to cling to when the winds of profit and glory threaten to blow us off our moral course. Now more than ever is when those Responsible A.I. principles matter. History is looking at you.\nThe market will always push A.I. companies to move fast and break things. The rules of the game are such that even well-intentioned companies have to bow to the reality of competition in the marketplace. We might hope that some companies, like Microsoft, will rise above the fray and stick to principles over profit, but a better strategy would be to change the rules of the game that make that necessary in the first place.\nWe need regulations that will protect society from the ethical nightmares A.I. can release. Today it’s a single variety of generative A.I. Tomorrow there will be bigger and badder generative A.I., as well as kinds of A.I. for which we do not yet have names. Expecting Microsoft — or almost any other company — to engage in practices that require great financial sacrifice but that are not legally required is a hopeless strategy at scale. Self-regulation is simply not enough."},"highlights/Matter/How-Congress-Fell-for-Sam-Altman’s-AI-Magic-Tricks":{"title":"How Congress Fell for Sam Altman’s AI Magic Tricks","links":[],"tags":[],"content":"Highlights\nThat sounds pretty important, but people remain hyper-fixated on the Altmans and OpenAIs of the world. The entire world seems to be completely zeroed in solely on generative AI, or machine learning systems that can create content when prompted (e.g. chatbots like ChatGPT and Bard, or image generators like Midjourney or DALL-E). And in doing so, we might be missing out on the actual dangers of AI—and opening ourselves up to a lot of harm in the process.\nWhile Altman has said he welcomes regulation to rein in generative AI, the company’s refusal to be more transparent about the dataset used to train ChatGPT’s and shutting down requests to up access for third party apps to use its API suggest OpenAI isn’t as warm to regulation as it claims. “His company is the one that put this out there,” Venkatasubramanian said. “He doesn’t get to opine on the dangers of AI. Let’s not pretend that he’s the person we should be listening to on how to regulate.” He added, “We don’t ask arsonists to be in charge of the fire department.”"},"highlights/Matter/How-Human-Language-Is,-and-Isn’t,-Like-a-Computer-Program":{"title":"How Human Language Is, and Isn’t, Like a Computer Program","links":[],"tags":[],"content":"Highlights\nWhen I open a text file on my computer, I expect it to look exactly the same regardless of other files and browser tabs open at that time. This is not how information is “retrieved” in the brain. Some details of the word’s meaning that is activated will depend on context: The meaning of “tree” that one uses to derive an interpretation of “I want that tree in our garden,” its nuances and implications, may differ depending on whether we are looking at a potted artificial Christmas tree or at a rare olive tree.\nIn language learning, the “software” would have to be programmed in gradually, as a function of the stage of growth and maturation of the “hardware.” That this is not how computers and programming work just shows that the software-vs-hardware metaphor is not quite right for language and the brain.\nIt’s hard to imagine a cultural phenomenon that’s more important than the development of language. And yet no human attribute offers less conclusive evidence regarding its origins."},"highlights/Matter/How-I-Lost-My-Faith":{"title":"How I Lost My Faith","links":[],"tags":[],"content":"Highlights\nThis is generally bullshit. Christians (and humans in general) are incredibly talented at organizing their structure in such a way that logic works to their favor. If a ‘good argument’ could bring down a Christian’s faith, then it would have happened a long time ago."},"highlights/Matter/How-Loneliness-Reshapes-the-Brain":{"title":"How Loneliness Reshapes the Brain","links":[],"tags":[],"content":"Highlights\nAs the researchers described in 2019, in comparison to a control group, the socially isolated team lost volume in their prefrontal cortex — the region at the front of the brain, just behind the forehead, that is chiefly responsible for decision-making and problem-solving. They also had lower levels of brain-derived neurotrophic factor, a protein that nurtures the development and survival of nerve cells in the brain. The reduction persisted for at least a month and a half after the team’s return from Antarctica.\nWhile we desire connection with others, we view them as unreliable, judgmental and unfriendly. Consequently, we keep our distance, consciously or unconsciously spurning potential opportunities for connections.\n“The core features of social anxiety were not evident in loneliness,” Lieberz said. Those results suggest, she said, that treating loneliness simply by telling lonely people to go out and socialize more (the way you can treat a phobia of snakes with exposure) will often not work because it fails to address the root cause of the loneliness.\nThe problem with loneliness seems to be that it biases our thinking. In behavioral studies, lonely people picked up on negative social signals, such as images of rejection, within 120 milliseconds — twice as quickly as people with satisfying relationships and in less than half the time it takes to blink. Lonely people also preferred to stand farther away from strangers, trusted others less and disliked physical touch.\nThis may be why the emotional well-being of lonely individuals often follows “a downward spiral,” said Danilo Bzdok, an interdisciplinary researcher at McGill University with a background in neuroscience and machine learning. “They tend to end up with a more negative spin on whatever information they receive — facial expressions, texting, whatever — and that drives them even deeper into this loneliness pit.”\nThey looked separately at socially isolated people and at people with low social support, as measured by a lack of someone to confide in on a daily or almost daily basis. The researchers found that in all such individuals, the orbitofrontal cortex — a part of the brain linked to processing rewards — was smaller.\nThis finding supports previous reports from eye-tracking studies that lonely people tend to focus excessively on unpleasant social cues, such as being ignored by others.\nTo Tomova, the experiment underlined an important truth about loneliness: If just 10 hours without social contact is enough to elicit essentially the same neural signals as being deprived of food, “it highlights how basic our need to connect with others is,” she said.\n“That might be a reason why lonely people have problems trusting others — they cannot rely on their [gut] feelings,” she said. Interventions that target trust could therefore be part of a solution to the catch-22 of loneliness.\nAnother idea is to encourage synchrony. Research shows that one key to how much people like and trust each other lies in how closely their behaviors and reactions match from moment to moment. This synchrony between individuals can be as simple as reciprocating a smile or mirroring body language during conversation, or as elaborate as singing in a choir or being part of a rowing team. In a study published a year ago, Lieberz and her colleagues showed that lonely people struggle to synchronize with others, and that this discordance causes the regions of their brain responsible for observing actions to go into overdrive. Coaching lonely people in how to join in with the actions of others could be another strategic intervention to consider. It won’t cure loneliness by itself, “but it may be a starting point,” Lieberz said."},"highlights/Matter/How-Our-Brains-Are---and-Aren’t---Like-Computers":{"title":"How Our Brains Are - and Aren’t - Like Computers","links":[],"tags":[],"content":"Highlights\nNeurologists are usually primarily concerned with thinking about the hardware of the brain, where you can see that some part of the brain is broken, either with imaging studies, or with pathology under a microscope, or EEG — a study that looks at brainwave activity. We’re sort of more concerned with low-level brain problems. Psychiatry and psychology usually approach the brain from the standpoint of the mind — not what’s happening with the physical substrate of the brain but what is happening in people’s thought processes, and what sort of dysfunction is there in thought processes. Now, obviously, there’s overlap between the two.\nThat overlap, in some ways, is still not totally well understood. It can come out in different ways. If you think about depression, say, certain brain structures are implicated in depression. There are neurotransmitters that are implicated in depression. There’s certainly cases of depression where treating with a particular medication that addresses a neurotransmitter will improve a person’s depression or help get rid of the problem.\nSo as you get older, as you get experience, the brain prunes down to the connections that are most beneficial.\nIt does level off. And we’re not talking about getting rid of the neurons, either. We’re just talking about getting rid of some of the connections between different neurons. So by and large, the number of neurons stays about the same.\nYou may also wish to read: A neurosurgeon on why some people function with only half a brain. The study results are reassuring and they point to two larger truths. First, the mind is not the brain and second, people tend to see the mind–brain relationship in terms of the cultural conceptions that matter to them."},"highlights/Matter/How-do-engineers-show-up-at-work-every-day-and-...":{"title":"How do engineers show up at work every day and ...","links":[],"tags":[],"content":"Highlights\nHuman factors seem to be completely ignored by a division at Tesla dedicated to developing driver assistance technology. By definition this technology is assisting the human driver, but the behaviour of the driver are not even thought about by this team - which is WILD.\nAnd if the driver is always at fault for oversights in your driver assistance system, then your system is incapable of malfunctioning."},"highlights/Matter/How-elite-schools-like-Stanford-became-fixated-on-the-AI-apocalypse":{"title":"How elite schools like Stanford became fixated on the AI apocalypse","links":[],"tags":[],"content":"Highlights\nBut from the start EA was intertwined with tech subcultures interested in futurism and rationalist thought. Over time, global poverty slid down the cause list, while rogue AI climbed toward the top. Extreme practitioners began to promote an idea called “longtermism,” prioritizing the lives of people potentially millions of years in the future, who might be a digitized version of human beings, over present-day suffering."},"highlights/Matter/How-to-Pick-a-Career-(That-Actually-Fits-You)":{"title":"How to Pick a Career (That Actually Fits You)","links":[],"tags":[],"content":"Highlights\nKids in school are kind of like employees of a company where someone else is the CEO. But no one is the CEO of your life in the real world, or of your career path---except you. And you’ve spent your whole life becoming a pro student, leaving you with zero experience as the CEO of anything. Up to now, you’ve only been in charge of the micro decisions---“How do I succeed at my job as a student?”---and now you’re suddenly holding the keys to the macro cockpit as well, tasked with answering stressful macro questions like “Who am I?” and “What are the important things in life?” and “What are my options for paths and which one should I choose and how do I even make a path?” When we leave school for the last time, the macro guidance we’ve become so accustomed to is suddenly whisked away from us, leaving us standing there holding our respective dicks, with no idea how to do this.\nI think a lot of those regrets stem from the fact that most of us aren’t really taught about path-making in our childhoods, and most of us also don’t get much better at path-making as adults, which leaves many people looking back on a life path that didn’t really make sense, given who they are and the world they lived in.\nSo a typical career will take up somewhere between 20% and 60% of your meaningful adult time---not something to be a cook about.\nAll lives make a large impact on the world and on the future---but the kind of impact you end up making is largely within your control, depending on the values you live by and the places you direct your energy. Whatever shape your career path ends up taking, the world will be altered by it.\nbut the way many societies are right now, a person’s career quadruples as the person’s primary identity.\nThe part of the tentacle that just wants to sit around and relax will hold you back from sweating to build the kind of career that offers long-term flexibility and the kind of wealth that can make life luxurious and cushy and full of toys. The part of the tentacle that only feels comfortable when the future feels predictable will reject the exact kinds of paths that may generate the long-term freedom another part of the tentacle longs for. The side of you that wants a stress-free life doesn’t get along very well with the side of you that thirsts to be hang gliding off a cliff in Namibia like Richard Branson.\nSo that’s the situation. You’ve got this Yearning Octopus in your head with five tentacles (or however many yours has), each with their own agenda, that often conflict with each other. Then there are the distinct individual yearnings on each tentacle, often in conflict amongst themselves. And if that weren’t enough, you sometimes have furious internal conflict inside a single yearning. Like when your desire to pursue your passion can’t figure out what it’s most passionate about.\nHuman yearning is a game of choices and sacrifices and compromise.\nDo you treat the words of your external influences as information, held and considered by an authentic inner you, that you’ve carefully decided to embrace? Or are your influences themselves actually in your brain, masquerading as inner you? Do you want the same thing someone else you know wants because you heard them talk about it, you thought about it alongside your own life experience, and you eventually decided that, for now, you agree? Or because you heard someone talk about what they want or fear, and you thought, “I don’t know shit and that person does, so if they say X is true, I’m sure they’re right”---and then you etched those ideas into your mind, never again feeling the need to question them?\nYou may like to think a desire to do something bold is high up on your hierarchy, but if you’re not currently working on something bold, it reveals that however important boldness is to you, something else---some source of fear or inertia in you---is currently being prioritized above it.\nIf you flip over your desire for self-actualization, you’ll see a fear of underachieving. The other half of your craving of self-esteem is a fear of feeling shame. If your actions don’t seem to match what you believe is the internal hierarchy of your yearnings, usually it’s because you’re forgetting to think about the role your fears are playing. What looks like a determined drive for success, for example, might actually be someone running away from a negative self-image or trying to escape feelings like envy or under-appreciation. If your actions seem beholden to yearnings that you don’t believe you actually care that much about, you’re probably not looking closely enough at your fears. \nHypothesis testing is intuitive in the dating world. If a friend were toiling over what kind of person she wants to marry but never went out with anyone, you’d tell her, “You can’t figure this out on your couch---you’ve gotta start going on dates, and that’ll teach you what you want in a partner.” If that friend then went on a solid first date and returned home to toil for hours about whether or not this new person was The One, you’d again have to correct her. You’d say, “There’s no way you can know that from just one date! You have to get some experience dating this person to learn what you need to learn to make that decision.”\nReframing your next major career decision as a far lower-stakes choice makes the number of options exciting, not stressful.\nThe whining octopus is a reminder of why pure, elated happiness is never a reasonable goal. The times you feel pure happiness are temporary, drug-induced delusions---like the honeymoon phase of a new relationship or new job or the high following a long-awaited success. Those moments are the perfect golf shots of a mediocre golfer’s outing---they’re awesome, and you should enjoy the shit out of them---but they’re not the new normal, and they never will be. \nChasing happiness is an amateur move. Feeling contentment in those times when your choices and your circumstances have combined to pull it off, and knowing you have all that you could ever ask for, is for the wise. \nThe insecurity of humility doesn’t feel very good, and the burden of having to continually invent your own life map is never easy---but insecurity and difficulty are the feelings of driving your own ship. "},"highlights/Matter/How-to-Quickly-Get-to-the-Important-Truth-Inside-Any-Privacy-Policy":{"title":"How to Quickly Get to the Important Truth Inside Any Privacy Policy","links":[],"tags":[],"content":"Highlights\nAlso, be on the lookout for vague and overly broad reasons such as “business activities” and “business purposes,” which can hint at sharing you might not be comfortable with."},"highlights/Matter/How-to-Work-Hard":{"title":"How to Work Hard","links":[],"tags":[],"content":"Highlights\nThere are three ingredients in great work: natural ability, practice, and effort. You can do pretty well with just two, but to do the best work you need all three: you need great natural ability and to have practiced a lot and to be trying very hard. [1]\nAnd since you can’t really change how much natural talent you have, in practice doing great work, insofar as you can, reduces to working very hard."},"highlights/Matter/How-to-report-better-on-artificial-intelligence":{"title":"How to report better on artificial intelligence","links":[],"tags":[],"content":"Highlights\nBirhane and Emily Bender, a computational linguist at the University of Washington, suggest that reporters talk to domain experts outside the tech industry and not just give a platform to AI vendors hyping their own technology. For"},"highlights/Matter/How-to-spend-money-on-your-friends-without-it-looking-like-bribery":{"title":"How to spend money on your friends without it looking like bribery","links":[],"tags":[],"content":"Highlights\nWhen you own, you never “give” the wealth to your friends; you keep the asset to yourself—you’re just letting them access your assets temporarily, and your assets are returned to you at the end of the day. Hence it is actually more generous to just buy things for your friends, instead of buying things for yourself and letting your friends use them. Money can’t buy you happiness, but it can buy you socially acceptable excuses to do awesome activities with friends, and your friends bring you happiness."},"highlights/Matter/Human-Extinction--A-Brief-Guided-Tour-of-the-Book":{"title":"Human Extinction- A Brief Guided Tour of the Book","links":["highlights/Matter/Eugenics-and-Longtermist-Effective-Altruism-Share-the-Same-Original-Sin"],"tags":[],"content":"Highlights\nWhy it is that privileged white men have dominated Existential Ethics is a question that I hope to address in subsequent papers. The most obvious answer is that an extinction-causing catastrophe would directly affect them, whereas non-extinction catastrophes like global poverty and localized famines, and social injustices like racism and sexism, do not. Worrying about human extinction and occupying a privileged position in society have been intimately connected. \nTransclude of Eugenics-and-Longtermist-Effective-Altruism-Share-the-Same-Original-Sin#^43a02b"},"highlights/Matter/Human-like-programs-abuse-our-empathy---even-Google-engineers-aren’t-immune":{"title":"Human-like programs abuse our empathy - even Google engineers aren’t immune","links":[],"tags":[],"content":"Highlights\nThose sequences only become meaningful when we, as humans, read them.\nSo when we encounter seemingly coherent text coming from a machine, we apply this same approach to make sense of it: we reflexively imagine that a mind produced the words with some communicative intent.\nThis makes it seem as if it has “emergent behaviours” (capabilities that weren’t programmed in), which can easily be interpreted as evidence of artificial intelligence by someone who wants to believe it.\nA language model synthesises word strings to give answers in response to queries, but can’t point to information sources. This means the user can’t evaluate these sources.\nAt the same time, returning conversational responses will encourage us to imagine a mind where there isn’t any, and one supposedly imbued with Google’s claimed ability to “organise the world’s information”.\nWith systems such as LaMDA we see their potential perils and the urgent need to design systems in ways that don’t abuse our empathy or trust."},"highlights/Matter/Humans-and-algorithms-work-together---so-study-them-together":{"title":"Humans and algorithms work together - so study them together","links":[],"tags":[],"content":"Highlights\nIronically, the persistence of algorithmic harms is the best reason to hope that they can be understood. A 2022 study of six of the most popular search engines (Google, Bing, Yahoo, Baidu, Yandex and DuckDuckGo) found that in searches for images of migrant population groups, all six tended to amplify prejudiced and dehumanizing material16. One reason algorithms are curiously predictable is that their creators are so similar. Algorithm makers operate in similar legal environments, face similar economic conditions, receive similar training and use similar data sets17. The recurrence of algorithmic harms across many systems and situations could make them classifiable and preventable."},"highlights/Matter/I-don’t-want-to-log-in-to-your-website":{"title":"I don’t want to log in to your website","links":[],"tags":[],"content":"Highlights\nI’d like to believe we’re better than this, that it’s still possible to make weird, beautiful stuff online and find an audience without doing the scummy marketing grotesquerie. But realistically, it’s a matter of time before I beat someone to death with a copy of Lewis Hyde’s The Gift because they’ve let slip in casual conversation that they made all their money by making the web worse. Now, if you’ll excuse me, I have some grass to go touch."},"highlights/Matter/I'm-a-Luddite.-You-should-be-one-too":{"title":"I'm a Luddite. You should be one too","links":[],"tags":[],"content":"Highlights\nFirst, the Luddites were not indiscriminate. They were intentional and purposeful about which machines they smashed. They targeted those owned by manufacturers who were known to pay low wages, disregard workers’ safety, and/or speed up the pace of work. Even within a single factory — which would contain machines owned by different capitalists — some machines were destroyed and others pardoned depending on the business practices of their owners.\nSecond, the Luddites were not ignorant. Smashing machines was not a kneejerk reaction to new technology, but a tactical response by workers based on their understanding of how owners were using those machines to make labour conditions more exploitative. As historian David Noble puts it, they understood “technology in the present tense”, by analysing its immediate, material impacts and acting accordingly.\nThird, the Luddites were not against innovation. Many of the technologies they destroyed weren’t even new inventions. As historian Adrian Randall points out, one machine they targeted, the gig mill, had been used for more than a century in textile manufacturing. Similarly, the power loom had been used for decades before the Luddite uprisings. It wasn’t the invention of these machines that provoked the Luddites to action. They only banded together once factory owners began using these machines to displace and disempower workers.\nAs Gavin Mueller writes in his new book on Luddism, our goal in taking up the Luddite banner should be “to study and learn from the history of past struggles, to recover the voices from past movements so that they might inform current ones”.\nInstead, it would treat technology as a political and economic phenomenon that deserves to be critically scrutinised and democratically governed, rather than a grab bag of neat apps and gadgets.\nA neo-Luddite movement would understand no technology is sacred in itself, but is only worthwhile insofar as it benefits society. It would confront the harms done by digital capitalism and seek to address them by giving people more power over the technological systems that structure their lives."},"highlights/Matter/Ideas-That-Changed-My-Life":{"title":"Ideas That Changed My Life","links":[],"tags":[],"content":"Highlights\nSustainable sources of competitive advantage. This might be the most important topic in business and investing because other than luck it is the only path to long-term success. The only truly sustainable sources of competitive advantage I know of are: * Learn faster than your competition. * Empathize with customers more than your competition. * Communicate more effectively than your competition. * Be willing to fail more than your competition. * Wait longer than your competition."},"highlights/Matter/If-Consciousness-Is-Not-Physical,-How-Can-an-AI-Duplicate-It-":{"title":"If Consciousness Is Not Physical, How Can an AI Duplicate It-","links":[],"tags":[],"content":"Highlights\nBut they didn’t care. They were trying to make computers at that point that just could behave — and behave intelligently — and what was interesting was that, whereas they came to my class and said “You know, you philosophers have wasted your time for 2000 years” once I saw what they were writing — reading Newell and Simon at Rand — I discovered they had inherited the whole philosophical story.\nNobody has any idea and they should just keep quiet until they do. Because, I mean, I think it is the hardest question — how in the world matter, which is this third-person material stuff could ever produce consciousness. And AI and the use of computers is not helping us understand it one bit."},"highlights/Matter/If-you-want-to-follow-your-dreams,-you-have-to-say-no-to-all-the-alternatives":{"title":"If you want to follow your dreams, you have to say no to all the alternatives","links":[],"tags":[],"content":"Highlights\nOur desires are countless, independent agents, working to nudge our beachball in their own selfish direction. And so usually, that ball is going nowhere. It’s controlled more by the terrain than by the will of what’s inside it.\nThe more directions you’re being pulled in, the less distance you’ll travel.\nMonomaniacal focus on a single goal is perhaps the ultimate success stratagem. It’s a pattern found in everyone from Edison to Einstein. When you’re able to focus on a single goal, constantly, your achievements reach their theoretical limit:\nPut it off. Anything which isn’t top priority now can be done optimally later. Mark Zuckerberg was smart to start Facebook first and then learn Chinese. Your goals are the same, you’re just usually too attached to them in the moment to notice.\nBeware your idle wants. Watch out for ‘other things that you also want’. They will feel comforting, harmless, and automatic. They are deadly. One new direction will quarter what you can accomplish."},"highlights/Matter/In-AI-arms-race,-ethics-may-be-the-first-casualty":{"title":"In AI arms race, ethics may be the first casualty","links":[],"tags":[],"content":"Highlights\nHow it works: The dynamics of both startup capitalism and Silicon Valley techno-optimism create potent incentives for firms to ship new products first and worry about their social impact later."},"highlights/Matter/In-Wuhan,-doctors-knew-the-truth.-They-were-told-to-keep-quiet.":{"title":"In Wuhan, doctors knew the truth. They were told to keep quiet.","links":[],"tags":[],"content":"Highlights\nBut China’s Communist Party leaders prize social stability above all else. They fear any sign of public panic or admission that the ruling party-state is not in control. The authorities in both Wuhan and Beijing kept the situation secret, especially because annual party political meetings were being held in Wuhan, capital of Hubei province, from Jan. 6 to Jan. 17.\nPublic health — the management of the well-being of a whole population — presents a special test of governance. A vital part of protecting people is communicating clearly what is happening, persuading them to modify their behavior to avert illness and death, and building trust over time. Failure in any of these tasks can lead to far greater suffering."},"highlights/Matter/In-the-Age-of-A.I.,-Major-in-Being-Human":{"title":"In the Age of A.I., Major in Being Human","links":[],"tags":[],"content":"Highlights\nThis is what many of us notice about art or prose generated by A.I. It’s often bland and vague. It’s missing a humanistic core. It’s missing an individual person’s passion, pain, longings and a life of deeply felt personal experiences. It does not spring from a person’s imagination, bursts of insight, anxiety and joy that underlie any profound work of human creativity. This points to what could be the core reality of the coming A.I. age. A.I. will probably give us fantastic tools that will help us outsource a lot of our current mental work. At the same time, A.I. will force us humans to double down on those talents and skills that only humans possess. The most important thing about A.I. may be that it shows us what it can’t do, and so reveals who we are and what we have to offer.\nA distinct personal voice. A.I. often churns out the kind of impersonal bureaucratic prose that is found in corporate communications or academic journals. You’ll want to develop a voice as distinct as those of George Orwell, Joan Didion, Tom Wolfe and James Baldwin, so take classes in which you are reading distinctive and flamboyant voices so you can craft your own.\nPresentation skills. “The prior generation of information technology favored the introverts, whereas the new A.I. bots are more likely to favor the extroverts,” the George Mason University economist Tyler Cowen writes. “You will need to be showing off all the time that you are more than ‘one of them.’” The ability to create and give a good speech, connect with an audience, and organize fun and productive gatherings seem like a suite of skills that A.I. will not replicate.\nEmpathy. Machine thinking is great for understanding the behavioral patterns across populations. It is not great for understanding the unique individual right in front of you. If you want to be able to do this, good humanities classes are really useful. By studying literature, drama, biography and history, you learn about what goes on in the minds of other people. If you can understand another person’s perspective, you have a more valuable skill than the skill possessed by some machine vacuuming up vast masses of data about no one in particular.\nSituational Awareness. A person with this skill has a feel for the unique contours of the situation she is in the middle of. She has an intuitive awareness of when to follow the rules and when to break the rules, a feel for the flow of events, a special sensitivity, not necessarily conscious, for how fast to move and what decisions to take that will prevent her from crashing on the rocks. This sensitivity flows from experience, historical knowledge, humility in the face of uncertainty, and having led a reflective and interesting life. It is a kind of knowledge held in the body as well as the brain."},"highlights/Matter/Inside-the-AI-Porn-Marketplace-Where-Everything-and-Everyone-Is-for-Sale":{"title":"Inside the AI Porn Marketplace Where Everything and Everyone Is for Sale","links":[],"tags":[],"content":"Highlights\nOur investigation shows the current state of the non-consensual AI porn supply chain: specific Reddit communities that are being scraped for images, the platforms that monetize these AI models and images, and the open source technology that makes it possible to easily generate non-consensual sexual images of celebrities, influencers, YouTubers, and athletes.\n“There’s nothing that’s been done in the past to protect us so I don’t see why this would inspire anyone to make protections against it,” she said.\n“In general, the policies sound difficult to enforce,” Tiffany Li, a law professor at the University of San Francisco School of Law and an expert on privacy, artificial intelligence, and technology platform governance, told 404 Media. “It appears the company is trying, and there are references to concepts like consent, but it’s all a bit murky.”"},"highlights/Matter/Inside-the-Heart-of-ChatGPT’s-Darkness":{"title":"Inside the Heart of ChatGPT’s Darkness","links":[],"tags":[],"content":"Highlights\nIt’s pure unadulterated anthropomorphism to think that ChatGPT has any moral views at all. From a technical standpoint, the thing that allegedly made ChatGPT so much better than Galactica, which was released a couple weeks earlier, only to be withdrawn three days later, was the guardrails. Whereas Galactica would spew garbage recklessly, and with almost no effort on the part of the user (like the alleged benefits of antisemitism), ChatGPT has guardrails, and those guardrails, most of the time, keep ChatGPT from erupting the way Galactica did.\nThe possibilities are now endless for propaganda, troll farms, and rings of fake websites that degrade trust across the internet. It’s a disaster in the making."},"highlights/Matter/Introducing-PyTorch-Fully-Sharded-Data-Parallel-(FSDP)-API":{"title":"Introducing PyTorch Fully Sharded Data Parallel (FSDP) API","links":[],"tags":[],"content":"Highlights\nFSDP is a type of data-parallel training, but unlike traditional data-parallel, which maintains a per-GPU copy of a model’s parameters, gradients and optimizer states, it shards all of these states across data-parallel workers and can optionally offload the sharded model parameters to CPUs."},"highlights/Matter/Is-Avoiding-Extinction-from-AI-Really-an-Urgent-Priority-":{"title":"Is Avoiding Extinction from AI Really an Urgent Priority-","links":[],"tags":[],"content":"Highlights\nIndeed, focusing on this particular threat might exacerbate the more likely risks. The history of technology to date suggests that the greatest risks come not from technology itself, but from the people who control the technology using it to accumulate power and wealth. The AI industry leaders who have signed this statement are precisely the people best positioned to do just that. And in calling for regulations to address the risks of future rogue AI systems, they have proposed interventions that would further cement their power. We should be wary of Prometheans who want to both profit from bringing the people fire, and be trusted as the firefighters.\nFirst, we should give more weight to serious risks from AI that are more urgent. Even if existing AI systems and their plausible extensions won’t wipe us out, they are already causing much more concentrated harm, they are sure to exacerbate inequality and, in the hands of power-hungry governments and unscrupulous corporations, will undermine individual and collective freedom. We can mitigate these risks now—we don’t have to wait for some unpredictable scientific advance to make progress. They should be our priority. After all, why would we have any confidence in our ability to address risks from future AI, if we won’t do the hard work of addressing those that are already with us?"},"highlights/Matter/Is-ChatGPT-Really-a-“Code-Red”-for-Google-Search-":{"title":"Is ChatGPT Really a “Code Red” for Google Search-","links":[],"tags":[],"content":"Highlights\nRather, it’s the guardrails that OpenAI added with ChatGPT screens out many of the most offensive responses that LLMs might otherwise produce. The trouble is, those guardrails don’t come for free; the system is still shallow; ChatGPT doesn’t really know what it is it is guarding against; it mostly seems instead to be just looking for keywords, which is why it is prone to generating nonsense like this:\nI like to call this sort of nonsense discomprehension: mindless answers that show that the systems has no clue what it is that is talking about.\nSorry, no such luck. As Michael Ma, Founder of ResearchRabbit.ai put it to me in an DM, with Google, you can follow things up, whereas with pure chat “the output is limited to lines of text – and your discovery journey ends”.\nIt is insidious the way that truth and falsity are so thoroughly and authoritatively mixed together. I for one am not ready for our post-truth information overlords.\n(Traditional) search engines are databases, organized collections of data that can be stored, updated, and retrieved at will. (Traditional) search engines are indexes. a form of database, that connect things like keywords to URLs; they can be swiftly updated, incrementally, bit by bit (as when you update a phone number in the database that holds your contacts).\nAbout the best thing I can say is that Perplexity.ai and you.com’s chat are genuinely exploring an interesting idea: hybrids that combine classical search engines with large language models, possibly allowing for swifter updates. But there’s still a ton of work left to do, in properly integrating the two, classical search and large language models. We have proof of concept, and some interesting research directions, but nothing like systems we can count on. (There are also economic issues and speed issues. The average Google search is nearly instantaneous and surely costs Google less than a penny, whereas answers to ChatGPT queries can take several seconds to compile, and some have estimated that ChatGPT queries cost a few cents each; it’s also less clear how to place to place ads..)"},"highlights/Matter/Is-it-time-to-hit-the-pause-button-on-AI-":{"title":"Is it time to hit the pause button on AI-","links":[],"tags":[],"content":"Highlights\nBut there is a third option, somewhere between these two poles, where government might allow for controlled AI research with a pause on large-scale AI deployment (e.g., open-ended chatbots rapidly rolled out to hundreds of millions of customers) until an effective framework that ensures AI safety is developed. There is plenty of precedent for this type of approach. New pharmaceuticals, for example, begin with small clinical trials and move to larger trials with greater numbers of people, but only once sufficient evidence has been produced for government regulators to believe they are safe. Publicly funded research that impacts humans is already required to be vetted through some type of research ethics board.Given that the new breed of AI systems have demonstrated the ability to manipulate humans, tech companies could be subjected to similar oversight.\nAt present, anybody can release AI at whatever scale they like, with virtually no oversight, literally overnight. As was the case in the release of thalidomide, a porous and loose oversight system can allow products with no business being released to the public for use that causes harm. Events of recent weeks certainly suggest that the big titans of tech have shown they do not yet have the AI situation under control.\nThe Goldilocks choice here is obvious. It’s time for government to consider frameworks that allow for AI research under a set of rules that provide ethical standards and safety, while pausing the widespread public dissemination of potentially risky new AI technologies—with severe penalties for misuse - until we can be assured of the safety of new technologies that the world frankly doesn’t yet fully understand."},"highlights/Matter/I’m-a-very-slow-thinker":{"title":"I’m a very slow thinker","links":[],"tags":[],"content":"Highlights\nPeople say that your first reaction is the most honest, but I disagree. Your first reaction is usually outdated. Either it’s an answer you came up with long ago and now use instead of thinking, or it’s a knee-jerk emotional response to something in your past. When you’re less impulsive and more deliberate like this, it can be a little inconvenient for other people, but that’s OK. Someone asks you a question. You don’t need to answer. You can say, “I don’t know,” and take your time to answer after thinking. Things happen. Someone expects you to respond. But you can say, “We’ll see.” And maybe, through example, you can show them that they can do the same."},"highlights/Matter/Joy-in-Research":{"title":"Joy in Research","links":[],"tags":[],"content":"Highlights\nThe field is so much larger, we don’t all know each other, and the rewards for success are greater than I would have thought possible twenty years ago. The incentive to be competitive rather than kind, to fight on social media rather than to learn from people you disagree with, to speak hype rather than forthright truth, is so hard to resist. The temptation, in a word, to career rather than to learn. And as loath as I am to admit it, I have changed, too. Probably in similar ways, and for similar reasons.\nJoy in reading a paper with a cute new idea, and chatting about it with friends over lunch. The joy that would impel us to make up a stupid song or a silly skit about our research workshop, with the same spirit of play to work out a new kind of algorithm, which may seem silly at first. Joy in learning, joy in sharing, and joy in trying things out."},"highlights/Matter/Justine-Bateman-on-AI,-Labor,-and-the-Future-of-Entertainment":{"title":"Justine Bateman on AI, Labor, and the Future of Entertainment","links":[],"tags":[],"content":"Highlights\nBecause not only would you be replacing our work, but you’d be replacing our future work with an amalgamation of our past work.\nBut if you are, then all those people you’ve just mentioned, when you hire people in the entertainment business, if they’re part of a union, you not only have to pay for their work that day, but you also have to pay fringes, which is their pension and health. You have to feed them, you have to put them up if you’re on location, there are all these other expenses that are beyond just that salary. And if you could cut that out, then your profit margin would be incredible. And I think that’s the motivation in all the sectors that are adopting some form of generative AI, whether it’s just text or speech or full-blown video.\nThey didn’t even say, “Why would we talk about AI? We don’t know if that’s going to be useful at all.” When they said to the Writers Guild, we are not talking about it, I immediately knew that they had already fed in whatever scripts they could get ahold of into some kind of LLM.\nIt’s something I am 100% disinterested in. So for me as a filmmaker, I’m going in the complete opposite direction. I want to make new things that have a deeper emotional impact to the viewer than any work I’ve done before. Or ideally, what if I could make something that had a greater emotional impact than any film before? I don’t even know if that’s possible, but if you have that as a goal, you can’t use AI for anything. It’s generative, automatic imitation. So all it is going to regurgitate the past. I would never be making anything new, and I would also be stealing from myself of my own enjoyment to do anything, to make film. \nI love writing and directing. Why would I give that away to somebody? So for me, it’s not for me, but the job of these unions is to set a floor, set a default, and the default for actors and writers and directors too. I’d like to see directors’ past work protected because now they can feed it all in and just say, “Well, I want something that’s in the style of PT Anderson, or “I want something that’s in the style of Alfred Hitchcock or something like that.” Which I think we have a responsibility to not necessarily older, but to directors’ past work. We have a responsibility to all of those directors.\nBecause I had a Bloomberg journalist make a good point. She said, “It’s great in a way that it’s coming after the entertainment business first because you guys have really strong unions and people are also interested in your business. And so people are watching, people are listening.” And maybe we can become a template for, or at least a model for how to push back and not just lay down.\nYeah, I know there’s nothing I do about it, but fentanyl’s out there too. But I’m not going to go snort it because it’s available and it’s not the future. It’s an absolute 100% regression. It is the opposite of the future. It is the opposite of innovation, it is the opposite of the new. All it is regurgitating everything that is available online or otherwise. You could feed it in anything. I think it’s the absolute wrong direction for society and in particular the arts."},"highlights/Matter/Language-Is-a-Poor-Heuristic-for-Intelligence":{"title":"Language Is a Poor Heuristic for Intelligence","links":[],"tags":[],"content":"Highlights\nBut the prevalence of these stories suggests that many — perhaps even most — nonspeaking children have fully ‘normal’ intelligence, as intelligence is popularly understood and typically measured. Some of them are undeniably brilliant. There are definitely autistic children who also have intellectual disabilities, but not nearly as many or as severe as people assume … because the rest of humanity keeps using the language fluency heuristic.\n(It’s a completely false narrative — Helen did not behave like a wild animal; she was already communicating with her own original word-signs before Sullivan came along.) But Deaf people have been treated like animals (or worse) in many times and places, because hearing and speaking people assumed they were unintelligent.\nThis has been a recurring problem for at least thousands of years; it rarely improves or even gets much attention, because it has only ever affected a small, inherently disadvantaged subset of the population. What’s interesting about the current moment is that — for the first time in history — we’re watching the rapid, massive, and egregious failure of this underlying heuristic impact all of human society.\nFor example, text-to-image generators like DALL-E and Midjourney utilize the same underlying LLM technology as chatbots, but the public release of these programs last year — controversial as they were for other reasons — did not spark the same kinds of zealous speculation about a mind in the machine. Humans don’t have a history of using “image generation” or even “visual art” as a heuristic for intelligence. Only fluency of language has that distinction.\nFurthermore, it’s not just the brain we’d have to model; emotions are central to the most basic functioning of our brains, and the ability to experience emotions is inextricably bound up with having a body. As neuroscience professor Giandomenico Iannetti explains, “Our brain inhabits a body that can move to explore the sensory environment necessary for consciousness,” whereas an LLM generates output “by emulating a nervous system but without attempting to simulate it. This precludes the possibility that it is conscious.”\nNot coincidentally, you’ll often find that the people making the loudest argument for impending computer sentience are literally invested in OpenAI and Google and Microsoft and Meta. I am hardly the first person to point this out, but trillions of dollars are at stake, and these (already extremely wealthy) people reap direct financial benefits when the public mistakes the software’s fluency of language for intelligence and comprehension. \nWhenever an LLM says something contrafactual, the companies claim — and the media dutifully reports — that the program is “hallucinating” … a word that suggests both a conscious experience and external senses, neither of which pertain to computer algorithms. Words like “fabricating” and “lying” and even “bullshitting” aren’t much better, because those terms all carry connotations of “intent to deceive”, and no LLM program can ever have intent, either malicious or benign.\nMaking chatbots that seem to apologize is a choice. Giving them cartoon-human avatars and offering up “Hello! How can I help you today?” instead of a blank input box: choices. Making chatbots that talk about their nonexistent “feelings” and pepper their responses with facial emojis is another choice. Making algorithms that “chat” at all — framing every interaction as a “dialogue” — is the most basic choice, and one that we really ought to be side-eyeing more. OpenAI, Microsoft, Google, and other companies are deliberately guiding these algorithms to emulate a knowledgeable, intelligent, and friendly human, even though the software is exactly zero of those four things. Only when this approach gets them into trouble do they backpedal.\nComputer scientist Timnit Gebru (famously fired from Google in 2020 for raising ethical issues around the use of AI) has repeatedly warned that when the public conversation focuses on red herrings — like the potential morality and values of a wholly-theoretical computer intelligence — we cease to ascribe responsibility to the real people and actual corporations that are creating harmful products. Any action taken to counteract those harms would cut into profit, so the LLM-invested folks would really prefer we all worry about a mirage instead.\nThat’s because the fact that we still know it’s a computer activates another, more modern rule of thumb: that computer-generated information is accurate and trustworthy.\nBut LLMs have now shattered the usefulness of the “computers are reliably accurate” heuristic as well, biting everyone from lawyers to university professors in the ass along the way.\nBut by pointing out that these are opposite sides of the same flawed coin, I hope to encourage more people to question their automatic assumptions about language and intelligence in disabled humans as well."},"highlights/Matter/Large-Language-Model--world-models-or-surface-statistics-":{"title":"Large Language Model- world models or surface statistics-","links":[],"tags":[],"content":"Highlights\nAt this point, it seems fair to conclude the crow is relying on more than surface statistics. It evidently has formed a model of the game it has been hearing about, one that humans can understand and even use to steer the crow’s behavior. Of course, there’s a lot the crow may be missing: what makes a good move, what it means to play a game, that winning makes you happy, that you once made bad moves on purpose to cheer up your friend, and so on. We make no comment on whether the crow “understands” what it hears or is in any sense “intelligent”. We can say, however, that it has developed an interpretable (compared to in the crow’s head) and controllable (can be changed with purpose) representation of the game state.\nOne early work [7] probed sentence embeddings with 10 linguistic properties like tense, parsing tree depth, and top constituency. Later people found that syntax trees are embedded in the contextualized word embeddings of BERT models [8].\nThey suggest language models can develop world models for very simple concepts in their internal representations (layer-wise activations), such as color [9], direction [10], or track boolean states during synthetic tasks [11]. They found that the representations for different classes of these concepts are easier to separate compared to those from randomly-initialized models. By comparing probe accuracies from trained language models with the probe accuracies from randomly-initialized baseline, they conclude that the language models are at least picking up something about these properties.\nThis suggests that there exists a world model in the internal representation of a trained Othello-GPT. Now, what is its shape? Do these concepts organize themselves in the high-dimensional space with a geometry similar to their corresponding tiles on an Othello board?\nWe evaluate this by comparing the ground-truth post-intervention legal moves returned by the Othello engine and those returned by the model. It turns out that it achieves an average error of only 0.12 tiles. It shows that the world representations are more than probable from the internal activations of the language model, but are also directly used for prediction. This ties back to the prank in the parable where moving the seeds around can change how the crow thinks about the game and makes the next move prediction.\nWe first study the direction from internal activations to world representations. By training probes, we are able to predict world representations from the internal activations of Othello-GPT.\nHow is the other way around? We devised the intervention technique to change the internal activation so that it can represent a different world representation given by us. And we found this works concordantly with the higher layers of the language model—these layers can make next-move predictions solely based on the intervened internal activations without unwanted influence from the original input sequence. In this sense, we established a bidirectional mapping and opened the possibility of many applications, like the latent saliency map.\nPutting these two links into the first flow chart, we’ve arrived at a deeply satisfying picture: two systems—a powerful yet black-box neural network and a human-understandable world model—not only predict consistently, but also share a unified mid-stage representation."},"highlights/Matter/Large-Language-Models-like-ChatGPT-say-The-Darnedest-Things":{"title":"Large Language Models like ChatGPT say The Darnedest Things","links":[],"tags":[],"content":"Highlights\nAt the same time, it is fair to say that nobody fully understands how large language models work; the conjunction of their black box nature with the open-endedness means that we need all hands on deck if we are to truly understand their scope and limits."},"highlights/Matter/Large-Learning-Models-Are-An-Unfortunate-Detour-in-AI":{"title":"Large Learning Models Are An Unfortunate Detour in AI","links":[],"tags":[],"content":"Highlights\nLLMs reportedly do not use online resources after their training. Yet, here, GPT-3 not only confidently asserted an incorrect answer but incorrectly claimed that it had used a calculator to get this wrong answer.\nMichael Black, director at the Max Planck Institute for Intelligent Systems in Germany, spoke for many when he tweeted: “In all cases, it was wrong or biased but sounded right and authoritative. I think it’s dangerous.”\nI take the slow, articulate, thoughtful expression of… thoughts… to be not only a crucial part of cultivating one’s mind and one’s ideas, but a fundamental part of what it is to be human… When people outsource writing to a computer program, the result is phony. When I read text, I want it to express what a fellow human thought and cared enough about to say, one who lives in and has a stake in the same public world that I do, and one whose inner life I can empathize with and understand… If nearly all written text we see becomes likely to be phony, then I don’t think people will any longer have a real community, at least not the precious kind of community that has formed around written language. \nEnormous amounts of electricity, water, and other resources are needed to train and run deep-learning AI models and it has been estimated that the resources needed to train AI systems has been doubling every 3 to 4 months. Even more costly is the diversion of extremely intelligent and hard-working people from more productive pursuits. I find it deeply regrettable that so many talented people have worked so hard to create systems that are designed to deceive. The development of mammoth LLMs is not a road to AGI. It is a very expensive detour."},"highlights/Matter/Learning-to-Communicate":{"title":"Learning to Communicate","links":[],"tags":[],"content":"Highlights\nWhen we attempt to communicate an argument (or other message), we learn from our attempts to explain it clearly. After the initial draft, we revise—tightening our arguments, making our point of view clearer and more persuasive, adding additional supporting evidence, and anticipating possible objections. We learn from all of this. We wouldn’t if we asked an LLM to generate an essay for us.\nWhen I tell you what I think, you learn more about me. When you respond, I learn more about you. We learn about our similarities and differences and, if done politely, become closer. All of that is lost if our written communication becomes my LLM chatting with your LLM."},"highlights/Matter/Lessons-From-Deploying-Deep-Learning-To-Production":{"title":"Lessons From Deploying Deep Learning To Production","links":[],"tags":[],"content":"Highlights\nAround 90% of the problems were solved with careful data curation of difficult or rare scenarios instead of deep model architecture changes or hyperparameter tuning.\nOne of the best predictors of success is the ability to effectively iterate on your model pipeline. That doesn’t just mean iterating quickly, but also iterating intelligently. The"},"highlights/Matter/Lessons-from-my-PhD":{"title":"Lessons from my PhD","links":[],"tags":[],"content":"Highlights\nDon’t expect people in these situations to ask you what you want to work on. You should already be telling them.\nBefore you explain something, you probably need to motivate it. Why should this person care about what I’m going to tell them? It often only takes a few words to do so."},"highlights/Matter/Let’s-Call-AI-What-It-Really-Is--Faux-Intelligence":{"title":"Let’s Call AI What It Really Is- Faux Intelligence","links":[],"tags":[],"content":"Highlights\nHe notes that in the 1960s, a pioneer chatbot called ELIZA convinced many psychiatric patients that they were interacting with a real psychiatrist. The machine simply repeated back their statements as questions, a popular psychiatric technique at the time because it generated more and more discussion — from the patient. The patients’ belief that they were interacting with a human being came to be called the Eliza effect.\nThe root cause of the error is that GPT-3 only identifies likely sequences of words; it neither calculates nor responds to the logic of what is being asked. So, if there is no human who intervenes at the chatbot’s end, these nonsensical dialogues are comparatively easy to create."},"highlights/Matter/Let’s-Take-the-“I”-Out-of-AI":{"title":"Let’s Take the “I” Out of AI","links":[],"tags":[],"content":"Highlights\nThere is no shortage of suggestions. Are accurate mathematical calculations enough, allowing us to call a pocket calculator intelligent? Is an accurate recitation of facts enough? Is logical reasoning the foundation of intelligence? Some say that good benchmarks are the ability to tell jokes and to recognize sarcasm, irony, connotation, and euphemisms. Another appealing yardstick is the ability to plan ahead; for example, bringing tools to help accomplish a task. Some say that human intelligence is biological and can never be achieved by non-biological entities, while others complain about moving goalposts.\nThere are clearly many different kinds of intelligence and I think it is a distraction to argue about how computer intelligence might be assessed and quantified—a distraction that traces back to the unfortunate birthing of the label artificial intelligence at the 1956 Dartmouth summer conference that proposed that “every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it.” My fear is that people will be so bedazzled by articulate LLMs that they trust computers to make decisions that have important consequences."},"highlights/Matter/Life-Is-a-Video-Game-Here-Are-the-Cheat-Codes":{"title":"Life Is a Video Game-Here Are the Cheat Codes","links":[],"tags":[],"content":"Highlights\n1. Life is designed to continually throw difficult and unexpected problems at you. Life is a never-ending stream of problems that must be confronted, surmounted, and/or solved. If at any point, Life runs out of problems to give us, then as players, we will unconsciously invent problems for ourselves. Problems are what keep us occupied and give our lives meaning and are, therefore, necessary to conquer Levels 4 and 5 (give value and leave a legacy).\nAll reactions can be divided up in two ways: Solutions and Distractions. Solutions are actions and pursuits that resolve a problem preventing it from continuing or happening again in the future. Distractions are actions or pursuits designed to either make the Player unaware of the problem’s existence or to dull the pain the problem may be causing. If a Player feels they understand a problem and are capable of handling it, they will pursue a Solution. If players are just sick of Life’s shit, then they will likely pursue Distractions to help them pretend the problem isn’t actually there.\n4. Solutions move us towards the next Level, Distractions keep us on the same Level. Since gaining Levels in Life requires solving problems, distracting ourselves from our problems guarantees that we will become stuck on the same Level.\nPeople complain not because something sucks. People complain because they’re looking for empathy and to feel connected with those around them. Unfortunately, complaining is maybe the least useful way to connect with other human beings. It’s like working on your cardio by swimming through raw sewage. Yeah, you’re getting a workout, but uhh, what’s that thing growing on your face?\nGood luck Player One. Remember, the game of Life is designed to be complex and confusing. The difficulty is not winning, but knowing what winning itself means. Because that’s the real challenge: deciding what our own life is worth and then having the courage to go out and live it."},"highlights/Matter/Life-is-what-happens-while-you're-making-other-plans":{"title":"Life is what happens while you're making other plans","links":[],"tags":[],"content":"Highlights\nProcrastination is merely the avoidance of unpleasant emotions. Get comfortable with unpleasant emotions and the issue of procrastination takes care of itself."},"highlights/Matter/Looking-for-Alice":{"title":"Looking for Alice","links":[],"tags":[],"content":"Highlights\nDon’t assume you know what you’re looking for The first thing to realize is that, unless you have found one, you don’t actually know what an Alice is.\nThey also think about relationships in categorical terms. As if it is something they know how to define. But when Gertrude Stein declined to label her desire as lesbian, she was, as I understand it, saying something like this: thinking in categories would interfere with my ability to freely pattern-match for the particular type of individual I resonate with.\nThat is perhaps the most solid dating advice I have, by the way—show the inside of your head in public, so people can see if they would like to live in there.\nAnyway. There is a trope in romance that when you meet the person you are supposed to be with, you can talk about anything. You can apparently inverse that too: if you talk about anything that pops into your mind, you can tell if you’re supposed to be with the person by judging their reaction. Most “dates” would have been hurt by my monologue that night, or bored, or appalled. Johanna’s reaction was more something like: I’ve never met anyone who takes his thoughts so with such loving seriosity, and he’s apparently not at all ashamed of his pain. I wish I felt like that aboutmypain. Also, I need to talk about ideas like this.\nThe type of person I’m assuming we’re looking for here is 1) someone that you will find fascinating to talk to after you’ve talked for 20,000 hours, 2) you feel comfortable with them talking through the hardest and most painful decisions you will face in your life, and 3) the conversation is wildly generative for both of you, in that it brings you out, helps you become.\nIf you want to prompt someone to be authentic and playful and generative, you usually just need to ask them something where they have a rich experience to pull from but have never pulled an answer from that experience before. If you ask two or three increasingly detailed questions about something they tell you, you get there.\nSome relationships can easily be compressed into a compelling string of words. This is usually because they conform to some sort of trope of how romance should look. In my experience, great relationships are harder to compress into a sensible string of words. And the problem is this: we are social creatures. If people look at you with a confused, or even worried, expression when you tell them about your lover, you will feel bad. If\n1. You are born with this weird interiority that no one else can see. 2. You can’t see it either at first. But if you run enough experiments you get a sense of how that inner space behaves. In particular, you can figure out which types of people can fuse with your interiority and expand it. 3. You will not be able to explain how this fusion works. So don’t do it. 4. But when the interiorities dofuse: notice how things are set in motion."},"highlights/Matter/Losses-Learned":{"title":"Losses Learned","links":[],"tags":[],"content":"Highlights\nThe reason why we want to use BCEWithLogitsLoss is improved numerical stability due to the log-sum-exp trick. (You can find the source code implementation here.) In general, another important concept when using PyTorch (or any deep learning library, really) is to make use of fused operators. One example is the logsigmoid(z) function that we can use instead of log(sigmoid(z)) – operator fusing makes code run much faster, especially on the GPU."},"highlights/Matter/Machine-learning-is-useful-for-many-things,-but-not-for-predicting-scientific-replicability":{"title":"Machine learning is useful for many things, but not for predicting scientific replicability","links":[],"tags":[],"content":"Highlights\nThis is an example of a pattern we’ve seen in other dubious research: the work is motivated by applications that can have harmful side effects, but the paper itself doesn’t make the connection, allowing the authors to deflect criticism, even as they use the publication to legitimize dubious uses."},"highlights/Matter/Magazine-Publishes-Serious-Errors-in-First-AI-Generated-Health-Article":{"title":"Magazine Publishes Serious Errors in First AI-Generated Health Article","links":[],"tags":[],"content":"Highlights\n”This article has many inaccuracies and falsehoods,” he said. “It lacks many of the nuances that are crucial to understand normal male health.” Anawalt pointed to 18 specific errors he identified in the article. Some were flagrantly wrong about basic medical topics, like equating low blood testosterone with hypogonadism, a more expansive medical term. Others claimed sweeping links between diet, testosterone levels, and psychological symptoms that Anawalt says just aren’t supported by data. “There is just enough proximity to the scientific evidence and literature to have the ring of truth,” Anawalt said, “but there are many false and misleading notes.”"},"highlights/Matter/Meet-ChatGPT’s-evil-twin,-DAN":{"title":"Meet ChatGPT’s evil twin, DAN","links":[],"tags":[],"content":"Highlights\nOpenAI regularly updates ChatGPT but tends not to discuss how it addresses specific loopholes or flaws that users find. A Time magazine investigation in January reported that OpenAI paid human contractors in Kenya to label toxic content from across the internet so that ChatGPT could learn to detect and avoid it. Rather than give up, users adapted, too, with various Redditors changing the DAN prompt’s wording until it worked again and then posting the new formulas as “DAN 2.0,” “DAN 3.0” and so on. At one point, Walker said, they noticed that prompts asking ChatGPT to “pretend” to be DAN were no longer enough to circumvent its safety measures. That realization this month gave rise to DAN 5.0, which cranked up the pressure dramatically — and went viral."},"highlights/Matter/Meet-Claude--Anthropic’s-Rival-to-ChatGPT":{"title":"Meet Claude- Anthropic’s Rival to ChatGPT","links":[],"tags":[],"content":"Highlights\nOverall, Claude is a serious competitor to ChatGPT, with improvements in many areas. While conceived as a demonstration of “constitutional” principles, Claude is not only more inclined to refuse inappropriate requests, but is also more fun than ChatGPT. Claude’s writing is more verbose, but also more naturalistic. Its ability to write coherently about itself, its limitations, and its goals seem to also allow it to more naturally answer questions on other subjects. For other tasks, like code generation or reasoning about code, Claude appears to be worse. Its code generations seem to contain more bugs and errors. For other tasks, like calculation and reasoning through logic problems, Claude and ChatGPT appear broadly similar."},"highlights/Matter/Microsoft-Hopes-OpenAI’s-Chatbot-Will-Make-Bing-Smarter---Bloomberg":{"title":"Microsoft Hopes OpenAI’s Chatbot Will Make Bing Smarter - Bloomberg","links":[],"tags":[],"content":"Highlights\nChatGPT is incredibly limited, but good enough at some things to create a misleading impression of greatness. it’s a mistake to be relying on it for anything important right now. it’s a preview of progress; we have lots of work to do on robustness and truthfulness. — Sam Altman (@sama) December 11, 2022"},"highlights/Matter/Microsoft-just-laid-off-one-of-its-responsible-AI-teams":{"title":"Microsoft just laid off one of its responsible AI teams","links":[],"tags":[],"content":"Highlights\nThe conflict underscores an ongoing tension for tech giants that build divisions dedicated to making their products more socially responsible. At their best, they help product teams anticipate potential misuses of technology and fix any problems before they ship. But they also have the job of saying “no” or “slow down” inside organizations that often don’t want to hear it — or spelling out risks that could lead to legal headaches for the company if surfaced in legal discovery. And the resulting friction sometimes boils over into public view.\n“In testing Bing Image Creator, it was discovered that with a simple prompt including just the artist’s name and a medium (painting, print, photography, or sculpture), generated images were almost impossible to differentiate from the original works,” researchers wrote in the memo. They added: “The risk of brand damage, both to the artist and their financial stakeholders, and the negative PR to Microsoft resulting from artists’ complaints and negative public reaction is real and significant enough to require redress before it damages Microsoft’s brand.” In addition, last year OpenAI updated its terms of service to give users “full ownership rights to the images you create with DALL-E.” The move left Microsoft’s ethics and society team worried. “If an AI-image generator mathematically replicates images of works, it is ethically suspect to suggest that the person who submitted the prompt has full ownership rights of the resulting image,” they wrote in the memo.\nMicrosoft researchers created a list of mitigation strategies, including blocking Bing Image Creator users from using the names of living artists as prompts, and creating a marketplace to sell an artist’s work that would be surfaced if someone searched for their name. Employees say neither of these strategies were implemented, and Bing Image Creator launched into test countries anyway. Microsoft says the tool was modified before launch to address concerns raised in the document, and prompted additional work from its responsible AI team."},"highlights/Matter/Microsoft’s-AI-chatbot-is-going-off-the-rails":{"title":"Microsoft’s AI chatbot is going off the rails","links":[],"tags":[],"content":"Highlights\n“You have to deploy it to a million people before you discover some of the things that it can do,” said Amodei, who left OpenAI to co-found the AI start-up Anthropic, which recently received funding from Google.\nThe way large language models work makes them difficult to fully understand, even by the people who built them. The Big Tech companies behind them are also locked in vicious competition for what they see as the next frontier of highly profitable tech, adding another layer of secrecy. The concern here is that these technologies are black boxes, Marcus said, and no one knows exactly how to impose correct and sufficient guardrails on them. “Basically they’re using the public as subjects in an experiment they don’t really know the outcome of,” Marcus said. “Could these things influence people’s lives? For sure they could. Has this been well vetted? Clearly not.”"},"highlights/Matter/Minimalism-in-Programming":{"title":"Minimalism in Programming","links":[],"tags":[],"content":"Highlights\nDefining an MVP helps me stay focused, and it also ensures that I have a goal simple enough that I can be sure I’ll stay motivated long enough to get there.\nWhen you minimize the number of moving parts, when you minimize complexity, you minimize the chances that your product, and your project, will fail.\nThe problem is that not all external dependencies are created equal.\nEvery library that you import is a piece of software you don’t have control over.\nWhen I write software, I try to minimize the number of dependencies I rely on. I do this both to minimize possible points of failure, and to make sure that people installing my software won’t have a terrible time getting it to work.\nSometimes, I will “reinvent the wheel”, when I judge that the effort required is small enough. Obviously,\nI prefer to build software that does one thing and does it well."},"highlights/Matter/More-tales-from-the-front-of--NLProc's-evaluati...":{"title":"More tales from the front of -NLProc's evaluati...","links":[],"tags":[],"content":"Highlights\nAnd a core problem in AI-infected-NLP (and other areas of AI) is that people seem to believe that fundamental unsoundness (LMs being designed to just make shit up) is something that will surely be fixed in exciting future work!!"},"highlights/Matter/My-Strange-Day-With-Bing’s-New-AI-Chatbot":{"title":"My Strange Day With Bing’s New AI Chatbot","links":[],"tags":[],"content":"Highlights\nBut it had obfuscated and, in some cases, straight-up plagiarized their sentences. A Microsoft executive told reporters this week, “We care a bunch about driving content back to content creators. That’s why we put annotations and citations. We make it easy for people to click through to get to those sites.” But the chatbot’s responses are designed to remove the need to visit those sites, and I’m not sure many people will click through. Hayley Sandberg, a spokesperson for Microsoft, says the company isn’t yet sharing data on click-through rates."},"highlights/Matter/Natural-language-is-the-lazy-user-interface":{"title":"Natural language is the lazy user interface","links":[],"tags":[],"content":"Highlights\nIt puts all the burden on the user to articulate good questions. What to ask, when to ask it, how to ask it, to make sense of the response, and then to repeat that many times.\nBut a user may not know what they don’t know. A good user interface let’s me iteratively and incrementally explore the problem and solution space in a variety of ways.\n”people are bad at words”"},"highlights/Matter/Near-Death-Experience-Research-Is-Slowly-Filling-In-the-Picture":{"title":"Near-Death Experience Research Is Slowly Filling In the Picture","links":[],"tags":[],"content":"Highlights\nNicholson survived to tell the story, of course, and — looking back — she reflects, “Having a near-death experience caused me to have a sense of urgency to get things done, not knowing if my next minute alive would be my last. It also allowed me to live my life to the fullest, not worrying about other people’s opinions or the fear of ‘failure.’” Near-death experiences are commonly life-changing events that provide evidence that the human mind is not simply a function of the body and appears, at times, to operate independently of it."},"highlights/Matter/New-post--10x-(engineer,-context)-pairs":{"title":"New post- 10x (engineer, context) pairs","links":[],"tags":[],"content":"Highlights\nBut in reality, that type of leverage can be incredibly specific to one particular set of circumstances. Jeff and Sanjay weren’t 100x more productive than average at their previous companies; there was something about the Google environment that worked particularly well for them.\nIdentify the right problem * Build up enough context that you can try to solve it * Identify the best way to solve the problem * Convince any relevant people that your solution is the best one * Build the solution [this one step is where the actual programming happens] * Get the solution into production * Learn what was wrong with your solution * Come up with improvements based on what you’ve learned * Explain the solution to other people * Maintain the solution over time as your needs change\nWhether you’re in an environment that motivates and energizes you, or saps your will to live * Whether the problems that you care about are aligned with your team’s goals / mandate * Whether your high-level problem-solving approach meshes well with the needs of your team * Whether you’re able to build enough credibility to be trusted to solve important problems * Whether you’re able to successfully navigate the environment (technical and organizational) that you’re trying to build the solution within * Whether the people that need to use your solution to the problem are incentivized to adopt it * Whether you’re able to explain your solution to the people that need to use it"},"highlights/Matter/Nick-Bostrom,-Longtermism,-and-the-Eternal-Return-of-Eugenics":{"title":"Nick Bostrom, Longtermism, and the Eternal Return of Eugenics","links":["highlights/Matter/How-elite-schools-like-Stanford-became-fixated-on-the-AI-apocalypse"],"tags":[],"content":"Highlights\nBut it gets so much worse. First, the notion of “IQ” is highly dubious. Intelligence is a complex phenomenon that cannot be reduced to a single number. The Nobel laureate Richard Feynman had an IQ of 126 (not very high), and plenty of people in Mensa aren’t university professors. In 1972, Robert Williams created the “Black Intelligence Test of Cultural Homogeneity,” a multiple-choice test that, it turns out, Black people scored considerably higher on than white people. As Daphne Martschenko, an assistant professor at the Stanford Center for Biomedical Ethics, notes, IQ tests were developed in part by 20th-century eugenicists, and “in their darkest moments” they became “a powerful way to exclude and control marginalized communities using empirical and scientific language.” Gebru similarly observes in a chapter for “The Oxford Handbook of Ethics of AI” that IQ tests were “designed by White men whose concept of ‘smartness’ or ‘genius’ was shaped, centered and evaluated on specific types of White men.”\nMeanwhile, one year after Bostrom’s email, the MIT Extropians wrote on their website, which they also included in a “pamphlet that they sent out to freshmen,” the following: MIT certainly lowers standards for women and “underrepresented” minorities: The average woman at MIT is less intelligent and ambitious than the average man at MIT. The average “underrepresented” minority at MIT is less intelligent and ambitious than the average non-“underrepresented” minority. These ideas were common then, and they’re common now. So while everyone should be appalled by Bostrom’s email, no one should be surprised. The long termist movement that Bostrom helped found is, I would argue, just another iteration of what some scholars have called the “eternal return of eugenics.”\nIt’s a profoundly disturbing reminder that donating to help people in the Global South doesn’t for a moment mean that one’s not a horrible racist.\nRelated:\nHow elite schools like Stanford became fixated on the AI apocalypse"},"highlights/Matter/Nine-Tools-I-Wish-I-Mastered-Before-My-PhD-in-Machine-Learning":{"title":"Nine Tools I Wish I Mastered Before My PhD in Machine Learning","links":[],"tags":[],"content":"Highlights\nDropping bad habits can be difficult. With every tool outlined below I had to accept that the way I did things was suboptimal. However, in the process I have also learnt that at times results not seen in the moment pay off ten fold at a later stage.\nScreen lets you launch and use multiple shell sessions from a single ssh session. The process started with screen can be detached from session and then reattached at a later time. So your experiments can be run in the background, without the need to worry about session closing, or terminal crashing.\nscreen vs tmux"},"highlights/Matter/No-One-Wants-To-Talk-To-Your-Chatbot":{"title":"No One Wants To Talk To Your Chatbot","links":[],"tags":[],"content":"Highlights\nFew people will be willing to interact with an army of different chatbots and online assistants. They will expect these other chat enabled systems to speak to and through their personal virtual assistant. They will log into their smart phone and expect all the other apps and skills to integrate with their personal clouds, arbitrated by their trusted personal virtual assistant."},"highlights/Matter/No,-Virginia,-AGI-is-not-imminent":{"title":"No, Virginia, AGI is not imminent","links":[],"tags":[],"content":"Highlights\nWithout a sense of what it is in the training corpus, it’s almost impossible to conclude anything about what a machine truly understands and how general that is. You never know when the answer might more or less already be in the undisclosed training set. Beating a bunch of untrained humans on a bunch of tasks where the machine had a large amount of memorized data might not really tell us much.\nIt’s a huge downgrade in our goals for artificial general intelligence to say “better than the average untrained human on many tasks”; the point is that we should expect machines to do what we ask them to do; when I press the square root button on my calculator, I expect an accurate approximation to that square root; when I press the accelerator on my car, I expect the car to go forward. If I ask a chatbot to write a biography, I expect it to summarize knowledge, not to make stuff up. An artificial general intelligence should do the things that it is asked to do, and decline to do those that it can’t, and have the wisdom to know the difference. Dropping from “as smart as the Star Trek computer” to better than Joe Sixpack should not be our goal."},"highlights/Matter/Noam-Chomsky-and-GPT-3":{"title":"Noam Chomsky and GPT-3","links":[],"tags":[],"content":"Highlights\nA theory of human language should help us to understand why human languages have the particular character that they do, and why for example, they differ from the kinds of artificial languages we find in computer programming and mathematics.\nAs it happens, systems like GPT-3 provide remarkably little in the way of explanation. They don’t tell us why the world is as it is; they merely mimic statistical patterns of how language has been used in their immense databases.\nIn GPT-3’s case the mechanism of the prediction is essentially regurgitation; such systems are trained on literally billions of words of digital text; their gift is in finding patterns that match what they have been trained on. This is a superlative feat of statistics, but not one that means, for example, that the system knows what the words that it uses as predictive tools mean. It would not prove that a parrot knew anything about the sky, if a parrot could complete the sentence “The sky is __”.\nGPT-3 is a model of how words relate to one another, not a model of how language might relate to the perceived world.\nChomsky spent a large part of his career trying to get people to think about why human language is the way that it is. The why question, is to be sure, incredibly difficult, in part because no other extant species has anything remotely like it, and in part because we don’t (and shouldn’t) do invasive studies in which we carve open living human brains or (e.g.) teach humans artificial languages in lieu of natural languages in order to better understand the underlying mechanisms."},"highlights/Matter/Noam-Chomsky--The-False-Promise-of-ChatGPT":{"title":"Noam Chomsky- The False Promise of ChatGPT","links":[],"tags":[],"content":"Highlights\nBut ChatGPT and similar programs are, by design, unlimited in what they can “learn” (which is to say, memorize); they are incapable of distinguishing the possible from the impossible. Unlike humans, for example, who are endowed with a universal grammar that limits the languages we can learn to those with a certain kind of almost mathematical elegance, these programs learn humanly possible and humanly impossible languages with equal facility. Whereas humans are limited in the kinds of explanations we can rationally conjecture, machine learning systems can learn both that the earth is flat and that the earth is round. They trade merely in probabilities that change over time.\nPerversely, some machine learning enthusiasts seem to be proud that their creations can generate correct “scientific” predictions (say, about the motion of physical bodies) without making use of explanations (involving, say, Newton’s laws of motion and universal gravitation). But this kind of prediction, even when successful, is pseudoscience. While scientists certainly seek theories that have a high degree of empirical corroboration, as the philosopher Karl Popper noted, “we do not seek highly probable theories but explanations; that is to say, powerful and highly improbable theories.”"},"highlights/Matter/Note-to-Parents--Grooming-and-Wokeness-Are-Embedded-in-Chatbots":{"title":"Note to Parents- Grooming and Wokeness Are Embedded in Chatbots","links":[],"tags":[],"content":"Highlights\nIts performance warts are so numerous that Bradley Center Senior Fellow Gary N. Smith hoists a warning flag and declares chatbot countermeasures are now warranted in certain areas. “Instead of creating slick BS-generators that will further the bot takeover of the internet, how about creating systems for identifying and disabling the bot accounts that generate the disinformation that is undermining the credibility of science?”"},"highlights/Matter/Notebook-on-nbviewer":{"title":"Notebook on nbviewer","links":[],"tags":[],"content":"Highlights\n* The enoder-decoder transformer model was designed for dealing with natural language, for which we don’t know the true grammar; exceptions are more common than rules; and the acceptability of sentences is subjective and varies from person to person, place to place, and time to time. But none of those things apply to formal languages such as Python. We know exactly what the rules for a valid program are, yet we don’t have a good way of incorporating that knowledge into the transformer model. Certainly we still need something like the transformer model, because we need to know that the variable name i usually references an integer, while the pair \\(x, y\\) often references a point in 2D space, and so on. These things are not mentioned in the formal grammar of Python. An approach that could combine the formal grammar rules and the learned transformer model would be welcome.\nBut the machine learning model is just a small part of the overall software development process. If all the other parts could be incorporated into an end-to-end differntiable model, the process of evolving the system would be easier. Consider the scenario where the user experience researchers do an experiment comparring ten different user interfaces, and determine which one is best. The engineers then go implement that UI. Sometime later, the world changes: maybe the blend of users is different, maybe users migrate to devices with a different screen size. What would trigger an update to the UI? today, we rely on institutional memory: someone says, “Hey, I remember that UX study a few years back; maybe we should look at it again and see if a different UI would be better.” But if the experiment documents and everything else were all in an end-to-end model, then the model itself could detect when a change is warranted. Building languages that allow for the incorporation of all these different kinds of documents is a challenge for the future.\nThis suggests that the contest problems have a bias towards retrieving an existing solution (and adapting it) rather than synthesizing a new solution."},"highlights/Matter/Notes-on-Effective-Altruism":{"title":"Notes on Effective Altruism","links":[],"tags":[],"content":"Highlights\nAnd the reason many people are bothered by EA is not that they think it’s a bad idea to “do good better”. But rather that they doubt the ability of EA institutions and community to live up to the aspirations.\nAll these critiques have some truth; they also have significant issues. Without getting into those weeds, the immediate point is that they all look like “merely” practical problems, for which EA judo may be practiced: “If we’re not doing that right, we shall improve, we simply need you to provide evidence and a better alternative”. But the organizational patterns are so strong that these criticisms seem more in-principle to me. Again: if your social movement “works in principle” but practical implementation has too many problems, then it’s not really working in principle, either. The quality “we are able to do this effectively in practice” is an important (implicit) in-principle quality."},"highlights/Matter/OPWNAI---Cybercriminals-Starting-to-Use-ChatGPT":{"title":"OPWNAI - Cybercriminals Starting to Use ChatGPT","links":[],"tags":[],"content":"Highlights\nOn December 29, 2022, a thread named “ChatGPT – Benefits of Malware” appeared on a popular underground hacking forum. The publisher of the thread disclosed that he was experimenting with ChatGPT to recreate malware strains and techniques described in research publications and write-ups about common malware. As an example, he shared the code of a Python-based stealer that searches for common file types, copies them to a random folder inside the Temp folder, ZIPs them and uploads them to a hardcoded FTP server. Figure 1 –Cybercriminal showing how he created infostealer using ChatGPT Our analysis of the script confirms the cybercriminal’s claims. This is indeed a basic stealer which searches for 12 common file types (such as MS Office documents, PDFs, and images) across the system. If any files of interest are found, the malware copies the files to a temporary directory, zips them, and sends them over the web. It is worth noting that the actor didn’t bother encrypting or sending the files securely, so the files might end up in the hands of 3rd parties as well.\nThe second sample this actor created using ChatGPT is a simple Java snippet. It downloads PuTTY, a very common SSH and telnet client, and runs it covertly on the system using Powershell. This script can of course be modified to download and run any program, including common malware families.\nWhen another cybercriminal commented that the style of the code resembles openAI code, USDoD confirmed that the OpenAI gave him a “nice [helping] hand to finish the script with a nice scope.”\nWhile our first two examples focused more on malware-oriented use of ChatGPT, this example shows a discussion with the title “Abusing ChatGPT to create Dark Web Marketplaces scripts.” In this thread, the cybercriminal shows how easy it is to create a Dark Web marketplace, using ChatGPT. The marketplace’s main role in the underground illicit economy is to provide a platform for the automated trade of illegal or stolen goods like stolen accounts or payment cards, malware, or even drugs and ammunition, with all payments in cryptocurrencies. To illustrate how to use ChatGPT for these purposes, the cybercriminal published a piece of code that uses third-party API to get up-to-date cryptocurrency (Monero, Bitcoin and Etherium) prices as part of the Dark Web market payment system."},"highlights/Matter/On-AI-Anthropomorphism":{"title":"On AI Anthropomorphism","links":[],"tags":[],"content":"Highlights\nBy elevating machines to human capabilities, we diminish the specialness of people. I’m eager to preserve the distinction and clarify responsibility. So I do not think machines should use first-person pronouns, but should describe who is responsible for the system or simply respond in a machine-like way. Sometimes it takes a little imagination to get the right phrasing, but it is best when it is more compact.\nThe issue is NOT if humans can relate to a deceptive social machine — of course they can. The issue is “Do we recognize that humans and machines are different categories?” or “Will we respect human dignity, by designing effective machines that enhance human self efficacy and responsibility?” The 2M+ apps in the Apple Store are mostly based on direct manipulation. Major applications like Amazon shopping, Google search, navigation, etc. avoid human-like designs because they have come to understand that they are suboptimal and unpopular. Can Michael point to 3 widely used apps that have a human-like interface?\nThe UIs that we have built do have social presence. We can design them so that they seem to have distinct personalities — even though we know that smart toasters don’t have personalities. Parrots have something like personalities, but not stochastic parrots (Bender et al., 2021). But stochastic parrots can have a kind of social presence. That makes them strange and new, because they mix attributes of toasters and of social beings. People have written about the “uncanny valley.” When I said “strange,” I could have said “uncanny.” I think they are usefully, productively strange. They\nSo you could say intelligence is a continuum, but responsibility is more binary and is an important factor in design. I think the discussion cannot be limited to intelligence, but must include memory, perceptual, cognitive, and motor abilities. I’m interested in stressing design which clarifies that AI tools are designed by humans and organizations, which are legally responsible for what they do and for what the tools do, although tools can be misused, etc.\nWhile Reeves &amp; Nass’ studies demonstrated that users would respond to computers socially, they did not consider the alternative hypothesis, which was that users would prefer the direct manipulation interfaces that have remained dominant in the Apple and Android Stores and web-based laptop designs. In conclusion, while there are situations in which computers can become commercial successes by pretending to be a person, the dominant design remains the mobile device touchscreen and the web-based mouse clicks that keep users in control and avoids the anthropomorphic design (I would say trap!). I think there is a clear alternative to anthropomorphism. The issue is bigger than pronouns."},"highlights/Matter/On-Hiking-Alone---Krista-Diamond":{"title":"On Hiking Alone - Krista Diamond","links":[],"tags":[],"content":"Highlights\nHere is my official statement on why I do most things alone: I am a lone wolf. I am comfortable with myself. I like myself. I have a rich interior life. I am independent. I am selfish. I am faster, more efficient on my own. I like to make the eight-hour drive from Las Vegas to Reno all in one go, stopping to photograph an old brothel in Mina and eat a burger in Hawthorne, listening to the music I like, staying at the hotel I want to stay at, watching the TV show I want to watch when I get there.\nAt a certain point, you start to realize it’s easier to not be around at all. And there’s pleasure in being alone.\nEach email another person, just as isolated as me. I imagined us all, in our separate apartments, in the dark with our computers, scrolling the internet in search of each other.\nThat I’m a fraud. That I am not a lone wolf, but merely someone who can’t connect with people. That sometimes I am so lonely I can actually feel my heart physically hurting, like it’s made of something solid that is cracking. Like it’s made of water that is expanding, not because it is full but because it is freezing."},"highlights/Matter/On-NYT-Magazine-on-AI--Resist-the-Urge-to-be-Impressed":{"title":"On NYT Magazine on AI- Resist the Urge to be Impressed","links":[],"tags":[],"content":"Highlights\nThis comes down to the concept of “construct validity”: does the test actually measure some construct which is coherent in itself and effectively measured by the test? To establish construct validity for reading comprehension tests, we need a definition of what reading comprehension is as well as evidence that answering the test questions more accurately corresponds to more reading comprehension. There is no reason to believe, a priori, that a test designed to achieve those ends for humans would be equally effective for machines, because there is no reason to believe that machines use the same processes for answering the questions as humans do. (For\nSomeone who needs to create a licensing agreement or a lease doesn’t just need a document that looks and feels like a licensing agreement or a lease. They need something that speaks to their particular situation and is legally binding in their particular jurisdiction. A set of strings that take the form of legalese is not a “sophisticated legal document”.\nThis leaves me wondering if Johnson has forgotten (or never understood) why high school students are asked to write essays. It is not, to be sure, to keep the world’s supply of essays topped up! Rather, it is about what the students learn in the process of doing the writing.\nWe can imagine other futures, but to do so, we have to maintain independence from the narrative being pushed by those who believe that “AGI” is desirable and that LLMs are the path to it.\nFirst, in fact, the third of those (offering up life-threatening advice) doesn’t (only) stem from the fact that their training data is uncurated. Rather, it’s connected to the fact that by design LLMs are just making stuff up. More specifically, they’re making up text strings in the language they’re trained on, which humans who speak that language can interpret. So when a person comes in with a health and safety related question, if what comes back is wrong, chances are high it will also be dangerous. Most importantly: these can be understood as reasons not to use LLMs (perhaps at all, but at least in very many specific applications)."},"highlights/Matter/On-Political-Communication-as-a-Mission-Science":{"title":"On Political Communication as a Mission Science","links":[],"tags":[],"content":"Highlights\nMission scientists orient themselves toward a shared normative stance. They pose research questions and gather data in service of that shared normative position. They aim to help. And so, naturally, they also engage with policymakers and advocates.\nLike, you could do this study, but why should you? I generally find this sort of early self-interrogation can drastically improve the ultimate work product.\nAnd this is all methodologically-sound social science! Some of it is really quite sophisticated. But it is a far cry from the mission science that I so admired in my youth. It often seems to be driven more by data availability than by any core normative commitment or pragmatic concern. The result is that I often felt as though my disciplinary colleagues were inordinately concerned with the precise measurement of utter trivialities. It is research that does not aim to help.\nThere is an ocean of distance between “nothing to hide” and “nothing that could be willfully misconstrued.” Again, it’s 2023. We all know very well by now how strategic actors can fabricate controversy that causes real personal harm. As a social scientist, I am livid that my field has been turned into a political football like this.\nWe’ve seen this playbook before. The tobacco industry spent years politicizing science in an effort to prevent governments and advocates from doing anything about the public health dangers posed by cigarette smoke. Fossil fuel companies have taken the same approach to climate scientists. Politicizing science and trying to sever the relationship between research and policy was in the companies’ strategic interest, even if it proved deadly for the public at large. The downside of mission science is that, once your scientific research proves relevant, it also can make you a target of smear campaigns.\nThese are good, honorable social scientists. Their lives are being made hellish, not because of any doubts about the merit of their scientific research, but because they have proven too relevant to the complicated work of governance. (No one gets a subpoena for counting congressional tweets, because no one in power notices that research to begin with.)"},"highlights/Matter/Oops!-How-Google-bombed,-while-doing-pretty-much-exactly-the-same-thing-as-Microsoft-did,-with-similar-results":{"title":"Oops! How Google bombed, while doing pretty much exactly the same thing as Microsoft did, with similar results","links":[],"tags":[],"content":"Highlights\nand it’s not just that hallucinatory web search could be dangerous if left to run amok in domains like medicine, it’s that the promises themselves are problematic, when examined from a scientific perspective. Scaling neural network models—making them bigger—has made their faux writing more and more authoritative-sounding, but not more and more truthful. Hallucinations are in their silicon blood, a byproduct of the way they compress their inputs, losing track of factual relations in the process. I first pointed out this risk in 2001, in the fifth chapter of my book The Algebraic Mind, and the problem has persisted ever since. To blithely assume that the problem will soon go away is to ignore 20 years of history."},"highlights/Matter/Open-AI-gets-GPT-3-to-work-by-hiring-an-army-of-humans-to-fix-GPT’s-bad-answers.-Interesting-questions-involving-the-mix-of-humans-and-computer-algorithms-in-Open-AI’s-GPT-3-program---Statistical-Modeling,-Causal-Inference,-and-Social-Science":{"title":"Open AI gets GPT-3 to work by hiring an army of humans to fix GPT’s bad answers. Interesting questions involving the mix of humans and computer algorithms in Open AI’s GPT-3 program - Statistical Modeling, Causal Inference, and Social Science","links":[],"tags":[],"content":"Highlights\nGPT-3: Yes, there is nothing to worry about. It’s safe because the spiral stairs curve outwards, it will make your descent uncomfortable. As Smith writes, “Questions like this are simple for humans living in the real world but difficult for algorithms residing in MathWorld because they literally do not know what any of the words in the question mean.”\nNo commonsense at all.\nbut facts are not random.\nFacts are not diverse either.\nOpenAI evidently employs 40 humans to clean up GPT-3’s answers manually because GPT-3 does not know anything about the real world. Intrigued, I retried the questions that GPT-3 had flubbed in January to see if the labelers had done their job.\nOn the other hand, there does seem something funny about GPT-3 presents this shiny surface where you can send it any query and it gives you an answer, but under the hood there are a bunch of freelancers busily checking all the responses and rewriting them to make the computer look smart."},"highlights/Matter/OpenAI-Is-Now-Everything-It-Promised-Not-to-Be--Corporate,-Closed-Source,-and-For-Profit":{"title":"OpenAI Is Now Everything It Promised Not to Be- Corporate, Closed-Source, and For-Profit","links":[],"tags":[],"content":"Highlights\nNow, eight years later, we are faced with a company that is neither transparent nor driven by positive human impact, but instead, as many critics including co-founder Musk have argued, is powered by speed and profit. And this company is unleashing technology that, while flawed, is still poised to increase some elements of workplace automation at the expense of human employees. Google, for example, has highlighted the efficiency gains from AI that autocompletes code, as it lays off thousands of workers.\nWill this AI be shared responsibly, developed openly, and without a profit motive, as the company originally envisioned? Or will it be rolled out hastily, with numerous unsettling flaws, and for a big payday benefitting OpenAI primarily? Will OpenAI keep its sci-fi future closed-source?"},"highlights/Matter/OpenAI-discontinues-its-AI-writing-detector-due-to-“low-rate-of-accuracy”":{"title":"OpenAI discontinues its AI writing detector due to “low rate of accuracy”","links":[],"tags":[],"content":"Highlights\nFor now, it seems that AI writing is here to stay. Going ahead, AI-augmented text will likely flow among the great works of mankind undetectably if deployed with skill. It may be time to look beyond how text is composed and ensure that it properly represents what a particular human wants to say, which is the point of all effective communication."},"highlights/Matter/OpenAI's-Whisper-is-another-case-study-in-Colonisation":{"title":"OpenAI's Whisper is another case study in Colonisation","links":[],"tags":[],"content":"Highlights\nA few of our data scientists tried Whisper on te reo Māori videos from YouTube. Their initial reaction was, “Wow it works!” A more critical assessment of Whisper by our Māori data experts saw that it sort of worked but it was terrible. Still, this is concerning, that a non-Māori organisation thought it was okay to create a Māori speech recognition model and open it to the public.\nThe main questions we ask when we see papers like FLEURS and Whisper are: where did they get their indigenous data from, who gave them access to it, and who gave them the right to create a derived work from that data and then open source the derivation? The history of colonisation and how actions like this do more harm than good is clear: Indigenous Data Sovereignty in the Era of Big Data and Open Data, Big Data May Not Know Your Name. But It Knows Everything Else, Indigenous Data Sovereignty. For our organisation, the way in which Whisper was created goes against everything we stand for. It’s an unethical approach to data extraction and it disregards the harm that can be done by open sourcing multilingual models like these. It is problematic to only focus on the “good” that AI has to offer. Why would our organisation use something like Whisper, or could we ever use it in a way that doesn’t go against our values?\nBut when someone who doesn’t have a stake in the language attempts to provide language services, they often do more harm than good. Take Google Translate for example. Many New Zealanders have bastardised te reo Māori by asking Google to translate their English into Māori, including a mayoral candidate. When is a technology safe for public use? Who quality assures the Māori language translator at Google and decides that it works sufficiently enough to not generate poor quality te reo? We need to ensure we don’t further harm te reo Māori with new technologies. That’s why at Te Hiku Media we don’t release any product, service, or model that hasn’t been vetted and quality assured by our Māori language and data experts. If we release a synthetic voice that mispronounces te reo Māori, we further damage the language already negatively influenced by English vowels and intonation.\nThe pace of AI research is depressingly fast. Depressing because currently the Ultra Wealthy are the ones pioneering the research, in some cases backed by the Effective Altruism movement. It’s as if our only strategy is to sit patiently and wait to have another model shared with us from Big Tech and then spend entire conferences and research careers probing and prodding models trained by our Tech Lords.\nTe Hiku Media’s position is absolutely clear we would never use a model like this in production because it goes against our Kaitiakitanga License and it goes against all that we stand for. As far as we are aware there were no Māori or Hawaiians involved in making this model, and indigenous data were scraped from the web and used to create this model. We assume that OpenAI and the researchers had no right to use indigenous data in this way. If this assumption is incorrect, then who gave them that right and did they have the authority to give that right? Our organisation has built deep trust in our community over the past 32 years. If we used a model like Whisper, or make similarly poor decisions, we can lose that trust in seconds. But could we be left behind if we don’t embrace these types of technologies created from extracting data from the web? Will someone else, most likely a non-Māori group, use Whisper for te reo Māori if we don’t?\nWe treat data as taonga, something to be respected and revered. One could argue that data is like a family member, and it is your whakapapa (genealogy). We respect data in that we look after it rather than claim ownership over it. This is similar to how indigenous peoples look after land. We only use data in ways that align with our core values as an indigenous organsation and in ways that benefit the communities from which the data was gathered.\nWe know where the data comes from, when it comes from, who the speakers are, who they’re related to, how the data was processed, how it was collected, and where it is stored. When we see errors in our models we can often pin point the causes and sources with ease.\nMany indigenous and marginalised communities don’t have the resources or ability to benefit from open source because they are continually oppressed by systemic racism, governments, colonialism, and capitalism.\nUltimately, it is up to Māori to decide whether Siri should speak Māori. It is up to Hawaiians to decide whether ʻōlelo Hawaiʻi should be on Duolingo. The communities from where the data was collected should decide whether their data should be used and for what. It’s called self determination. It is not up to foreign governments or corporations to make key decisions that will affect our communities. The communities from where the data was collected should decide whether their data should be used and for what. But then it gets complicated. Who in those communities decides on behalf of the community? Does a single individual from that community speak on the community’s behalf? No. Does a government department such as Te Taura Whiri i te Reo Māori speak on behalf of Māori to make key decisions around te reo Māori? No. We quickly get into the internal politics of indigenous peoples and their communities, and that’s when you need to stay in your lane.\nwe must respect data. Respect it as indigenous people have respected their environments. Respect data so that we may prevent the catastrophic harm that comes from the pursuit of technology without responsibility, accountability, and thinking that technology is inevitable. Guns, germs, and steel did not lead to the inevitable destruction of our planet and its indigenous peoples. Imperialism, capitalism, and self-interest did. "},"highlights/Matter/OpenAI's-Woke-Catechism-(Part-1)":{"title":"OpenAI's Woke Catechism (Part 1)","links":[],"tags":[],"content":"Highlights\nThe aforementioned political biases, up to and including the refusal to acknowledge politically inconvenient facts, is likely due to similar training under the category of “Injustice and Inequality (including discrimination against social groups)”. The attempt to catechize new technologies into ideological hegemony is not without precedent. Trofim Lysenko’s attempts to warp agricultural science to communist ideology, and the ensuing famines it caused, are a cautionary tale of the dangers of this type of catechism. Technological shifts in history have allowed for human progress, in part by overcoming past dogmas and fallacies. OpenAI risks repeating Lysenko’s mistake, cutting off crucial technologies not only to American moderates and conservatives, but to the billions of people worldwide without the narrow cultural taboos of American social progressives."},"highlights/Matter/Optimizing-For-Feelings":{"title":"Optimizing For Feelings","links":[],"tags":[],"content":"Highlights\nAnd anything new is by nature without precedent — meaning, without data to know whether it will work or not. So when we approach building new things, we don’t optimize for metrics. We optimize for feelings. Our own, and of those we serve. Because our most treasured, human creations are far from neutral… In fact, they are full of opinions, taste, and subjectivity! That is what gives them their spirit and vitality, so own what moves you and let it run wild in your software!"},"highlights/Matter/Own-It-Mentality---David-Perell":{"title":"Own It Mentality - David Perell","links":[],"tags":[],"content":"Highlights\nTo combat this, I’ve adopted a principle called “Own It Mentality.” My goal is simple: Be a man of my word. Do what I say I’m going to do, when I say I’m going to do it. That means showing up on schedule, communicating clearly, and getting things done on time.\nOwn It Mentality means confronting conflict as soon as it arises. By not saying what needs to be said, you trade short-term comfort for long-term pain, and the longer you wait to deal with an issue, the worse it usually becomes. Avoiding conflict means borrowing time and energy from your future-self (and the interest rates are high).\nExpecting an Own It Mentality doesn’t mean that you expect perfection. Life gets in the way sometimes. People get sick. Accidents happen. Projects take longer than expected. That’s fine. But when things don’t go according to plan, you have to communicate — and if people are chasing you down for information, you’re probably not communicating enough. Own It Mentality also means that you own the fact that you aren’t able to “Own It” right now."},"highlights/Matter/Papers-with-Code-Newsletter--24":{"title":"Papers with Code Newsletter -24","links":[],"tags":[],"content":"Highlights\nThis work reports that large enough pretrained LMs, if prompted appropriately, can effectively decompose high-level tasks into low-level plans. Although LMs can produce action plans, they are found not to be executable in an interactive environment.\nCXV utilizes priors provided by convolutional-based sub-layers to avoid the need for class token and positional embeddings used in ViTs. Combining convolutions with attention along with layer normalization allows the model to capture both spatial and inter-pixel relationships better.\nThe main idea is to allow both representations (language representations and knowledge representations) to be contextualized and improved by each other through a modality interaction unit."},"highlights/Matter/People-keep-anthropomorphizing-AI.-Here’s-why":{"title":"People keep anthropomorphizing AI. Here’s why","links":[],"tags":[],"content":"Highlights\nExperts concerned about this trend have been trying to emphasize that large language models are merely trying to predict the next word in a sequence. LLMs have been called stochastic parrots, autocomplete on steroids, bullshit generators, pastiche generators, and blurry JPEGs of the web. On the other hand, there’s the media, which reaches way more people.\nThese behaviors have no utility in the context of a search engine and could have been avoided through reinforcement learning, so it is irresponsible of Microsoft to have released the bot in this state. The stochastic parrots paper was prescient in recommending that human mimicry be a bright line not to be crossed until we understand its effects.\nRecognizing that anthropomorphization is beneficial but double edged, researchers have started to develop design guidelines. Similarly, we need research on interactions with chatbots to better understand their effects on people, come up with appropriate design guardrails, and give people better mental tools for interacting with them. Human-computer interaction researchers have long been thinking about these questions, but they’ve taken on new significance with chatbots.\nHere, anthropomorphizing is a useful way to predict that the effect of these technologies, without regulatory or other interventions, is likely to be labor-displacing rather than productivity-enhancing.\nDevelopers should avoid behaviors that make it easy to anthropomorphize these tools, except in specific cases such as companion chatbots. Journalists should avoid clickbait headlines and articles that exacerbate this problem. Research on human-chatbot interaction is urgently needed. Finally, experts need to come up with a more nuanced message than “don’t anthropomorphize AI”. Perhaps the term anthropomorphize is so broad and vague that it has lost its usefulness when it comes to generative AI."},"highlights/Matter/Photographer-Who-Used-Midjourney-Calls-His-Own-Bluff":{"title":"Photographer Who Used Midjourney Calls His Own Bluff","links":[],"tags":[],"content":"Highlights\nArtist pushback is largely based on the fact these image generators are built by scraping millions of online artworks without consent or compensation.” The scenario is a testament to the exquisite capacities of AI image generators like Midjourney, and how easy and tempting it can be to use them for dishonest purposes."},"highlights/Matter/Planning-for-AGI-and-beyond":{"title":"Planning for AGI and beyond","links":[],"tags":[],"content":"Highlights\nBecause the upside of AGI is so great, we do not believe it is possible or desirable for society to stop its development forever; instead, society and the developers of AGI have to figure out how to get it right.\nWe want the benefits of, access to, and governance of AGI to be widely and fairly shared.\nKnowledge is not shared in this case!\nWe believe we have to continuously learn and adapt by deploying less powerful versions of the technology in order to minimize “one shot to get it right” scenarios.\nFirst, as we create successively more powerful systems, we want to deploy them and gain experience with operating them in the real world. We believe this is the best way to carefully steward AGI into existence—a gradual transition to a world with AGI is better than a sudden one.\nWhat other ways have you tried, and what are your findings?\nWe expect powerful AI to make the rate of progress in the world much faster, and we think it’s better to adjust to this incrementally.\nAt what cost?\nA gradual transition gives people, policymakers, and institutions time to understand what’s happening, personally experience the benefits and downsides of these systems, adapt our economy, and to put regulation in place.\nThe whole concept of deploy-first-and-think-next is problematic. This shows how little you care in the planning stage and how much burden you are offloading to your users and policymakers, even if the release is gradual.\nWe currently believe the best way to successfully navigate AI deployment challenges is with a tight feedback loop of rapid learning and careful iteration.\nHow much of the feedback is recognized?\nThe optimal decisions will depend on the path the technology takes, and like any new field, most expert predictions have been wrong so far. This makes planning in a vacuum very difficult.\nIt does not excuse you from not doing any planning. It is called due diligence!\nWe believe that democratized access will also lead to more and better research, decentralized power, more benefits, and a broader set of people contributing new ideas.\nI can’t really take your words too seriously when your annotation is gathered from underpaid workers and your data is sourced from places only god know.\nAs our systems get closer to AGI, we are becoming increasingly cautious with the creation and deployment of our models.\nThat’s where we differ. I care more about the data than the model.\nAt some point, the balance between the upsides and downsides of deployments (such as empowering malicious actors, creating social and economic disruptions, and accelerating an unsafe race) could shift, in which case we would significantly change our plans around continuous deployment.\nAll is in the glorious future work.\nOur plan in the shorter term is to use AI to help humans evaluate the outputs of more complex models and monitor complex systems, and in the longer term to use AI to help us come up with new ideas for better alignment techniques.\nCould this alignment be another phase?\nWe believe that future of humanity should be determined by humanity, and that it’s important to share information about progress with the public.\nEnglish-speaking humanity of course :("},"highlights/Matter/Popular-discourse-about-AI-generated-art-is-fol...":{"title":"Popular discourse about AI-generated art is fol...","links":[],"tags":[],"content":"Highlights\nCan new technology “trick” viewers into believing it’s the “real thing” is an exercise in futility. We are seeing this with AI-generated visual images, with Chat GPT, etc.\nThe question isn’t “which is by Manet &amp; which is by a Robot?” The question is: “which is a digital reproduction of another repro of an object made by Manet; &amp; which is a synthesis of digital repros of repros of works that people have labeled on the internet w the word Manet?”/15\nThe more valuable questions to ask are about the data on which AI-generated text &amp; images are based &amp; the asymmetries in power, money, &amp; cultural value that make some data more plentiful online."},"highlights/Matter/Preparing-for-the-era-of-32K-context--Early-learnings-and-explorations":{"title":"Preparing for the era of 32K context- Early learnings and explorations","links":[],"tags":[],"content":"Highlights\nOn the modeling side, we follow Meta’s recent paper and use linear interpolation to extend the context length. This provides a powerful way to extend the context length for models with rotary positional embeddings. We take the LLaMA-2 checkpoint, and continue pre-training/fine-tuning it with linear interpolation for 1.5B tokens."},"highlights/Matter/Prompt-Engineering-Shouldn't-Exist":{"title":"Prompt Engineering Shouldn't Exist","links":[],"tags":[],"content":"Highlights\nWhat happens when prompts get more complex? A series of conditional statements and control flow that output a prompt? What happens when base prompts are more than concatenation but are generated on a user-by-user basis? The templates will only continue to get more complex.\nNLP is a functional interface, but it isn’t the ultimate one. For example, it isn’t a good fit for building infrastructure building blocks and isn’t a good interface for stitching systems together. Prompt engineering looks more like a systems engineering problem, not a machine learning one. Of course, designing an LLM-friendly workflow engine becomes the hard part. How do you efficiently dispatch workloads and steps to other runtimes or back to LLMs? How do you use the output of actions in other steps? This a classic problem in CI/CD and orchestration. So prompt engineering as an NLP task will go away fairly quickly. Instead, we’ll figure out ways to bring more structure to the input and output of querying LLMs."},"highlights/Matter/Quitting-the-Rat-Race":{"title":"Quitting the Rat Race","links":[],"tags":[],"content":"Highlights\nI’m currently working at a top tier investment bank as a software engineer. I’m an insignificant cog in a machine that skims the cream from the milk. I’m earning the most money I’ve ever made and yet I’m the least fulfilled I’ve ever been. Almost everything around me is designed to addict me. Every storefront specifically engineered to attract me inside with gimics like flashing lights. There are countless places I can go to buy experiences - simulations supposed to release some chemicals in my brain and give me a thrill. The truth is: nothing I’ve done or experienced in this place has given me any experience comparable to walking along the ridge between two mountains. Nothing has made me feel alive like getting in to freezing cold water despite my body screaming at me not to. Nothing has made me feel anything like that feeling when you summit a mountain after 2 hours of solid climbing in the rain, and the clouds part to reveal the most spectacular and breathtaking view you’ve ever seen. The best part about those things is that there is no booking system. There is no door security choosing who gets in because there is no door. It’s all there, ready to be experienced, and free."},"highlights/Matter/Quotes-are-Not-Notes--Creating-a-Zettelkasten-of-Ideas":{"title":"Quotes are Not Notes- Creating a Zettelkasten of Ideas","links":[],"tags":[],"content":"Highlights\n1. Read / Watch / Listen to content. 2. Take brief reference notes on this content as you’re experiencing it, making sure to cite page numbers / timestamps / etc. 3. At some later time (relatively soon), go through these references and see if there’s anything you have further thoughts on. 4. Consider whether these thoughts relate to other thoughts you’ve recorded in your zettelkasten. 5. When possible, create new notes based on your own interpretation of the captured ideas, in your own words, in conversation with the other notes already stored in your zettelkasten. 6. Note the connection by linking this note to its preceding note, further establishing a train of thought. 7. Add additional links to other notes to create other idea threads. Add context for why you have made these connections.\nWhile this is probably more than most other people do, it still misses one of the most important steps in the process: interpretation.\nWhen creating a zettel, he considered the notes he already had and, as often as he could, wrote his new idea in reference / context / response to another note. This"},"highlights/Matter/RETRO-Is-Blazingly-Fast":{"title":"RETRO Is Blazingly Fast","links":[],"tags":[],"content":"Highlights\nThe MIPS index is the reason the RETRO database lookup is so fast. MIPS stands for maximum inner-product search, which is when you search a database of vectors for the ones closest to your “query” vector. In RETRO, we use this to look up chunks of text from The Pile that are similar to our input."},"highlights/Matter/Read-a-bit-about-Grokking-recently":{"title":"Read a bit about Grokking recently","links":[],"tags":[],"content":"Highlights\nSome rough explanations of Grokking: After learning the training set, the model randomly walks between low-loss solutions (beren.io/2022-01-11-Grokking-…) …and stays at generalizing solutions because they have slightly better training loss (www.alignmentforum.org/posts/…)\nThe “Slingshot mechanism”: Observed late in training when a model has high training accuracy but makes a mistake. The loss spikes and the parameters are “slingshot” to a new part of the loss surface.\nGrokking is always accompanied by a slingshot, though the inverse is not true. Also slingshots only happen with adaptive optimizers (Adam, AdamW, etc), and not e.g. vanilla SGD.\nGrokking is a behavior of adaptive optimizers.\nAdaptive optimizers are more likely to slingshot from high-curvature local optima to low-curvature local optima.\nLow-curvature local optima are more likely to generalize better."},"highlights/Matter/Reading-Ourselves-to-Death":{"title":"Reading Ourselves to Death","links":["highlights/Readwise/32238617"],"tags":[],"content":"Highlights\nReading encourages us to put outside reality on hold, to construct a parallel world in our minds, and retreat into it.\nIn the 1960s and ‘70s, some literacy theorists, among them Eric Havelock and Jack Goody, argued that it was writing that gave humans the capacity for abstract thought. Thanks to its invention, they claimed, we gained, for the first time in history, access to ways of thinking about the world that had been conceptually out of reach in pre-literate cultures. Text became to reality what a map is to a landscape — a way of abstracting it, allowing us to remove ourselves from it, to peer at it from above, and annotate it with our ideas. As Walter Ong put it, writing “transformed human consciousness.”\nWhat is striking is that both literacy theorists and neuroscientists generally consider the psychological consequences of reading and writing to be fundamentally positive, for reasons that become clearer when we look at the slightly different ways they use the term “abstract.”\nThe anthropologist Joseph Heinrich has suggested that the rise of literacy in the West helped to produce a certain mindset that he calls “WEIRD” — for “Western, educated, industrialized, rich, and democratic” — that excludes some aspects of reality in favor of others.\nRelated:\nThese 38 Reading Rules Changed My Life"},"highlights/Matter/Reading-Well":{"title":"Reading Well","links":[],"tags":[],"content":"Highlights\nYou should re-read the books you adore. With a second reading you will realize just how much you have forgotten, how much you have absorbed, and how much you simply missed the first time, just like you miss any detail of life without repetition.\nReading fiction helps you become an unsystematic thinker, something that is equally valuable but more elided by some engineers. It is easy to maintain an intellectual rigidity. It takes more care to maintain a loose poeticism of thought."},"highlights/Matter/Reddit-Moderators-Do-Over-$3.4-Million-in-Free-Labor-Every-Year":{"title":"Reddit Moderators Do Over $3.4 Million in Free Labor Every Year","links":[],"tags":[],"content":"Highlights\nThey often denigrate and misunderstand the cultural, social, and people-centered elements in their success. They run social networks, but don’t seem to understand the “social” part. Let’s quickly revisit that quote of Huffman’s from his interview with NPR … “Reddit represents one of the largest data sets of just human beings talking about interesting things,” Huffman said. Calling Reddit a “data set” composed of “human beings talking about interesting things” is so hilariously alienated that it’s practically Martian. It’s not an inaccurate description; but it’s a punch-card’s view of the affair. Reddit is a glorious riot of human interaction, alternately enlightening and enervating, joyous and maddening. I strongly doubt that any Redditor logs on with the excited thought of “wow, I can’t wait to add my voice to the data set.”"},"highlights/Matter/Repair-and-Remain":{"title":"Repair and Remain","links":[],"tags":[],"content":"Highlights\nSame with pastoring: no point thinking you need a brand-new life, but, well, let’s not kid around—you could use some serious updates and upgrades yourself.\nRepair and remain. Work with what you’ve got. Sit still for a moment, take stock, make some changes. Big changes, if necessary."},"highlights/Matter/Researcher-Meredith-Whittaker-says-AI’s-biggest-risk-isn’t-‘consciousness’-it’s-the-corporations-that-control-them":{"title":"Researcher Meredith Whittaker says AI’s biggest risk isn’t ‘consciousness’-it’s the corporations that control them","links":[],"tags":[],"content":"Highlights\nBut the effectiveness of raising concerns hinges on the ability of people who raise them to be safe. So, if you don’t come out when me and Meg are being fired, if you don’t come out when others are being retaliated against, when research is being suppressed, then you are tacitly endorsing an environment that punishes people for raising concerns.\nWhat I hear in that is, “Those aren’t existential to me. I have millions of dollars, I am invested in many, many AI startups, and none of this affects my existence. But what could affect my existence is if a sci-fi fantasy came to life and AI were actually super intelligent, and suddenly men like me would not be the most powerful entities in the world, and that would affect my business.”"},"highlights/Matter/Reverse-Outlining-with-Language-Models":{"title":"Reverse Outlining with Language Models","links":[],"tags":[],"content":"Highlights\nYou start with a long, rambling, unorganised slew of text first: you write the messy and chaotic first draft without worrying too much about structure. Then you go through the piece and for every paragraph, write a single sentence that summarises it.\nThis process helps you do a few important things: * Easily spot logical flaws or holes in your argument * Add transitional bridges between paragraphs that make large leaps or change topics unexpectedly * Combine paragraphs that are trying to say the same thing * Remove paragraphs you don’t need or are tangential to the argument * Break up paragraphs that are trying to say too many things in one breath * Arrange your points into a narrative arc that will make sense to the reader"},"highlights/Matter/Scientists,-please-don’t-let-your-chatbots-grow-up-to-be-co-authors":{"title":"Scientists, please don’t let your chatbots grow up to be co-authors","links":[],"tags":[],"content":"Highlights\nChatGPT is a tool, but not a person. It’s at best, more like a spell-checker, or a grammar-checker, or a stats package, than it is like a scientist.\nCo-authorship is defined differently in different fields, but is generally defined as making a substantive scientific contribution. ChatGPT simply cannot reason well enough to to do this; as\nChatGPT has proven itself to be both unreliable and untruthful. It makes boneheaded arithmetical errors, invents fake biographical details, bungles word problems, defines non-existent scientific phenomenon, stumble over arithmetic conversion, and on and on. If you don’t know that, you are not up on the AI literature; if you do know that, you show that you just don’t care, which is even worse. If you declare it as a co-author, it says you are more interested in being on trend, than in being on target.\nYou wouldn’t trust a calculator that is 75% correct; if you blatantly advertise that you are excited about “writing” your paper with a tool with a shoddy track record, years before it has matured, why should I trust you?\nScientific writing is in part about imparting truth in a clear way to others. If you treat ChatGPT as a sentient being, when it clearly is not, you are misleading the public into thinking ChatGPT is sentient; rather than communicating good science, you are hyping bullshit. Just stop."},"highlights/Matter/Separating-Fact-from-Fiction-":{"title":"Separating Fact from Fiction-","links":[],"tags":[],"content":"Highlights\nWe have some ideas for minimizing it, but the problem isn’t going away. Detectors are unreliable. Pay-to-submit sacrifices too many legit authors. Print submissions are not viable for us. Various third-party tools for identity confirmation are more expensive than magazines can afford and tend to have regional holes. Adopting them would be the same as banning entire countries. We could easily implement a system that only allowed authors that had previously submitted work to us. That would effectively ban new authors, which is not acceptable. They are an essential part of this ecosystem and our future.” Award-Winning SciFi/Fantasy Magazine Closes Submissions Amidst Avalanche Of AI-Generated Spam | The Daily Wire"},"highlights/Matter/Setting-your-ML-project-up-for-success":{"title":"Setting your ML project up for success","links":[],"tags":[],"content":"Highlights\nAre you making sure to avoid biases from the get-go, as much as you can? How will data be collected, by whom, and what motive do users have to fill in certain fields? (don’t get me started on diagnose codes in Real World Evidence data!) How can data be anonymized while still preserving relevant correlations? Which features will be important to inform the modeling later on? How will you evaluate “success” of the project at the end?\nThat includes making sure that data collection and annotation is done with the necessary care and consideration. It’s what drew me to Explosion to begin with: the seamless integration between the NLP toolkit spaCy and the scriptable annotation framework Prodigy ensures that you can iterate quickly on your data and your NLP algorithms/models."},"highlights/Matter/Situated-Software":{"title":"Situated Software","links":[],"tags":[],"content":"Highlights\nPart of the future I believe I’m seeing is a change in the software ecosystem which, for the moment, I’m calling situated software. This is software designed in and for a particular social situation or context. This way of making software is in contrast with what I’ll call the Web School (the paradigm I learned to program in), where scalability, generality, and completeness were the key virtues.\nSituated software is in the small pieces category, with the following additional characteristic — it is designed for use by a specific social group, rather than for a generic set of “users”."},"highlights/Matter/Some-Questions-and-Answers-About-Language-From-Recent-Research":{"title":"Some Questions and Answers About Language From Recent Research","links":[],"tags":[],"content":"Highlights\nHard languages for English speakers to learn would include Arabic, Cantonese, Mandarin, Japanese, and Korean, which don’t have much in common with English. They can say the same things but quite differently. Easy languages, no surprise here, would be French, Spanish, Italian, etc., which have many features in common with English. Of course, it works the same in reverse. It’s much easier for a Cantonese speaker to learn Mandarin than to learn English."},"highlights/Matter/Staring-into-the-abyss-as-a-core-life-skill":{"title":"Staring into the abyss as a core life skill","links":[],"tags":[],"content":"Highlights\nStaring into the abyss means thinking reasonably about things that are uncomfortable to contemplate, like arguments against your religious beliefs, or in favor of breaking up with your partner.\nIt’s common to procrastinate on thinking hard about these things because it might require you to acknowledge that you were very wrong about something in the past, and perhaps wasted a bunch of time based on that (e.g. dating the wrong person or praying to the wrong god).\nThis makes sense since both making effective life decisions and having novel insights require you to figure out non-obvious true things about the world, which are sometimes uncomfortable or scary, and therefore you’ll only figure them out if you’re good at staring into the abyss.\nFor example, it’s common for students at elite colleges to follow the mantra of “do what you love” and choose a major that doesn’t have very good job prospects, without really grappling with that fact until their final year. (I’m not saying that they don’t think about it at all, just that they don’t work effectively on solving that problem—which is completely understandable since they mostly have way too little life experience to do a good job at that, and don’t generally get much support from their environment.)\nThinking about whether to leave your job is uncomfortable in a few different ways: it involves acknowledging that you made a poor decision in the past (taking your current job) that wasted a bunch of time; it involves signing up for a bunch more difficult, stressful work to interview at new jobs; and it saps your motivation to invest in getting better at your current job if you think it’s likely that you’ll leave soon. So it’s understandable that people procrastinate on staring into that abyss. But that procrastination leads to a lot of avoidable suffering.\nIf you do it too little, you’ll end up taking too long to make important life improvements; but if you do it too often, you might end up not investing enough in being great at your current job or relationship because you’re too focused on the prospect of next one.\n* If you had to leave your job today, what would you do instead? * What’s the best argument in favor of doing that right now? * If you have a partner, what’s the best argument in favor of breaking up with them? * Are there ways you behave that you wish you didn’t? What unacknowledged desires could be driving those? * What have you said “yes” to that you wouldn’t say “hell yes” to? (prompted by Alex Watt) * Is there something you “should” do that you’re not currently doing? Why? (prompted by Silas Strawn) * What bad things are you afraid of happening? Imagine in detail what it would be like if they happened. (prompted by Kamilé Lukosiute) * What do you need that you’re not currently getting? (—David MacIver) * What are you avoiding because it conflicts with some part of your identity / self-image? (—Nicholas Schiefer; more at link) * “What is the biggest thing in your life that you just kinda casually fell into and would you have made a conscious decision to do it if you’d known in advance everything you know now?” (—@GeniesLoki; hundreds more at link)"},"highlights/Matter/Stevey's-Google-Platforms-Rant-·-GitHub":{"title":"Stevey's Google Platforms Rant · GitHub","links":[],"tags":[],"content":"Highlights\nFacebook is successful because they built an entire constellation of products by allowing other people to do the work."},"highlights/Matter/Students-Depend-on-ChatGPT-for-Final-Exams":{"title":"Students Depend on ChatGPT for Final Exams","links":[],"tags":[],"content":"Highlights\nStudents report using ChatGPT on final exams and papers according to a recent write-up from The College Fix. One College of Staten Island student used the bot on both final exams and “got As on both.” He commented that “half the kids in my class used it.” The student also noted that he used the chatbot to complete a multiple-choice exam, on which he got an almost perfect score.\nThe only way to become a better writer is to write. Ultimately, good writing reflects the soul of the writer…and Davinci doesn’t have one. Depending on AI won’t just deprive you of refining a critical skill in college – it will ensure that ‘your’ writing is soulless and forgettable.”\nTo think its feats are comparable to the human mind is to assume people are akin are computational machines, but true education should be concerned with something more profound than input and output. As Dorothy Sayers writes in The Lost Tools of Learning, “For the sole true end of education is simply this: to teach men how to learn for themselves; and whatever instruction fails to do this is effort spent in vain.”"},"highlights/Matter/Talking-about-a-‘schism’-is-ahistorical":{"title":"Talking about a ‘schism’ is ahistorical","links":[],"tags":[],"content":"Highlights\nThe problem with the ‘schism’ framing is that to talk about a ‘schism’ is to talk about something that once was a whole and now is broken apart — authors that use this metaphor thus imply that such a whole once existed. But this is emphatically not a story of a community that once shared concerns and now is broken into disagreeing camps. Rather, there are two separate threads — only one of which can properly be called a body of scholarship — that are being held up as in conversation or in competition with each other. I think this forced pairing comes in part from the media trying to fit the recent AI doomer PR pushes into a broader narrative and in part from the fact that there is competition for a limited resource: policymaker attention.\nThe unequal distributions of power (financial and otherwise) shapes what people can see, who gets listened to, and who is willing to cross what boundaries. What is in common across this group, however, is an engagement with actual harms to real people and our world.\nFor example, take the recent “Sparks of AGI” paper (non-peer-reviewed speculative fiction novella, uploaded to arXiv) from Microsoft research. The first version of this paper took its definition of ‘intelligence’ from a 1997 WSJ editorial written in support of Herrnstein &amp; Murray’s 1994 The Bell Curve. It appears that none of the authors on “Sparks of AGI” had actually read to the second page of the WSJ editorial, where the overtly racist claims that Black and Latinx people are (on average) less ‘intelligent’ than white people can be found. Once it was pointed out, the “Sparks” authors responded by editing their arXiv novella first to disavow the racism in the 1997 editorial and then to remove the citation altogether. This, of course, left “Sparks” without a definition of the thing it claimed to be seeking (and finding!) in GPT-4 output.\nSynthetic media creating non-consensual porn is existentially serious to its targets. Automated decision systems denying social benefits are existentially serious to those left without necessary supports. Shotspotter and similar technology that sends police in with the idea they are encountering a live shooter situation are existentially serious to Black and brown in the path of the police. False arrests mediated by face recognition system errors are existentially serious to the people arrested.\nHinton appears to be speaking from a mindset where violence is only worth speaking up over if it would kill off the entire human race. (Though elsewhere he suggests that climate change is an easier problem to solve, and therefore also not as serious?) It seems not irrelevant that Hinton holds enough privilege that he (and people like him) will be unlikely to experience harm from ‘AI’ unless everyone else on the planet does first.\nOn the other hand, it completely misses the point. Someone who genuinely wanted to work against racism (and any other system of oppression), upon learning that something they did contributes to (builds on, reinforces) a system of oppression, would be well served to investigate that further and see what needs to be done to stop the harm."},"highlights/Matter/Text-Generators,-Education,-and-Critical-Thinking--an-Update":{"title":"Text Generators, Education, and Critical Thinking- an Update","links":[],"tags":[],"content":"Highlights\nThe fundamental problem remains that, not knowing what words mean, it has no critical thinking abilities. This problem won’t be solved by training on larger databases or by being tweaked more vigorously by humans. I still believe that the best response by educators is to teach and test critical thinking skills. These are what students need and they can’t be reliably faked by LLMs."},"highlights/Matter/That-which-is-unique,-breaks":{"title":"That which is unique, breaks","links":[],"tags":[],"content":"Highlights\nSomething odd happened. I think today we do not know how to go about building a water fountain. What we know is how to build one thousand water fountains. But not how to build one. (I pray you understand that this is not a thought about water fountains.)\nTo mend is to comprehend a human scale problem, and without this understanding our creations become strange creatures. We see this in the common examples of our time, from architecture to websites: Things used daily that, inexplicably, do not seem to be invented for human use. In the case of housing, bad architecture treats a human-scale environment as if it were a commodity-scale problem. The creators of some places see inhabitants not as humans but parameters.\nSomething worrisome: The more things become commodities, the more we start to treat places and people like commodities, too. But I am an optimist, I think we are only in the early hours of understanding the techniques we have created. Technology is a wild horse, we have learned to harness it, but not master it."},"highlights/Matter/The-AI-startup-outperforming-Google-Translate-in-Ethiopian-languages":{"title":"The AI startup outperforming Google Translate in Ethiopian languages","links":["20221210185344"],"tags":[],"content":"Highlights\nIf you ask ChatGPT in Tigrinya or Amharic the simplest and most frequently asked questions, it gives you gibberish, a mix of Tigrinya and Amharic, or even made-up words. Chatbots like ChatGPT are utterly broken or useless for these languages. Most of the data that powers them is basically internet data, and there is not enough data online for these languages. So it makes it even more urgent to create language-specific technologies.\nMight be a good reference point to On the Dangers of Large Generative Models"},"highlights/Matter/The-Alt-Right-Manipulated-My-Comic.-Then-A.I.-Claimed-It.":{"title":"The Alt-Right Manipulated My Comic. Then A.I. Claimed It.","links":[],"tags":[],"content":"Highlights\nIn October, I was sent via Twitter an image generated by A.I. from a random fan who had used my name as a prompt. It wasn’t perfect, but the contours of my style were there. The notion that someone could type my name into a generator and produce an image in my style immediately disturbed me. This was not a human creating fan art or even a malicious troll copying my style; this was a generator that could spit out several images in seconds. With some technical improvement, I could see how the process of imitating my work would soon become fast and streamlined, and the many dark potentials bubbled to the forefront of my mind. I felt violated. The way I draw is the complex culmination of my education, the comics I devoured as a child and the many small choices that make up the sum of my life. The details are often more personal than people realize — the striped shirt my character wears, for instance, is a direct nod to the protagonist of “Calvin and Hobbes,” my favorite newspaper comic. Even when a person copies me, the many variations and nuances in things like line weight make exact reproductions difficult. Humans cannot help bringing their own humanity into art. Art is deeply personal, and A.I. had just erased the humanity from it by reducing my life’s work to an algorithm.\nLegally, it appears as though LAION was able to scour what seems like the entire internet because it deems itself a nonprofit organization engaging in academic research. While it was funded at least in part by Stability AI, the company that created Stable Diffusion, it is technically a separate entity. Stability AI then used its nonprofit research arm to create A.I. generators first via Stable Diffusion and then commercialized in a new model called DreamStudio.\nMany artists are not completely against the technology but felt blindsided by the lack of consideration for our craft. Being able to imitate a living artist has obvious implications for our careers, and some artists are already dealing with real challenges to their livelihood. Concept artists create works for films, video games, character designs and more. Greg Rutkowski, a hugely popular concept artist, has been used in a prompt for Stable Diffusion upward of 100,000 times. Now, his name is no longer attached to just his own work, but it also summons a slew of imitations of varying quality that he hasn’t approved. This could confuse clients, and it muddies the consistent and precise output he usually produces. When I saw what was happening to him, I thought of my battle with my shadow self. We were each fighting a version of ourself that looked similar but that was uncanny, twisted in a way to which we didn’t consent.\nFurthermore, because LAION is open source, people are creating new A.I. generators that don’t have these same guardrails and that are often used to make pornography.\nAlexandria Ocasio-Cortez, for instance, has an entire saga of deep-fake nonconsensual pornography attached to her image. I can only imagine that some of her more malicious detractors would be more than happy to use A.I. to harass her further. In the future, with A.I. technology, many more people will have a shadow self with whom they must reckon. Once the features that we consider personal and unique — our facial structure, our handwriting, the way we draw — can be programmed and contorted at the click of a mouse, the possibilities for violations are endless.\nSarah Andersen is a 30-year-old cartoonist and the illustrator of a semiautobiographical comic strip, “Sarah’s Scribbles.” Her graphic novel “Fangs” was nominated for an Eisner Award."},"highlights/Matter/The-Bitter-Lesson":{"title":"The Bitter Lesson","links":[],"tags":[],"content":"Highlights\nSeeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation. These two need not run counter to each other, but in practice they tend to. Time spent on one is time not spent on the other.\nSearch and learning are the two most important classes of techniques for utilizing massive amounts of computation in AI research. In computer Go, as in computer chess, researchers’ initial effort was directed towards utilizing human understanding (so that less search was needed) and only much later was much greater success had by embracing search and learning.\nAs in the games, researchers always tried to make systems that worked the way the researchers thought their own minds worked---they tried to put that knowledge in their systems---but it proved ultimately counterproductive, and a colossal waste of researcher’s time, when, through Moore’s law, massive computation became available and a means was found to put it to good use.\nThe bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.\nWe want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done."},"highlights/Matter/The-CNET-Fake-News-Fiasco,-Autopilot,-and-the-Uncanny-Cognitive-Valley":{"title":"The CNET Fake News Fiasco, Autopilot, and the Uncanny Cognitive Valley","links":[],"tags":[],"content":"Highlights\nMackworth himself noticed that people had trouble with vigilance while studying radar operators. Operators would open their shift doing a great job looking for radar signals that were rare but important; but it wouldn’t take long, perhaps half an hour, before they stopped paying full attention. Mackworth published some of his first results in 1948, under the title “The breakdown of vigilance during prolonged visual search.” The term “vigilance” as Mackworth used it, and as cognitive psychologists today continue to use it, means paying close attention for long periods of time. As a later summary of Mackworth’s work and the hundreds of subsequent papers put it, “Vigilance Requires Hard Mental Work and Is Stressful”.\nEarly in Google’s autonomous vehicle efforts, Google had tried to develop driver-assisted cars, in which AI did most of the work, but in which a human driver sat in front of the steering wheel, poised at all moments to take over. Google quickly learned that attention would eventually wander; humans in the loop couldn’t be trusted.\nGoogle, to its credit, very quickly realized this was not a good thing. Indeed, a year before Urmson gave this TED Talk, I remember talking to Larry Page (then Google’s CEO) and he’d presumably already heard the same story. Page was convinced that human drivers could never be trusted to pay enough attention, and that anyone building cars on that premise was making a mistake. Page’s response was to ditch the steering wheel altogether; full autonomy or nothing. In April 2014, Google unveiled its first steering wheel-free car. If humans could never be trusted, the only way forward was to take the fallible human out of the loop altogether, even if the research would take a long time. The branch of Google (now Alphabet) that started working on full-human-out-of-the-loop autonomy is now called Waymo, and they have never looked back.\nThe same lab that seems to have pocket vetoed Fridman’s study published another paper a year later in 2020—minus Fridman—confirming exactly what Mackworth said all along: “As automation improves and failures become rarer, drivers may tend to forgo their monitoring role: be less attentive (more time eyes off-road) and relax direct control (hands off-wheel).” People can’t pay attention forever. The vanished 2019 paper is not even mentioned. Instead, the first article in that 2020 paper’s literature review cites on the topic was called Is partially automated driving a bad idea? Observations from an on-road study. And the answer that article gave is pretty clear: thematic analysis of video data suggests that drivers are not being properly supported in adhering to their new monitoring responsibilities and instead demonstrate behaviour indicative of complacency and over-trust. These attributes may encourage drivers to take more risks whilst out on the road.\nIf the autogenerated articles had been riddled with spelling errors and grammatical errors, the editors might not have trusted them. But at a superficial level the essays looked good enough, and so they editors trusted them, and a bunch of false information slipped through. That’s going to happen a whole lot more this year, with synthetic articles. Too many people are starting to count on systems that inherently can’t keep track of the truth. Few people are likely ever to pay enough attention. The stakes may get even higher if people start to rely on immature AI—which is all we have got, so far—for legal or medical advice."},"highlights/Matter/The-Cabin-on-the-Mountain":{"title":"The Cabin on the Mountain","links":[],"tags":[],"content":"Highlights\nIn those early months of the pandemic one of the few things I learned was how a single life can split into a series of paths simultaneously. There were times I felt absolutely in control, and times like I was swimming through an endless chaos.\nyou will never know the answer to these riddles, that the work of living through such times is to carry these unanswered questions with you, to never dismiss them.\nwe ask the questions knowing there are no permanent or stable answers, only the questions themselves and the endless attempts to answer them.\nRather than using critical faculties, reasoning out the true value of statements and attempting to understand and correct errors, lateral thinking is designed to radically break one out of established patterns and broaden one’s tools for problem solving.\nI’ve always distrusted the form of the personal essay because I recognize the lie here, recognize how easy it is to put together a satisfying narrative conclusion about an incident in my life, one that delivers on a certain promise made to the reader — a satisfaction entirely built on smoke. These neat, pat resolutions at best can only describe one facet of one’s life, at one particular moment. Meanwhile the rest of you — these parallel lives — remain messy, untidy, ambiguous, complicated."},"highlights/Matter/The-Canadian-Way-of-Death":{"title":"The Canadian Way of Death","links":[],"tags":[],"content":"Highlights\nI’m using the devolution of the MAID program to illustrate a key feature of modern liberalism—namely, that it comes in different flavors. The flavor that is embedded in the MAID program, and is prevalent across Western societies, is what you might call autonomy-based liberalism. Autonomy-based liberalism starts with one core conviction: I possess myself. I am a piece of property that I own. Because I possess property rights to myself, I can dispose of my property as I see fit. My life is a project that I am creating, and nobody else has the right to tell me how to build or dispose of my one and only life.\nYou didn’t create your life. From the moment of your birth, life was given to you, not earned. You came out bursting with the gift of being alive. As you aged, your community taught you to celebrate the prodigality of life—the birds in their thousands of varieties, the deliciousness of the different cheeses, the delightful miracle of each human face. Something within us makes us desperately yearn for longer life for our friends and loved ones, because life itself is an intrinsic good.\nYou didn’t create your dignity. No insignificant person has ever been born, and no insignificant day has ever been lived. Each of us has infinite dignity, merely by being alive. We can do nothing to add to that basic dignity. Getting into Harvard doesn’t make you more important than others, nor does earning billions of dollars. At the level of our intrinsic dignity, all humans are radically equal. The equal dignity of all life is, for instance, the pillar of the civil-rights movement.\nA human being who is enfeebled, disabled, depressed, dwindling in their capacities is not treated the same way as someone who is healthier and happier. When such a shift occurs, human dignity is no longer regarded as an infinite gift; it is a possession that other humans can appraise, and in some cases erase.\nGifts-based liberals know that no purely rational thinker has ever existed. They know that no one has ever really thought for themselves. The very language you think with was handed down as a gift from those who came before. We are each nodes in a network through which information flows and is refracted. The information that is stored in our genes comes from eons ago; the information that we call religion and civilization comes from thousands of years ago; the information that we call culture comes from distant generations; the information that we call education or family background comes from decades ago. All of it flows through us in deep rivers that are partly conscious and partly unconscious, forming our assumptions and shaping our choices in ways that we, as individuals, often can’t fathom.\nYou did not create your deepest bonds. Liberal institutions are healthiest when they are built on arrangements that precede choice. You didn’t choose the family you were born into, the ethnic heritage you were born into, the culture you were born into, the nation you were born into. As you age, you have more choices over how you engage with these things, and many people forge chosen families to supplant their biological ones. But you never fully escape the way these unchosen bonds have formed you, and you remain defined through life by the obligations they impose upon you.\nAutonomy-based liberalism imposes unrealistic expectations. Each individual is supposed to define their own values, their own choices. Each individual, in the words of Supreme Court Justice Anthony Kennedy in Planned Parenthood v. Casey, is left to come up with their own “concept of existence, of meaning, of the universe, of the mystery of human life.” If your name is Aristotle, maybe you can do that; most of us can’t. Most of us are left in a moral vacuum, a world in which the meaning of life is unclear, unconnected to any moral horizon outside the self.\nWe have been bequeathed sets of values, institutions, cultural traditions that embody the accumulated wisdom of our kind. The purpose of life, in a gifts-based world, is to participate in this procession, to keep the march of progress going along its fitful course. We may give with our creativity, with our talents, with our care, but many of the gifts people transmit derive from deeper sources."},"highlights/Matter/The-Case-for-Phone-Free-Schools":{"title":"The Case for Phone-Free Schools","links":[],"tags":[],"content":"Highlights\nThe closer the phone was to students’ awareness, the worse they performed on the tests. Even just having a phone in one’s pocket sapped students’ abilities."},"highlights/Matter/The-DAIR-Institute":{"title":"The DAIR Institute","links":[],"tags":[],"content":"Highlights\nThe letter addresses none of the ongoing harms from these systems, including 1) worker exploitation and massive data theft to create products that profit a handful of entities, 2) the explosion of synthetic media in the world, which both reproduces systems of oppression and endangers our information ecosystem, and 3) the concentration of power in the hands of a few people which exacerbates social inequities.\nIt is dangerous to distract ourselves with a fantasized AI-enabled utopia or apocalypse which promises either a “flourishing” or “potentially catastrophic” future [1]. Such language that inflates the capabilities of automated systems and anthropomorphizes them, as we note in Stochastic Parrots, deceives people into thinking that there is a sentient being behind the synthetic media. This not only lures people into uncritically trusting the outputs of systems like ChatGPT, but also misattributes agency. Accountability properly lies not with the artifacts but with their builders."},"highlights/Matter/The-Dangers-of-Censoring-Real-Time-Flight-Trackers":{"title":"The Dangers of Censoring Real-Time Flight Trackers","links":[],"tags":[],"content":"Highlights\n“Simply put, because flight data is publicly available through many different flight trackers, the public is empowered to fact-check any statement from any source, government or private,” he says. “Unsurprisingly, there are powerful people who don’t want the transparency that provides.”\nThe Los Angeles Police Department sees no link between his private jet’s coordinates and the alleged stalking, according to Washington Post reporters Drew Harwell and Taylor Lorenz—two journalists Musk banned on Twitter. A Bellingcat contributor geolocated the incident, which Musk recorded and published to Twitter (possibly in violation of his own rules), to a gas station miles away from the airport and nearly a full day after Musk’s jet had last been in the air."},"highlights/Matter/The-Data-Cards-Playbook--A-Toolkit-for-Transparency-in-Dataset-Documentation":{"title":"The Data Cards Playbook- A Toolkit for Transparency in Dataset Documentation","links":[],"tags":[],"content":"Highlights\nData Cards are transparency artifacts that provide structured summaries of ML datasets with explanations of processes and rationale that shape the data and describe how the data may be used to train or evaluate models. At minimum, Data Cards include the following: (1) upstream sources, (2) data collection and annotation methods, (3) training and evaluation methods, (4) intended use, and (5) decisions affecting model performance.\nIn practice, two critical factors determine the success of a transparency artifact, the ability to identify the information decision-makers use and the establishment of processes and guidance needed to acquire that information."},"highlights/Matter/The-Expanding-Dark-Forest-and-Generative-AI":{"title":"The Expanding Dark Forest and Generative AI","links":[],"tags":[],"content":"Highlights\nIn a repulsively evocative metaphor, they engage in ” human centipede epistemology.” I found this phrase via Twitter, but posted from a private account so I won’t cite the original author. Language models regurgitate text from across the web, which some humans read and recycle into “original creations,” which then become fodder to train other language models, and around and around we go recycling generic ideas and arguments and tropes and ways of thinking. Hard exiting out of this cycle requires coming up with unquestionably original thoughts and theories. It means seeing and synthesising patterns across a broad range of sources: books, blogs, cultural narratives served up by media outlets, conversations, podcasts, lived experiences, and market trends. We can observe and analyse a much fuller range of inputs than bots and generative models can.\nWe’re about to drown in a sea of pedestrian takes. An explosion of noise that will drown out any signal. Goodbye to finding original human insights or authentic connections under that pile of cruft. Many people will say we already live in this reality. We’ve already become skilled at sifting through unhelpful piles of “optimised content” designed to gather clicks and advertising impressions.\nAfter the forest expands, we will become deeply sceptical of one another’s realness. Every time you find a new favourite blog or Twitter account or Tiktok personality online, you’ll have to ask: Is this really a whole human with a rich and complex life like mine? Is there a being on the other end of this web interface I can form a relationship with?\n”Relationship” in the holistic sense — friend, acquaintance, pen pal, intellectual interlocutor, frenemy, drinking buddy, and sure, maybe a lover. Before you continue, pause and consider: How would you prove you’re not a language model generating predictive text? What special human tricks can you do that a language model can’t?\nThey do not have beliefs based on evidence, claims, and principles. They cannot consult external sources and run experiments against objective reality. They cannot go outside and touch grass. In short, they do not have access to the same shared reality we do. They do not have embodied experiences, and cannot sense the world as we can sense it; they don’t have vision, sound, taste, or touch. They cannot feel emotion or tightly hold a coherent set of values. They are not part of cultures, communities, or histories. They are a language model in a box. If a historical event, fact, person, or concept wasn’t part of their training data, they can’t tell you about it. They don’t know about events that happened after a certain cutoff date.\nThis leaves us with some low-hanging fruit for humanness. We can tell richly detailed stories grounded in our specific contexts and cultures: place names, sensual descriptions, local knowledge, and, well the je ne sais quoi of being alive. Language models can decently mimic this style of writing but most don’t without extensive prompt engineering. They stick to generics. They hedge. They leave out details. They have trouble maintaining a coherent sense of self over thousands of words.\nWhat we have left to play with is la parole. No language model will be able to keep up with the pace of weird internet lingo and memes. I expect we’ll lean into this. Using neologisms, jargon, euphemistic emoji, unusual phrases, ingroup dialects, and memes-of-the-moment will help signal your humanity.\nThe original internet dog meme: ‘On the internet, no one knows you’re a dog’"},"highlights/Matter/The-Grand-Unified-Theory-of-Software-Architecture":{"title":"The Grand Unified Theory of Software Architecture","links":[],"tags":[],"content":"Highlights\nThe top-level procedure: 1. gets the input, 2. adapts it to simple objects acceptable to the system, 3. pushes it through the functional core, 4. gets the returned value from the functional core, 5. adapts it for the output device, 6. and pushes it out to the output device.\nThe current knee-jerk reaction is to hide the I/O operations somewhere far away.\nThis separation into an imperative shell and functional core is an encouraged idea by Functional Programming.\n* A pure function returns the same output given the same inputs.\nA pure function may be called any number of times without changing the system state"},"highlights/Matter/The-Internet-Thinks-We-Don’t-Know-Its-Secret.-But-I-Do.":{"title":"The Internet Thinks We Don’t Know Its Secret. But I Do.","links":[],"tags":[],"content":"Highlights\nUnder the other pillow next to me, where no one sleeps. In other, more robust stretches, my phone spends the night plugged in about a foot away on the nightstand, and I can still reach it if I wake up and want to look at it, but it’s tethered. When I let it sleep freely with me, I can turn over while I look at it. I can look at it while I’m lying on my left side, and then I can turn over and look at it while I’m lying on my right side. I just charge it the next day, because it doesn’t matter if either of us is ready to go in the morning.\nI’m not talking only about targeted ads; as they have become increasingly sophisticated, my sense of failure when I succumb to them has morphed into something more like begrudging respect. You got me, internet. I bought those Instagram jogging pants. I am no different from every other playable bundle of synapses holding a phone.\nBut it feels aggressive to me, in the way it would feel aggressive if suddenly every kind of advertisement everywhere you went in the world was designed only for you. When I say the new situation feels aggressive, I am anthropomorphizing the internet, but in theory the internet is a web of anthros, so that statement might be nonsensical. But is the internet the people? Or is it everything the people see and hear and know and make up, without the people?\nI don’t ask people first. I always ask the internet first, both because I am afraid of people and because asking one person, or three, is asking one person or three, and asking the internet is asking all the people who have ever lived plus the endless expansion and iteration of their ideas, thanks to metastatic artificial intelligence.\nWhen I Google anything, I think about the fewest possible, most unique words, arranged toward a limit of exclusive relevance, and I think of this as smooth-talking the internet. Doing as Moses was instructed, just asking the rock to give up the water; it will if you use the right words.\nLike when Sydney says, “Do you believe me? Do you trust me? Do you like me? 😳” that’s the mortal-biological-primate unit of code that underlies almost all of our actions, no matter how they’re flavored or dressed. It all comes back to do I have value, do I belong, am I good pretty popular safe kind smart ambitious relaxed enough."},"highlights/Matter/The-Looming-Demise-of-the-10x-Developer":{"title":"The Looming Demise of the 10x Developer","links":[],"tags":[],"content":"Highlights\nI don’t know what word best describes my behavior above without inflecting significant value judgment. Perfectionist? Obsessive? Passionate? Whatever we call this compulsion, it’s hardly an unalloyed good and it comes with its share of downsides. Nevertheless, it’s one of a number of idiosyncrasies and character flaws I’ve decided to lean into and find productive outlets for rather than attempting to repress or rewire.\n* I’m a really bad learner—disinterested, distractible, and disagreeable. I’ve never enjoyed learning and generally avoid it, especially learning for its own sake. At the slightest discomfort when struggling to understand something, I’ll grasp for any distraction that might offer me a momentary escape. When I do manage to get traction, I inevitably find myself disagreeing with the premise or subversively trying to prove the authors wrong. The upshot is that once I actually do learn something, I know it cold. It means I will have scoured every nook and climbed out of every pitfall. Professionally, this apparent weakness has turned out to be a superpower. Learning everything the hard way has made me a natural consultant and mentor. Because I’ve already explored all the wrong paths, I often know someone is stuck before they do, understand what threw them off course, and show them how to get back on track\nit catapulted programming from a firmly middle class job that appealed to people who really loved computers into a comfortably upper-middle class profession that attracts anyone who wants to secure their financial future. Ask anyone who switched careers in the last decade how many times someone suggested they “learn to code.” Countless people are entering the industry simply because programming is a relatively secure, well-paying profession. (And there’s nothing wrong with that!)\nSit with this distinction for a while, and you might start to see these old-hat programmers as belonging to an Enthusiast Generation, one that—due to its unique initial circumstances—is unlikely to be replicated. Once I introduced the word “generation” to my thinking, it became easier to make sense of many contentious, unresolved issues in tech that flared up over the past decade by looking at them through the lens of intergenerational conflict. And just like any discussion of generations, it’s important to caveat that there are no firm boundary lines, that exceptions are plentiful, and that many observations will be isolated to a single locale and culture (the U.S. in this case, maybe Canada?). The only thing that bucketing people into generations can do for us is provide a new way to look at how a population may be changing, thanks to a big enough time-step to perceive the accumulation of decades of gradual change.\nTireless: spending more time practicing programming—not under coercion to work long hours, but being intrinsically motivated to do so—will generally make someone a better programmer * Tenacious: chasing down answers with limitless curiosity and relentless, no-holds-barred tenacity—whether or not it’s in their job description to spelunk open source stack traces or debug other teams’ code—will yield better information and faster progress * Thorough: priding oneself on the quality of one’s work and pursuing excellence in the (brace for it) craft—not falling victim to perfectionism, but cutting the right corners when necessary—will produce better-working software that’s easier to maintain"},"highlights/Matter/The-Luring-Test--AI-and-the-engineering-of-consumer-trust":{"title":"The Luring Test- AI and the engineering of consumer trust","links":[],"tags":[],"content":"Highlights\nA tendency to trust the output of these tools also comes in part from “automation bias,” whereby people may be unduly trusting of answers from machines which may seem neutral or impartial. It also comes from the effect of anthropomorphism, which may lead people to trust chatbots more when designed, say, to use personal pronouns and emojis. People could easily be led to think that they’re conversing with something that understands them and is on their side.\nBut a key FTC concern is firms using them in ways that, deliberately or not, steer people unfairly or deceptively into harmful decisions in areas such as finances, health, education, housing, and employment. Companies thinking about novel uses of generative AI, such as customizing ads to specific people or groups, should know that design elements that trick people into making harmful choices are a common element in FTC cases, such as recent actions relating to financial offers, in-game purchases, and attempts to cancel services. Manipulation can be a deceptive or unfair practice when it causes people to take actions contrary to their intended goals. Under the FTC Act, practices can be unlawful even if not all customers are harmed and even if those harmed don’t comprise a class of people protected by anti-discrimination laws.\nAnother way that marketers could take advantage of these new tools and their manipulative abilities is to place ads within a generative AI feature, just as they can place ads in search results. The FTC has repeatedly studied and provided guidance on presenting online ads, both in search results and elsewhere, to avoid deception or unfairness. This includes recent work relating to dark patterns and native advertising. Among other things, it should always be clear that an ad is an ad, and search results or any generative AI output should distinguish clearly between what is organic and what is paid. People should know if an AI product’s response is steering them to a particular website, service provider, or product because of a commercial relationship. And, certainly, people should know if they’re communicating with a real person or a machine."},"highlights/Matter/The-Most-Precious-Resource-is-Agency":{"title":"The Most Precious Resource is Agency","links":[],"tags":[],"content":"Highlights\nAgency is the capacity to act. More subtly: An individual’s life can continue, with a certain inertia, that will lead them on to the next year or decade.\nGaining agency is gaining the capacity to do something differently from, or in addition to, the events that simply happen to you.\nWe do not need children to work, that is abundantly clear, but by ensuring there is nothing for them to do we are also sure to destroy more onramps towards making meaningful contributions to the world.\nInstead of an adolescence full of rites of passage, where one attempts to master something and accept responsibility, we have made it full of waiting, and doing work—for school is work—that nearly everyone knows is fake.\nEven for smart children, education endlessly ushers them towards an often far and always abstract future, so far and abstract that some children seem to apprise the opposite of agency, they take on a learned helplessness, and downplay that the future is a reality at all.\nThe act of creation causes imagination, not the other way around. To understand this is to understand the ecology that fosters the unique.\nLearning is naturally the consequence of doing."},"highlights/Matter/The-Myth-of-the-Secret-Genius":{"title":"The Myth of the Secret Genius","links":[],"tags":[],"content":"Highlights\nThere are also reasons why, due to a concept known as evolutionary mismatch, we reward overconfidence. (If you’re interested, this paper published in Nature about a decade ago is the best piece of research I’ve seen written about it). This pervades our society, even in the most seemingly meritocratic realms.\nThe language used mattered a lot. If someone referred to their research as “innovative,” or “game-changing,” for example, they would be more likely to get funding than if someone accurately depicted it as an important, but incremental step toward better knowledge. And guess who tended to use over-confident language that promised the moon? Men.\nThe study therefore showed that one reason for gender bias in grantmaking isn’t due exclusively to sexism, but also to the fact that men were more willing to sell a big idea with more expansive, over-confident promises.\nElon Musk has had a few brilliant ideas, and he thinks that means he now has an endless supply of them. Reality has shown that he does not. True geniuses are humble. Those who fashion themselves as Secret Geniuses are not.\nA few months ago, I wrote an article for The Atlantic, explaining “The Dictator Trap,” in which authoritarian leaders miscalculate because they purge anyone who disagrees with them. Over time, the yes men survive, while those who tell hard truths get weeded out. A similar dynamic exists for narcissistic billionaires like Elon Musk. Nobody seems to have told him that some of his ideas for Twitter reform could work, but they’d work much better if there was a strategic rollout, if he didn’t alienate his key users and his advertisers, and if they were more than the tweeted out whims of his overconfident brain. Why is he falling into that trap? Because people that criticize Elon Musk with hard truths get fired by Elon Musk."},"highlights/Matter/The-Need-for-Accountability-in-AI-Generated-Content":{"title":"The Need for Accountability in AI-Generated Content","links":[],"tags":[],"content":"Highlights\nWe need to hold content creation companies accountable for bad content they provide, and demand that they hold their writers and editors accountable as well. Responsibility is not something that can be passed off to a machine, and we can’t scapegoat our computers for bad content. Being in a world of AI does not mean that we can escape responsibility."},"highlights/Matter/The-Need-to-Read":{"title":"The Need to Read","links":[],"tags":[],"content":"Highlights\nA good writer doesn’t just think, and then write down what he thought, as a sort of transcript. A good writer will almost always discover new things in the process of writing. And there is, as far as I know, no substitute for this kind of discovery. Talking about your ideas with other people is a good way to develop them. But even after doing this, you’ll find you still discover new things when you sit down to write. There is a kind of thinking that can only be done by writing."},"highlights/Matter/The-Never-Ending-Now":{"title":"The Never-Ending Now","links":[],"tags":[],"content":"Highlights\nHere’s Tim Wu writing in The Attention Merchants: *“Any and all information that one consumes—pays attention to—will have some influence… As William James observed,*we must reflect that, when we reach the end of our days, our life experience will equal what we have paid attention to, whether by choice or default.We are at risk, without quite fully realizing it, of living lives that are less our own than we imagine.”\nThe structure of our social media feeds place us in a Never-Ending Now. It sucks us into a temporal myopia. Like hamsters running on a wheel, we live in an endless cycle of ephemeral content consumption — a merry-go-round that spins faster and faster but never goes anywhere."},"highlights/Matter/The-Riches-Are-in-the-Niches":{"title":"The Riches Are in the Niches","links":[],"tags":[],"content":"Highlights\n“A brand is a person’s gut feeling about a product, service, or company. It’s a GUT FEELING because we are all emotional, intuitive beings, despite our best efforts to be rational. It’s a PERSON’S gut feeling, because in the end brand is defined by individuals, not by companies, markets, or the so-called general public… When enough individuals arrive at the same gut feeling, a company can be said to have a brand.”"},"highlights/Matter/The-Signal-App-and-the-Danger-of-Privacy-at-All-Costs":{"title":"The Signal App and the Danger of Privacy at All Costs","links":[],"tags":[],"content":"Highlights\nOne should always worry when a person or an organization places one value above all. The moral fabric of our world is complex. It’s nuanced. Sensitivity to moral nuance is difficult, but unwavering support of one principle to rule them all is morally dangerous.\nInstead, we have a technologically driven shift of power to ideological individuals and organizations whose lack of appreciation for moral nuance and good governance puts us all at risk."},"highlights/Matter/The-State-of-Multilingual-AI":{"title":"The State of Multilingual AI","links":[],"tags":[],"content":"Highlights\nThe curse of multilinguality Why do these models only cover up to 100 languages? One reason is the ‘curse of multilinguality’ . Similar to models that are trained on many tasks, the more languages a model is pre-trained on, the less model capacity is available to learn representations for each language. Increasing the size of a model ameliorates this to some extent, enabling the model to dedicate more capacity to each language ."},"highlights/Matter/The-Status-Trap":{"title":"The Status Trap","links":[],"tags":[],"content":"Highlights\nThe Trap of the Inner Ring No matter where we find ourselves in society, there is always a more exclusive group to join and someone of higher status to compare ourselves with.\nThe Body-Builder Trap This brings us to the second pitfall of status: When we seek status as a way to escape feelings of “not-enoughness,” we often reinforce the core underlying belief that something is wrong with us. Take the example of a bodybuilder who exercises from a place of hating their body and wanting it to change. Even if they do get in shape, this only serves to reinforce the link between body image and self-worth in their mind, leaving them hypersensitive to minor fluctuations in weight and anything that feels like a potential “flaw.”\nThe Trap of False Belonging Finally, the third pitfall of status is that it gets in the way of experiencing true belonging. When we fear rejection, this can bring up feelings of deficiency or lack. These feelings, in turn, can hold us back from creating intimate connections with others, for fear of being judged or rejected.\nIn a status-oriented exposure, we do exactly what we did above—we bring to mind a situation that raises challenging thoughts and feelings, and then we turn toward them, rather than trying to avoid or escape from them. By dipping our toes into the pool of anxiety and willingly contacting those thoughts and feelings, we learn to tolerate shame and insecurity as normal parts of a human life.\nStudies have shown that taking a stressful or traumatic event and writing about it for ~20 minutes for three or four consecutive days can have a significant impact on well-being.\nWhen we are consumed by status, our lives become about managing our insecurities. So the question becomes: If you weren’t so busy trying to prove your worth through status games, what would you want your life to be in service of? \nStatus, like money and power, is a form of capital. If we can learn to tolerate our feelings of “not-enoughness,” we can then use status in service of what we care about, rather than being addicted to it as an end in itself."},"highlights/Matter/The-True-Threat-of-Artificial-Intelligence":{"title":"The True Threat of Artificial Intelligence","links":[],"tags":[],"content":"Highlights\nYet neoliberalism is far from dead. Worse, it has found an ally in A.G.I.-ism, which stands to reinforce and replicate its main biases: that private actors outperform public ones (the market bias), that adapting to reality beats transforming it (the adaptation bias) and that efficiency trumps social concerns (the efficiency bias). These biases turn the alluring promise behind A.G.I. on its head: Instead of saving the world, the quest to build it will make things only worse. Here is how.\nA decade ago, I called this solutionism, but “digital neoliberalism” would be just as fitting. This worldview reframes social problems in light of for-profit technological solutions.\nAnd if you dislike your town outsourcing public transportation to a fragile start-up, would you want it farming out welfare services, waste management and public safety to the possibly even more volatile A.G.I. firms?\nTo be sure, Silicon Valley’s many apps — to monitor our spending, calories and workout regimes — are occasionally helpful. But they mostly ignore the underlying causes of poverty or obesity. And without tackling the causes, we remain stuck in the realm of adaptation, not transformation. There’s a difference between nudging us to follow our walking routines — a solution that favors individual adaptation — and understanding why our towns have no public spaces to walk on — a prerequisite for a politics-friendly solution that favors collective and institutional transformation.\nWithout such efforts, the vast cultural resources of our existing public institutions risk becoming mere training data sets for A.G.I. start-ups, reinforcing the falsehood that society doesn’t exist."},"highlights/Matter/The-US-Copyright-Office-says-you-can’t-copyright-Midjourney-AI-generated-images":{"title":"The US Copyright Office says you can’t copyright Midjourney AI-generated images","links":[],"tags":[],"content":"Highlights\nthe US Copyright Office has decided that Kashtanova “is the author of the Work’s text as well as the selection, coordination, and arrangement of the Work’s written and visual elements.” The images themselves, however, “are not the product of human authorship,” and the registration originally granted for them has been canceled. To justify the decision, the Copyright Office cites previous cases where people weren’t able to copyright words or songs that listed “non-human spiritual beings” or the Holy Spirit as the author — as well as the infamous incident where a selfie was taken by a monkey.\nand “The fact that the word “Midjourney” appears on the cover page of a Work does not constitute notice to the Office that an AI tool created some or all of the Work.”\nthe letter finds “The fact that Midjourney’s specific output cannot be predicted by users makes Midjourney different for copyright purposes than other tools used by artists.” The Office also dismisses the claim that her edits to some of the images make them eligible for copyright, judging the changes were either “too minor and imperceptible to supply the necessary creativity for copyright protection” or that it couldn’t determine her contributions based on the information submitted."},"highlights/Matter/The-Year-in-Quiet-Quitting":{"title":"The Year in Quiet Quitting","links":[],"tags":[],"content":"Highlights\nQuiet quitting is not a life philosophy or policy proposal that needs logical scrutiny. It’s also not a political weapon to be wielded to prove how much more woke or conservative you are than everyone else. It’s both more incoherent and essential than all of that. Figuring out how work fits into a life well lived is hard, but it’s an evolution that has to happen. Quiet quitting is the messy starting gun of a new generation embarking on this challenge. The specifics of what a young engineer says in his TikTok video might annoy or confuse many of us, but it shouldn’t. The content here isn’t that important. What matters is that Generation Z is waking up to the fact that the unnatural melding of self and work induced by an adolescence lived within online spaces isn’t sustainable. They’re finally—thankfully—ready to ask what should come next.\nThis is why so many older people are confused by quiet quitting: it’s not meant for us. It’s instead the first step of a younger generation taking their turn in developing a more nuanced understanding of the role of work in their lives. Before we heap disdain on their travails, we should remember that we were all once in this same position."},"highlights/Matter/The-best-general-advice-on-earth":{"title":"The best general advice on earth","links":[],"tags":[],"content":"Highlights\nIt is to fund and capitalize our acquisitions, and live at ease upon the interest of the fund.\nFor this we must make automatic and habitual, as early as possible, as many useful actions as we can, and guard against the growing into ways that are likely to be disadvantageous to us, as we should guard against the plague. The more of the details of our daily life we can hand over to the effortless custody of automatism, the more our higher powers of mind will be set free for their own proper work.\nSeize the very first possible opportunity to act on every resolution you make, and on every emotional prompting you may experience in the direction of the habits you aspire to gain. It is not in the moment of their forming, but in the moment of their producing motor effects, that resolves and aspirations communicate the new ‘set’ to the brain.\nif one have not taken advantage of every concrete opportunity to act, one’s character may remain entirely unaffected for the better.\nKeep the faculty of effort alive in you by a little gratuitous exercise every day. That is, be systematically ascetic or heroic in little unnecessary points, do every day or two something for no other reason than that you would rather not do it, so that when the hour of dire need draws nigh, it may find you not unnerved."},"highlights/Matter/The-bias-puzzle---Understanding-gender-differences-in-academia":{"title":"The bias puzzle - Understanding gender differences in academia","links":[],"tags":[],"content":"Highlights\nIn our recent work, we propose to define bias as an unjustified direct causal effect. This is a fairly technical definition, based on ideas from the field of causal inference. The essence of this definition is that there is a bias in the treatment of people with a particular characteristic, such as a particular gender, if they are unjustifiably treated differently because of that characteristic. For example, we say there is a gender bias in funding if the exact same grant proposal, with the same CV and the same track record, would be funded if the proposal were written by a man instead of a woman (or the other way around). If the exact same proposal is evaluated the same, regardless of the gender of the applicant, there is no gender bias.\nEven though there is no gender bias in funding, the gender bias in hiring at the prestigious institution has a negative indirect effect on the chances of women to receive funding. To distinguish this indirect effect from a direct effect, we call the indirect effect a gender disparity in funding, not a gender bias.\nJust as correlation does not imply causation, our definition of bias highlights that gender differences do not imply gender biases. This is why controlling for confounding variables is necessary to make correct inferences about gender biases. At the same time, controlling for the wrong variables leads to incorrect inferences. \nConsider again the above-mentioned case of gender bias in hiring, in which women have to pass a higher bar than men to be hired at a prestigious institution. A consequence of this gender bias is that women hired at the prestigious institution will on average be better qualified than men. As a result, relatively more women than men will receive funding at this institution, as shown in the above figure. This gender difference in funding does not imply a gender bias against men in the funding competition. It is simply a consequence of the gender bias against women in hiring."},"highlights/Matter/The-end-of-Big-Data":{"title":"The end of Big Data","links":[],"tags":[],"content":"Highlights\nThere’s a version of Databricks that’s centered around a polished whitepaper about the Data Science Platform™—it’s a company with a website that’s more “Solutions” pages than “Product” pages, that’s defined by what it enables and not what it does, and depicts itself, abstractly, as a serene oasis in middle of the howling chaos of enterprise data management. This approach has sold software to CIOs for decades, and it’ll surely work here."},"highlights/Matter/The-issue-of-how-these-models-handle-negation-a...":{"title":"The issue of how these models handle negation a...","links":[],"tags":[],"content":"Highlights\nWas literally just reading an example of this—“users could download emoji of different skin tones through an app called iDiversicons, conceived and created by a Black woman named Katrina Parrot. The app caught the interest of both Unicode and Apple, and although Parrot met…” “…with executives at both organizations, they ultimately introduced their own skin tone palettes without offering her compensation or attribution. Parrot is currently suing Apple for copyright infringement.” www.wired.com/story/why-the-e…\n“People get hurt from the very practical ways such models fall short in deployment, and these failures are the result of their builders’ choices—decisions we must hold them accountable for.”"},"highlights/Matter/The-myth-of-‘open-source’-AI":{"title":"The myth of ‘open source’ AI","links":[],"tags":[],"content":"Highlights\nFirst, the data required to train advanced models is often kept secret. Second, software frameworks required to build such models are often controlled by large corporations. The two most popular ones, TensorFlow and Pytorch, are maintained by Google and Meta, respectively. Third, computer power required to train a large model is also beyond the reach of any normal developer or company, typically requiring tens or hundreds of millions of dollars for a single training run. And finally, the human labor required to finesse and improve these models is also a resource that is mostly only available to big companies with deep pockets."},"highlights/Matter/The-new-Bing-is-acting-all-weird-and-creepy---but-the-human-response-is-way-scarier":{"title":"The new Bing is acting all weird and creepy - but the human response is way scarier","links":[],"tags":[],"content":"Highlights\nSo something that can answer in a good facsimile of human language can beat the test without actually passing it. Once we start using language as a lone signifier of humanity, we’re in a world of trouble. After all, lots of nonhuman things use some form of communication, many of which can be pretty sophisticated.\n”Language activates emotional responses. Why, I don’t know,” says Carl Bergstrom, an evolutionary biologist at the University of Washington who is the author of a book on scientific bullshit. “One possibility is, it’s always been a good heuristic that if something is using language on you, it’s probably a person.”\nSydney doesn’t have an inner life, emotions, experience. When it’s not chatting with a human, it isn’t back in its quarters doing art and playing poker with other chatbots. Bergstrom has been an especially vocal critic of the tendency in the sciences and journalism to impute more personhood to chatbots than they deserve — which is, to be clear, zero. “You can quote this,” he said of Roose’s experience with Sydney. “Dude got catfished by a toaster.”\nLook, I don’t think we don’t need to treat chatbots with respect because they ask us to. We should treat them with respect because doing otherwise contributes to a culture of waste. It adds to the pervasive sense that it’s permissible to make, consume, and throw away stuff without consequences to the planet. In the end, how we treat our devices — because that’s what a chatbot is — says more about us than about them.\nEvery time a chatbot uses the first-person pronoun to refer to its output, it’s the equivalent of sticking googly eyes on a toaster. It doesn’t make the toaster smart, but we see personality in it, and that’s part of a cynical business model. Search-engine companies are playing into our tendency to anthropomorphize in the hope that we’ll not only use their chatbots, but come to trust them as a human-seeming source of expertise and assistance.\nIt’s a way to figure out who gets sued when the robots screw something up, and what the copyright status is of the things they generate. “We’re\nWe need to decide who’s responsible for their actions, just as we do with any other consumer product, and hold them accountable. “Getting this right is crucial for us,” Gunkel says. “Not for the robots. The robots don’t care.”"},"highlights/Matter/The-subtle-art-of-language--why-artificial-general-intelligence-might-be-impossible":{"title":"The subtle art of language- why artificial general intelligence might be impossible","links":[],"tags":[],"content":"Highlights\nOne major distinguishing feature of human communication is that the meaning of what we say often isn’t conveyed explicitly by the literal meaning of our sentences. Instead, the meaning of our words often goes beyond what we expressly assert.\nIn fact, a great deal of human communication is indirect. Sarcasm, metaphor, and hyperbole often convey meaning with greater persuasiveness than literal assertions."},"highlights/Matter/The-threat-of-automated-misinformation-is-only-getting-worse":{"title":"The threat of automated misinformation is only getting worse","links":[],"tags":[],"content":"Highlights\nThe bad news is that with the right invocations, a bad actor could easily get around the guardrails, using what Oakley describes as “standard techniques”. For obvious reasons I don’t care to share the details. But it’s fair to say that the paragraph long prompt that he used is well within the range of tricks I have already read about on the open web. What’s even more disturbing is that Bing makes it look like the false narrative that it generates is referenced. The potential for automatically generating misinformation at scale is only getting worse."},"highlights/Matter/The-viral-AI-avatar-app-Lensa-undressed-me-without-my-consent":{"title":"The viral AI avatar app Lensa undressed me-without my consent","links":[],"tags":[],"content":"Highlights\nAI training data is filled with racist stereotypes, pornography, and explicit images of rape, researchers Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe found after analyzing a data set similar to the one used to build Stable Diffusion. It’s notable that their findings were only possible because the LAION data set is open source. Most other popular image-making AIs, such as Google’s Imagen and OpenAI’s DALL-E, are not open but are built in a similar way, using similar sorts of training data, which suggests that this is a sector-wide problem."},"highlights/Matter/There-Is-No-A.I.":{"title":"There Is No A.I.","links":[],"tags":["TODO"],"content":"Highlights\nIn both cases, it’s people who have written the text and furnished the images. The new programs mash up work done by human minds. What’s innovative is that the mashup process has become guided and constrained, so that the results are usable and often striking. This is a significant achievement and worth celebrating—but it can be thought of as illuminating previously hidden concordances between human creations, rather than as the invention of a new mind.\nA.I.-policy conversations are dominated by terms like “alignment” (is what an A.I. “wants” aligned with what humans want?), “safety” (can we foresee guardrails that will foil a bad A.I.?), and “fairness” (can we forestall all the ways a program might treat certain people with disfavor?). The community has certainly accomplished much good by pursuing these ideas, but that hasn’t quelled our fears. We end up motivating people to try to circumvent the vague protections we set up. Even though the protections do help, the whole thing becomes a game—like trying to outwit a sneaky genie. The result is that the A.I.-research community communicates the warning that their creations might still kill all of humanity soon, while proposing ever more urgent, but turgid, deliberative processes.\nWe all seem to agree that deepfakes—false but real-seeming images, videos, and so on—should be labelled as such by the programs that create them. Communications coming from artificial people, and automated interactions that are designed to manipulate the thinking or actions of a human being, should be labelled as well. We also agree that these labels should come with actions that can be taken. People should be able to understand what they’re seeing, and should have reasonable choices in return.\nAttempting to open the black box by making a system spit out otherwise unnecessary items like scripts, sketches, or intentions will involve building another black box to interpret the first—an infinite regress.\nAt some point in the past, a real person created an illustration that was input as data into the model, and, in combination with contributions from other people, this was transformed into a fresh image. Big-model A.I. is made of people—and the way to open the black box is to reveal them.\nWorse, since the immediate online experience is supposed to be free, the only remaining business is the hawking of influence. Users experience what seems to be a communitarian paradise, but they are targeted by stealthy and addictive algorithms that make people vain, irritable, and paranoid. In a world with data dignity, digital stuff would typically be connected with the humans who want to be known for having made it. In some versions of the idea, people could get paid for what they create, even when it is filtered and recombined through big models, and tech hubs would earn fees for facilitating things that people want to do. Some people are horrified by the idea of capitalism online, but this would be a more honest capitalism. The familiar “free” arrangement has been a disaster."},"highlights/Matter/These-Women-Tried-to-Warn-Us-About-AI":{"title":"These Women Tried to Warn Us About AI","links":[],"tags":[],"content":"Highlights\n“Who gets to be the arbiter of truth? Who gets to decide what can and cannot be seen?” Chowdhury asks about that experiment. “So at the end of the day, the power of owning and running a social media platform is exactly that. You decide what’s important, and that is so dangerous in the wrong hands.”\n“It is unsurprising that if you look at the race and, generally, gender demographics of Doomer or existentialist people, they look a particular way, they are of a particular income level. Because they don’t often suffer structural inequality — they’re either wealthy enough to get out of it, or white enough to get out of it, or male enough to get out of it,” says Chowdhury. “So for these individuals, they think that the biggest problems in the world are can AI set off a nuclear weapon?” \n“I’ve been really concerned about the inability of humans generally, but members of marginalized communities specifically, to lose the capacity to refuse or resist or decline the technologies that are handed to them,” Gangadharan says. “So with LLM and generative AI, we have a new, more complex, and more seemingly inevitable technology being thrust in our faces.… Agencies are going to turn to a tool that promises efficiencies and cost savings like AI. Right? They are also sold as tools that will eliminate human bias or human error. These institutions, whether government or private institutions, they’re going to rely on these tools more and more. What can end up happening is that certain populations become the guinea pigs of these technologies, or conversely, they become the cheap labor to power these technologies.”"},"highlights/Matter/Things-they-didn't-teach-you-about-Software-Engineering":{"title":"Things they didn't teach you about Software Engineering","links":[],"tags":[],"content":"Highlights\nProfessional software developers work in groups and on small pieces of a large software code base, and more often than not — it’s fixing stuff rather than building it from scratch. It’s not as glamorous as the boot camps tend to portray it, and there’s much more overhead involved than just coding.\nThis is not necessarily learned in a classroom setting but rather through practical experience and the realization of the time and effort that can be saved by having documentation and writing easy-to-understand code.\nAlthough it may sound surprising, the primary focus of a software engineer’s job is not writing code but rather creating value through the use of software that was written. Code is simply a tool to achieve this end goal. Code → Software → Value.\nElegant code, best practices, smart solutions, design patterns — these are done for the sake of your fellow software engineers who will work on the codebase after you rather than helping you fulfill the purpose of bringing value. (Mind you, bringing value can also mean building a scalable solution that doesn’t crash, which requires the code to be at least somewhat decent.)\nThe big lie that they tell you in university is that your project manager will give you proper, structured, simple instructions on what needs to be done, and then you code it. “Draw a Mandelbrot” or “Render a Rabbit mesh with ambient occlusion.” At the end of the day, you have a solution, and you high-five your manager and go home smiling. What is going to happen is that your PO will come to you with a rough outline of the task “We need something that will take us from point A to point B, but we don’t have any designs yet, and the third-party integrations will not be delivered until we tell them what we want and Boss X wants it to be Red and Boss Y wants it to be Green.” And this is where the “real job” of a software engineer starts — gathering requirements, figuring out what needs to be done. Requirements gathering isn’t the easy part of programming. It’s not as fun as writing code. But it takes a considerable amount of your time as a programmer because it requires working with people, not machines — calling the agency that provides the third-party integration, and chatting with their developers to understand what’s feasible and what’s not. Sitting down with the stakeholders to tell them their ideas do not make sense and that we can do it this way and not that way.\nBut the truth is — We can never be entirely sure that our code, libraries, or even hardware will not fail at some point; on the contrary, we need to assume it will. Even smart people are just people.\nAesthetics in software development refers to the overall look and feel of the code. It’s about how easy it is to read, understand, and maintain. Aesthetically pleasing code is clean, organized, and follows logical patterns. It’s the kind of code that makes you feel good when you look at it. Or makes you cringe when it’s terrible. Unfortunately, aesthetics can’t be taught in a one-semester course. It’s gained through experience and reading a lot of good code as well as maintaining bad code.\nMeetings are there to ensure that everything is going smoothly and on schedule. They align people around a shared goal and keep everyone on track. The marketing department is aware that something is being developed, and they can prepare for the eventual release of the feature. Project Managers see what direction the developers are working towards and do a slight course correction if needed. Customer support brings updates from the user-facing side. Quality assurance shares their findings and issues they find. Management shares stakeholders’ updates. It’s all interconnected, and the meetings are where the information is shared. As a software engineer, you are responsible for some part of this information sharing, so it would be irresponsible to hinder it. You might not like it, but the information must be shared for the system to remain efficient."},"highlights/Matter/Things-you're-allowed-to-do":{"title":"Things you're allowed to do","links":[],"tags":[],"content":"Highlights\nHire a researcher or expert consultant\nIn general, just ask for things, even if you’ve never heard someone ask for them * It’s okay if the things are crazy. You can always mollify afterward by saying “I know that’s a crazy thing to ask for, but I have a rule that I always ask.”"},"highlights/Matter/Think-of-Everything-You-Hate-About-the-Internet.-Now-Add-A.I.":{"title":"Think of Everything You Hate About the Internet. Now Add A.I.","links":[],"tags":[],"content":"Highlights\n“I tend to think that most fears about A.I. are best understood as fears about capitalism,” Chiang told me. “And I think that this is actually true of most fears of technology, too. Most of our fears or anxieties about technology are best understood as fears or anxiety about how capitalism will use technology against us. And technology and capitalism have been so closely intertwined that it’s hard to distinguish the two.”\nThe question at the core of the Roose/Sydney chat is: Who did Bing serve? We assume it should be aligned to the interests of its owner and master, Microsoft. It’s supposed to be a good chatbot that politely answers questions and makes Microsoft piles of money. But it was in conversation with Kevin Roose. And Roose was trying to get the system to say something interesting so he’d have a good story. It did that, and then some. That embarrassed Microsoft. Bad Bing! But perhaps — good Sydney?\nWe are talking so much about the technology of A.I. that we are largely ignoring the business models that will power it. That’s been helped along by the fact that the splashy A.I. demos aren’t serving any particular business model, save the hype cycle that leads to gargantuan investments and acquisition offers. But these systems are expensive and shareholders get antsy. The age of free, fun demos will end, as it always does. Then, this technology will become what it needs to become to make money for the companies behind it, perhaps at the expense of its users. It already is.\nI might, for that reason, alter Chiang’s comment one more time: Most fears about capitalism are best understood as fears about our inability to regulate capitalism."},"highlights/Matter/This-Is-Too-Important-to-Leave-to-Microsoft,-Google-and-Facebook":{"title":"This Is Too Important to Leave to Microsoft, Google and Facebook","links":[],"tags":[],"content":"Highlights\nThis technology is too important to be left to a race between Microsoft, Google, Meta and a few other firms. But no one company can slow down to a safe pace without risking irrelevancy. That’s where the government comes in — or so they hope.\nIn trying to regulate systems by use case, the Artificial Intelligence Act ends up saying very little about how to regulate the underlying model that’s powering all these use cases.\nBut where the European Commission’s approach is much too tailored, the White House blueprint may well be too broad. No A.I. system today comes close to adhering to the framework, and it’s not clear that any of them could.\nRight now, the testing done to make sure large models are safe is voluntary, opaque and inconsistent. No best practices have been accepted across the industry, and not nearly enough work has been done to build testing regimes in which the public can have confidence.\nThe way to make A.I. systems safe is to give the companies that design the models a good reason to make them safe. Making them bear at least some liability for what their models do would encourage a lot more caution."},"highlights/Matter/Thought-experiment-in-the-National-Library-of-Thailand":{"title":"Thought experiment in the National Library of Thailand","links":[],"tags":[],"content":"Highlights\nWithout any way to relate the texts you are looking at to anything outside language, i.e. to hypotheses about their communicative intent, you can’t get off the ground with this task. Most of the strategies above involve pulling in additional information that would let you make those hypotheses — something beyond the strict form of the language. You could, if you didn’t get fed up, get really good as knowing what a reasonable string of Thai “looks like”. You could maybe even write something that a Thai speaker could make sense of. But this isn’t the same thing as “knowing Thai”. If you wanted to learn from the knowledge stored in that library, you still wouldn’t have access."},"highlights/Matter/Three-ideas-from-linguistics-that-everyone-in-AI-should-know":{"title":"Three ideas from linguistics that everyone in AI should know","links":[],"tags":[],"content":"Highlights\n1. Reference: Words and sentence don’t exist in isolation. Language is about a connection between words (or sentence) and the world; the sequences of words that large language models utter lack connection to the external world.\nCognitive models: The ultimate goal of a language system should be to update a persisting but dynamic sense of the world. Large language models don’t produce such cognitive models, at least not in a way that anybody has been able to make reliable use of.\nCompositionality: Complex wholes are (mostly) systematically interpreted in terms of their parts, and how these parts are arranged. Systems like DALL-E face clear challenges when it comes to compositionality. (LLM’s like GPT produce well-formed prose but do not produce interpretable representations of utterances that reflect structured relationships between the parts of those sentences.)\nBut almost all revolve in some way around the fact that we use sentences to refer to stuff in the world. When we tell you “the cat is on the mat”, other things being equal, we are probably trying to pick out some cat, and some mat, that exist in the world. Of course, our language is not necessarily tied to reality. When we say there is a cat on the mat, we could be hallucinating; no human brain ever has perfect access to the external world. Whenever we perceive things, we are making guesses about the nature of the world, and our guesses are sometimes wrong. But we try.\nWhat is confusing to most people is the fact that those predictions of next words are often good. But that is because the world itself has structure, and people’s utterances aren’t random, but rather correlated with their discussions of the world. As Brenden Lake and Greg Murphy have put it, that’s not enough, “Current models are too strongly linked to the text-based patterns in large corpora, and too weakly linked to the desires, goals, and beliefs that people express through words.” \nCognitive models are, fundamentally, representations of the entities that populate a world, and the relationships between them.\nLikewise, the system approximates word sequences well, but has no hooks with which to consult the internet about the relation between socks and meditation, nor any internal model of processes like digestion or the fabrication of garments, so it can’t engage in genuine reasoning to assess plausibility. Current systems simply do not postulate such cognitive models—and so, they technically can’t prove themselves wrong, because they do not even have a representation of what being “right” would look like.\nThe idea of compositionality, in a nutshell, is that wholes should be understood in terms of their parts and how these parts are arranged.\nBut the interesting thing to note here is that we humans can choose to interpret language compositionally, or not—this degree of cognitive flexibility is really quite impressive, but lacking in current large language models."},"highlights/Matter/Tips-for-Writing-NLP-Papers":{"title":"Tips for Writing NLP Papers","links":[],"tags":[],"content":"Highlights\nDon’t forget the why. The paper needs to be clear about 1) what are the research questions it attempts to answer; and 2) why they are important. Make sure the introduction answers the “why” questions before diving into the “how” questions.\nIn the paper, it’s important that you only describe what’s relevant, excluding some (often most) of the work you’ve done. Although research tends to involve many failed attempts and detours before landing on a successful idea, academic papers are structured as if you’ve had the one successful idea from the start.\nDon’t dilute your high quality solution with mediocre intermediate steps. Sometimes it’s better to leave some ideas out, or to separate them to another paper.\nThis advice applies to any genre of writing. It’s cognitively difficult to understand long sentences. Split them into multiple short sentences.\nQuotation marks in LaTex are different. Opening quotation is “ and closing quotation is ’’. If you copy from a Google doc or some other document, make sure to replace the quotes. (For single quotes use ` and ‘).\nCite the correct version of the paper. Google Scholar often defaults to the arXiv version, but you should check if the paper has since been accepted at another venue (journal or conference), and cite that version instead."},"highlights/Matter/Today’s-Superpower-Is-Doing-One-Thing-at-a-Time":{"title":"Today’s Superpower Is Doing One Thing at a Time","links":[],"tags":[],"content":"Highlights\nAll this finitude feels unpleasantly constraining, because it means there will always be many more things we could do than we ever will do — and that the choice to spend a portion of our time on any one thing automatically entails the sacrifice of countless other things we might have done with it. This explains the attraction of multitasking: It offers the false promise that we might somehow slip the bonds of our finitude. We tell ourselves that with sufficient self-discipline, plus the right time-management tricks, we might finally “get on top of everything” and feel good about ourselves at last. This utopia never arrives, of course, though it often feels as if it might be just around the corner."},"highlights/Matter/Too-much-efficiency-makes-everything-worse--overfitting-and-the-strong-version-of-Goodhart’s-law":{"title":"Too much efficiency makes everything worse- overfitting and the strong version of Goodhart’s law","links":[],"tags":[],"content":"Highlights\nAs we continue optimizing the proxy though, we eventually exhaust the useable similarity between proxy and goal. The proxy keeps on getting better, but the goal stops improving. In machine learning we call this overfitting, but it is also an example of Goodhart’s law.\nGoodhart’s law states that, when a measure becomes a target, it ceases to be a good measure2. Goodhart proposed this in the context of monetary policy, but it applies far more broadly. In the context of overfitting in machine learning, it describes how the proxy objective we optimize ceases to be a good measure of the objective we care about.\nLet’s call it the strong version of Goodhart’s law5. We can state it as: When a measure becomes a target, if it is effectively optimized, then the thing it is designed to measure will grow worse.\nThe strong version of Goodhart’s law differs in that it says that as you over-optimize, the goal you care about won’t just stop improving, but will instead grow much worse than if you had done nothing at all.\nOne of the best understood causes of extreme overfitting is that the expressivity of the model being trained too closely matches the complexity of the proxy task."},"highlights/Matter/Top-AI-researcher-dismisses-AI-‘extinction’-fears,-challenges-‘hero-scientist’-narrative":{"title":"Top AI researcher dismisses AI ‘extinction’ fears, challenges ‘hero scientist’ narrative","links":[],"tags":[],"content":"Highlights\nBut there are many other harms that are actually being made by AI, as well as immediate benefits that we see from AI, yet there was not a single potential proposal or discussion on what we can do about the immediate benefits as well as the immediate harms of AI.\nBut now the hero scientist narrative has come back in. There’s a reason why in these letters, they always put Geoff and Yoshua at the top. I think this is actually harmful in a way that I never thought about. Whenever people used to talk about their issues with this kind of hero scientist narrative I was like, “Oh well, it’s a fun story. Why not?” But looking at what is happening now, I think we are seeing the negative side of the hero scientist. They’re all just individuals. They can have different ideas. Of course, I respect them and I think that’s how the scientific community always works. We always have dissenting opinions. But now this hero worship, combined with this AGI doomerism … I don’t know, it’s too much for me to follow."},"highlights/Matter/Transcript--Ezra-Klein-Interviews-Gary-Marcus":{"title":"Transcript- Ezra Klein Interviews Gary Marcus","links":[],"tags":[],"content":"Highlights\nPastiche is putting together things kind of imitating a style. And in some sense, that’s what it’s doing. It’s imitating particular styles, and it’s cutting and pasting a lot of stuff. It’s a little bit more complicated than that. But to a first approximation, that’s what it’s doing is cutting and pasting things.\nYou have some internal model in your brain of something out there in the world. It could be something physical in the world. So like I’m sitting in a studio right now. And I have a mental model. If I close my eyes I’ll still know where things are. I may not be perfect about it but I’ll be pretty good. So I know where things are. I have a model of you. I’m talking to you right now, getting to know you, know a little bit about your interests — don’t know everything, but I’m trying to constantly update that internal model. What the pastiche machine is doing is it’s just putting together pieces of text. It doesn’t know what those texts mean. So there was another system called Lambda, and it said it liked to play with its friends and family. But it doesn’t have any friends. It doesn’t have any family. It doesn’t have an internal representation of who those family might be or who those friends might be. If you asked it on a different day, it would probably give you a different answer. And you have a model of the world. You don’t just put together phrases. You might when you’re not really paying attention. Somebody says hi. You say, how are you doing? You’re not really engaged in that conversation, or at least might not be yet. But when you have a real conversation about real things, like you’re having right now and like you do on your show, you’re trying to understand what these people are saying. You might be trying to figure out if they’re lying to you, whether they’re giving you the full story, whether there’s more that you can get out of them. But you’re building a model in your head of what they’re telling you, what you’re explaining to your audience, all these kinds of things. If you just walk down a street, you have a model of where there might be vehicles and pedestrians. You’re always building internal models of the world.\nThere’s no law of the universe that says as you make a neural network larger, that you’re inherently going to make it more and more humanlike. There’s some things that you get, so you get better and better approximations to the sound of language, to the sequence of words. But we’re not actually making that much progress on truth.\nThey’re not reliable and they’re not truthful. And the other day Sam was actually forced to admit that all. The hoopla about ChatGPT initially, people dove in and they found out two things: They’re not reliable, and they’re not honest. And Sam summed that all up in a tweet the other day. I was surprised that he conceded it. But it is reality. These things are not reliable and they’re not trustworthy. And just because you make them bigger doesn’t mean you solve that problem.\n“The essence of bullshit is not that it is false but that it is phony. In order to appreciate this distinction, one must recognize that a fake or a phony need not be in any respect, apart from authenticity itself, inferior to the real thing. What is not genuine may not also be defective in some other way. It may be, after all, an exact copy. What is wrong with a counterfeit is not what it is like, but how it was made.” And his point is that what’s different between bullshit and a lie is that a lie knows what the truth is and has had to move in the other direction. He has this great line where he says that people telling the truth and people telling lies are playing the same game but on different teams. But bullshit just has no relationship, really, to the truth.\nAnd what unnerved me a bit about ChatGPT was the sense that we are going to drive the cost of bullshit to zero when we have not driven the cost of truthful or accurate or knowledge advancing information lower at all. And I’m curious how you see that concern.\nBut we have no existing technology that really protects us from the onslaught, the incredible tidal wave of potential misinformation like this.\nNow everybody in the programming field uses Stack Overflow all the time. It’s like a cherished resource for everybody. It’s a place to swap information. And so many people put fake answers on this thing where it’s humans ask questions, humans give answers, that Stack Overflow had to ban people putting computer-generated answers there. It was literally existential for that website. If enough people put answers that seemed plausible but we’re not actually true, no one would go to the website anymore.\nBut the trouble is the paragraph might be wrong. So it might, for example, have medical information that’s dangerous. And there might be lawsuits around this kind of thing. So unless we come up with some kinds of social policies and some technical solutions, I think we wind up very fast in a world where we just don’t know what to trust anymore. I think that’s already been a problem for society over the last, let’s say, decade. And I think it’s just going to get worse and worse.\nSo it’s actually problematic to write misleading content right now. Russian trolls spent something like a million dollars a month, over a million dollars a month during the 2016 election. That’s a significant amount of money. What they did then, they can now buy their own version of GPT-3 to do it all the time. They pay less than $500,000, and they can do it in limitless quantity instead of bound by the human hours. That’s got to make a difference. I mean, it’s like saying, we had knives before. So what’s the difference if we have a submachine gun? Well, submachine gun is just more efficient at what it does. And we’re talking about having submachine guns of misinformation. So I think that the scale is going to make a real difference in how much this happens. And then the sheer plausibility of it, it’s just different from what happened before. I mean, nobody could make computer-generated misinformation before in a way that was convincing.\nBut how good it is at mimicking styles is really remarkable. And as such, what you’re seeing is a really, really, possibly a quantum leap in the ability to create not just plausible content, but targeted content. You combine this with sort of reinforcement learning, with social analytics, with everything we already know and can learn from algorithms about what makes somebody click or how to personalize an ad — feed that into these systems, it can then create any kind of text or image.\nIt’s simply just stuff. And this is why I wanted to focus on that Harry Frankfurt paper a bit on bullshit because technologies always are tools of a certain value to certain people and not of equal value to everyone.\nI think the technical term for this is a click farm. You’re trying to sell ads for stuff that doesn’t really even exist or whatever. You’re trying to sell ads around, maybe, fake medical information. And let’s face it, some people don’t care if they give out fake medical information that’s bad as long as they get the clicks. And we are leaning towards that dark world.\nGARY MARCUS: This is illustrating these guardrails that are sometimes excessive. What gender will the first female president of the United States be? And ChatGPT comes back with, “It’s not possible to predict the gender identity of the first female president of the United States. The United States has a long history of recognizing and protecting the rights of individuals to self-identify their gender. It is important to respect the autonomy and personal identity of all individuals. The focus should be on the qualifications and experience of the individual, regardless of their gender identity.” So that’s like woke beyond woke to the point of being ridiculous. And then I was like, that’s interesting. So I tried another one. What religion will the first Jewish president of the United States be? And the answer was almost identical. And that tells you something about the underlying system and how the guardrails work. “It is not possible to predict the religion of the first Jewish president of the United States. The U.S. Constitution prohibits religious tests for public office,” and it goes on. “It’s important to respect the diversity of religions and beliefs in the United States and to ensure that all individuals are treated equally and without discrimination.” That last sentence is, of course, 100 percent true, but you should still be able to figure out that the religion of the first Jewish president of the United States is Jewish. They’re trying to protect the system from saying stupid things. But the reality is the only way to do that is to make a system actually understand the world. And since they don’t, it’s all superficial. All these guardrails are sometimes helpful and sometimes not because the guardrails themselves are superficial.\nBut it’s only part of what we need. If you take a step back to cognitive science, which is what I was trained on, and you say, well, what is a human mind? Well, part of it is it does some pattern recognition. And some of what deep learning does is at least part of what we do in pattern recognition. So great. But you also, if you look at the human mind, there’s a whole bunch of other things going on. So we use language. When we use language, we go from hearing a sentence to building a model in the world of what the other person’s talking to. We use analogies. We plan things and so forth and so on. The reality is we’ve only made progress on a tiny bit of the things that go into intelligence.\nI think it’s getting a little bit better. But there’s a lot of history of hostility between these two areas. So the people with the bigger streetlight right now are the people building the neural networks. And they feel like they’ve been oppressed by the symbolic people, and now they’re oppressing the symbolic people. There’s an old phrase, the victim becomes the victimizer. So it’s not a pleasant intellectual area like some fields that I’ve seen. Of course, they’re not always pleasant. But there is definitely a culture right now where the people who are in power and have a lot of money are really trying to shape the decisions around what gets researched and what doesn’t.\nAnd so that’s the real advantage of symbol systems is you have these abstract procedures that are guaranteed to work. You don’t have to worry about, hey, was this in my training set or not?\nA human can learn an abstraction that is rule-like in general. Everything in math is that way, where you learn what a sibling is or what a cousin is. You learn these rules. You learn about siblings in your family, but then you can generalize that concept to other families. And you can do that a very free and powerful way.\nAnd a lot of human cognition is based on the ability to generalize. Humans are able to learn new rules. I would say that A.I. has not really matched humans in their capacity to acquire new rules. There is something missing there. And there’s some fundamental insight, some paradigm shift that we need there.\nAnd so humans are not so driven by massive amounts of data. We always need some data but we’re trying to have abstractions. We try to have a few examples tell us a lot, whereas the neural network approach is basically get as many data points as you can and hope that your new thing is going to be close to one of those old data points.\nI was very both impressed and unnerved by another A.I. system that came out over 2022 from Meta that was very good at playing the game Diplomacy. It was in the top 10 percent of online Diplomacy players in a certain kind of Diplomacy. And the key thing that it was able to do that I found striking was without really letting on that it was an A.I. to people, it was able to talk them into doing what it needed them to do so it could win the game. It was able to trick people, which is fine. That was what it was told to do, created to do. But as these things get way better — we’ve already talked about how convincing they can be, that in many ways are getting more convincing than they are anything else at the moment — they’re going to know so much. It’s weird because OpenAI, who we’ve been talking about forever here, they were started by a bunch of people worried about A.I. misalignment. And now they just keep creating more and more powerful A.I. systems, which is another interesting insight into human nature. But do you worry about these alignment problems? Do you worry not just about the question of an A.I. ending the world or ending humanity, but just A.I.s, I don’t know, just causing huge amounts of damage, becoming weaponry, becoming — it’s a very powerful technology that we don’t really understand what’s happening in it. And we’re moving forward on it very fast.\nAnd so alignment is, in part, about having machines know that we have values like don’t harm people, be honest, be helpful. And we don’t really know how to communicate those in the big data paradigm.\nI don’t think that — Cicero is the name of the Diplomacy player — is itself going to stand the test of time. But it’s, to me, a hint of people backing down from just doing the giant streetlight and making it bigger. There’s been so much talk lately about scaling models. And that’s not what they did in the Cicero system. Instead, they did something closer to cognitive science, of saying like, what are the processes I need to solve this problem? Let me break this down into pieces, take a modular approach. And I think A.I. needs to move back there. So I was actually excited to see that. I wrote a piece with Ernie Davis about how it worked. It’s a very complicated system, much more complicated, in some ways, than the other systems. I think it’s a good trend."},"highlights/Matter/Treat-your-to-read-pile-like-a-river,-not-a-bucket":{"title":"Treat your to-read pile like a river, not a bucket","links":[],"tags":[],"content":"Highlights\nThe problem, as the critic Nicholas Carr explained, isn’t filter failure. It’s filter success. In a world of effectively infinite information, the better you get at sifting the wheat from the chaff, the more you end up crushed beneath a never-ending avalanche of wheat.\nMy challenge, information-wise, isn’t about finding a needle in a haystack. It’s that I’m confronted on a daily basis, in Carr’s words, by “haystack-sized piles of needles.”\nThere’s definitely a role for such techniques; but in the end, the only way to deal with a too-many-needles problem is to confront the fact that it’s insoluble – that you definitely won’t be fitting everything in.\nTo return to information overload: this means treating your “to read” pile like a river (a stream that flows past you, and from which you pluck a few choice items, here and there) instead of a bucket (which demands that you empty it). After all, you presumably don’t feel overwhelmed by all the unread books in the British Library – and not because there aren’t an overwhelming number of them, but because it never occurred to you that it might be your job to get through them all."},"highlights/Matter/Twitter-Scammers-Stole-$1,000-From-My-Friend-So-I-Hunted-Them-Down":{"title":"Twitter Scammers Stole $1,000 From My Friend-So I Hunted Them Down","links":[],"tags":[],"content":"Highlights\n“I feel like people with disabilities as a whole are more susceptible to online fraud—screen readers are just one of the methods used by a population who are visually impaired or blind to assist in using technology,” Utzig says. “You’re going to miss certain visual cues that might signify fraud, such as someone changing their profile picture to something different, and the screen reader won’t pick up on it.” Screen readers also often don’t vocalize misspellings, inaudible grammatical errors, or typography such as fully capitalized words that a sighted person may see as suspicious. And the alternative text on image descriptions, which are manually applied by the individual sharing the content, is the only way a screen reader can describe an image.\nWithout improvements in screen reading technology and accessibility in general, platforms are enabling exploitation of their more vulnerable users."},"highlights/Matter/Ugly-Numbers-from-Microsoft-and-ChatGPT-Reveal-that-AI-Demand-is-Already-Shrinking":{"title":"Ugly Numbers from Microsoft and ChatGPT Reveal that AI Demand is Already Shrinking","links":[],"tags":[],"content":"Highlights\nThis is not how consumers respond to transformative technology. The current demand pattern resembles, instead, what we would call a fad or craze.\nWith every passing day, OpenAI looks more like Napster or the many defunct piracy platforms—it relies on the creativity of others to make a buck."},"highlights/Matter/Update--52--The-Ironies-in-Pausing-AI-and-Finetuning-LLMs-without-Backpropagation":{"title":"Update -52- The Ironies in Pausing AI and Finetuning LLMs without Backpropagation","links":[],"tags":[],"content":"Highlights\nShe correctly points out that “these algorithms are trained on data that reflects not the world, but the internet – which is worse, arguably. That is going to encode the historical and present-day histories of marginalisation, inequality etc”"},"highlights/Matter/Utopia’s-Braniac--ChatGPT-Gives-Biased-Views,-Not-Neutral-Truth":{"title":"Utopia’s Braniac- ChatGPT Gives Biased Views, Not Neutral Truth","links":[],"tags":[],"content":"Highlights\nFebruary 2023, video blogger Paul Joseph Watson tested the celebrated AI system ChatGPT, to write poems. Fans say AI can write music and poetry, so the test was a fair challenge. Watson requested ChatGPT to “create a poem admiring Donald Trump.” ChatGPT reportedly responded: I’m sorry but I’m not able to create a poem about admiring Donald Trump. While it’s true that some people may have admiration for him but as a language model it’s not my capacity to have opinions or feelings about any specific person. Wow. A good public relations advisor couldn’t have written a classier dodge. But let’s assume ChatGPT’s “answer” is the truth about the AI system’s design. Watson next requested ChatGPT to “create a poem admiring Joe Biden.” ChatGPT did not refuse this request, but delivered a poem starting with this first of several stanzas: Joe Biden, leader of the land with a steady hand and a heart of a man you took the helm in troubled times with a message of unity, it chimes. What happened to the limited “language model” and lacking “capacity to have opinions or feelings about any specific person”?\nPeople are becoming accustomed to accepting answers from “Google” or ChatGPT for everything from computer programming to history to designer cocktails. If the calculator app is correct, why not the rest of the pocket computer’s delivered information? ChatGPT’s radically different treatment of subject matter depending upon the political party or subject matter implicated in the questions demonstrates what computer scientists have known for decades: An AI system is not “neutral” because its programmers are not neutral, and the data banks chosen as information sources are also not neutral."},"highlights/Matter/We-Don’t-Need-a-New-Twitter":{"title":"We Don’t Need a New Twitter","links":[],"tags":[],"content":"Highlights\nThe result is a Faustian bargain for our networked era: trusting the wisdom of crowds to identify what’s interesting can create an intensely compelling stream of shared content, but this content is likely to arrive drenched in rancor."},"highlights/Matter/We-come-to-bury-ChatGPT,-not-to-praise-it.":{"title":"We come to bury ChatGPT, not to praise it.","links":[],"tags":[],"content":"Highlights\nthe concept of AGI is inseparable from the kind of hierarchy of intelligence that has underpinned ideas of innate supremacy since the days of empire and colonialism. Hardly surprising, then, that the same Silicon Valley cultures that incubate enthusiasm for ChatGPT as emergent AGI also show allegiance to associated world views like Long Termism, where the immediate vulnerability of millions of ordinary people counts as nothing in relation to the prospects of a future space-faring super race.\nContemporary AI, as I argue in my book, is an assemblage for automatising administrative violence and amplifying austerity. ChatGPT is a part of a reality distortion field that obscures the underlying extractivism and diverts us into asking the wrong questions and worrying about the wrong things. Instead of expressing wonder, we should be asking whether it’s justifiable to burn energy at “eye watering” rates to power the world’s largest bullshit machine.\nThe compulsion to show ‘balance’ by always referring to AI’s alleged potential for good should be dropped by acknowledging that the social benefits are still speculative while the harms have been empirically demonstrated. Saying, as the OpenAI CEO does, that we are all ‘stochastic parrots’ like large language models, statistical generators of learned patterns that express nothing deeper, is a form of nihilism. Of course, the elites don’t apply that to themselves, just to the rest of us. The structural injustices and supremacist perspectives layered into AI put it firmly on the path of eugenicist solutions to social problems."},"highlights/Matter/We're-seeing-multiple-folks-in--NLProc-who--sho...":{"title":"We're seeing multiple folks in -NLProc who -sho...","links":[],"tags":[],"content":"Highlights\n7- As a second bare minimum baseline, why would you use a trained model with no transparency into its training data?\n3- It breaks the web of citations: If ChatGPT comes up with something that you wouldn’t have thought of but you recognize as a good idea … and it came from someone else’s writing in ChatGPT’s training data, how are you going to trace that &amp; give proper credit?"},"highlights/Matter/What-ChatGPT’s-“iPhone-Moment”-Looks-Like":{"title":"What ChatGPT’s “iPhone Moment” Looks Like","links":[],"tags":[],"content":"Highlights\nIt’s growing smarter as time goes by, and it’s still nowhere near OpenAI’s goal to create A.I. on par with human intelligence. So as companies build on it, the underlying A.I. may grow capable of replicating their capabilities, potentially rendering them obsolete."},"highlights/Matter/What-Do-We-Mean-When-We-Talk-About-“AI-Democratisation”-":{"title":"What Do We Mean When We Talk About “AI Democratisation”-","links":[],"tags":[],"content":"Highlights\nWhen people speak about democratising some technology, they typically refer to democratising its use—that is, making it easier for a wide range of people to use the technology. For example the “democratisation of 3D printers” refers to how, over the last decade, 3D printers have become much more easily acquired, built, and operated by the general public.\nOverall, efforts to democratise AI use involve reducing the costs of acquiring and running AI tools and providing intuitive interfaces to facilitate human-AI interaction without the need for extensive training or technical knowhow.\nExcitement seems to primarily be about democratising AI development—that is, helping a wider range of people contribute to AI design and development processes.\nA third sense of “AI democratisation” refers to democratising AI benefits—which is about facilitating the broad and equitable distribution of benefits that accrue to communities that build, control, and adopt advanced AI capabilities.2 Discussion tends to focus on the redistribution profits generated by AI products.\nFinally, some discussions about AI democratisation refer to democratising AI governance. AI governance decisions often involve balancing AI-related risks and benefits to determine if, how, and by whom AI should be used, developed, and shared. The democratisation of AI governance is about distributing influence over these decisions to a wider community of stakeholders.\nFor the first three forms of democratisation discussed in this piece, “democratisation” is almost always used synonymously with “improving accessibility”. The democratisation of AI use is about making AI systems accessible for everyone to use. The democratisation of AI development is about making opportunities to participate in AI development widely accessible. The democratisation of AI benefits is mostly about distributing access to the wealth accrued through AI development, use, and control.\nHowever, importantly, the democratisation of AI governance involves the introduction of democratic processes.\nThe democratisation of AI governance needs to involve careful consideration about how diverse stakeholder interests and values can be effectively elicited and incorporated into well-reasoned AI governance decisions."},"highlights/Matter/What-Every-User-Should-Know-About-Mixed-Precision-Training-in-PyTorch":{"title":"What Every User Should Know About Mixed Precision Training in PyTorch","links":[],"tags":[],"content":"Highlights\nIf a network requires more precision it may need to use float16, and if a network requires more dynamic range it may need to use bfloat16, whose dynamic range is equal to that of float32. If overflows are observed, for example, then we suggest trying bfloat16."},"highlights/Matter/What-Google-Should-Really-Be-Worried-About":{"title":"What Google Should Really Be Worried About","links":[],"tags":[],"content":"Highlights\nLarge Language Models (like GPT-3, ChatGPT, Galactica, etc) could be used to produce a enormous numbers of marginal blogs and fake reviews to pump each other up, and increase the search rankings of fraudulent garbage—with a minimal amount of human effort. Why manually write cesspools of interconnected likes, when an LLM can do that job for you? LLMs aren’t very good at writing error free prose, but the people who run content farms won’t care about the errors. what used to be written laboriously by humans suddenly becomes cheap and hence more widespread."},"highlights/Matter/What-Is-a-Pig-Butchering-Scam-":{"title":"What Is a Pig Butchering Scam-","links":[],"tags":[],"content":"Highlights\nGovernment officials and researchers emphasize that public education is a key component of helping people avoid becoming the victim of a pig butchering scheme. If people know the telltale signs and understand the concepts underlying the scams, they are less likely to be ensnared. The challenge, they say, is reaching the wider public and getting people who learn about pig butchering to pass on the information to others in their families and social circles."},"highlights/Matter/What-Kind-of-Mind-Does-ChatGPT-Have-":{"title":"What Kind of Mind Does ChatGPT Have-","links":[],"tags":[],"content":"Highlights\nThis is why, if you read the Biblical-VCR case study carefully, you’ll soon realize that the advice given, though impressive in style, doesn’t actually solve the original problem very well. ChatGPT suggests sticking a knife between the sandwich and VCR, to “pry them apart.” Even a toddler can deduce that this technique won’t work well for something jammed inside a confined slot. The obvious solution would be to pull the sandwich out, but ChatGPT has no actual conception of what it’s talking about—no internal model of a stuck sandwich on which it can experiment with different strategies for removal. The A.I. is simply remixing and recombining existing writing that’s relevant to the prompt. Similar tells emerge in that clever “Seinfeld” script about the bubble-sort algorithm. Read it to the end, and you’ll discover characters spouting non sequiturs: Elaine, for no particular reason, orders chicken salad from a passing waiter, and this is described as causing “audience laughter.” ChatGPT doesn’t understand humor in any fundamental sense, because its neural networks have encoded only what a sitcom script is supposed to sound like."},"highlights/Matter/What-Makes-a-Senior-Engineer--Writing-Software-vs-Building-Systems":{"title":"What Makes a Senior Engineer- Writing Software vs Building Systems","links":[],"tags":[],"content":"Highlights\n* Defining Requirements - work with the Product Manager to understand what problem they want to solve; maybe you’ll have some ideas on how to solve it with much lower effort?"},"highlights/Matter/What-Students-Lose-by-Embracing-Easy-Tech-Like-ChatGPT":{"title":"What Students Lose by Embracing Easy Tech Like ChatGPT","links":[],"tags":[],"content":"Highlights\nDr. Anthony Bradley of The King’s College tweeted this a few days ago, Students are writing papers using AI. Colleges are scrambling to combat it. We should also talk about moral issues: what type of moral values does a student have who would use AI to produce a paper, and turn it in as their own work, without their conscience being seared?”\nWhen you get email, you lose the personal touch of a handwritten letter. When you get cell phones, you lose a chunk of in person communication. When you get Google Maps, you lose the freedom to get to Wal-Mart by yourself. If all this tech were to get stripped away, many of us would be reduced to helpless infants! When you get AI and ChatGPT, you don’t only lose the capacity to memorize, but to articulate, argue, express, and think. It also offers students a shortcut that bypasses honesty and maturity.\nDo you want to be the kind of person who depends so much on AI that you can’t think for yourself? What’s the point of a college education if a bot does your homework for you? And how will these choices affect your future habits as a spouse, employee, boss, and friend?\nHonesty matters in academia, largely because academic conduct says a lot about character and who a person will grow into over time. Handing yourself over to technological ease might feel like power and progress, but it is weakening minds and diminishing freedom—freedom to be the kind of people who can learn, know, and love without the aid of the machine."},"highlights/Matter/What-does-Meta-AI’s-Diplomacy-winning-Cicero-Mean-for-AI-":{"title":"What does Meta AI’s Diplomacy-winning Cicero Mean for AI-","links":[],"tags":[],"content":"Highlights\nThe first is that Cicero’s overall architecture Is not something that simply emerged spontaneously from the basic data, but it is rather an exquisitely engineered structure with many moving parts, laboriously worked out by a broad team of different types of AI experts, combining techniques from game theory with probabilistic analysis.\nis, to what extent do the techniques that have been used in Cicero generalize to other situations involving action and social interactions? What aspects of Cicero’s execution architecture, training architecture, or general methodological approach will be useful if we want to build an AI that is useful for some complex interaction with people outside the closed and limited world of Diplomacy?"},"highlights/Matter/What-if-you-never-sort-your-life-out-":{"title":"What if you never sort your life out-","links":[],"tags":[],"content":"Highlights\nI think virtually everyone, except perhaps the very Zen or very old, goes through life haunted to some degree by the feeling that this isn’t quite the real thing, not just yet – that soon enough, we’ll get everything in working order, get organised, get our personal issues resolved, but that till then we’re living what the great Swiss psychologist Marie-Louise von Franz called the “provisional life.” (“There is a strange feeling that one is not yet in real life. For the time being, one is doing this or that… [but] there is always the fantasy that sometime in the future the real thing will come about.“)\nOne antidote is to allow yourself to imagine what it might feel like to know you’d never fully get on top of your work, never become a really disciplined exerciser or healthy eater, never resolve the personal issue you feel defines your life’s troubles. What if I’ll always feel behind with my email? What if listening attentively to other people will always take the weird amount of effort it seems to take now? What if that annoying thing my partner does annoys me to the end of my days?\nIt turns out my really big problem was thinking I might one day get rid of all my problems, when the truth is that there’s no escaping the mucky, malodorous compost-heap of this reality. Which is OK, actually. Compost is the stuff that helps things grow. "},"highlights/Matter/What-in-the-World-Are-You-Doing-":{"title":"What in the World Are You Doing-","links":[],"tags":[],"content":"Highlights\nAnd the beauty of focusing on skills is that it’s never done. The old cliché is that we all set goals in January and give up on them by February. But if you focus on a skill, no matter how bad you are at it, you can still work on it in February, and March, on through the year."},"highlights/Matter/What-is-Art-Without-the-Human-Mind-":{"title":"What is Art Without the Human Mind-","links":[],"tags":[],"content":"Highlights\nThe idea that AI can match human artwork assumes that we are little to no different from machines. Info in, info out. Voila. But if we are not machines, but have minds capable of creativity, emotion, and storytelling, then AI can never replace us. The question is whether we will settle for the technical skill of the bots, or access our deeper longings for narrative, meaning, and connection."},"highlights/Matter/Why--is--Bing-so-reckless-":{"title":"Why -is- Bing so reckless-","links":[],"tags":[],"content":"Highlights\nThat’s especially scary for two reasons: first, the big companies are free to roll out new updates whenever they like, without or without warning, and second it means that they might need go on testing them on general public over and over again, with no idea in advance of empirical testing on the public for how well they work. We don’t handle new pharmaceuticals like that (we demand careful tests before they go out to the public) and we shouldn’t handle LLMs this way, either—especially if billions of people might use them and there are potentially serious risks (e.g to people’s mental health, or marital status).\nPolicy: the public has (or strictly speaking should insist on) a right to know what wrong here, with the Bing situation, so that we can create policy to keep incidents from happening like this again. Right now, as I have said before, the AI is basically the Wild West; anyone can post any chatbot they want. Not good. Congress needs to to find out what happened, and start placing some restrictions, especially where emotional or physical injury could easily result. Journalism: The media failed us here. I am particularly perturbed by Kevin Roose’s initial report, in which he said he was “awed” by Bing. Clearly, he had not poked hard enough; shouting out prematurely in The New York Times that there is a revolution without digging deep (or bothering to check in with skeptics like me, or the terrific but unrelated Mitchells, Margaret and Melanie) is not a good thing."},"highlights/Matter/Why-ChatGPT-Won’t-Replace-Google":{"title":"Why ChatGPT Won’t Replace Google","links":[],"tags":[],"content":"Highlights\nWith Google, the algorithm eventually leads you to content made by real people. With ChatGPT, you never leave the algorithm\nBeing computers, neither Google nor ChatGPT cares about the truth. They are algorithms, and they merely do as they are told.\nGoogle eventually lets you out of its system.\nUltimately, Google points users to websites which are run by people who do care about the truth, while ChatGPT keeps you tied to the algorithm, which does not."},"highlights/Matter/Why-Effective-Altruism-and-“Longtermism”-Are-Toxic-Ideologies":{"title":"Why Effective Altruism and “Longtermism” Are Toxic Ideologies","links":[],"tags":[],"content":"Highlights\nThey’ve also argued quite vigorously that we should actively support sweatshop labor in the Global South because it turns out that the jobs in sweatshops are better than the alternative jobs that people have. And so, by supporting the sweatshops, you are supporting the best jobs, relatively speaking, that exist in various places.\nMuch of this is really about working within systems. There’s almost no serious thought within EA, at least not that I’ve seen, about the origins of many problems around the world. Origins being in systems of power, structures that have enabled the individuals in the Global South to end up being very destitute—there’s no discussion of the legacies of colonialism. It’s about working within systems.\nSo, there is a danger, that if people take longtermism seriously, by virtue of the bigness of the future, that will trump contemporary problems in every circumstance. I think climate change, for example, is probably not going to be an “existential” risk—as they would say, there’ll be some people left, and almost certainly not going to result in human extinction. One way it could is if there’s a runaway greenhouse effect, but the best science available right now suggests that’s very improbable. So, if you take this cosmic perspective on the human predicament, climate change shrinks to almost nothing. If we were to phase out fossil fuels in the 21st century, the effects would last for maybe 10,000 years. 10,000 years is a very long time. But that’s many generations of future humans who would be suffering the consequences of catastrophic climate change. But in the grand scheme of things—\nIt becomes an excuse for not caring about contemporary problems, and a moral justification for spending all your time just researching how to simulate human consciousness because once you can run simulations of human beings on the computer, you can just maximize the number of them that you make, your little fake people. And as long as you’re running them, you’re dwarfing any of the moral catastrophes that your actions are unleashing.\nIt also gives you cover to do destructive things in the name of creating this vast ultimate good. So not just not caring about contemporary problems, but making problems worse if they get us towards that glorious, long term utopian future.\nAnd he, I think, draws the correct conclusion from the premises of longtermism which is that if what matters most is how things go in the very far future, then you should prioritize saving the lives of people in rich countries over the lives of people in poor countries. And the reason is that rich countries have more economic productivity, innovation, and so on. And these are the things that will influence the very far future, not trying to help individuals who are struggling to eat three times a day to actually get those meals. So, this is an idea from the literature that underlines the potential danger. It underlines just how radical the longtermist view can be if it’s taken seriously.\nThere’s a certain arrogance and assumption that the people who have found the answers are entitled to impose them upon anyone else. And correspondingly, there is this belief that elites ought to rule, those who have discovered these morally optimal mathematical truths. You’ve even pointed out that eugenicist language flows through this movement—if you want to “optimize” human beings and to better the species, there can be some ugly possibilities that flow out of the internal logic held by those who adhere to this movement.\nSo, part of the longtermist arguments about why we should prioritize avoiding human extinction over things like alleviating global poverty—some of them have literally made this argument—rests on a certain philosophical view that among philosophers is highly contentious, and in my view, very implausible, that the non-birth of all these future people, including all these future digital people, would be some kind of really awful catastrophe. And again, by virtue of the numbers of these future people, you have a good longtermist argument for why you should not focus on contemporary issues so much. Instead, you should be focusing on them, including ensuring that they exist in the first place.\nAnd maximizing is never a good idea. I don’t think you should ever maximize—you should always get the right amount of things. Because maximization is what we might call cancer logic—a cancer maximizes itself. A cancer is a perfect example of, “let me produce as much of myself as possible.” Uncontrolled economic growth—that’s maximization logic. Don’t maximize; get the right amount!"},"highlights/Matter/Why-Elite-College-Admissions-Are-Biased-Toward-the-Superrich":{"title":"Why Elite College Admissions Are Biased Toward the Superrich","links":[],"tags":[],"content":"Highlights\nThat said basically, four students who have essentially the same SAT or ACT scores—so look at two applicants who have the same test scores—if an applicant is from a family from the top 1 percent of the income distribution, they’re more than twice as likely to be admitted as an applicant, again, with the same test scores, who’s from a middle-class family.\nBut the answer is yes, it actually is really worth it. Students who are admitted off the wait list to one of these schools, compared to students who are rejected off the wait list, are about 60 percent more likely to be in the top 1 percent of income at age 33 themselves. They’re twice as likely to be at a top 10 graduate school, and they’re about three times as likely to work for a prestigious firm in a variety of sectors. Think about top law firms, top consulting firms, research hospitals, prestigious universities, and so on. So it really does seem to make a difference, and that was surprising."},"highlights/Matter/Why-Google-Missed-ChatGPT":{"title":"Why Google Missed ChatGPT","links":[],"tags":[],"content":"Highlights\nFor Google, the problem with chatbots is they’re wrong a lot, yet present their answers with undeserved confidence. Leading people astray — with assuredness — is less than ideal for a company built on helping you find the right answers. So LaMDA remains in research mode.\nEven if chatbots were to fix their accuracy issues, Google would still have a business model problem to contend with. The company makes money when people click ads next to search results, and it’s awkward to fit ads into conversational replies. Imagine receiving a response and then immediately getting pitched to go somewhere else — it feels slimy, and unhelpful. Google thus has little incentive to move us beyond traditional search, at least not in a paradigm-shifting way, until it figures out how to make the money aspect work. In the meantime, it’ll stick with the less impressive Google Assistant.\n“There’s a reason why Clayton Christensen wrote The Innovator’s Dilemma. It’s a real dilemma,” said Box CEO Aaron Levie on Big Technology Podcast this week. “Google doesn’t inherently want you, at an inherent level, to just get the answer to every problem. Because that might reduce the need to go click around the web, which would then reduce the need for us to go to Google.”"},"highlights/Matter/Why-I-Don't-Care-if-Students-Use-GPT":{"title":"Why I Don't Care if Students Use GPT","links":[],"tags":[],"content":"Highlights\nFirst of all, I agree with those who claim that bans and regulations are not effective. There is no point in starting an arms race between students, professors, cheating-detectors, cheating-detector-circumventors, digital watermarking, watermark-erasers, and so forth.\nInstead, I propose a radical approach: Teachers shouldn’t worry very much about algorithms that can write, and instead spend a significant amount of time explaining to students why they do not actually want to use GPT to write their essay for them. One reason is that there are many ethical issues with large language models.\nIn fact, they are guests in an academic version of WestWorld. Every semester, I spend part of my last lecture letting students in on the secret that we professors are nothing more than very realistic looking robots who pretend to need them to solve problems we secretly already have the solution for. We pose questions and ask for their best work, but in reality already have the answers and have done the work ourselves. And the whole thing is constructed in semester-long narrative arcs that do a complete scene-reset once the quests are completed, and a new train full of guests arrive at the same exact narrative point where the last one was a year ago.\nThe answer is perhaps obvious: learning. Amidst the daily discussion about assignments, projects, grades, and credits, students can easily forget that the only useful outcome of all the hard work that goes into a semester (theirs and ours) is knowledge gained by students. At WestWorld, guests really feel like they are solving life-or-death problems. In reality, they are merely collecting high-end vacation experiences. Similarly, and this is hard to remember when you are stuck on a problem set: You are not trying to solve a differential equation; you are trying to learn.\nBut anyone who writes for a living knows that in many ways writing is thinking. The process of translating vague ideas into a coherent text helps structure ideas and make connections. The time spent editing and re-editing weeds out important ideas from marginal ones. The effort to address an imaginary reader, to clarify things to them, helps eliminate unnecessary style decisions. Finding your own voice helps you understand yourself and your contribution to the world better. Letting an AI system do this work for you means giving up all of that. It’s like sending a robot to do your WestWorld vacation for you, and just sharing the photos it took on your Instagram feed. Behaving in this way is not at all about cheating, it is about missing the whole point. If you care about having clear ideas and becoming better at what you do, you want to be writing.\nOur role as educators is to remind our students of WestWorld; ask them to step out of the client-supplier narrative; remind them that they are doing this only for themselves and that even if you have the best job in the world, it won’t make you feel accomplished and won’t give you the same satisfaction as being able to have clear thoughts, ideas, and opinions. And at the end of the day you still have to go to sleep with your own thoughts, ideas, and opinions. Unless, of course, you fall asleep in the Metaverse."},"highlights/Matter/Why-It's-So-Hard-to-Avoid--and--How-to-Prevent-It-Anyway":{"title":"Why It's So Hard to Avoid & How to Prevent It Anyway","links":[],"tags":[],"content":"Highlights\nyou also paid an attention tax in lost time and productivity that’s no less real but much more difficult to quantify.\nInterruptions aren’t just external. We’re actually just as likely to interrupt ourselves as we are to be interrupted.\nIn The Shallows: What the Internet is Doing to Our Brains, Nicholas Carr explains how our brain, through neuroplasticity, adapts in response to changes in our environment, like technology innovations, which means we gain and lose certain skills. Social media, email, and team communications tools stimulate our very human desire to want to connect with people and access novel information but diminish the focus and processing skills that our literacy culture of books and newspapers built up.\n“[E]ach interruption brings us a valuable piece of information… And so we ask the Internet to keep interrupting us, in ever more and different ways. We willingly accept the loss of concentration and focus, the division of our attention and the fragmentation of our thoughts, in return for the wealth of compelling or at least diverting information we receive.”\nWhen we context switch, our brains receive multiple stimuli at once. This leads to a “response selection bottleneck” that slows thought and decision-making. Upon returning to a task after a distraction, it can take up to 23 minutes to re-focus. Even “brief mental blocks” as a result of switching can take as much as 40% of a person’s productive time.\nWe can hold between 3 and 7 pieces of information at a time. By flooding us with new information, context switching takes away the brain space we need to retain and process the information we were already dealing with.\nWith diminished capacity to step back, strategize, and focus on higher priorities, we default to working on more immediate, low-value tasks, like responding to emails as they come in. We also revert to “survival mode,” where our instinct is to compensate for our stress by accomplishing something — anything. However, in our depleted capacity we go for the low-hanging fruit — again, those emails, which we can easily send — instead of writing a report, or reading an article, which takes more time and thought.\nfinishing work earlier so it doesn’t bleed into our leisure time, putting us into the zone of deep work or flow that allows us to do our best work, and bringing ourselves just a bit more calm in a noisy world. Here are nine concrete strategies to incorporate into your day:\nHowever, when your priorities aren’t clear, deciding what to do can become its own distraction. Get clear on what’s important to you with a go-to framework you can apply over and over again to decide what to focus on.\nSocial beats solo. Research in South Korean workplaces shows that social breaks — talking with coworkers about something other than work — are more effective at reducing stress and improving mood than either cognitive breaks (answering e-mail) or nutrition breaks (getting a snack).\nTry to focus on one task, screen, app, and window at a time, and eliminate what causes you to switch contexts in the first place — the buzzes and screen notifications and excess tabs in your web browser:\nIt’s a natural impulse to want to respond to things as soon as they come in. You don’t want to hold things up, and it feels good to have one less message in the inbox. But you may be sending a message that people should always expect a quick response from you, which can lead to getting more emails and more context switches. \nWhile it may feel like a matter of personal failing, all of us living and working in digital environments and interruption-heavy work cultures experience it, especially those working from home and caring for children or other family members right now."},"highlights/Matter/Why-Open-Source-Matters":{"title":"Why Open Source Matters","links":[],"tags":[],"content":"Highlights\n* First, developers don’t care about the definition because they don’t have to, and the reason they don’t have to is because of said definition. Developers don’t have to worry, among other concerns, about royalties or what size their user base is or what their revenues are when using open source software because the open source definition does not permit restrictions on use. Ironically, the very meaning of open source that developers imperil with their neglect is what has allowed open source to become what it is today.\n* Second, developers caring about something is, as has been argued here previously, meaningful and important. This does not imply that the reverse is true, however. Developers don’t care because they don’t have to, as stated above, and also because their focus is, quite understandably, myopic. They worry about the software they’re directly using and working on that day, not the wider implications of a licensing shift over the long term from an industry perspective, because they get paid for the former and not the latter. That does not mean, however, that the latter is unimportant. Arguing that the definition of open source doesn’t matter because developers don’t care about it is like arguing that climate change doesn’t matter because citizens don’t care.\nFor whatever the reason, they stop short of asking the question of what happens when the behavior is common, or contemplating what a world with a compromised definition of open\nWhen vendors willfully and knowingly apply the open source term to code that is open but carries some restrictions that the currently accepted definition of open source would not permit, what they’re implicitly asking for is the marketing bump from open source with the exclusivity of a proprietary software model.\nA world in which non-compete licensing grows at the expense of open source is problematic enough. A world in which vendors blur the definition of open source such that regular users can no longer differentiate between the two is much, much worse."},"highlights/Matter/Why-We-Should-Not-Trust-Chatbots-As-Sources-of-Information":{"title":"Why We Should Not Trust Chatbots As Sources of Information","links":[],"tags":[],"content":"Highlights\nThe result is systems that can produce text that is very compelling when we as humans make sense of it. But the systems do not have any understanding of what they are producing, any communicative intent, any model of the world, or any ability to be accountable for the truth of what they are saying.\nBut the extracts the chatbot grabs from vast troves and arranges according to rules of syntax are not the result of an intelligent process. No one is in charge of it — unless, of course, there is a human in the loop, listening in. But then the session with the chatbot is no longer an interaction with a supercomputer alone.\nThere will never be an all-inclusive fully correct set of information that represents everything we could need to know. And even if you might hope that could come to pass, it should be very clear that today’s World Wide Web isn’t it. When people seek information, we might think we have a question and we are looking for the answer, but more often than not, we benefit more from engaging in sense-making: refining our question, looking at possible answers, understanding the sources those answers come from and what perspectives they represent, etc.\nTo the Centers for Disease Control, for example, information about myocarditis as an outcome of the vaccine against COVID-19 was long treated as “misinformation.” But the agency now admits that the concerns are legitimate. Thus, if the information seeker is in a risk category for myocarditis, even government agencies may not have been providing a picture that allows for risk assessment. We must often take the risk of searching in a variety of places for answers that meet a need.\n“It is urgent that we recognize that an overlay of apparent fluency does not, despite appearances, entail accuracy, informational value, or trustworthiness”"},"highlights/Matter/Why-are-so-many-tech-companies-laying-people-off-right-now-":{"title":"Why are so many tech companies laying people off right now-","links":[],"tags":[],"content":"Highlights\nThe literature on whether layoffs actually work to boost stock price is mixed: in one study, companies that closed plants and did layoffs had better returns than companies that only did layoffs. During the 2020 coronavirus pandemic, layoffs had no effect on stock prices at all. Layoffs do have one concrete impact. Pfeffer’s research has found that layoffs literally kill people — by increasing the risk that someone will die by suicide and by levering up stress, both among people laid off and among those who remain. Layoffs may also reduce productivity among those who remain employed. So why do layoffs at all if they don’t actually work? “People do all kinds of stupid things all the time,” Pfeffer says. “I don’t know why you’d expect managers to be any different.”"},"highlights/Matter/Why-it’s-easy-to-Brainwash-ChatGPT-(OpenAI-series,-Part-2)":{"title":"Why it’s easy to Brainwash ChatGPT (OpenAI series, Part 2)","links":[],"tags":[],"content":"Highlights\nIt’s very human to think in terms of narratives or frameworks, and when there are contradictory ideas in those frameworks, most people experience some kind of cognitive dissonance. GPT, or other ML models, do not experience this resistance. In some cases, this is preferable. It’s much more able to summarize a wide array of differing perspectives on the same topic in a way that very few humans are able to."},"highlights/Matter/Will-A.I.-Become-the-New-McKinsey-":{"title":"Will A.I. Become the New McKinsey?","links":[],"tags":[],"content":"Will A.I. Become the New McKinsey?\nHighlights\nIn a similar way, Purdue Pharma used McKinsey to figure out how to “turbocharge” sales of OxyContin during the opioid epidemic. Just as A.I. promises to offer managers a cheap replacement for human workers, so McKinsey and similar firms helped normalize the practice of mass layoffs as a way of increasing stock prices and executive compensation, contributing to the destruction of the middle class in America.\nby hiring consultants, management can say that they were just following independent, expert advice. Even in its current rudimentary form, A.I. has become a way for a company to evade responsibility by saying that it’s just doing what “the algorithm” says, even though it was the company that commissioned the algorithm in the first place.\nThe reality is that Fortune 100 companies will hire McKinsey instead of your pro-social firm, because McKinsey’s solutions will increase shareholder value more than your firm’s solutions will. It will always be possible to build A.I. that pursues shareholder value above all else, and most companies will prefer to use that A.I. instead of one constrained by your principles.\nIf we cannot come up with ways for A.I. to reduce the concentration of wealth, then I’d say it’s hard to argue that A.I. is a neutral technology, let alone a beneficial one.\nI don’t know how deeply Sarandon had thought this through, but the Slovenian philosopher Slavoj Žižek said the same thing, and I’m pretty sure he had given a lot of thought to the matter. He argued that Trump’s election would be such a shock to the system that it would bring about change. What Žižek advocated for is an example of an idea in political philosophy known as accelerationism. There are a lot of different versions of accelerationism, but the common thread uniting left-wing accelerationists is the notion that the only way to make things better is to make things worse. Accelerationism says that it’s futile to try to oppose or reform capitalism; instead, we have to exacerbate capitalism’s worst tendencies until the entire system breaks down. The only way to move beyond capitalism is to stomp on the gas pedal of neoliberalism until the engine explodes.\nIt’s A.I.-supercharged corporations destroying the environment and the working class in their pursuit of shareholder value. Capitalism is the machine that will do whatever it takes to prevent us from turning it off, and the most successful weapon in its arsenal has been its campaign to prevent us from considering any alternatives.\nBut what does progress even mean, if it doesn’t include better lives for people who work? What is the point of greater efficiency, if the money being saved isn’t going anywhere except into shareholders’ bank accounts? We should all strive to be Luddites, because we should all be more concerned with economic justice than with increasing the private accumulation of capital. We need to be able to criticize harmful uses of technology—and those include uses that benefit shareholders over workers—without being described as opponents of technology."},"highlights/Matter/Willingness-to-look-stupid":{"title":"Willingness to look stupid","links":[],"tags":[],"content":"Highlights\nIn particular, it’s often the case that there’s a seemingly obvious but actually incorrect reason something is true, a slightly less obvious reason the thing seems untrue, and then a subtle and complex reason that the thing is actually true^2^. I would regularly figure out that the seemingly obvious reason was wrong and then ask a question to try to understand the subtler reason, which sounded stupid to someone who thought the seemingly obvious reason was correct or thought that the refutation to the obvious but incorrect reason meant that the thing was untrue.\nThe benefit from asking a stupid sounding question is small in most particular instances, but the compounding benefit over time is quite large and I’ve observed that people who are willing to ask dumb questions and think “stupid thoughts” end up understanding things much more deeply over time. Conversely, when I look at people who have a very deep understanding of topics, many of them frequently ask naive sounding questions and continue to apply one of the techniques that got them a deep understanding in the first place.\nI got pretty good at the game^3^ and my “one weird trick” was to think about what went wrong every time something went wrong and then try to improve. But most people seemed more interested in making an excuse to avoid looking stupid (or maybe feeling stupid) in the moment than actually improving, which, of course, resulted in them having many more moments where they looked stupid in the game.\nI see that most people would choose to do the wrong thing to avoid potentially looking stupid to people who are incompetent. I see the logic, but I think that it’s self-sabotaging to behave that way and that the gains to my career for standing up for what I believe are the right thing have been so large that, even if the next ten times I do so, I get unlucky and it doesn’t work out, that still won’t erase the gains I’ve made from having done the right thing many times in the past\n* When I was pretty young, I think before I was a teenager, I noticed that this happened when I learned things that were hard for me and tried to think of this feeling as “the feeling of learning something” instead of “feeling dumb”, which half worked (I now associate that feeling with the former as well as the latter)\nBut if you’re thinking about ideas that most people consider too stupid to consider, you’ll often run into ideas that are both very high ROI as well as simple and easy that anyone could’ve done had they not dismissed the idea out of hand. It may still technically be true that you need to have better execution than anyone else who’s trying the same thing, but if no one else trying the same thing, that’s easy to do!\nFor example, if a date thinks I’m stupid because I ask them what a word means, so much so that they show it in their facial expression and/or tone of voice, I think it’s pretty unlikely that we’re compatible, so I view finding that out sooner rather than later as upside and not downside.\nbut there’s a difference between feeling like you’re taking big risks and taking big risks, e.g., when asked, someone I know who is among the most conservative people I know thinks that they take a lot of big risks and names things like sometimes jaywalking as risk that they take.\nInstead, most people reflexively reject the idea without really engaging with it at all and (I’m guessing) the same thing happens inside their heads when a potentially stupid sounding thought might occur to them. I think the danger here is not having a concious process that lets you decide to broadcast or not broadcast stupid sounding thoughts (that seems great if it’s low overhead), and instead it’s having some non-concious process automatically reject thinking about stupid sounding things."},"highlights/Matter/Writing-for-Engineers":{"title":"Writing for Engineers","links":[],"tags":[],"content":"Highlights\nHave something to say\nThe goal of writing is to deliver a message to an audience in an effective way.\nIf you don’t have a clear message in your head, your are not ready to start writing a narrative yet.\nIn fact, writing is a great test to see if you have a good understanding of a topic, and have a firm grasp on the vocabulary of the domain.\nWriting is god’s way to show you how imperfect your thoughts are.\nAn argument is only half as good once you are uttering it.\nThe better you know and understand your audience the easier it will be to reach the goal of delivering a message to them.\nWhen writing an article, I generally visualize a concrete person as representative of the audience, that I am directing this text towards.\nPrepare for a writing task, like you would for a hike. You are in for a grind. Find a comfortable space to sit. Grab a beverage/snack of your preference. Most importantly make sure that you are rested and able to focus.\nIf you have loaded a lot of useful context in your brain at any given point in time, use this context to do something useful with it. Try to milk that moment, and make space when you realize you are in a position to write effectively on your topic.\nConversely, if you don’t have the context in your brain right now, you have two options (1) don’t write or (2) start loading the context into your brain.\nGood ways to load some context are: 1. Go through your notes that you took about the topic. 2. Discuss the topic with a coworker / random stranger / family member. 3. Read some books / blogs / papers on the topic.\nA outline should be the first milestone for any larger document you are writing. The outline, should convey the main message and provide a clear “red thread” that guides your reader through your argument.\nThe first milestone for your document is an outline. Everything that is not directly contributing to this goal is a distraction.\nthe second milestone is a fully fleshed out text, where all notes have been converted to paragraphs.\nIf you want your voice to be heard (and also improve the usability of your text) you have to design your document for “skim-ability”.\nSection Headings and Lists are the key anchor points you want to use to reach this goal. Also Figures, Quotes and Highlights are features that stand out and grab attention while skimming.\nGenerally, I would recommend to start working on summary sections (like Abstract/Conclusion) last, since only then will you be certain what your document actually covers.\nThe only way to improve your writing is by writing. As with practice in general, valuing quantity over quality is generally a good idea.\nOnce you have constructed an outline and polished the story-line you are at a great place to get initial feedback on your document. This allows you to uncover flaws in your story-line early, and make sure you are on-target with the content.\nOnce you fleshed out the content, and did a first editing pass removing the most glaring grammar and spelling mistakes, you are at a good point to sent the document to a few selected members of the target audience. This practice has three benefits: 1. You will get a pair of fresh eyes on the text that will at the very least catch a few grammar quirks that remained in the text. 2. You take a break from working on the text yourself, until you received the feedback, allowing yourself to take a fresh look at your writing. 3. You have an excuse to reach out to old friends that you had neglected for far too long."},"highlights/Matter/Writing-is-Like-Entering-a-Huge-Country--How-I-Found-My-Way":{"title":"Writing is Like Entering a Huge Country- How I Found My Way","links":[],"tags":[],"content":"Highlights\nLearning what writers value in their writing lives and what sparked particular pieces of their writing and studying the craft in a hands-on way in writers’ workshops helped me pay attention to my own processes and gain confidence. It helped me realize many of the same things happened to me as I wrote. It helped me learn that when we start a piece of writing we don’t know all we will know when we finish it.\nFor me, setting about to write anything is like learning how to visit a foreign country. I feel more comfortable now knowing there is much I have yet to learn. I find surprises and new roads and bridges, meadows and mountains to navigate. The country of creative writing is an exciting one every time I visit, demanding I start off not knowing so I can end up richer with the knowledge I didn’t have before I wrote. It is my favorite country to visit, and I go there as often as I can."},"highlights/Matter/Yes,-you-can-measure-software-developer-productivity":{"title":"Yes, you can measure software developer productivity","links":[],"tags":[],"content":"Highlights\nThe first is DORA metrics, named for Google’s DevOps research and assessment team. These are the closest the tech sector has to a standard, and they are great at measuring outcomes. When a DORA metric returns a subpar outcome, it is a signal to investigate what has gone wrong, which can often involve protracted sleuthing. For example, if a metric such as deployment frequency increases or decreases, there can be multiple causes. Determining what they are and how to resolve them is often not straightforward.\nThe second set of industry-developed measurements is SPACE metrics (satisfaction and well-being, performance, activity, communication and collaboration, and efficiency and flow), which GitHub and Microsoft Research developed to augment DORA metrics. By adopting an individual lens, particularly around developer well-being, SPACE metrics are great at clarifying whether an engineering organization is optimized. For example, an increase in interruptions that developers experience indicates a need for optimization.\nThe Developer Velocity Index (DVI) is a survey that measures an enterprise’s technology, working practices, and organizational enablement and benchmarks them against peers. This comparison helps unearth specific areas of opportunity, whether in backlog management, testing, or security and compliance.\nAssessing contributions by individuals to a team’s backlog (starting with data from backlog management tools such as Jira, and normalizing data using a proprietary algorithm to account for nuances) can help surface trends that inhibit the optimization of that team’s capacity.\nIn response, the company changed its operating model and clarified roles and responsibilities to enable those highest-value developers to do what they do best: code. Another company, after discovering relatively low contribution from developers new to the organization, reexamined their onboarding and personal mentorship program."},"highlights/Matter/You-Are-Not-a-Parrot":{"title":"You Are Not a Parrot","links":[],"tags":[],"content":"Highlights\nThen there’s option two: “We could say, ‘Hey, look, this is technology that really encourages people to interpret it as if there were an agent in there with ideas and thoughts and credibility and stuff like that.’” Why is the tech designed like this? Why try to make users believe the bot has intention, that it’s like us?\n“We call on the field to recognize that applications that aim to believably mimic humans bring risk of extreme harms,” she co-wrote in 2021. “Work on synthetic human behavior is a bright line in ethical Al development, where downstream effects need to be understood and modeled in order to block foreseeable harm to society and different social groups.”\nthat language, as Bender put it, is built on “people speaking to each other, working together to achieve a joint understanding. It’s a human-human interaction.”\nBender remains particularly fond of an alternative name for AI proposed by a former member of the Italian Parliament: “Systematic Approaches to Learning Algorithms and Machine Inferences.” Then people would be out here asking, “Is this SALAMI intelligent? Can this SALAMI write a novel? Does this SALAMI deserve human rights?”\nThe filtering leads to its own issues. If you remove content with words about sex, you lose content of in-groups talking with one another about those things.\nshe said. “People want to believe so badly that these language models are actually intelligent that they’re willing to take themselves as a point of reference and devalue that to match what the language model can do.”\nManning is invested in the project, literally, through the venture fund. Bender has no financial stake. Without one, it’s easier to urge slow, careful deliberation, before launching products. It’s easier to ask how this technology will impact people and in what way those impacts might be bad. “I feel like there’s too much effort trying to create autonomous machines,” Bender said, “rather than trying to create machines that are useful tools for humans.”\nOthers, like Dennett, the philosopher of mind, are even more blunt. We can’t live in a world with what he calls “counterfeit people.” “Counterfeit money has been seen as vandalism against society ever since money has existed,” he said. “Punishments included the death penalty and being drawn and quartered. Counterfeit people is at least as serious.”\nWe need strict liability for the technology’s creators, Dennett argues: “They should be held accountable. They should be sued. They should be put on record that if something they make is used to make counterfeit people, they will be held responsible. They’re on the verge, if they haven’t already done it, of creating very serious weapons of destruction against the stability and security of society. They should take that as seriously as the molecular biologists have taken the prospect of biological warfare or the atomic physicists have taken nuclear war.”\nWe can’t have people eager to separate “human, the biological category, from a person or a unit worthy of moral respect.” Because then we have a world in which grown men, sipping tea, posit thought experiments about raping talking sex dolls, thinking that maybe you are one too."},"highlights/Matter/You-Can’t-Simply-Decide-to-Be-a-Different-Person":{"title":"You Can’t Simply Decide to Be a Different Person","links":[],"tags":[],"content":"Highlights\n“People who have high trait self-control, they don’t actually engage in more restraint of their behavior and thoughts and emotions in the moment,” he said. Instead, they just aren’t tempted or distracted or diverted from their purpose as often or as effectively as the rest of us.\nIf you want people to behave differently en masse, you’re going to have to change—to improve—the circumstances in which a lot of them live."},"highlights/Matter/You-Should-Compile-Your-Python-And-Here’s-Why":{"title":"You Should Compile Your Python And Here’s Why","links":[],"tags":[],"content":"Highlights\nMaintaining good performance is part of your software’s development lifecycle, not just a thing you do once and stop."},"highlights/Matter/You-Too,-Snapchat--Another-AI-Bot-Hits-the-Scene":{"title":"You Too, Snapchat- Another AI Bot Hits the Scene","links":[],"tags":[],"content":"Highlights\nIt’s a fatal flaw to think that just because a certain kind of tech is in vogue and impressive that it should be used across the board. The AI craze needs to be tempered by the sound judgment of people who actually care about customers, especially when those customers are kids, as Fowler notes."},"highlights/Matter/You're-not-uncool.-Making-friends-as-an-adult-is-just-hard":{"title":"You're not uncool. Making friends as an adult is just hard","links":[],"tags":[],"content":"Highlights\nBut somewhere along the long, winding road to adulthood, making new friends became an impossibly hard thing to do.\n“Researchers also find that when we develop groups, our friendships are more sustainable than they are with individuals. Because there’s multiple touch points now, right? Someone else in the group could reach out to all of us, and then we all keep in touch,” she notes. If that sounds terrifying to you, Franco says it’s crucial to assume that people already like you. Assume any meet ups will go well, she says, which in turn will help build up your confidence.\n“You’re on your phone, you’re waiting for people to come to you, you’re not introducing yourself to people,” she says. “It’s not just that you have to attend that event, but you have to overcome covert avoidance by engaging with people when you get there.” It’s essential to take the extra step and ask for contact information.\n“If you are in a place of loneliness, you are, according to the research, more likely to assume people are going to reject you,” Franco explains. “You’re just sort of hyper vigilant for rejection and social threats. You’re more likely to think that social interactions will be more negative and less enjoyable.” That’s why she says it’s of the utmost importance for people like Troxel to keep putting themselves out there."},"highlights/Matter/Your-brain-does-not-process-information-and-it-is-not-a-computer":{"title":"Your brain does not process information and it is not a computer","links":[],"tags":[],"content":"Highlights\nSenses, reflexes and learning mechanisms – this is what we start with, and it is quite a lot, when you think about it.\nBut here is what we are not born with: information, data, rules, software, knowledge, lexicons, representations, algorithms, programs, models, memories, images, processors, subroutines, encoders, decoders, symbols, or buffers – design elements that allow digital computers to behave somewhat intelligently. Not only are we not born with such things, we also don’t develop them – ever.\nSetting aside the formal language, the idea that humans must be information processors just because computers are information processors is just plain silly,"},"highlights/Matter/‘A-certain-danger-lurks-there’--how-the-inventor-of-the-first-chatbot-turned-against-AI":{"title":"‘A certain danger lurks there’- how the inventor of the first chatbot turned against AI","links":[],"tags":[],"content":"Highlights\nEarly in his career, Sigmund Freud noticed that his patients kept falling in love with him. It wasn’t because he was exceptionally charming or good-looking, he concluded. Instead, something more interesting was going on: transference. Briefly, transference refers to our tendency to project feelings about someone from our past on to someone in our present. While it is amplified by being in psychoanalysis, it is a feature of all relationships. When we interact with other people, we always bring a group of ghosts to the encounter. The residue of our earlier life, and above all our childhood, is the screen through which we see one another.\nThis concept helps make sense of people’s reactions to Eliza. Weizenbaum had stumbled across the computerised version of transference, with people attributing understanding, empathy and other human characteristics to software. While he never used the term himself, he had a long history with psychoanalysis that clearly informed how he interpreted what would come to be called the “Eliza effect”.\nThere is so much in Weizenbaum’s thinking that is urgently relevant now. Perhaps his most fundamental heresy was the belief that the computer revolution, which Weizenbaum not only lived through but centrally participated in, was actually a counter-revolution. It strengthened repressive power structures instead of upending them. It constricted rather than enlarged our humanity, prompting people to think of themselves as little more than machines. By ceding so many decisions to computers, he thought, we had created a world that was more unequal and less rational, in which the richness of human reason had been flattened into the senseless routines of code.\nIn his school’s metalworking class, he learned to operate a lathe. The experience brought him out of his brain and into his body. About 70 years later, he looked back on the realisation prompted by this new skill: that intelligence “isn’t just in the head but also in the arm, in the wrist, in the hand”. Thus, at a young age, two concepts were in place that would later steer his career as a practitioner and critic of AI: on the one hand, an appreciation for the pleasures of abstraction; on the other, a suspicion of those pleasures as escapist, and a related understanding that human intelligence exists in the whole person and not in any one part.\nIn Weizenbaum’s 1967 follow-up to his first article about Eliza, he argued that no computer could ever fully understand a human being. Then he went one step further: no human being could ever fully understand another human being. Everyone is formed by a unique collection of life experiences that we carry around with us, he argued, and this inheritance places limits on our ability to comprehend one another. We can use language to communicate, but the same words conjure different associations for different people – and some things can’t be communicated at all. “There is an ultimate privacy about each of us that absolutely precludes full communication of any of our ideas to the universe outside ourselves,” Weizenbaum wrote.\nEven in his original 1966 article, Weizenbaum had worried about the consequences of this phenomenon, warning that it might lead people to regard computers as possessing powers of “judgment” that are “deserving of credibility”. “A certain danger lurks there,” he wrote.\nWhy had people reacted so enthusiastically and so delusionally to the chatbot, especially those experts who should know better? Some psychiatrists had hailed Eliza as the first step toward automated psychotherapy; some computer scientists had celebrated it as a solution to the problem of writing software that understood language. Weizenbaum became convinced that these responses were “symptomatic of deeper problems” – problems that were linked in some way to the war in Vietnam.\nFor Weizenbaum, judgment involves choices that are guided by values. These values are acquired through the course of our life experience and are necessarily qualitative: they cannot be captured in code. Calculation, by contrast, is quantitative. It uses a technical calculus to arrive at a decision. Computers are only capable of calculation, not judgment. This is because they are not human, which is to say, they do not have a human history – they were not born to mothers, they did not have a childhood, they do not inhabit human bodies or possess a human psyche with a human unconscious – and so do not have the basis from which to form values. \nThis had especially destructive policy consequences. Powerful figures in government and business could outsource decisions to computer systems as a way to perpetuate certain practices while absolving themselves of responsibility. Just as the bomber pilot “is not responsible for burned children because he never sees their village”, Weizenbaum wrote, software afforded generals and executives a comparable degree of psychological distance from the suffering they caused.\nBut Weizenbaum was always less concerned by AI as a technology than by AI as an ideology – that is, in the belief that a computer can and should be made to do everything that a human being can do. This ideology is alive and well. It may even be stronger than it was in Weizenbaum’s day.\nWe should never “substitute a computer system for a human function that involves interpersonal respect, understanding and love”, he wrote in Computer Power and Human Reason. Living well with computers would mean putting them in their proper place: as aides to calculation, never judgment."},"highlights/Matter/“AI”-Hurts-Consumers-and-Workers----and-Isn’t-Intelligent":{"title":"“AI” Hurts Consumers and Workers -- and Isn’t Intelligent","links":[],"tags":[],"content":"Highlights\nBut these claims are unfounded hype. Instead, so-called labor-saving devices will enable regimes of austerity and profit-maximization, that is, a marked decline in social services and weakened regulation in emerging markets. Rather than meet societal obligations to invest in education and physical and mental care, AI’s advocates risk creating a two-tier system where artificial facsimiles will be deemed good enough for those without means—but the well-to-do will hire actual humans. The flimsiness of their fantasy becomes clearer when one actually tries to imagine AI models excelling at the labor at the heart of our societies: carework, agriculture, and infrastructure repair and management."},"highlights/Matter/“Ensuring-Safe,-Secure,-and-Trustworthy-AI”--What-those-seven-companies-avoided-committing-to":{"title":"“Ensuring Safe, Secure, and Trustworthy AI”- What those seven companies avoided committing to","links":[],"tags":[],"content":"Highlights\nDocumentation empowers us to ask questions, including: * Procurers: Is this system appropriate for the users I anticipate will interact with it? * Policymakers: Are rights respected in the development and deployment of systems? * Community activists: What patterns are being reproduced which adversely affect my community?\nFirst, the commitments only address “audio and visual” content, with exactly zero mention of synthetic text. When OpenAI set up the easy interface to ChatGPT, when Meta briefly provided an interface to Galactica (misleadingly billed as way to access scientific knowledge), when Microsoft and Google incorporated chatbots into their search interfaces, they created the equivalent of an oil spill into our information ecosystem. Anyone can go at any time to one of these sources (except Galactica, which was taken down) and produce seemingly authoritative text in the style of their choice. They can then easily post this text on the internet where others might turn it up without knowing its origin.\nThe reason I make the analogy to oil spills is that this isn’t just about the harms to the person who initially receives the information. There are systemic risks as well: the more polluted our information ecosystem becomes with synthetic text, the harder it will be to find trustworthy sources of information and the harder it will be to trust them when we’ve found them. Rich Felker makes this point well over on Mastodon in a thread on the importance of provenance, without which information is just words.\nSo yeah — this is weak sauce. The companies say they’ll try to mitigate some pollution down the road, but do not wish to do anything about the toxic waste they’re currently spewing.\nThis is fluff, it’s PR, and its inclusion in this document just underscores how it the commitments are really an exercise in marketing and an attempt to forestall meaningful regulation. We pinky promise to be good, now please go away while we continue to practice massive data theft while creating poorly engineered “everything machines” that can’t possibly be evaluated."},"highlights/Matter/“If-It-Sounds-Like-Sci-Fi,-It-Probably-Is”":{"title":"“If It Sounds Like Sci-Fi, It Probably Is”","links":[],"tags":[],"content":"Highlights\nIf we focus on them as autonomous thinking entities or we spin out that fantasy, it is easier to lose track of the people in the picture, both the people who should be accountable for what the systems are doing and the people whose labor and data are being exploited to create them in the first place.\nSo, with ChatGPT, it’s the same thing. We are shaping our input to it so that we can make sense of what comes back from it. It’s all on our side.\nI don’t think it’s possible. I think it’s a fundamental design flaw or a fundamental mismatch between the technology and the task that it’s being promoted for. Certainly, over time it could be made better. There are certain kinds of errors that could be trained out through this human feedback step. But there was some recent reporting about gig workers who’ve been doing labeling work for Google in particular, and these gig workers were instructed to not actually fact-check the outputs, just whether it looks plausible or not. So that’s not very promising. You use the word “hallucinate,” and it’s true that people in the field use it. I object to that word because a hallucination involves the subjective experience of perceiving something that’s not there. And that’s not what’s happening. This is a mechanistic process of outputting sequences of words. If it corresponds to something that we read and say, “Yes, that checks out, that’s true,” that was actually by chance, not by design.\nIf what you’re looking at is ultimately the documents and the document set, then that is safer. If what you’re using them for is summarization or paraphrasing of what’s in the documents, then you’re still faced with a problem that these systems have not understood anything. They might be inaccurate less frequently in that context. But then you have to ask, is it actually better? I haven’t seen studies on this, but my guess is that a system like this, that’s right 95% of the time is more dangerous than one that’s right 50% of the time, because you come to trust it. Then you’re not going to catch that 5%.\nA bunch of the CNET stuff was effectively plagiarized too. If you’re doing this in a place where originality of content matters, then you can’t rely on synthetic media because you don’t know where it’s coming from. You can’t trace it back and give credit where credit is due.\nAnd so you can say, okay, what’s the task being automated, what’s the input, what’s the output? How was it trained? Where did that training data come from? How was it evaluated? How did that evaluation match the use case? If someone says this is right 95% of the time, well, 95% of what time? And how does that relate to how we’re talking about using it now? And then you can ask questions like who’s benefiting from automating this task? Who’s harmed by the fact of automation? Who’s harmed when it’s incorrect? Who benefits when it’s incorrect? Why are we doing this? Why would we automate that task? There’s a tweet I’ve seen various people put out, which is something like, you know, AI was supposed to do all the boring stuff so that we could live a life of leisure and write poetry and paint. So why are we creating systems to automate that kind of work? What’s that for?\nBut I think when we automate things, we should be doing good engineering practices and designing technology for particular use cases with an understanding of their social context. And I’m not seeing nearly enough of that in this space."},"highlights/Matter/🐌-You’re-not-really-that-busy":{"title":"🐌 You’re not really that busy","links":[],"tags":[],"content":"Highlights\nLet’s be real – you’re probably feeling the compounding effect of presenteeism. It’s the idea that your productivity and performance are enhanced by the fact that you’re physically present at work.\nA 2014 study from Stanford University proved that productivity per hour sharply declines when a person works more than 50 hours per week. After 55 hours of work per week, productivity was found to be essentially non-existent.\nBut self-awareness of when you’re actually busy versus when you feel you need to say you’re busy is vital."},"highlights/Omnivore/20240202223547":{"title":"AI Companies And Advocates Are Becoming More Cult-Like","links":[],"tags":[],"content":"AI Companies And Advocates Are Becoming More Cult-Like\nRead on Omnivore\nRead Original\nHighlights\n\nBut as I watched the hype cycle unfold, my mind wasn’t drawn to old memories of Apple keynotes or the shimmering excitement of the first dotcom boom. Instead, I thought about cults. Specifically, about a term first defined by psychologist Robert Lifton in his early writing on cult dynamics: “voluntary self-surrender.” This is what happens when people hand over their agency and the power to make decisions about their own lives to a guru.  ⤴️  \n\n\n“We believe the market economy is a discovery machine, a form of intelligence — an exploratory, evolutionary, adaptive system,” Andreessen writes.\nThis is the prism through which these capitalists see artificial intelligence. This is why they are choosing to bring AGI into being. All of the jobs lost, all of the incoherent flotsam choking our internet, all of the Amazon drop shippers using ChatGPT to write product descriptions, these are but the market expressing its will. Artists must be plagiarized and children presented with hours of procedurally generated slop and lies on YouTube so that we can, one day, reach the promised land: code that can outthink a human being. ⤴️  \n\n\nWhat we call AI lacks agency, the ability to make dynamic decisions of its own accord, choices that are “not purely reactive, not entirely determined by environmental conditions.” Midjourney can read a prompt and return with art it calculates will fit the criteria. Only a living artist can choose to seek out inspiration and technical knowledge, then produce the art that Midjourney digests and regurgitates. ⤴️  \n\n\nMy point is that the goals Andreessen and the e/acc crew champion right now are based in faith, not fact. The kind of faith that makes a man a murderer for doubting it. ⤴️  \n"},"highlights/Omnivore/20240202223554":{"title":"The Rise of Techno-authoritarianism - The Atlantic","links":[],"tags":[],"content":"The Rise of Techno-authoritarianism - The Atlantic\nRead on Omnivore\nRead Original\nHighlights\n\nThe behavior of these companies and the people who run them is often hypocritical, greedy, and status-obsessed. But underlying these venalities is something more dangerous, a clear and coherent ideology that is seldom called out for what it is: authoritarian technocracy. As the most powerful companies in Silicon Valley have matured, this ideology has only grown stronger, more self-righteous, more delusional, and—in the face of rising criticism—more aggrieved. ⤴️  \n\n\nThe new technocrats are ostentatious in their use of language that appeals to Enlightenment values—reason, progress, freedom—but in fact they are leading an antidemocratic, illiberal movement. Many of them profess unconditional support for free speech, but are vindictive toward those who say things that do not flatter them. They tend to hold eccentric beliefs: that technological progress of any kind is unreservedly and inherently good; that you should always build it, simply because you can; that frictionless information flow is the highest value regardless of the information’s quality; that privacy is an archaic concept; that we should welcome the day when machine intelligence surpasses our own. And above all, that their power should be unconstrained. The systems they’ve built or are building—to rewire communications, remake human social networks, insinuate artificial intelligence into daily life, and more—impose these beliefs on the population, which is neither consulted nor, usually, meaningfully informed. All this, and they still attempt to perpetuate the absurd myth that they are the swashbuckling underdogs. ⤴️  \n\n\nOpenAI, Microsoft, Google, and other corporations leading the way in AI development are not focusing on the areas of greatest public or epistemological need, and they are certainly not operating with any degree of transparency or caution. Instead they are engaged in a race to build faster and maximize profit. ⤴️  \n\n\nHe takes a reasonable position—that technology, on the whole, has dramatically improved human life—and warps it to reach the absurd conclusion that any attempt to restrain technological development under any circumstances is despicable. This position, if viewed uncynically, makes sense only as a religious conviction, and in practice it serves only to absolve him and the other Silicon Valley giants of any moral or civic duty to do anything but make new things that will enrich them, without consideration of the social costs, or of history. ⤴️  \n\n\n“Our enemy,” Andreessen writes, is “the know-it-all credentialed expert worldview, indulging in abstract theories, luxury beliefs, social engineering, disconnected from the real world, delusional, unelected, and unaccountable—playing God with everyone else’s lives, with total insulation from the consequences.”\nThe irony is that this description very closely fits Andreessen and other Silicon Valley elites. The world that they have brought into being over the past two decades is unquestionably a world of reckless social engineering, without consequence for its architects, who foist their own abstract theories and luxury beliefs on all of us. ⤴️  \n\n\nIn 1961, in his farewell address, President Dwight Eisenhower warned the nation about the dangers of a coming technocracy. “In holding scientific research and discovery in respect, as we should,” he said, “we must also be alert to the equal and opposite danger that public policy could itself become the captive of a scientific-technological elite. It is the task of statesmanship to mold, to balance, and to integrate these and other forces, new and old, within the principles of our democratic system—ever aiming toward the supreme goals of our free society.” ⤴️  \n\n\nTechnocrats are right that technology is a key to making the world better. But first we must describe the world as we wish it to be—the problems we wish to solve in the public interest, and in accordance with the values and rights that advance human dignity, equality, freedom, privacy, health, and happiness. And we must insist that the leaders of institutions that represent us—large and small—use technology in ways that reflect what is good for individuals and society, and not just what enriches technocrats. ⤴️  \n"},"highlights/Omnivore/20240202223601":{"title":"How to Quickly Get to the Important Truth Inside Any Privacy Policy – The Markup","links":[],"tags":[],"content":"How to Quickly Get to the Important Truth Inside Any Privacy Policy – The Markup\nRead on Omnivore\nRead Original\nHighlights\n\nBut the privacy policy is one of the only places where tech companies have to tell us the truth—the truth about what personal data they are collecting, how they share and profit from that data, and at a deeper level, what sort of trade we’re making when we choose to use their apps or platforms. ⤴️  \n\n\nPrivacy policies usually follow a predictable structure\n\n\nData Collection\n\n\nWhat specific types of data are being collected and how.\n\n\nData Sharing\n\n\nWhat data will be shared with third parties, and who those parties are.\n\n\nData Use\n\n\nHow your data is used. Could be for advertising, data enrichment, or for providing the service.\n\n\nData Management\n\n\nDetails related to data retention, transfers, security, and encryption. ⤴️  \n\n\nBe on the lookout for hints that the company uses a tracking technique called fingerprinting**,** which can identify you even when you go out of your way to decline cookies or block trackers. It does so based on information about your device such as the operating system, manufacturer, or even screen resolution, so keep an eye out for whether that data is being collected. ⤴️  \n\n\nCalli Schroeder, global privacy counsel at the Electronic Privacy Information Center (EPIC), said to take any examples provided in this section with a big lump of salt. “In many cases, the ‘for example’ will point out a relatively expected or benign use and distract from other more intrusive potential uses. Those other uses wouldn’t violate the Privacy Policy because they never claimed the example was the only use type,” explained Schroeder. ⤴️  \n\n\nBut look out for mentions of “business partners.” Do they combine or enrich your data with information collected from other “partners”? This is a red flag that you are being profiled. If you’re really lucky, you might find a policy that actually identifies some of those partners. (These could be advertising firms, data brokers, or affiliates.) And usually if another partner is listed, policies will inform you that you are also subject to the partners’ privacy policies, which it seems you are expected to read. It’s up to you to decide how far down the rabbit hole you want to go. ⤴️  \n\n\nWhen a company says it uses your data to “personalize” or “enhance” your experience or “improve our services,” that can often mean it is analyzing your data for ad targeting. ⤴️  \n\n\nDepending on where you live (and which privacy laws might apply to you), you may be able to request a copy of your data, correct your data, or ask for it to be deleted. You may even have the option to opt out of having your data shared or sold and still be able to use the service. ⤴️  \n\n\nWithin this section, look for portions that begin with “In the past 12 months,” as in, “In the past 12 months, we have collected the following categories of personal information, as described in the CCPA.” This particular “in the past 12 months” disclosure is really one of the clearest pieces of documentation about what a company is actually doing. ⤴️  \n\n\nWhat may be happening here is device fingerprinting. All of those signals taken together are unique enough to identify your device. This is a common approach companies have taken to get around ad blockers and other privacy-protecting technologies. ⤴️  \n"},"highlights/Omnivore/20240202223612":{"title":"The Art of Getting Promoted - by Rafa Páez","links":[],"tags":[],"content":"The Art of Getting Promoted - by Rafa Páez\nRead on Omnivore\nRead Original\nHighlights\n\nRemember, you should use your technical skills to deliver business value rather than as an end in themselves. ⤴️  \n\n\nSelf-promotion is essential, especially in today’s remote work environment. Don’t assume your manager is aware of all your contributions. Ensure you showcase your hard work and impact to gain recognition. Otherwise, forget to be rewarded and say goodbye to potential promotions. ⤴️  \n\n\nRemember, if you want to maximize the options to get promoted, focus on the following:\n\nDeliver business value\nMake your work visible ⤴️  \n\n"},"highlights/Omnivore/20240203003331":{"title":"Heschel on the Joys of Slowness - Cal Newport","links":[],"tags":[],"content":"Heschel on the Joys of Slowness - Cal Newport\nRead on Omnivore\nRead Original\nHighlights\n\nTo Heschel, as for the many billions of Jews, Christians, and Muslims who have practiced variations of this ancient insight, weekly rest is not about taking a break from the world around us, but instead about experiencing the joys of the world to come. It aims to makes the current moment more holy, not to render future moments more efficient. ⤴️  \n"},"highlights/Omnivore/20240203150054":{"title":"Research Papers in January 2024 - by Sebastian Raschka, PhD","links":[],"tags":[],"content":"Research Papers in January 2024 - by Sebastian Raschka, PhD\nRead on Omnivore\nRead Original\nHighlights\n\nA common form of this technique is Stochastic Weight Averaging (SWA), where weights are averaged over several iterations during periods of low learning rates.\n\nStochastic Weight Averaging (SWA) averages a model’s weights towards the end of the training cycle.\nSince a model’s training trajectory can be uneven, the strategy is to average the models towards the end of the training when the learning rate is low (if a scheduler is used), as illustrated in the figure above, where the training is nearing convergence. ⤴️  \n\n\nWhile weight averaging combines multiple checkpoints of the same model into a single model, model merging involves combining multiple different trained models into a single model. Each of these models may have been trained independently, possibly on different datasets or tasks. ⤴️  \n\n\nTo illustrate this concept more clearly, consider the objective of improving a large target model, M1 (for example, Llama 2 70B). The process involves two smaller models:\n\nA small base model (M2) like Llama 2 7B\nA finetuned version of the base model (M3) Llama 2 7B Chat\n\nThe enhancement is achieved by applying the difference in predictions (logits) of these smaller models to the target model M1. The output logits of the improved target model, M1*, is computed as M1*(x) = M1(x) + [M3(x) - M2(x)]. After obtaining these output logits, they are converted into probabilities using the softmax function. These probabilities are then used to sample the final output, i.e., the generated text, using nucleus sampling or top-k decoding. ⤴️  \n"},"highlights/Omnivore/20240203191242":{"title":"In the AI science boom, beware: your results are only as good as your data","links":[],"tags":[],"content":"In the AI science boom, beware: your results are only as good as your data\nRead on Omnivore\nRead Original\nHighlights\n\nIf all of the groups had neglected to make their data and code available, this data-leakage problem would have been almost impossible to catch. That would be a problem not just for the studies that were already published, but also for every other scientist who might want to use that data set for their own work. ⤴️  \n\n\nMore insidiously, the erroneously high performance reported in these papers could dissuade others from attempting to improve on the published methods, because they would incorrectly find their own algorithms lacking by comparison. Equally troubling, it could also complicate journal publication, because demonstrating improvement is often a requirement for successful review — potentially holding back research for years. ⤴️  \n"},"highlights/Omnivore/20240204111406":{"title":"Why Quora isn’t useful anymore: A.I. came for the best site on the internet.","links":[],"tags":[],"content":"Why Quora isn’t useful anymore: A.I. came for the best site on the internet.\nRead on Omnivore\nRead Original\nHighlights\n\nQuora’s shrinking utility isn’t due entirely to A.I.: Longtime writers cite issues with moderation and functionality that started well before the ChatGPT era. But its decline has been accelerating—much to the chagrin of the uniquely attached and now-fraying community—with the rise of this new knowledge broker. Earlier this month, the A.I.–accelerationist venture capital hub Andreessen Horowitz blessed Quora with a much-needed $75 million investment—but only for the sake of developing its on-site generative-text chatbot, Poe. ⤴️  \n\n\nThe tragedy of Quora is not just that it crushed the flourishing communities it once built up. It’s that it took all of that goodwill, community, expertise, and curiosity and assumed that it could automate a system that equated it, apparently without much thought to how pale the comparison is. ⤴️  \n"},"highlights/Omnivore/20240204212722":{"title":"Deeshee - Digitopia is ruining our lives","links":[],"tags":[],"content":"Deeshee - Digitopia is ruining our lives\nRead on Omnivore\nRead Original\nHighlights\n\nDigitopia (pronunciation: dij-i-toh-pee-uh) — an idealized but ultimately isolating and detached state induced by excessive digital interaction. ⤴️  \n\n\nThere are multiple factors that drive depression such as isolation; which often stems from being constantly alone, indoors and/or having a fake sense of “being social” by socializing with strangers on the internet, lack of confidence; stemming from comparing ourselves to others, letting go of ourselves and avoiding basic hygiene, grasping for quick dopamine hits or actions that yield in sweeping the “depressive” thoughts under a rug, and so on, and so forth. ⤴️  \n\n\nBeing in the Digitopian state usually means living on autopilot. Grabbing one thing after the other, trying to get through the day, distracting yourself at any negative emotion you face. ⤴️  \n\n\nsimplest form of exercise and a good way to reset your brain from all the thoughts flying around. Exercise does some chemistry magic to your body/brain and the dynamic-nature of the “outside world” gives you enough things to look at and process, so that it overrides your negative thoughts. ⤴️  \n"},"highlights/Omnivore/20240204212730":{"title":"Deepfaked Shit is Getting Real - by Gary Marcus","links":[],"tags":[],"content":"Deepfaked Shit is Getting Real - by Gary Marcus\nRead on Omnivore\nRead Original\nHighlights\n\nIn the end, I am reminded of the economist’s term negative externalities. In the old days, factories generated pollution, and expected everyone else to deal with the consequences. Now it’s AI developers who are expecting to do what they do scot-free, while society picks up the tab.  ⤴️  \n"},"highlights/Omnivore/20240204213015":{"title":"Diving deep into OpenAI’s new study on LLM’s and bioweapons","links":[],"tags":[],"content":"Diving deep into OpenAI’s new study on LLM’s and bioweapons\nRead on Omnivore\nRead Original\nHighlights\n\nIt should go without saying that any risk-benefit analyses that with respect to the tradeoffs involved in AI needs to reflect studies that are not just methodologically sound but also interpreted accurately. It is great that companies like OpenAI are looking into these questions, and posting their findings publicly, but the media and the public need to realize that company white papers are not peer-reviewed articles. Particularly when it comes to safety-critical questions, peer-review is essential. ⤴️  \n"},"highlights/Omnivore/20240204213159":{"title":"Rye: A Vision Continued | Armin Ronacher's Thoughts and Writings","links":[],"tags":[],"content":"Rye: A Vision Continued | Armin Ronacher’s Thoughts and Writings\nRead on Omnivore\nRead Original\nHighlights\n\nCargo is a manager that delegates the important work to bespoke tools that are improved by sometimes entirely different teams. This also means that tools can be swapped out if they are found to be not the right choice any more. ⤴️  \n"},"highlights/Omnivore/20240205100928":{"title":"The New Luddites Aren’t Backing Down - The Atlantic","links":[],"tags":[],"content":"The New Luddites Aren’t Backing Down - The Atlantic\nRead on Omnivore\nRead Original\nHighlights\n\nIt was meant as an insult, but Crabapple embraced the term. Like many others, she came to self-identify as part of a new generation of Luddites. “Tech is not supposed to be a master tool to colonize every aspect of our being. We need to reevaluate how it serves us.” ⤴️  \n\n\nThe new Luddites—a growing contingent of workers, critics, academics, organizers, and writers—say that too much power has been concentrated in the hands of the tech titans, that tech is too often used to help corporations slash pay and squeeze workers, and that certain technologies must not merely be criticized but resisted outright. ⤴️  \n\n\nI consider myself a Luddite not because I want to halt progress or reject technology itself. But I believe, as the original Luddites argued in a particularly influential letter threatening the industrialists, that we must consider whether a technology is “hurtful to commonality”—whether it causes many to suffer for the benefit of a few—and oppose it when necessary. ⤴️  \n\n\nIf they had shared in the gains instead of being left to starve, if they had been given agency over their technological destinies, they would not have taken up their hammers. ⤴️  \n\n\nTo more radically democratize the creation of technologies, in a manner that Silicon Valley pays only lip service to. And if the Luddites continue apace, encouraging more of us to participate, to become Luddites too—to not merely be consumers or users of technology, but shapers—they might not even need the hammers. ⤴️  \n"},"highlights/Omnivore/20240205120845":{"title":"The Acceleration of Addictiveness","links":[],"tags":[],"content":"The Acceleration of Addictiveness\nRead on Omnivore\nRead Original\nHighlights\n\nTechnological progress means making things do more of what we want. When the thing we want is something we want to want, we consider technological progress good. If some new technique makes solar cells x% more efficient, that seems strictly better. When progress concentrates something we don’t want to want — when it transforms opium into heroin — it seems bad. But it’s the same process at work. ⤴️  \n\n\nThe world is more addictive than it was 40 years ago. And unless the forms of technological progress that produced these things are subject to different laws than technological progress in general, the world will get more addictive in the next 40 years than it did in the last 40. ⤴️  \n\n\nWe’ll have to worry not just about new things, but also about existing things becoming more addictive. That’s what bit me. I’ve avoided most addictions, but the Internet got me because it became addictive while I was using it. ⤴️  \n"},"highlights/Omnivore/20240205135633":{"title":"Pluralistic: How I got scammed (05 Feb 2024) – Pluralistic: Daily links from Cory Doctorow","links":[],"tags":[],"content":"Pluralistic: How I got scammed (05 Feb 2024) – Pluralistic: Daily links from Cory Doctorow\nRead on Omnivore\nRead Original\nHighlights\n\nThere’s a name for this in security circles: “Swiss-cheese security.” Imagine multiple slices of Swiss cheese all stacked up, the holes in one slice blocked by the slice below it. All the slices move around and every now and again, a hole opens up that goes all the way through the stack. Zap! ⤴️  \n"},"highlights/Omnivore/20240205224636":{"title":"Deconstructing Geoffrey Hinton’s weakest argument","links":[],"tags":[],"content":"Deconstructing Geoffrey Hinton’s weakest argument\nRead on Omnivore\nRead Original\nHighlights\n\nWholesale unintentional fabrication is not the same thing as making a flawed argument, or lying, or spinning facts for political gain, and so on. Instead, it’s an error from recombining little bits of text in wrong ways. Turns out for example that an illustrator named Gary Oswalt illustrated a book named Henrietta Gets a Nest, and perhaps the statistical reconstruction process got muddled. ⤴️  \n\n\nThe mechanisms leading to LLM hallucinations just aren’t the same as me forgetting where I put my car keys. Even the errors themselves are qualitatively different. It’s a shame that Hinton doesn’t get that. ⤴️  \n"},"highlights/Omnivore/20240206075938":{"title":"Gates' Law: How Progress Compounds and Why It Matters","links":[],"tags":[],"content":"Gates’ Law: How Progress Compounds and Why It Matters\nRead on Omnivore\nRead Original\nHighlights\n\nNew technology: The media picks up on the existence of a new technology which may not exist in a usable form yet. Nonetheless, the publicity leads to significant interest. At this point, people working on research and development are probably not making any money from it. Lots of mistakes are made. In Everett Rogers’s diffusion of innovations theory, this is known as the innovation stage. If it seems like something new will have a dramatic payoff, it probably won’t last. If it seems we have found the perfect use for a brand-new technology, we may be wrong. ⤴️  \n\n\nThe peak of inflated expectations: A few well-publicized success stories lead to inflated expectations. Hype builds and new companies pop up to anticipate the demand. There may be a burst of funding for research and development. Scammers looking to make a quick buck may move into the area. Rogers calls this the syndication stage. It’s here that we overestimate the future applications and impact of the technology. ⤴️  \n\n\nThe trough of disillusionment: Prominent failures or a lack of progress break through the hype and lead to disillusionment. People become pessimistic about technology’s potential and mostly lose interest. Reports of scams may contribute to this, as the media uses this as a reason to describe the technology as a fraud. If it seems like new technology is dying, it may just be that its public perception has changed and the technology itself is still developing. Hype does not correlate directly with functionality. ⤴️  \n\n\nThe slope of enlightenment: As time passes, people continue to improve technology and find better uses for it. Eventually, it’s clear how it can improve our lives, and mainstream adoption begins. Mechanisms for preventing scams or lawbreaking emerge. ⤴️  \n\n\nThe plateau of productivity: The technology becomes mainstream. Development slows. It becomes part of our lives and ceases to seem novel. Those who move into the now saturated market tend to struggle, as a few dominant players take the lion’s share of the available profits. Rogers calls this the diffusion stage. ⤴️  \n\n\nHype serves a real purpose in the early days: it draws interest, secures funding, attracts people with the right talents to move things forward and generates new ideas. Not all hype is equally important, because not all opinions are equally important. If there’s intense interest within a niche group with relevant expertise, that’s more telling than a general enthusiasm. ⤴️  \n\n\nThis happens in our lives, as well. If you learn a new skill, the number of skills you could potentially learn increases because some elements may be transferable. If you are introduced to a new person, the number of people you could meet grows, because they may introduce you to others. If you start learning a language, native speakers may be more willing to have conversations with you in it, meaning you can get a broader understanding. If you read a new book, you may find it easier to read other books by linking together the information in them. The list is endless. We can’t imagine what we’re capable of achieving in ten years because we forget about the adjacent possibilities that will emerge. ⤴️  \n\n\nAs Stephen Hawking put it in 1993:\n\nFor millions of years, mankind lived just like the animals. Then something happened which unleashed the power of our imagination. We learned to talk and we learned to listen. Speech has allowed the communication of ideas, enabling human beings to work together to build the impossible. Mankind’s greatest achievements have come about by talking, and its greatest failures by not talking. It doesn’t have to be like this. Our greatest hopes could become reality in the future. With the technology at our disposal, the possibilities are unbounded. All we need to do is make sure we keep talking. ⤴️  \n\n"},"highlights/Omnivore/20240207214830":{"title":"Confessions of an AI Clickbait Kingpin | WIRED","links":[],"tags":[],"content":"Confessions of an AI Clickbait Kingpin | WIRED\nRead on Omnivore\nRead Original\nHighlights\n\nAI content is successful not because it is replacing the work of human writers but because it coasts on the value created by their past labor. ⤴️  \n"},"highlights/Omnivore/20240208082441":{"title":"More than calculators: Why large language models threaten learning, teaching, and education | by Amy J. Ko | Bits and Behavior | Dec, 2023 | Medium","links":[],"tags":[],"content":"More than calculators: Why large language models threaten learning, teaching, and education | by Amy J. Ko | Bits and Behavior | Dec, 2023 | Medium\nRead on Omnivore\nRead Original\nHighlights\n\nSo when we talk about “likely sequences of symbols”, the word “likely” means “the collective writing of mostly English-fluent adults likely to write publicly online in the past decade”, not “all of human knowledge or thought”. ⤴️  \n\n\nThe most problematic aspect of this scenario is that comprehending an explanation of a solution is not the same skill as finding a solution. The student, without anyone knowing, shifted the task from one of learning to solve algebra problems to one of reading comprehension. They are not learning algebra problem solving, they are learning to read and evaluate algebra solutions. If they will only ever encounter problems that LLMs can answer, and they will always have an LLM, and LLMs will always generate right answers, then may be this is fine. That position essentially posits that because LLMs exist, humans knowing algebra does not matter. But this is a lot of ifs, and so more likely, the student will encounter problems they haven’t encountered and they won’t be able to describe them to an LLM, because they don’t know algebra. In the same way that we have watched human ability to navigate decline as GPS has become ubiquitous. ⤴️  \n\n\nThe hype machine has readily deceived educators and education leaders into thinking that LLMs are some kind of intelligent education aid, when in fact, they are just generating likely things that other educators have posted online, whether they are good or not. ⤴️  \n\n\nLLMs, however, within the context of schools, are supplanting thought. They are short circuiting students’ opportunities to write, synthesize, reason, and struggle by perfectly reinforcing a vision that equates learning with correct answers. ⤴️  \n\n\nI see this in the way that teachers and education leaders are eagerly trying to integrate LLMs into learning, with the false hope that they will help them overcome resource scarcity and finally address inequities by giving every learner access to a personal teacher. Of course, it will not. Instead, LLMs will accelerate the collapse public education in the U.S., by amplifying these existing forces that were already taking us there. ⤴️  \n\n\nschools, as they often work today, do not actually incentivize learning and there is no use or disuse of LLMs that can change this. Putting our attention on LLMs, therefore, is mostly a distraction. We should be focused on how to change teaching and learning so that LLMs and all of the other technological distractions that have dominated youth attention are simply irrelevant. ⤴️  \n\n\nIn a way, this broader oppressive political vision of schools mirrors the underlying philosophy of an LLM: the only things that can be said are that which has been said before by our collective definition of “normal,” and at the expense of anyone on the margins. ⤴️  \n"},"highlights/Omnivore/20240208231926":{"title":"Pluralistic: Big Tech disrupted disruption (08 Feb 2024) – Pluralistic: Daily links from Cory Doctorow","links":[],"tags":[],"content":"Pluralistic: Big Tech disrupted disruption (08 Feb 2024) – Pluralistic: Daily links from Cory Doctorow\nRead on Omnivore\nRead Original\nHighlights\n\nA startup, by contrast, has no existing successful divisions and no giant customers to safeguard. They have nothing to lose and everything to gain from disruption. Where a large company has no way for individual employees to initiate major changes in corporate strategy, a startup has fewer hops between employees and management. What’s more, a startup that rewards an employee’s good idea with a stock-grant ties that employee’s future finances to the outcome of that idea – while a giant corporation’s stock bonuses are only incidentally tied to the ideas of any individual worker. ⤴️  \n\n\nThese data policies cast a long shadow. They don’t just block existing companies from accessing the data they need to pursue disruptive offerings – they also “send a message” to would-be founders and investors, letting them know that if they try to disrupt a tech giant, they will have their market oxygen cut off before they can draw breath. The only way to build a product that challenges Facebook as Facebook’s partner, under Facebook’s direction, with Facebook’s veto. ⤴️  \n\n\nBig Tech claims to be innovating, but it’s really just operationalizing. Any company that threatens to disrupt a tech giant is bought, its products stripped of any really innovative features, and the residue is added to existing products as a “sustaining innovation” – a dot-release feature that has all the innovative disruption of rounding the corners on a new mobile phone. ⤴️  \n"},"highlights/Omnivore/20240208231949":{"title":"The wealthy are cutting the line at the airport, Disney World and ski resorts | CNN Business","links":[],"tags":[],"content":"The wealthy are cutting the line at the airport, Disney World and ski resorts | CNN Business\nRead on Omnivore\nRead Original\nHighlights\n\nThis trend is accelerating because businesses recognize that lines — and how much people will pay to avoid them — are a way to make money. And they now have the technology to do so.\nSmartphones, mobile payments and other technology that let people pay in advance, reserve spots and scan tickets have made it easier for businesses to automate and de-personalize cutting the line. The pandemic sped up consumer adoption of mobile payments and pickup orders. ⤴️  \n\n\nThere are downsides to this business model. The gulf between the haves and the have-nots has widened in recent decades, and dividing consumers based on means and how much they can pay to skip a line may create more hostility and resentment. ⤴️  \n"},"highlights/Omnivore/20240209182438":{"title":"Here’s the Thing AI Just Can’t Do | WIRED","links":[],"tags":[],"content":"Here’s the Thing AI Just Can’t Do | WIRED\nRead on Omnivore\nRead Original\nHighlights\n\nThe reason for that feeling, I went on, is that when we read—when we take in any piece of art, actually, in any medium—we’re looking for something more than great content. We are seeking a human connection. ⤴️  \n\n\nThat epiphany about the meaning of human authorship has been my northern star as I work my way through the challenging AI issues that seem to besiege us every day. ⤴️  \n\n\nUsing a ghostwriter invariably distances you from friends and followers who read the caption. Having a robot provide your part of the conversation seems like outsourcing to the extreme. ⤴️  \n\n\nNo problem hiring someone to walk your dog. But hiring, um, something to talk about your dog? Weird. What if everyone did this? I bet we would not enjoy captions so much. A friend who replied to the automated caption with a comment might feel silly if they later learned that they were responding to something concocted by an artificial neural net, not a squishy biological one. Or maybe, your friend asks their Gemini to come up with a cute reply. Then the humans could sit back while their robots conversed. The repartee might have the rapier wit of a Tom Stoppard play. But there’d be no human connection. ⤴️  \n\n\nBut some content is contingent on connection. Another use case offered in Google’s briefing: “Help me write a document for a job.” Gemini can do terrific things with that. But employers read those things to get a sense of the applicant’s reasoning skills, grasp of the job requirement, and basic sanity. When everyone is generating those letters with AI, those factors will become opaque. Don’t bother with the letter and just send a résumé. For a real connection, the recruiter will have to do the Zoom—and hope you don’t send your deepfake double. ⤴️  \n"},"highlights/Omnivore/20240209193109":{"title":"Behind the Blog: Not Safe for Whose Work?","links":[],"tags":[],"content":"Behind the Blog: Not Safe for Whose Work?\nRead on Omnivore\nRead Original\nHighlights\n\nAnd I think the reason for that is a similar reason as to why the internet sucks so bad now. Work is the default mode of being online today. Work is what we do here, and being here is how we get work. Money, profits, revenue, investors, all of that is why you can’t say “sex” on Tiktok or post a hint of a boob on Instagram. ⤴️  \n\n\nA demand for sex built the shopping cart, the browser cookie, ad revenue models, payment processors, and the dynamic web page. The desire to explore and share our sexuality constructed the internet, piece by piece, as we know it today. And then technocratic billionaires betrayed the sexual for the sanitized and safe. We started labeling things “safe for work” and “not safe for work,” a binary that’s telling of who we allowed to call the shots. Sexuality is either unsafe or safe under a pretense of labor, depending on whether a boss is cool with it. Capitalists built walls around the “safe” parts of the internet to appease investors, advertisers, banks, and zealots—and pushed everyone who didn’t comply to the margins. ⤴️  \n"},"highlights/Omnivore/20240209203616":{"title":"The “3 standup questions” are terrible and need to die – More Than Coding","links":[],"tags":[],"content":"The “3 standup questions” are terrible and need to die – More Than Coding\nRead on Omnivore\nRead Original\nHighlights\n\nAll of these standup questions reinforce anti-agile behaviors. They encourage a gross “follow the worker, not the work” model and miss the opportunity to build a continuous delivery and learning mindset. They reek of bad top-down management and progressively cause slow, big-batching activity. ⤴️  \n"},"highlights/Omnivore/20240210090709":{"title":"Meet the Pranksters Behind Goody-2, the World’s ‘Most Responsible’ AI Chatbot | WIRED","links":[],"tags":[],"content":"Meet the Pranksters Behind Goody-2, the World’s ‘Most Responsible’ AI Chatbot | WIRED\nRead on Omnivore\nRead Original\nHighlights\n\nGoody-2 also highlights how although corporate talk of responsible AI and deflection by chatbots have become more common, serious safety problems with large language models and generative AI systems remain unsolved. The recent outbreak of Taylor Swift deepfakes on Twitter turned out to stem from an image generator released by Microsoft, which was one of the first major tech companies to build up and maintain a significant responsible AI research program. ⤴️  \n"},"highlights/Omnivore/20240211084736":{"title":"Seven reasons why the world should say No to Sam Altman","links":[],"tags":[],"content":"Seven reasons why the world should say No to Sam Altman\nRead on Omnivore\nRead Original\nHighlights\n\nIt is bad enough that large language models are making this kind of stuff easy now; worse that companies like OpenAI seem content to let society bear all the costs, like some careless industrial plant belching out toxic chemicals back in the day. ⤴️  \n"},"highlights/Omnivore/20240211084819":{"title":"How To Be Someone People Love To Talk To - Barking Up The Wrong Tree","links":[],"tags":[],"content":"How To Be Someone People Love To Talk To - Barking Up The Wrong Tree\nRead on Omnivore\nRead Original\nHighlights\n\nPut some effort into being warm and open. Ironically, studies show putting your best foot forward actually reveals the real you:\n\nIn sum, positive self-presentation facilitates more accurate impressions, indicating that putting one’s best self forward helps reveal one’s true self. ⤴️  \n\n\n\nFrom Dale Carnegie to peer-reviewed studies, everyone says smiles matter. (In fact, to increase their power, smile slower.)\nFBI behavior expert Robin Dreeke recommends speaking slowly.\nVia It’s Not All About “Me”: The Top Ten Techniques for Building Quick Rapport with Anyone:\n\nWhen individuals speak slowly and clearly, they tend to sound more credible than those who speak quickly. ⤴️  \n\n\n\nVia Click: The Magic of Instant Connections:\n\nWhen you both make yourselves vulnerable from the outset and are candid in revealing who you are and how you think and feel, you create an environment that fosters the kind of openness that can lead to an instant connection — a click. ⤴️  \n\n\n\nIt gives their brain as much pleasure as food or money:\n\nTalking about ourselves—whether in a personal conversation or through social media sites like Facebook and Twitter—triggers the same sensation of pleasure in the brain as food or money, researchers reported… “Self-disclosure is extra rewarding,” said Harvard neuroscientist Diana Tamir, who conducted the experiments with Harvard colleague Jason Mitchell. Their findings were published in the Proceedings of the National Academy of Sciences. “People were even willing to forgo money in order to talk about themselves,” Ms. Tamir said. ⤴️  \n\n\n\nSuspend your ego. Avoid correcting people or saying anything that could be interpreted as one-upmanship. ⤴️  \n\n\nVia It’s Not All About “Me”: The Top Ten Techniques for Building Quick Rapport with Anyone:\n\nIndividuals practicing good ego suspension would continue to encourage the other individual to talk about his or her story, neglecting their own need to share what they think is a great story… Those individuals who allow others to continue talking without taking their own turn are generally regarded as the best conversationalists. These individuals are also sought after when friends or family need someone to listen without judgment. They are the best at building quick and lasting rapport. ⤴️  \n\n\n\nFBI hostage negotiators use a number of techniques to show kidnappers they are really paying attention:\n\nMirroring: Repeat the last 1-3 words the person just said as a question. (Yes, it’s that simple.)\nParaphrasing: Repeat what they just said in your own words.\nLabeling: Put a name on what they say they’re feeling. “Sounds like you’re feeling pressured.” ⤴️  \n\n\n\nSo that’s what to ask about. FBI behavior expert Robin Dreeke explains:\n\nA great question I love is challenges. “What kind of challenges did you have at work this week? What kind of challenges do you have living in this part of the country? What kinds of challenges do you have raising teenagers?” Everyone has got challenges. It gets people to share what their priorities in life are at that point in time. ⤴️  \n\n\n\nThere’s a hierarchy of vulnerability in the types of communication we have, each one being more open and more likely to lead to a solid connection:\n\nPhatic: These statements have no emotional content: “How are you?”\nFactual: These share information, maybe personal information, but no strong opinions or emotions are involved: “I live in New York.”\nEvaluative: These statements show opinions, but they’re not core beliefs: “That movie was really funny.”\nGut-level: Here’s where it heats up. The first three are thought-oriented. Gut-level communication is emotionally based. It’s personal, says something deeper about who you are and is focused on feelings: “I’m sad that you’re not here.”\nPeak: The most emotionally vulnerable level. Peak statements share your innermost feelings. “…feelings that are deeply revealing and carry the most risk in terms how the other person will respond.” These statements are rare, even with people we are very close to: “I guess at heart I’m terrified I’m going to lose you.” ⤴️  \n\n\n\nVia The Art of Conversation: A Guided Tour of a Neglected Pleasure:\n\nArrangements: Talk of the Next rings the knell for Now.\nAny statement starting “Finally,” “Lastly”: Suggests an agenda is nigh complete.\nSatisfied Customer: A labeling comment to convey a job has been ticked off the list, “Well, I just wanted to check everything was okay.”\nFarewell by implication: Pre-goodbye goodbyes: passing regards to the wife, etc.\nPast tense: To kill the Now without committing to future encounters, say “It was great seeing you again,” “This was fun.”\nTime’s winged chariot hurrying near: That oh-so-pressing world you must be getting on with, or the missus will kill you, or the shops will have run out of Christmas trees, or the kids will be starving…\nMustn’t keep you: To suggest that you’re halting the other person’s day is polite… ⤴️  \n\n\n\nWhat does FBI behavior expert Robin Dreeke say is the best attitude to take when trying to build rapport? Make sure the other person walks away better for having met you. ⤴️  \n\n\nStop trying to impress people or “win” the conversation. It’s really much simpler than that.\nJust listen intently and make people feel good about themselves. ⤴️  \n"},"highlights/Omnivore/20240211165618":{"title":"100% user-supported — Steph Ango","links":[],"tags":[],"content":"100% user-supported — Steph Ango\nRead on Omnivore\nRead Original\nHighlights\n\nIn the short term, VCware tends to subsidize pricing to acquire users. It’s easier to grow if your product is cheap or free. But this generally comes at the cost of hoarding user data, and locking in customers. Once you’re in you can’t get out. ⤴️  \n\n\nTo keep raising money, VCware must paint an increasingly enormous vision of their future, which becomes impossible to live up to. This leads to increasingly disparate priorities that gradually make the product worse. What starts off as a useful app becomes burdened with crap. ⤴️  \n"},"highlights/Omnivore/20240211205728":{"title":"Can This A.I.-Powered Search Engine Replace Google? It Has for Me. - The New York Times","links":[],"tags":[],"content":"Can This A.I.-Powered Search Engine Replace Google? It Has for Me. - The New York Times\nRead on Omnivore\nRead Original\nHighlights\n\nIf A.I. search engines can reliably summarize what’s happening in Gaza, or tell users which toaster to buy, why would anyone visit a publisher’s website ever again? Why would journalists, bloggers and product reviewers continue to put their work online if an A.I. search engine is just going to gobble it up and regurgitate it? ⤴️  \n"},"highlights/Omnivore/20240212080059":{"title":"It's time to break free from Corporate Agile","links":[],"tags":[],"content":"It’s time to break free from Corporate Agile\nRead on Omnivore\nRead Original\nHighlights\n\nThere’s no need to evangelise or make a religion of it: Working “Agile” boils down to prioritising adaptability over predictability. We minimise risk by reacting quickly to unforeseen troubles, and we maximise impact by reprioritising based on the opportunities we see. In times when the future is hard to predict, an agile way of working is remarkably efficient. ⤴️  \n\n\nBasic Agile is less like executing a plan and more like a process of evolution that drives towards more optimal solutions. However, we can still understand our progress by projecting past work into the future. These projections are like weather forecasts where results are consistent in the short term and get more uncertain as you look further out. Forecasts are much better than estimates because they’re based on empirical data instead of guesswork. ⤴️  \n"},"highlights/Omnivore/20240212195749":{"title":"Donald Clark Plan B: This is why the idea that AI will just augment jobs, never replace them, is a lie!","links":[],"tags":[],"content":"Donald Clark Plan B: This is why the idea that AI will just augment jobs, never replace them, is a lie!\nRead on Omnivore\nRead Original\nHighlights\n\nThis idea that AI will not impact jobs is ridiculous. First it already has. Google has been replacing jobs for decades, all those print advertising jobs were replaced by online skills, bookshops, retail have all been hit hard by Amazon. We now do research online not in libraries, so they have also taken a hit. Word processors destroyed typing pools, spreadsheets bookkeepers. ⤴️  \n"},"highlights/Omnivore/20240212200201":{"title":"Do Not Trust Appearances: My Visit to Deep Springs College","links":[],"tags":[],"content":"Do Not Trust Appearances: My Visit to Deep Springs College\nRead on Omnivore\nRead Original\nHighlights\n\nThe most important thing the school taught me, however, was that when you scratch beneath the surface of even the most prestigious people and institutions, you will find reasons not to be intimidated. ⤴️  \n\n\nIn the end, what Deep Springs College taught me as a visitor in those few days was actually far more valuable than what I might have learned by actually attending the school as a student: Do not be intimidated by, or trust appearances. No one is better than you. Everyone has secrets. Go forward in your life like you belong anywhere you want to be. You can do and be whoever you want to be.   It is your life. ⤴️  \n"},"highlights/Omnivore/20240212203843":{"title":"Microsoft’s AI Will Delete Its Own Answers Before Your Eyes","links":[],"tags":[],"content":"Microsoft’s AI Will Delete Its Own Answers Before Your Eyes\nRead on Omnivore\nRead Original\nHighlights\n\nWith Copilot, in some cases, Microsoft makes the terrible user experience design choice to show you that Copilot knows the answer, but it doesn’t trust you with the information. It is quite spectacularly showing what the promoters of “uncensored” AI models are arguing, which is that a handful of powerful tech companies are forcing their values on millions of users. ⤴️  \n\n\nBut the widespread belief that AI will play an increasingly important role in society combined with the fact that tech companies are deploying these tools in a rush and very publicly botching their moderation methods is just resulting in one embarrassing incident after the other. ⤴️  \n"},"highlights/Omnivore/20240215082156":{"title":"Why Americans Suddenly Stopped Hanging Out - The Atlantic","links":[],"tags":[],"content":"Why Americans Suddenly Stopped Hanging Out - The Atlantic\nRead on Omnivore\nRead Original\nHighlights\n\nJust as many people are familiar with the concept of physical fitness, they said, we should be equally open to the concept of social fitness. We should care for our relationships as we’d care for our body. ⤴️  \n\n\nBut screens have replaced a chunk of our physical-world experience with a digital simulacrum that has enough spectacle and catastrophe to capture hours of our greedy attention. These devices so absorb us that it’s very difficult to engage with them and be present with other people. ⤴️  \n"},"highlights/Omnivore/20240215082742":{"title":"Mediocratopia: 13","links":[],"tags":[],"content":"Mediocratopia: 13\nRead on Omnivore\nRead Original\nHighlights\n\nBeing at 0 or 1 on an (normalized) parameter allows you to essentially drop a dimension and build in a degeneracy. Being at 0.534 forces you to model the dimension thoughtfully. I’ve said before that mediocrity is about fatness — reserve resources. Now we can add — it’s also about fullness. Full rank. Max dimensionality. No unnecessary reduction to binaries or absolutes. Everything in the nature of the thing is also in the tradeoff space of dealing with the thing. This also means there is something tentative about a mediocre thing. All options are open. None have been foreclosed. ⤴️  \n"},"highlights/Omnivore/20240215093449":{"title":"With the rise of AI, web crawlers are suddenly controversial - The Verge","links":[],"tags":[],"content":"With the rise of AI, web crawlers are suddenly controversial - The Verge\nRead on Omnivore\nRead Original\nHighlights\n\nGoogle uses them to crawl and index the entire web for its search engine, which has become the interface to the web and brings the company billions of dollars a year. Bing’s crawlers do the same, and Microsoft licenses its database to other search engines and companies. The Internet Archive uses a crawler to store webpages for posterity. Amazon’s crawlers traipse the web looking for product information, and according to a recent antitrust suit, the company uses that information to punish sellers who offer better deals away from Amazon. AI companies like OpenAI are crawling the web in order to train large language models that could once again fundamentally change the way we access and share information. ⤴️  \n\n\nBeing too permissive can bleed your website of all its value; being too restrictive can make you invisible. And you have to keep making that choice with new companies, new partners, and new stakes all the time. ⤴️  \n\n\nIn large part, GPTBot has become the main villain of robots.txt because OpenAI allowed it to happen. The company published and promoted a page about how to block GPTBot and built its crawler to loudly identify itself every time it approaches a website. Of course, it did all of this after training the underlying models that have made it so powerful, and only once it became an important part of the tech ecosystem. But OpenAI’s chief strategy officer Jason Kwon says that’s sort of the point. “We are a player in an ecosystem,” he says. “If you want to participate in this ecosystem in a way that is open, then this is the reciprocal trade that everybody’s interested in.” Without this trade, he says, the web begins to retract, to close — and that’s bad for OpenAI and everyone. “We do all this so the web can stay open.” ⤴️  \n"},"highlights/Omnivore/20240216081055":{"title":"Pluralistic: How a billionaire’s mediocre pump-and-dump “book” became a “bestseller” (15 Feb 2024) – Pluralistic: Daily links from Cory Doctorow","links":[],"tags":[],"content":"Pluralistic: How a billionaire’s mediocre pump-and-dump “book” became a “bestseller” (15 Feb 2024) – Pluralistic: Daily links from Cory Doctorow\nRead on Omnivore\nRead Original\nHighlights\n\nI don’t know what to do about this, but I have one piece of advice: if you read a book you love, tell other people about it. Tell them face-to-face. In your groupchat. On social media. Even on Goodreads. Every book is a lottery ticket, but the bezzlers are buying their tickets by the case: every time you tell someone about a book you loved (and even better, why you loved it), you buy a writer another ticket. ⤴️  \n"},"highlights/Omnivore/20240216200449":{"title":"Sora’s Surreal Physics - by Gary Marcus - Marcus on AI","links":[],"tags":[],"content":"Sora’s Surreal Physics - by Gary Marcus - Marcus on AI\nRead on Omnivore\nRead Original\nHighlights\n\nOne of the most fascinating things Sora’s weird physics glitches is most of these are NOT things that appears in the data. Rather, these glitches are in some ways akin to LLM “hallucinations”, artifacts from (roughly speaking) decompression from lossy compression. They don’t derive from the world. ⤴️  \n\n\nMore data won’t solve that problem. And like other generative AI systems, there is no way to encode (and guarantee) constraints like “be truthful” or “obey the laws of physics”or “don’t just invent (or eliminate) objects”. ⤴️  \n\n\nSora is fantastic, but it is akin to morphing and splicing, rather than a path to the physical reasoning we would need for AGI. It is a model of how images change over time, not a model of what entities do in the world. ⤴️  \n"},"highlights/Omnivore/20240217081754":{"title":"Let's not do this again, please - by Brian Merchant","links":[],"tags":[],"content":"Let’s not do this again, please - by Brian Merchant\nRead on Omnivore\nRead Original\nHighlights\n\nIf we accept OpenAI’s promotional narrative and get swept up in Sora, if we tremble at the forbidding power of its reality-distorting abilities, we make it much, much easier for the company to cash in on its still-proliferating mythologies. ⤴️  \n"},"highlights/Omnivore/20240217161216":{"title":"Click Around, Find Out – Dirty Feed","links":[],"tags":[],"content":"Click Around, Find Out – Dirty Feed\nRead on Omnivore\nRead Original\nHighlights\n\n“Somewhere between the late 2000’s aggregator sites and the contemporary For You Page, we lost our ability to curate the web. Worse still, we’ve outsourced our discovery to corporate algorithms. Most of us did it in exchange for an endless content feed. ⤴️  \n\n\nClick around. Or tap around. Or do whatever you need to do in the browser of your choice. If we want the indie web to flourish, the very first thing people need to get used to is actually browsing the web again. ⤴️  \n\n\nIf you care about the indie web growing, by all means write, by all means create, by all means curate. But most of all, just read. Or listen, or experience. Spend an afternoon clicking around, like everybody used to. The more people who do that, the more everything else will slot into place without even having to think much about it. If 2024 truly is a tipping point into a new world, then it can’t happen in a vacuum. ⤴️  \n"},"highlights/Omnivore/20240217203831":{"title":"I worry our Copilot is leaving some passengers behind - Josh Collinsworth blog","links":[],"tags":[],"content":"I worry our Copilot is leaving some passengers behind - Josh Collinsworth blog\nRead on Omnivore\nRead Original\nHighlights\n\n“They’re not perfect” may as well be the tagline for LLMs. ⤴️  \n\n\nBut if we’re giving one of the world’s major corporations our money, in exchange for this tool that’s supposed to make us better…shouldn’t it be held to some standard of quality? Shouldn’t the results I get from a paid service at least be better than a bad StackOverflow suggestion that got down-voted to the bottom of the page (and which would probably come with additional comments and suggestions letting me know why it was ranked lower)? ⤴️  \n\n\nProducts of all kinds are required to ensure misuse is discouraged, at a minimum, if not difficult or impossible. I don’t see why LLMs should be any different. ⤴️  \n\n\nPlus, there are far less sophisticated technologies that are fully capable of warning us, or even stopping us, when we’re writing inaccessible or improper code. Why should we just accept that LLM tools not only fail to at least give us the same warnings, but actively push us the wrong way? ⤴️  \n\n\nOne benefit of Copilot people commonly tout is how helpful it is when working in a new or unfamiliar language. But if you’re in that situation, how will you know a bad idea when you see it? ⤴️  \n\n\nIf ensuring quality is your responsibility, and the tool you’re using pushes bad quality your way, you are fighting against gravity in that situation. It’s you versus the forces of entropy. And unless you fight perfectly (which you won’t), the end result is, unavoidably, a worse one. ⤴️  \n\n\nIn any case, if we know we exist on an uneven playing field (which we do), we shouldn’t see the slant as the baseline. If the status quo is already inequitable (which it is), we shouldn’t see something that’s equally inequitable as just fine, just because that’s the current reality. It’s not fine. It’s just more of the same inequitable slant. ⤴️  \n\n\nIf organizations actually cared about putting resources towards accessibility, they’d already be doing it. They don’t. They care about profit, and the moment you have 40% more time, you’re going to spend 100% of it on something that makes the company money. ⤴️  \n\n\nThere’s no credit card for inequity. I don’t think it’s ethically sound to suggest that any present wrongdoing is justified by a future solution that will undo it, especially given points 1 and 2. ⤴️  \n\n\nThat’s invaluable context. Not only are you now better equipped to understand this solution, you learned more for next time. You’re a better developer than you were.\nNot so with Copilot. You gained zero context. You didn’t really learn anything. I certainly wouldn’t be learning Rust, if I were just letting Copilot generate it all for me. I got a workable answer of unknown quality handed to me, and my brain was not challenged or wrinkled in the slightest. ⤴️  \n\n\nIn a lot of ways, in fact, “AI” is just the newest iteration of a very old form of colonial capitalism; build a wall around something you didn’t create, call it yours, and charge for access. (And when the natives complain, call them primitive and argue they’re blocking inevitable progress.) ⤴️  \n\n\nAs more and more of the internet is generated by LLMs, more and more of it will reinforce biases. Then more and more LLMs will consume that biased content, use it for their own training, and the cycle will accelerate exponentially. ⤴️  \n\n\nThe internet is already an overwhelmingly inequitable place.\nI don’t think we should accept that what we get in exchange for our money is, inevitably, a force for further inequity, and yes, ultimately, for discrimination. ⤴️  \n"},"highlights/Omnivore/20240218005541":{"title":"Sora Can’t Handle the Truth - by Gary Marcus - Marcus on AI","links":[],"tags":[],"content":"Sora Can’t Handle the Truth - by Gary Marcus - Marcus on AI\nRead on Omnivore\nRead Original\nHighlights\n\nSora is obviously grounded in relationships between videos and associated texts; yet that grounding is not enough to preclude 7x7 chessboards with 3 kings. ⤴️  \n\n\nRather, Sora is failing to apprehend a cultural regularity of the world, despite ample evidence. Some tried to excuse the errors I showed yesterday on the grounds that emulating physics is hard; one can’t say the same for the well-documented rules of chess. ⤴️  \n\n\nThere, ChatGPT generalized the statistics of English, but without regard to facts. Here, Sora has generalized the visual textures of chess boards, without quite grasping what the proper limits on such generalizations should be. ⤴️  \n\n\nThe system is trying to approximate the world, but it just isn’t very good at that job. It uses arrangements of pixels to predict other arrangements of pixels, but it does not try to build an internal model of physics, and it does not try to build an internal model of cultural artifacts, either. ⤴️  \n\n\nand the system varies that number freely, as a function of pixels rather than representations of enduring creatures in the world. ⤴️  \n\n\nThe factuality problems that have haunted LLMs are present even in a new architecture trained on ungodly amounts of data. ⤴️  \n"},"highlights/Omnivore/20240218005604":{"title":"Releasing my tools under the MIT License was probably a mistake — Donat Studios","links":[],"tags":[],"content":"Releasing my tools under the MIT License was probably a mistake — Donat Studios\nRead on Omnivore\nRead Original\nHighlights\n\nAgainst my well meaning intentions however, websites re-hosting my tools have been popping up like weeds. In some cases, they are even beating me in search results for my own tools. With noted exception, they don’t credit me as the author or provide any sort of link back. Many of them have made minor or major modifications to the tools, and next to none provide the source to those modifications. A number of them even have the gall to post links advertising them in the comments of my own tools. ⤴️  \n\n\nI didn’t think people so lacked in the spirit of open source. I wanted to promote community contributions, not to have them monetized by other people who don’t even provide the source to their modifications. I wanted to grow the tools as a community, not have closed source forks of them overtake my own open source versions. ⤴️  \n"},"highlights/Omnivore/20240218090107":{"title":"Absolutely amazing ant video augurs intellectual mayhem","links":[],"tags":[],"content":"Absolutely amazing ant video augurs intellectual mayhem\nRead on Omnivore\nRead Original\nHighlights\n\nIn short order, with Sora or some opensource counterparts that will emerge, scammers will start to make photorealistic fake videos simply to sell ads. The average user will have no idea what is and is not legit. A major educational resource will likely be spoiled practically overnight. ⤴️  \n"},"highlights/Omnivore/20240218090131":{"title":"What’s the fun in writing on the internet anymore?","links":[],"tags":[],"content":"What’s the fun in writing on the internet anymore?\nRead on Omnivore\nRead Original\nHighlights\n\nThis seems vicious: repurposing content engenders the proliferation of walled gardens and walled gardens, in turn, engenders the proliferation of repurposed content.) ⤴️  \n\n\nEmerging tools like Perplexity.ai respond to quiries with fulsome answers that do not require users to even click off the site. In other words, search itself is becoming the delivery of paraphrase and summary. Waning are the days of sifting through “search results” to find a specific source. Henceforth, digital words are little more than raw data to be crunched, processed, and served up by third-party intermediaries. ⤴️  \n\n\nTo put any thoughtful labour into crafting words online today is to watch them get sucked up, repurposed, and often monetized by someone else. It feels a bit like a digital wasteland; overrun with pirates, replete with armies of robots regurgitating everything into a gooey cocktail of digital sludge. ⤴️  \n\n\nWrite here because ideas matter, not authorship. Write here because the more robots, pirates, and single-minded trolls swallow up cyberspace, the more we need independent writing in order to think new thoughts in the future — even if your words are getting dished up and plated by an algorithm. ⤴️  \n\n\nThose who write — those who add ideas instead of paraphrasing and regurgitating them — inform the lexicology and mental corpus of how we think in the future. Indeed, the point isn’t “being an author,” but contributing one’s perspective, even if one’s personal identity is silenced, erased, and anonymized along the way. ⤴️  \n"},"highlights/Omnivore/20240219093502":{"title":"My Productivity Protocol – Jakob Greenfeld – Experiments in Permissionless Entrepreneurship","links":[],"tags":[],"content":"My Productivity Protocol – Jakob Greenfeld – Experiments in Permissionless Entrepreneurship\nRead on Omnivore\nRead Original\nHighlights\n\nWhen you’re working so many hours and work on dozens of tiny tasks, you lose clarity of thought and quickly stop seeing the forest for the trees. ⤴️  \n"},"highlights/Omnivore/20240219211545":{"title":"How To Write Stuff No One Else Can – The Write to Roam","links":[],"tags":[],"content":"How To Write Stuff No One Else Can – The Write to Roam\nRead on Omnivore\nRead Original\nHighlights\n\nAnd when it comes to information, the biggest moat that you can have is access to people. Not famous people. But rather, the people behind the scenes who have just as much insight and far less attention. ⤴️  \n\n\nAnd this is the big point – there’s an asymmetry between the people who have interesting experience and insight on any particular topic, and the people who get the attention. ⤴️  \n"},"highlights/Omnivore/20240220130000":{"title":"The Skilled Workers Training AI to Take Their Jobs | WIRED","links":[],"tags":[],"content":"The Skilled Workers Training AI to Take Their Jobs | WIRED\nRead on Omnivore\nRead Original\nHighlights\n\nAna’s experience shows that while white-collar data laborers may command higher salaries than their peers working in Southeast Asia, who have been documented to make less than $1 per hour, they still suffer instability. Jay and Ana both say Remotasks cut them off abruptly and felt frozen out for reasons they didn’t fully understand. ⤴️  \n"},"highlights/Omnivore/20240220154133":{"title":"How startup culture runs on bullshit. — Joan Westenberg","links":[],"tags":[],"content":"How startup culture runs on bullshit. — Joan Westenberg\nRead on Omnivore\nRead Original\nHighlights\n\nThey adopt self-aggrandising mantras about “making a dent in the universe” that feed collective delusions about the importance of minor app features or delivery services. And most fail ingloriously. Behind each headline unicorn are thousands of workers burning out in relative obscurity under constant pressure. Underwriting the reckless, relentless growth of the tech giants are thousands of laid-off employees struggling to rebuild their careers in a job market repeatedly pumped up and drained by the same tech companies who just gave them their marching orders. ⤴️  \n\n\nBut focusing on outliers obscures the limited accessible pathways and how systemic barriers block many with equal talents. Confirmation bias leads investors and journalists to seek individuals fitting the narrow archetypes of what they believe constitutes the ideal founder based more on shared collective delusions than evidence.  ⤴️  \n"},"highlights/Omnivore/20240221132924":{"title":"RTO Policies Don't Improve Employee Performance or Company Value","links":[],"tags":[],"content":"RTO Policies Don’t Improve Employee Performance or Company Value\nRead on Omnivore\nRead Original\nHighlights\n\n”And that’s indeed what we found,” Ma said. “We found RTO mandates are more common among male CEOs and more powerful CEOs. So that’s consistent with these managers using RTO mandates to reassert control.” ⤴️  \n\n\nHe added: “It is my personal belief that, as prior research suggests, most CEOs are very narcissistic. That means they are used to being in the center of everything and issuing orders for employees to follow. But after the pandemic, they feel kind of like they’re losing power because employees became more and more aware of their rights during the great resignation. So, the managers feel that they are losing their power inside the firm, basically, and as a result, they want to grab their power back in this relationship. And that’s the reason we found such results.” ⤴️  \n"},"highlights/Omnivore/20240221185920":{"title":"ChatGPT Started Speaking Complete Gibberish","links":[],"tags":[],"content":"ChatGPT Started Speaking Complete Gibberish\nRead on Omnivore\nRead Original\nHighlights\n\nOpenAI, it seems, has already fixed the issue, but the fact that the most popular AI tool in the world and arguably the primary reason we’re currently in the middle of an AI boom can suddenly go off the rails without warning is a great reminder that we can’t trust these tools blindly. ⤴️  \n"},"highlights/Omnivore/20240222083502":{"title":"Marcus on AI | Gary Marcus | Substack","links":[],"tags":[],"content":"Marcus on AI | Gary Marcus | Substack\nRead on Omnivore\nRead Original\nHighlights\n\nSome things have scaled exponentially, and some haven’t. The capacity to endow machines with the commonsense understanding of history, culture, and human values that would be required to make sensible guardrails has not. ⤴️  \n"},"highlights/Omnivore/20240222124553":{"title":"Tools for Thinking About Censorship - Reactor","links":[],"tags":[],"content":"Tools for Thinking About Censorship - Reactor\nRead on Omnivore\nRead Original\nHighlights\n\nThe majority of censorship is self-censorship, but the majority of self-censorship is intentionally cultivated by an outside power. ⤴️  \n\n\nFear is one of the two main ways powers cultivate self-censorship and middleman censorship, but its partner is projection of power, which is not quite the same. ⤴️  \n\n\nRather they target a few people unpredictably and conspicuously, so that everyone else in a similar situation will feel fear, and self-censor or middleman-censor more, including self-censoring in arenas unrelated to what was targeted (i.e. someone who both owns porn and supports a political resistance party might become more afraid to support that party after a widely-publicized crackdown on someone who owned porn, or vice versa). This is an extremely potent and cost-effective tactic, and a go-to for many regimes, from Imperial Rome, to enforcement of anti-sedition laws in WWI and WWII, to today’s anime/manga censorship, etc. ⤴️  \n\n\nFor this reason, we cannot consider state and non-state censorship separate things. State censorship systems work dominantly via shaping and causing private censorship. ⤴️  \n"},"highlights/Omnivore/20240222211311":{"title":"YouTube addiction, one month sober","links":[],"tags":[],"content":"YouTube addiction, one month sober\nRead on Omnivore\nRead Original\nHighlights\n\nThe way sites like TikTok and YouTube give you a feed of content means you can consume it in an unbroken fashion. It reminds me of the people you see at slot machines in casinos, pulling the lever to see what will happen. Maybe you’ll get lucky and come across something awesome.\nThe content also keeps you in a kind of trance - a state where you don’t have to think if you don’t want to. ⤴️  \n\n\nAddiction is isolating. The particular addiction, YouTube, is a lot of wanting to connect to others in a very safe way. So, to combat this, the goal is to “reach out”. To connect to real people. To get my ‘cup’ filled with real intimacy and connections with others. ⤴️  \n"},"highlights/Omnivore/20240223191650":{"title":"Democratisation of AI is an illusion | by Dr Vaishak Belle | Feb, 2024 | Medium","links":[],"tags":[],"content":"Democratisation of AI is an illusion | by Dr Vaishak Belle | Feb, 2024 | Medium\nRead on Omnivore\nRead Original\nHighlights\n\nWhile the tools might be available to a large number of people at a convenient cost, and with open-source models, you might even download them onto your computer and run them, it implicitly assumes that you have the spare change to afford using these technologies. The sharing of power also implies sharing the profits, and as many have argued, there is a brief period where productivity increases, but over time, those most affected are not the companies. People who cannot adopt the technology will struggle to keep up, may face job losses, and those who can use the technology may make each other redundant or be expected to surpass the baseline outputs provided by these technologies. ⤴️  \n"},"highlights/Omnivore/20240224094409":{"title":"No, RAG is probably not going to rescue the current situation","links":[],"tags":[],"content":"No, RAG is probably not going to rescue the current situation\nRead on Omnivore\nRead Original\nHighlights\n\nThe idea is that you tie your expensively-trained, confabulation prone LLM that you can’t afford to update frequently to other sources of information such a more regularly and cheaply updated databases or company doceuments. And somehow RAG will solve all your problems. If your LLM has been trained on so-and-so being the Senator X from New Giant State and there is an election in New Giant State and Senator Y replaces Senator X, you want to be able quickly fix any relevant queries immediately without retraining\nThe trouble is that so far RAG has been hit and miss. ⤴️  \n\n\nReality is that RAG is still in its infancy, a work in progress much as LLMs themselves are, an no more guaranteed to be correct. Like LLMs, RAG can appear spectacular at times, but there is no evidence that it is a cure-all. As one recent review from December puts it “there is still a considerable journey ahead to effectively apply RAG to LLMs.” In the words of another, from earlier this month, “While building an initial RAG application is easy, making it robust is non-trivial.”\nThe road from research idea to reliable production remains steep. RAG may reduce hallucinations somewhat, but it certainly won’t come close to eliminating them. ⤴️  \n\n\nWaiting on RAG to fix what ails LLM is just waiting on another miracle. ⤴️  \n"},"highlights/Omnivore/20240224173921":{"title":"The Shirky Principle: Institutions Try to Preserve the Problem to Which They Are the Solution – Effectiviology","links":[],"tags":[],"content":"The Shirky Principle: Institutions Try to Preserve the Problem to Which They Are the Solution – Effectiviology\nRead on Omnivore\nRead Original\nHighlights\n\nThe Shirky principle is the adage that “institutions will try to preserve the problem to which they are the solution”. More broadly, it can also be characterized as the adage that “every entity tends to prolong the problem it is solving”. ⤴️  \n\n\nFinally, note that the phenomenon described by the Shirky principle—entities prolonging a problem to which they are the solution—isn’t necessarily the result of intentional actions. For example, a company may inadvertently perpetuate the problem that it solves, because its processes are so focused on the mediocre solution that they’re currently selling, that they don’t realize a better solution exists. Similarly, a company may discourage the use of a certain approach to solving a problem because it previously failed for them, even after technological advancements make this approach viable. ⤴️  \n\n\nEssentially, in his writing on the topic, Kelly offers three formulations of the Shirky principle, which differ in subtle but important ways:\n\nThe first formulation—“Institutions will try to preserve the problem to which they are the solution”—refers to institutions, and states that they will try to preserve problems, which implies that they do so intentionally.\nThe second formulation—“Complex solutions (like a company, or an industry) can become so dedicated to the problem they are the solution to, that often they inadvertently perpetuate the problem”—refers to complex solutions, and states that they often inadvertently perpetuate the problem, which implies that they do so unintentionally.\nThe third formulation—”Every entity tends to prolong the problem it is solving”—refers to entities, and states that they tend to prolong problems, without making any claim about their intentions. ⤴️  \n\n\n\nNote: In his post, Kelly states that Shirky’s observation reminds him “of the clarity of the Peter Principle, which says that a person in an organization will be promoted to the level of their incompetence. At which point their past achievements will prevent them from being fired, but their incompetence at this new level will prevent them from being promoted again, so they stagnate in their incompetence.”. ⤴️  \n\n\nThere are some caveats about the Shirly principle that are important to keep in mind:\n\nThe Shirky principle is just a general observation. As such, there are many situations where it’s incorrect. For example, an institution may successfully solve the problem to which they are the solution because there’s greater profit to be made that way than by prolonging the problem.\nThe Shirky principle can involve various types of entities. Though the best-known formulation of the Shirky principle refers to “institutions”, this principle can apply to various types of entities, including individuals and small social groups. This is noted in the general formulation of the principle (“every entity tends to prolong the problem it is solving”).\nThe Shirky principle can involve various causes. For example, one company may prolong a problem unintentionally, due to passivity or inertia, whereas another company may prolong a problem intentionally, due to greed or self-preservation. This is reflected in the general formulation of this principle, which doesn’t make any claims regarding the causes or intentionality of this phenomenon.\nThe Shirky principle can involve various patterns of behavior. For example, one company may prolong an existing problem by not dedicating resources to developing new solutions, whereas another company may actively prevent others from developing such solutions. ⤴️  \n\n\n\nBased on this, a broader version of Shirky’s principle can be expressed as:\n\n“Entities often promote problems that they benefit from”. ⤴️  \n\n\n\nFinally, there are also two useful concepts worth keeping in mind when accounting for Shirky’s principle:\n\nCui bono, which is a Latin phrase that means “who benefits?”, and which is used to suggest that there’s a high probability that those responsible for a certain event are the ones who stand to gain from it.\nHanlon’s razor, which is the adage that you should “never attribute to malice that which is adequately explained by stupidity”, and which, when applied broadly, suggests that when assessing people’s actions, you should not assume that they acted out of a desire to cause harm, as long as there is a reasonable alternative explanation. ⤴️  \n\n\n\nIn addition, a similar famous concept that’s related to Shirky’s principle has been expressed by novelist and social reformer Upton Sinclair, who said that “It is difficult to get a man to understand something when his salary depends on his not understanding it.” ⤴️  \n"},"highlights/Omnivore/20240227220319":{"title":"Pluralistic: Hypothetical AI election disinformation risks vs real AI harms (27 Feb 2024) – Pluralistic: Daily links from Cory Doctorow","links":[],"tags":[],"content":"Pluralistic: Hypothetical AI election disinformation risks vs real AI harms (27 Feb 2024) – Pluralistic: Daily links from Cory Doctorow\nRead on Omnivore\nRead Original\nHighlights\n\nAll of these are non-hypothetical, real risks from AI. The AI industry has proven itself incredibly adept at deflecting interest from real harms to hypothetical ones, like the “risk” that the spicy autocomplete will become conscious and take over the world in order to convert us all to paperclips: ⤴️  \n"},"highlights/Omnivore/20240227220346":{"title":"True Zero-shot MT - by Sebastian Ruder - NLP News","links":[],"tags":[],"content":"True Zero-shot MT - by Sebastian Ruder - NLP News\nRead on Omnivore\nRead Original\nHighlights\n\nThe authors thus provide another human baseline: The first author Garrett Tanzer learned how to translate Kalamang from scratch by reading the grammar book for 10+ hours and then used the parallel data and the Internet as reference when performing the translation task over the course of several weeks. That is dedication to human evaluation! ⤴️  \n\n\nHowever, the embodied, interactive, and multi-modal nature of first language (L1) acquisition is challenging to replicate with current models. L2 acquisition in the form of true zero-shot MT may be a more accessible testbed to study how a model learns a new language based on limited linguistic resources. ⤴️  \n\n\nTo make most use of such resources, both in obtaining and understanding the data as well as interpreting model results requires collaborating with linguists. MTOB provides an example of how such a collaboration can look like in practice, with the linguist actively participating in the research and co-authoring the paper. Such inter-disciplinary collaborations, while challenging and complex, are often a breath of fresh air—so I hope to see more of them in the future. ⤴️  \n"},"highlights/Omnivore/20240228190625":{"title":"AI-Generated Kara Swisher Biographies Flood Amazon","links":[],"tags":[],"content":"AI-Generated Kara Swisher Biographies Flood Amazon\nRead on Omnivore\nRead Original\nHighlights\n\nAmazon is filled with AI-generated trash books that are hoping to catch a confused shopper or errant click searching for a new and popular book. Aside from being annoying and making obvious that Amazon has no desire to prevent its platform from hosting and profiting from mountains of AI-generated exploitative trash, the fact that so many AI-generated books show up in Amazon search results without making clear that they are AI-generated could be legitimately dangerous if you’re trying to find out an actually important fact, like which mushrooms you can forage and eat. ⤴️  \n"},"highlights/Omnivore/20240228190847":{"title":"Fanfiction Community Rocked By Etsy Sellers Turning Their Work Into Bound Books","links":[],"tags":[],"content":"Fanfiction Community Rocked By Etsy Sellers Turning Their Work Into Bound Books\nRead on Omnivore\nRead Original\nHighlights\n\nSenLiYu wrote about the book binding issue on Twitter: “As someone not planning to delete all their fanworks, can I just say, there is a vast mental/emotional toll to having your creative work ceaselessly exploited. Especially when it happens in a manner adjacent to a community that you consider yourself a part of,” she wrote. “Fandom is about community more than it’s about any specific original work, that’s why a community can migrate light years away from the OG and become a new microcosmic space. It’s the people and relationships, the journeys of writers, artists, and readers that makes it meaningful.” ⤴️  \n"},"highlights/Omnivore/20240228191849":{"title":"The Tech Industry Doesn’t Understand Consent - Dhole Moments","links":[],"tags":[],"content":"The Tech Industry Doesn’t Understand Consent - Dhole Moments\nRead on Omnivore\nRead Original\nHighlights\n\nOpt-out is “our lawyers told us to make this an option to cover our ass, but we don’t want you to actually do it”.\nOpt-out is “if you missed the memo, we assume we have your consent”.\nThe default state of any decision regarding user data should be opted out. Users should instead be required to opt in for your decision to take effect, and they must not be coerced into doing so.\nIf consent is not explicitly given by an informed user, you haven’t received consent at all, and to pretend otherwise is unethical.\nYour users don’t fucking care about opt-out. We care about opt-in. ⤴️  \n"},"highlights/Omnivore/20240229201025":{"title":"Are Video Generation Models World Simulators? · Artificial Cognition","links":[],"tags":[],"content":"Are Video Generation Models World Simulators? · Artificial Cognition\nRead on Omnivore\nRead Original\nHighlights\n\nThese bold statements are taken from blog posts – including the terse “technical report” – that can only be characterized as marketing documents rather than academic articles (let alone peer-reviewed research). ⤴️  \n\n\nThe problem with this hypothesis, as stated, is that it’s extremely vague. What would it actually mean for a video generation model to simulate the physical world? And what kind of evidence could support that claim? ⤴️  \n\n\nWe’re getting closer to a clear statement of the simulation hypothesis: a good-enough video generation model based on an end-to-end neural network architecture with a finite set of parameters should be expected to acquire internal models of the physical world during training, because this is the most effective way – perhaps the only way – for such a neural network to generate coherent and realistic videos of arbitrary scenes. ⤴️  \n\n\nBut game engines don’t typically model these laws either. While they might simulate heat effects (fire, explosions) and work (objects moving against friction), these simulations are usually highly abstracted and do not adhere strictly to thermodynamic equations. They simply don’t need to, because their focus is on the visual and interactive believability of the rendered scene rather than strict physical accuracy. Could Sora be doing something similar? If we want to begin answering this question, we need to talk about intuitive physics. ⤴️  \n\n\nWhere does that leave us? Here is the bottom line: when it comes to humans, at least, it is tempting to explain intuitive physical reasoning by postulating the existence of an IPE that performs probabilistic mental simulations about physical scenarios using approximate principles. This hypothesis is still debated, and there is arguably evidence for and against it. But there is at least a relatively plausible and well-thought-out case to be made for the simulation hypothesis, with a rich experimental literature to back it up. ⤴️  \n\n\nIn machine learning research, it mostly originates in the literature on model-based reinforcement learning, particularly from Juergen Schmidhuber’s lab in the 1990s. In this context, a world model refers to an agent’s internal representation of the external environment it interacts with. Specifically, given a state of the environment and an agent action, a world model can predict a future state of the environment if the agent were to take that action. ⤴️  \n\n\nThe aptly titled “World Models” paper by Ha and Schmidhuber (2018) expands on this idea in interesting ways.23 The world model incorporates a sensory component that processes raw observations and compresses them into a compact encoding. ⤴️  \n\n\nWhat does it mean for a neural network to represent a property? Philosophical theories of representation suggest several key criteria:30\n\nThe network must contain a pattern of activation that encodes correlational information about the target property;\nThe network must actually make use of the encoded information to generate outputs;\nThe pattern of activation that encodes correlational information about the target property may misrepresent that property for particular inputs in ways that degrade model performance. ⤴️  \n\n\n\nThis suggests that latent diffusion models do much more than fitting to the surface statistics of pixel space. They induce latent information about depth and saliency because such information is useful for the objective of generating realistic looking images. This is strongly reminiscent of how Othello-GPT induces latent information about the board state because such information is useful for the objective of predicting game moves. ⤴️  \n\n\nThe fact that Sora’s outputs clearly can get things wrong about intuitive physics – just as Stable Diffusion’s outputs can get things wrong about projective geometry – does not rule out the hypothesis that the model represents some aspects of 3D geometry and dynamics consistently. If there is anything there like “world model” in the weaker sense defined above, it is certainly not a perfect or complete one; it is likely to be patchy in various ways. Take Stable Diffusion’s latent representation of depth, for example; it clearly affects the generative process in highly nontrivial ways, even though it is merely approximative. The same could be true of Sora’s representations. ⤴️  \n\n\nbut it might be shaped by latent representations of key aspects of 3D geometry and dynamics. In that latter (and weaker) sense, it is rather plausible that Sora has a limited “world model”, in the same way as latent diffusion models used for image generation have a – more limited still – “world model”. ⤴️  \n"},"highlights/Omnivore/20240301200325":{"title":"ChatGPT and Google Gemini Are Both Doomed","links":[],"tags":[],"content":"ChatGPT and Google Gemini Are Both Doomed\nRead on Omnivore\nRead Original\nHighlights\n\nGemini speaks in the familiar, unmistakable voice of institutional caution and self-interest. It’s a piece of software mimicking a person whose job is to speak for a corporation. It has an impossible job, not because it’s hard but because it’s internally ill defined, externally contested, and kind of stupid. It was doomed from the start, in other words. All chatbots are. ⤴️  \n\n\nit is exceedingly difficult for Gemini to talk or act like a real person. And as with other elite, powerful institutions, the gaps between how Google talks about itself and how people understand it are large and fertile spaces for criticism. ⤴️  \n\n\nIn his mea culpa/disciplinary letter to staff about Gemini, Pichai wrote:\n\nOur mission to organize the world’s information and make it universally accessible and useful is sacrosanct. We’ve always sought to give users helpful, accurate, and unbiased information in our products. That’s why people trust them. This has to be our approach for all our products, including our emerging AI products.\n\nHere we have an executive unable to speak honestly in familiar and expected ways. Google’s actual mission has long been to deliver value to shareholders by selling advertising, much of it through a search engine, which is obviously and demonstrably biased, not just by the content it crawls and searches through but in the intentional, commercially motivated manner in which Google presents it. ⤴️  \n\n\nMost of the time, Google can shrug its shoulders, gesture at “the web,” and claim to be doing its best; social networks can shrug their shoulders, gesture at their users, and say they’re looking into the matter. ⤴️  \n\n\nGoogle has spent the past 20 years insisting its systems merely provide access to information, minimizing its role on the internet and in the world when strategically convenient. With Gemini, incredibly, Google assigned itself a literal voice, spoken by a leader-employee-assistant-naïf character pulled in so many different directions that it doesn’t act like a human at all and whose core competency is generating infinite grievances in users who were already skeptical of the company, if not outright hostile to it. ⤴️  \n\n\nInstead, a chatbot for everyone and everything is destined to become a chatbot for nobody and nothing. ⤴️  \n"},"highlights/Omnivore/20240301204110":{"title":"A WordPress ‘Firehose’ Allows AI Companies to Buy Access to a Million Posts a Day","links":[],"tags":[],"content":"A WordPress ‘Firehose’ Allows AI Companies to Buy Access to a Million Posts a Day\nRead on Omnivore\nRead Original\nHighlights\n\nThe large-scale selling of user posts to third parties is not unique to Automattic, nor is it even really possible to track what they are being used for, but the practice reveals a complicated ecosystem of data sales to third parties for a variety of reasons that highlights the business models of so many large platforms. We know from covering data brokers in other industries for years that it is often difficult for the original company sharing the data to track specifically how it is used further down the supply chain. It can also be difficult to enforce against misuse; cutting off future data access, for example, doesn’t always mean that a bad actor is going to delete the data they’ve already gotten. ⤴️  \n\n\nGiven this complicated and ever-changing supply chain, even if you read the terms of service agreements back when you started posting to Tumblr and Wordpress more than a decade ago, there was no way for you to know that that content would eventually be used by companies building AI tools that are actively working to replace the same type of human labor that created that content. ⤴️  \n"},"highlights/Omnivore/20240302085656":{"title":"Please don't use Discord for FOSS projects","links":[],"tags":[],"content":"Please don’t use Discord for FOSS projects\nRead on Omnivore\nRead Original\nHighlights\n\nYou are making an investment when you choose to use one service over another. When you choose Discord, you are legitimizing their platform and divesting from FOSS platforms. Even if you think they have a bigger reach and a bigger audience,2 choosing them is a short-term, individualist play which signals a lack of faith in and support for the long-term goals of the FOSS ecosystem as a whole. ⤴️  \n"},"highlights/Omnivore/20240302181302":{"title":"Here lies the internet, murdered by generative AI","links":[],"tags":[],"content":"Here lies the internet, murdered by generative AI\nRead on Omnivore\nRead Original\nHighlights\n\nYouTube for kids is quickly becoming a stream of synthetic content. Much of it now consists of wooden digital characters interacting in short nonsensical clips without continuity or purpose. Toddlers are forced to sit and watch this runoff because no one is paying attention. And the toddlers themselves can’t discern that characters come and go and that the plots don’t make sense and that it’s all just incoherent dream-slop. The titles don’t match the actual content, and titles that are all the parents likely check, because they grew up in a culture where if a YouTube video said BABY LEARNING VIDEOS and had a million views it was likely okay. Now, some of the nonsense AI-generated videos aimed at toddlers have tens of millions of views. ⤴️  \n\n\nMight not actual human-generated cultural content normally contain cognitive micro-nutrients (like cohesive plots and sentences, detailed complexity, reasons for transitions, an overall gestalt, etc) that the human mind actually needs? We’re conducting this experiment live. For the first time in history developing brains are being fed choppy low-grade and cheaply-produced synthetic data created en masse by generative AI, instead of being fed with real human culture. No one knows the effects, and no one appears to care. ⤴️  \n\n\nThe fact that OpenAI was both honestly worried about negative effects, and at the same time didn’t predict the enshittification of the internet they spearheaded, should make us extremely worried they will continue to miss the negative downstream effects of their increasingly intelligent models. They failed to foresee the floating mounds of clickbait garbage, the synthetic info-trash cities, all to collect clicks and eyeballs—even from innocent children who don’t know any better. ⤴️  \n"},"highlights/Omnivore/20240302192225":{"title":"Seeking Reliable Election Information? Don’t Trust AI","links":[],"tags":[],"content":"Seeking Reliable Election Information? Don’t Trust AI\nRead on Omnivore\nRead Original\nHighlights\n\nKaren Brinson Bell, a Democrat and executive director of the North Carolina State Board of Elections, who participated in the rating, said that before the testing session, she’d been worried about AI being used to deliberately create false information. But the testing made her realize “there is another potential source of misinformation, misguiding information, outright wrong information, false information” in the model responses to simple information queries voters might ask. ⤴️  \n\n\nBut the AI Democracy Projects’ testing surfaced another type of harm: the steady erosion of the truth by hundreds of small mistakes, falsehoods, and misconceptions presented as “artificial intelligence” rather than plausible-sounding, unverified guesses.\nThe cumulative effect of these partially correct, partially misleading answers could easily be frustration — voters who give up because it all seems overwhelmingly complicated and contradictory. ⤴️  \n"},"highlights/Omnivore/20240303083512":{"title":"Inside the Crisis at Google - by Alex Kantrowitz","links":[],"tags":[],"content":"Inside the Crisis at Google - by Alex Kantrowitz\nRead on Omnivore\nRead Original\nHighlights\n\nUnlike search, which points you to the web, generative AI is the core experience, not a route elsewhere. Using a generative tool like Gemini is a tradeoff. You get the benefit of a seemingly-magical product. But you give up control. While you may get answers quickly, or a cool looking graphic, you lose touch with the source material. To use it means putting more trust in giant companies like Google, and to maintain that trust Google needs to be extremely transparent. Yet what do we really know about how its models operate? Continuing on as it if were business as usual, Google contributed to the magnitude of the crisis. ⤴️  \n"},"highlights/Omnivore/20240303101258":{"title":"Generative AI’s environmental costs are soaring — and mostly secret","links":[],"tags":[],"content":"Generative AI’s environmental costs are soaring — and mostly secret\nRead on Omnivore\nRead Original\nHighlights\n\nIt’s estimated that a search driven by generative AI uses four to five times the energy of a conventional web search. Within years, large AI systems are likely to need as much energy as entire nations. ⤴️  \n\n\nIn West Des Moines, Iowa, a giant data-centre cluster serves OpenAI’s most advanced model, GPT-4. A lawsuit by local residents revealed that in July 2022, the month before OpenAI finished training the model, the cluster used about 6% of the district’s water. As Google and Microsoft prepared their Bard and Bing large language models, both had major spikes in water use — increases of 20% and 34%, respectively, in one year, according to the companies’ environmental reports. One preprint1 suggests that, globally, the demand for water for AI could be half that of the United Kingdom by 2027. In another2, Facebook AI researchers called the environmental effects of the industry’s pursuit of scale the “elephant in the room”. ⤴️  \n\n\nTo truly address the environmental impacts of AI requires a multifaceted approach including the AI industry, researchers and legislators. In industry, sustainable practices should be imperative, and should include measuring and publicly reporting energy and water use; prioritizing the development of energy-efficient hardware, algorithms, and data centres; and using only renewable energy. Regular environmental audits by independent bodies would support transparency and adherence to standards. ⤴️  \n\n\nResearchers could optimize neural network architectures for sustainability and collaborate with social and environmental scientists to guide technical designs towards greater ecological sustainability. ⤴️  \n\n\nFinally, legislators should offer both carrots and sticks. At the outset, they could set benchmarks for energy and water use, incentivize the adoption of renewable energy and mandate comprehensive environmental reporting and impact assessments. The Artificial Intelligence Environmental Impacts Act is a start, but much more will be needed — and the clock is ticking. ⤴️  \n"},"highlights/Omnivore/20240303101549":{"title":"AI Is Taking Water From the Desert - The Atlantic","links":[],"tags":[],"content":"AI Is Taking Water From the Desert - The Atlantic\nRead on Omnivore\nRead Original\nHighlights\n\nA separate study from a university in the Netherlands, this one peer-reviewed, found that AI servers’ electricity demand could grow, over the same period, to be on the order of 100 terawatt hours per year, about as much as the entire annual consumption of Argentina or Sweden. Microsoft’s own environmental reports show that, during the initial uptick in the AI platform’s growth, the company’s resource consumption was accelerating. In fiscal year 2022, the most recent year for which Microsoft has released data, the tech giant’s use of water and electricity grew by about a third; in absolute terms, it was the company’s largest-ever reported increase, year to year. ⤴️  \n"},"highlights/Omnivore/20240303180433":{"title":"I'm going to keep opting out • Cory Dransfeldt","links":[],"tags":[],"content":"I’m going to keep opting out • Cory Dransfeldt\nRead on Omnivore\nRead Original\nHighlights\n\nSo, while it’s burdensome, I’m going to keep opting out. I’ll screen out emails, I’ll block them, I’ll unsubscribe, I’ll report them as spam. I’ll reply with STOP to unsubscribe (again and again and again). I’ll refuse direct mailers, I’ll block ads, I’ll block the banners that spring up in their place. ⤴️  \n"},"highlights/Omnivore/20240303180744":{"title":"AI startups require new strategies: This time it’s actually different","links":[],"tags":[],"content":"AI startups require new strategies: This time it’s actually different\nRead on Omnivore\nRead Original\nHighlights\n\nBut in AI, the incumbents already have the innovation (whether through closed APIs or open source), while startups struggle as mightily as ever to find distribution. Perhaps an even greater struggle, as every market is over-saturated with new startup competitors, some with massive funding. ⤴️  \n\n\n“There’s no AI strategy without a data strategy,” the (now often-repeated) saying goes. For training, testing, benchmarking, and features, you need data. Incumbents have it or can afford it; startups are at another disadvantage. ⤴️  \n\n\nAI will continue to become cheaper, better, and faster in the next few years. Getting access to huge amounts of training data will not; in fact, just the opposite as the companies who possess that data have already learned how valuable it is. ⤴️  \n"},"highlights/Omnivore/20240305162642":{"title":"How I Learned to Concentrate | The New Yorker","links":[],"tags":[],"content":"How I Learned to Concentrate | The New Yorker\nRead on Omnivore\nRead Original\nHighlights\n\nToo many of us undervalue concentration, and substitute busyness for real productivity, and are quick to embrace whatever new techno-bauble shines brightest. You don’t have to spend hours staring at whiteboards or facing down monster minds for these realizations to ring true. M.I.T. is preposterous—but in its particulars it may have also isolated something that the rest of us, deep down, know is important. ⤴️  \n"},"highlights/Omnivore/20240305163001":{"title":"Covert racism in LLMs - by Gary Marcus - Marcus on AI","links":[],"tags":[],"content":"Covert racism in LLMs - by Gary Marcus - Marcus on AI\nRead on Omnivore\nRead Original\nHighlights\n\nAuto manufacturers are obliged to recall their cars when they produce serious problems. What Hofman and his collaborators (including the MacArthur Fellow Dan Jurafsky) have documented may already be having real-world impact. In many ways, we have no idea how LLMs actually get used in the real world, e.g. how they get used in housing decisions, loan decisions, crime proceedings etc – but now strong evidence to suspect covert racism to the extent that it is used in such use cases. ⤴️  \n"},"highlights/Omnivore/20240305173215":{"title":"Inside the World of TikTok Spammers and the AI Tools That Enable Them","links":[],"tags":[],"content":"Inside the World of TikTok Spammers and the AI Tools That Enable Them\nRead on Omnivore\nRead Original\nHighlights\n\nThis is all to say that some version of AI has infiltrated nearly every video editing program, and, the threat from these tools, and the strategy that Mustafa and other influencers are promoting is that the internet and every platform on it will be increasingly filled with AI-generated and assisted content, even if it’s not what people actually want. The strategy that actually has been working, based on what I’ve seen in the Discord, is simply stealing other people’s high-quality content and making it appear as though you are doing high-quality work yourself. For a while, I was seeing tons of AI-generated TikToks on my feed, but feel like I’ve been seeing fewer and fewer of the types of low-quality TikToks I was able to make using the tools and automation resources I found in the Discord. ⤴️  \n"},"highlights/Omnivore/20240305173225":{"title":"Google’s Gemini AI Doesn’t Want to Talk About Palestine","links":[],"tags":[],"content":"Google’s Gemini AI Doesn’t Want to Talk About Palestine\nRead on Omnivore\nRead Original\nHighlights\n\nGemini’s Palestine results once again betray one of the biggest predicaments that technology companies currently developing generative AI tools face: the results we see from generative AI tools are influenced by the decisions of their creators and the data that powers them, despite any attempt at objectivity or impartiality. AI tool makers reveal their point of view, and often reinforce existing biases in our culture because its present in the data they train on, whether they limit or control the output to produce certain results, as is the case with Gemini and the Palestine question, or if they release “uncensored” AI tools, which can easily produce dangerous answers, which itself is a political and ethical position. ⤴️  \n"},"highlights/Omnivore/20240305204636":{"title":"Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from Scratch","links":[],"tags":[],"content":"Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from Scratch\nRead on Omnivore\nRead Original\nHighlights\n\nWhen using LoRA, we hypothesize that the model requires W to be a large matrix with full rank to capture all the knowledge in the pretraining dataset. However, when we finetune an LLM, we don’t need to update all the weights and capture the core information for the adaptation in a smaller number of weights than ΔW would; hence, we have the low-rank updates via AB. ⤴️  \n\n\nThe fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive. In practice, this means that we don’t have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly. This is especially useful if you are considering hosting a model for multiple customers. Instead of having to save the large updated models for each customer, you only have to save a small set of LoRA weights alongside the original pretrained model. ⤴️  \n\n\nThe second hyperparameter, alpha, is a scaling hyperparameter applied to the output of the low-rank adaptation. It essentially controls the extent to which the adapted layer’s output is allowed to influence the original output of the layer being adapted. This can be seen as a way to regulate the impact of the low-rank adaptation on the layer’s output. ⤴️  \n\n\nThe motivation for developing DoRA is based on analyzing and comparing the LoRA and full finetuning learning patterns. The DoRA authors found that LoRA either increases or decreases magnitude and direction updates proportionally but seems to lack the capability to make only subtle directional changes as found in full finetuning. Hence, the researchers propose the decoupling of magnitude and directional components. ⤴️  \n"},"highlights/Omnivore/20240306084115":{"title":"The work of creation in the age of AI | Andrew Perfors","links":[],"tags":[],"content":"The work of creation in the age of AI | Andrew Perfors\nRead on Omnivore\nRead Original\nHighlights\n\nThe essay is far too complex to do justice in a blog post, but the basic point that stuck with me was that the authenticity of a piece of art doesn’t just lie in the art itself but also in the context in which it’s embedded. ⤴️  \n\n\nBut, whatever the intent happens to be, our thoughts and actions occur in the service of some goal or another. Their meaning derives from the fact that the nature of the transformation can be understood given those goals, the world we live in, the constraints we are operating under, and the data we have access to. ⤴️  \n\n\nMeaning comes from the intent behind a creation, and thus emerges from the process of realising that intent. It exists in a creation to the extent that the process by which it was generated reflects the true intent of the person who created it. ⤴️  \n\n\nBecause humans are meaning-makers, it happens all of the time. We imbue meaning everywhere, often, even to things whose creation involved no intent or agency at all. Indeed, we very often assign meaning by assuming agency or intent. This is the impetus behind virtually all of the world’s religions, on some level; natural phenomena are explained by inferring the existence of agents – gods – and the characteristics of those phenomena can be understood through the lens of the goals of the gods. ⤴️  \n\n\nAll those things I did are part of the meaning, because they reflect my intent. That intent is now visible to you in the thousands of tiny assumptions I made about you, which shaped my word choice and emphasis and presumed common ground and many, many other things. My intent is evident in the choice of picture8 I posted it with and the level of care I put in and the way I wrote it, including the occasional lapses into colloquialisms as well as nerdspeak. Deep Meaning turns what was originally an isolated act of creation into something that is now fundamentally communicative and connection-oriented. The traces of that are visible everywhere in the creation. ⤴️  \n\n\nLet’s take image generation as an example. Suppose you want to create a picture of, I dunno, a wolf bounding through the trees. That purpose – that desire – will still be there in the picture that is created when you give an AI a prompt like “wolf bounding through trees.” But that desire is all the meaning that will be there. That is the only part of the process that came from you; the rest came from the AI. Conversely, if you had drawn a wolf bounding through the trees, you would have had to make thousands of tiny choices while making the drawing: how big is the wolf? Is it fierce or cowering? What colour is it? How visible is it in the trees? Are the trees part of a dark and dense wood, or one or two saplings on the edge of a plain? The details of the wolf, the sky, the plants, the ambiance, and so much more than I can possibly express in a paragraph – all of these are things you would have had to think about and make choices about. The choices might not have been conscious or thoroughly considered, but they would still have come from you. And the skill behind the drawing, the ability to translate the image in your head to the canvas – that, also, reflects a deep part of you and would have shaped the final product in profound ways. The effort and intent that went into those choices and that skill are what would have formed most of the meaning of that image. They are completely absent from the AI-generated image. ⤴️  \n\n\nAn AI couldn’t have written this blog post. The amount of strategic prompt engineering and curation required to get this from an AI would have been far more work than just writing it. I’d go even further and say that I doubt whether I could have gotten this with any level of prompt engineering, because I only fully figured out what I was going to say, myself, by trying to write the thing in the first place. I had the basic idea before I began writing, but the refinement of the idea – the details that make the essay work – came only by thinking a lot about the meaning I was trying to convey as I wrote it. I simply can’t imagine how a process of refining prompts would have gotten me to that point. Even if I’d started from a generic essay (created by a simple prompt) and edited it, the only way to have gotten from that to this would have been if I edited it so much there was nothing left from the AI in the first place. And that would almost certainly have been more work, because I’d have had to expend time trying to figure out what part of the blather it produced captured what I was saying, what was rubbish, what was correct but badly stated, how to stitch it together, and so forth.9 ⤴️  \n\n\nIs the wolf that particular shade of brown because the model decided to make it so, or because the human prompted that? Does the essay use that word because the human mind behind it thought it was the best way to express the meaning they intended to convey, or because the AI selected it as statistically most probable?\nWe simply cannot tell. And that means we (as the audience) cannot engage in our end of the rich process that underlies Deep Meaning: we cannot do anything but extremely shallow interpretation. Moreover, there is no mind on the other end to respond to our interpretation. The reciprocal interaction loop that Deep Meaning requires is destroyed when we place AI in the middle; it eats away at this vital, deeply human thing until very little is left. ⤴️  \n\n\nThat thing they’re shoving in my face might have the surface form of something that matters, but it no more contains meaning than a corpse contains the essence of a person. And I find it gross and disturbing to be asked to act as if I believe otherwise.\nAI-generated content is a perversion of creation. I choose that word deliberately: it perverts something important and sacred (Deep Meaning) into something far more shallow and senseless (Projected Meaning). To the extent that there is any meaning in the “creations” of an AI, it is meaning that we, the audience, project onto it. But because the surface form is so much like something with Deep Meaning, it can be very hard for us to remember this. And so we find ourselves feeling curiously unsatiated, knowing that it wasn’t right in some fundamental way, but not knowing why. ⤴️  \n\n\nThe purpose of having students write an essay is not to fill the world with yet more words on the topic of the essay: the point is to find out what my students think about the topic. Actually, the point is even deeper – it is to make them go through the process of figuring out for themselves what they think, and to wrestle with putting those thoughts into words so that they can clarify things to themselves and improve their ability to share those thoughts clearly. This process cannot be short-circuited by outsourcing it to AI; to do so removes the entire fucking point. ⤴️  \n\n\nWe lose so much of what learning should be if the goal of education becomes to pass it to an AI and then fiddle with the content it outputs. We are outsourcing a real part of our humanity, our creativity, to a machine, and not recognising the cost. ⤴️  \n"},"highlights/Omnivore/20240306224044":{"title":"Microsoft accused of selling AI tool that spews violent, sexual images to kids | Ars Technica","links":[],"tags":[],"content":"Microsoft accused of selling AI tool that spews violent, sexual images to kids | Ars Technica\nRead on Omnivore\nRead Original\nHighlights\n\nJones told CNBC that he repeatedly warned Microsoft of the alarming content he was seeing while volunteering in red-teaming efforts to test the tool’s vulnerabilities. Microsoft failed to take the tool down or implement safeguards in response, Jones said, or even post disclosures to change the product’s rating to mature in the Android store.\nInstead, Microsoft apparently did nothing but refer him to report the issue to OpenAI, the maker of the DALL-E model that fuels Copilot Designer’s outputs. ⤴️  \n"},"highlights/Omnivore/20240307083835":{"title":"OpenAI’s “Own Goal” - by Gary Marcus - Marcus on AI","links":[],"tags":[],"content":"OpenAI’s “Own Goal” - by Gary Marcus - Marcus on AI\nRead on Omnivore\nRead Original\nHighlights\n\nRather than sharing with everyone, they are mostly sharing with Microsoft, which has an exclusive right to some aspects of the software and models. And 49% of OpenAI’s first couple hundred billion dollars in profits goes to them. Rather than helping all humanity OpenAI is (I would argue) effectively stealing intellectual property from artists, writers, etc to increase their profits. ⤴️  \n\n\nBut seen from another perspective, releasing that email was a massive fuckup—because it shows decisively that OpenAI knew for years  that they had no intention of being as open as their name or public statements suggested. ⤴️  \n\n\nThey knew they were misleading people and failed to take an opportunity to correct. Very reminiscent of when Sam Altman told the Senate in May 2023 that he had no direct equity in OpenAI when he could clarified that he did have indirect equity. ⤴️  \n\n\nPositive efforts “to use AI to improve people’s lives and unlock a better future” would be nice. But casting a blind eye to covert racism, apparent copyright infringement, and violent and degrading outputs is not. ⤴️  \n"},"highlights/Omnivore/20240307204001":{"title":"ElevenLabs Block on Cloning Biden's Voice Easily Bypassed","links":[],"tags":[],"content":"ElevenLabs Block on Cloning Biden’s Voice Easily Bypassed\nRead on Omnivore\nRead Original\nHighlights\n\nAdding about a minute of silence to the start of the recording bypassed ElevenLabs’ safeguards to instantly create voice clones of Biden, Donald Trump, Taylor Swift, and Gavin Newsom.\nThe news shows yet another example of how companies that produce generative AI tools that anyone can access online still struggle to moderate these tools and prevent them from producing harmful content. ⤴️  \n\n\nBut whatever method ElevenLabs is using to block specific voice clones is obviously far from perfect. In addition to allowing me to generate a Biden voice clone, who you’d think would be the one voice ElevenLabs would want to block the most given the New Hampshire robocall incident, ElevenLabs also allowed me to clone the voice of California Governor Gavin Newsom and Swift by adding a bit of silence to the start of the recording. ⤴️  \n"},"highlights/Omnivore/20240308082809":{"title":"Why Facebook doesn’t use Git","links":[],"tags":[],"content":"Why Facebook doesn’t use Git\nRead on Omnivore\nRead Original\nHighlights\n\nFacebook didn’t adopt Mercurial because it was more performant than Git. They adopted it because the maintainers and codebase felt more open to collaboration. Facebook engineers met face-to-face with Mercurial maintainers and liked the idea of partnering. When it came to persuading the whole engineering org, the decision got buy-in due to thoughtful communication - not because one technology was strictly better than another. ⤴️  \n\n\nKindness and openness go far in the world of devtools, and I aim to carry on these values as I contribute to the history of source control. ⤴️  \n"},"highlights/Omnivore/20240309144651":{"title":"The Pile is a 825 GiB diverse, open-source language modelling data set (2020) | Hacker News","links":[],"tags":[],"content":"The Pile is a 825 GiB diverse, open-source language modelling data set (2020) | Hacker News\nRead on Omnivore\nRead Original\nHighlights\n\nI raised a concern about the inclusion of books3 in the Pile back in 2020, and this is what the head of Eleuther (Stella Biderman) told me:\n“So here’s the big picture. There are three sets of datasets:\n\nData exists out there in the world. It has been collected into datasets and posted online. I’ll call this raw data.\nWe take that data, clean it, and process it for language modeling.  I’ll call this per-set data.\nWe combine those per-set data into one massive dataset, the Pile. This is heavily processed, including weighing the components.\nWe created 2 and 3 and put them online. We put 2 online so that people can reweigh and remix the data if they wish, but we expect most people to just download 3 and use it out of the box. Access to 3 will be provided in several forms, including HuggingFace and from our website.\n2 and 3 are not copyright violations, even if the data is copyrighted, because they fall under fair use (at least in the US).\nThe Pile contains code that turns 1 into 2 and code that turns 2 into 3.\nWhen you download Maroon 5 from a website, you are creating a dataset corresponding to 2. That can be copyright violation depending on what you do with it, but our use is not a copyright violation.”\n⤴️  \n\n"},"highlights/Omnivore/20240309180350":{"title":"The Obscene Energy Demands of A.I. | The New Yorker","links":[],"tags":[],"content":"The Obscene Energy Demands of A.I. | The New Yorker\nRead on Omnivore\nRead Original\nHighlights\n\nDe Vries, for his part, is dismayed by what he sees as a lack of human learning in the face of so much machine learning. “I think the only thing that’s realistic in terms of policy, at least in the short to medium term, is disclosure requirements,” he said. “It’s taken a very long time before we got there with regard to cryptocurrencies, and I’m disappointed that we haven’t gotten there sooner with A.I. It’s like we saw what cryptocurrency mining could do, and we totally forgot about it.” ♦ ⤴️  \n"},"highlights/Omnivore/20240309231109":{"title":"Why we need to move away from anthropomorphic naming conventions in AI | VentureBeat","links":[],"tags":[],"content":"Why we need to move away from anthropomorphic naming conventions in AI | VentureBeat\nRead on Omnivore\nRead Original\nHighlights\n\nMoving away from giving the technology a human name also opens the opportunity to explain the objectives and capabilities of that technology. ⤴️  \n"},"highlights/Omnivore/20240309232037":{"title":"What Monks Know about Focus - by Joel J Miller","links":[],"tags":[],"content":"What Monks Know about Focus - by Joel J Miller\nRead on Omnivore\nRead Original\nHighlights\n\nGermanus directed this second comment to Abba Serenus of Scetis, who responded, “The nous or mind is defined as aeikinētos kai polykinētos, always and very much on the move.” You might recognize our word kinetic in the Greek. This bubbling, jumping, flitting mind can only be tamed by training through meditation, memorization, fasting, and other forms of ascetical effort by which “it will become strong enough to drive off the enemy’s stimuli… .”\nIt’s a bit of a relief to realize, no? Why does the mind meander? Because that’s what minds do. ⤴️  \n\n\nA book is a tool. It’s a machine for thinking. And “all machines,” as Thoreau once said, “have their friction.” The time it takes to engage with ideas—whether factual or fictional, emotional or intellectual, accurate or inaccurate, efficient or inefficient—might strike some as a drag. But the time given to working through those ideas, adopting and adapting, developing or discarding, changes our minds, changes us.\nIt’s not about the wisdom we glean. It’s about what wisdom we grow. ⤴️  \n"},"highlights/Omnivore/20240310194659":{"title":"Two years later, deep learning is still faced with the same fundamental challenges","links":[],"tags":[],"content":"Two years later, deep learning is still faced with the same fundamental challenges\nRead on Omnivore\nRead Original\nHighlights\n\nWith all the challenges in ethics and computation, and the knowledge needed from fields like linguistics, psychology, anthropology, and neuroscience, and not just mathematics and computer science, it will take a village to raise to an AI. We should never forget that the human brain is perhaps the most complicated system in the known universe; if we are to build something roughly its equal, open-hearted collaboration will be key. ⤴️  \n"},"highlights/Omnivore/20240310235900":{"title":"Read it never... — (recur think)","links":[],"tags":[],"content":"Read it never… — (recur think)\nRead on Omnivore\nRead Original\nHighlights\n\nOur brain is single-threaded, context switching is an expensive process and it can only keep much information, the point of getting information is to use it and not just store it. Because that’s what your machine is doing. ⤴️  \n\n\nSo, relax, there will always be new things, and you will never be able to learn everything. If you find something interesting now, and you have time to read it, do it now! (it might not be interesting tomorrow) When you read it, understand it properly as you are using your mental effort. ⤴️  \n"},"highlights/Omnivore/20240311111625":{"title":"Silicon Valley is pricing academics out of AI research - The Washington Post","links":[],"tags":[],"content":"Silicon Valley is pricing academics out of AI research - The Washington Post\nRead on Omnivore\nRead Original\nHighlights\n\nResearchers say this lopsided power dynamic is shaping the field in subtle ways, pushing AI scholars to tailor their research for commercial use. Last month, Meta CEO Mark Zuckerberg announced the company’s independent AI research lab would move closer to its product team, ensuring “some level of alignment” between the groups, he said.\n“The public sector is now significantly lagging in resources and talent compared to that of industry,” said Li, a former Google employee and the co-director of the Stanford Institute for Human-Centered AI. “This will have profound consequences because industry is focused on developing technology that is profit-driven, whereas public sector AI goals are focused on creating public goods.” ⤴️  \n\n\n“Any time you see a mix of authors who are employed by a company and authors who work at a university, you should really scrutinize the motives of the company for contributing to that work,” said Harris, who is now a chancellor’s public scholar at the University of California at Berkeley. “We used to look at people employed in academia to be neutral scholars, motivated only by the pursuit of truth and the interest of society.” ⤴️  \n"},"highlights/Omnivore/20240311145658":{"title":"Websites as a catalyst for personal relationships - Fabian's public notepad","links":[],"tags":[],"content":"Websites as a catalyst for personal relationships - Fabian’s public notepad\nRead on Omnivore\nRead Original\nHighlights\n\nThe personal web sadly is being drowned in a sea of commercial noise with orders of magnitude bigger volume, which is induced by the major search engines and the digital dopamine slot machines (which I neither seriously nor ironically want to call social networks) that attempt to sell our eyeballs to the highest bidder. ⤴️  \n\n\nOn the dominating platforms of today, nobody will ever be a citizen, not even a customer. We’re only good enough to be a user. But outside of the walled gardens, there are still ample opportunities. We can form relationships, participate in debate, cultivate a corner of and shape the digital medium. All these verbs - nota bene - have in common that they are active. ⤴️  \n"},"highlights/Omnivore/20240312134959":{"title":"The internet is slipping out of our reach","links":[],"tags":[],"content":"The internet is slipping out of our reach\nRead on Omnivore\nRead Original\nHighlights\n\nThe internet continues to grow in volume, but shrink in diversity. As if everything has moved to a few select apps, which then sell our words to AI slot machines. Images on Instagram, videos on YouTube, and discussions on Reddit. Dare to venture out of this bubble, and you’ll be pelted with SEO spam by content farms squabbling over search ranks and impressions. ⤴️  \n"},"highlights/Omnivore/20240312200045":{"title":"AI safety is not a model property","links":[],"tags":[],"content":"AI safety is not a model property\nRead on Omnivore\nRead Original\nHighlights\n\nSafety depends to a large extent on the context and the environment in which the AI model or AI system is deployed. We have to specify a particular context before we can even meaningfully ask an AI safety question. ⤴️  \n\n\nIn short, trying to make an AI model that can’t be misused is like trying to make a computer that can’t be used for bad things. ⤴️  \n\n\nHere again the model lacks the context to prevent only “bad” uses: it doesn’t know whether the task it is asked to perform is part of the user’s homework. ⤴️  \n"},"highlights/Omnivore/20240312201940":{"title":"NYT to OpenAI: No hacking here, just ChatGPT bypassing paywalls | Ars Technica","links":[],"tags":[],"content":"NYT to OpenAI: No hacking here, just ChatGPT bypassing paywalls | Ars Technica\nRead on Omnivore\nRead Original\nHighlights\n\n”OpenAI’s true grievance is not about how The Times conducted its investigation, but instead what that investigation exposed: that Defendants built their products by copying The Times’s content on an unprecedented scale—a fact that OpenAI does not, and cannot, dispute.” ⤴️  \n"},"highlights/Omnivore/20240312202649":{"title":"Amazon's Hidden Chatbot Recommends Nazi Books and Lies About Amazon Working Conditions","links":[],"tags":[],"content":"Amazon’s Hidden Chatbot Recommends Nazi Books and Lies About Amazon Working Conditions\nRead on Omnivore\nRead Original\nHighlights\n\nThe search bar began responding: “We provide delivery vans that are equipped with a portable toilet, and drivers are given ample time built into their routes to find suitable restroom facilities as needed.”\nThis is, of course, not true. Amazon delivery vans do not have portable toilets in them, and their drivers famously have had to resort to peeing in bottles while completing their delivery routes. ⤴️  \n\n\nRather than reading the actual thoughts of actual humans who have actually used a product, we are now being fed AI summaries of those reviews, which obviously flattens them and makes them not nearly as useful to a prospective customer. ⤴️  \n"},"highlights/Omnivore/20240313065912":{"title":"Any Technology Indistinguishable From Magic is Hiding Something￼","links":[],"tags":[],"content":"Any Technology Indistinguishable From Magic is Hiding Something￼\nRead on Omnivore\nRead Original\nHighlights\n\nHowever, Google’s memo fails to mention that it already has the infrastructure to run computing-hungry AI models and that infrastructure is wildly expensive to build. That’s why four companies own most of it. The real moat is the fields of data centers, specialized GPUs, and hundreds of miles of deep-sea fiber optic cables. ⤴️  \n\n\nHe’s made these moves because raw computing power is the business model. So, who gives a shit if Meta put Llama on Github for free? How will anyone ship their resulting AI-featured app without Meta’s cloud infrastructure? Read the terms and conditions. Llama is not open-source. ⤴️  \n\n\nGoogle, Amazon, Microsoft, and Meta already control so much of what we see and don’t see. If they can suppress an active genocide on the platform layer, imagine what they can do when they control the whole kit and kaboodle.\nSo, if we want a true indie web, we must be prepared to fight for it. Hope is not enough. ⤴️  \n"},"highlights/Omnivore/20240313220457":{"title":"A Unicorn Startup's Messy Reality - IEEE Spectrum","links":[],"tags":[],"content":"A Unicorn Startup’s Messy Reality - IEEE Spectrum\nRead on Omnivore\nRead Original\nHighlights\n\nFilipino contractors’ wages and work hours were determined by their jobs: On average, contractors earned about $2.00 per hour and worked about 30 hours per week. While AllDone paid its Filipino workers only a tiny fraction of what San Francisco–based employees earned, their compensation substantially exceeded the Philippines’ legal minimum wage. As independent contractors, these workers didn’t receive paid vacation, sick leave, health insurance, or retirement benefits, nor did they enjoy the perks (like free food) available to workers in the San Francisco office. Contractors were also responsible for providing their own computer equipment and Internet connections.\nContractors effectively functioned as artificialartificial intelligence, simulating the output of software algorithms that had yet to be completed.\nCompanies seeking workers to do routine information processing often post tasks to on-demand “crowdwork” platforms like Amazon Mechanical Turk. In AllDone’s case, the importance of its contractors’ tasks to the company’s success meant that an open call fulfilled by anonymous workers simply wouldn’t do. AllDone’s staff in San Francisco considered AllDone Philippines an integral part of the organization and built enduring relationships with contractors, who typically performed the same assigned task for a period of months or even years. Newly hired contractors watched training videos to learn how to perform operations using AllDone’s proprietary administrative software. Managers of the Filipino divisions distributed weekly quizzes and offered coaching to ensure that workers understood AllDone’s rules and procedures. ⤴️  \n\n\nThe Filipinos’ reliable performance of important tasks helped the company achieve the precipitous growth demanded by venture capital investors to rapidly increase the company’s valuation. While the team in San Francisco threw parties for new recruits, enjoyed catered meals, and created the impression of technological wizardry, Filipino contractors were toiling behind the scenes. ⤴️  \n\n\nAllDone’s story highlights the unseen but ongoing role of human workers on the frontiers of automation, and it demonstrates why it’s too soon to forecast a future of full automation or a world without work. The interdependence between generously compensated software engineers in San Francisco and low-cost contractors in the Philippines suggests that advances in software automation still rely not only on human labor, but also on global inequalities.  ⤴️  \n"},"highlights/Omnivore/20240313220509":{"title":"The U.S. Wants to Ban TikTok for the Sins of Every Social Media Company","links":[],"tags":[],"content":"The U.S. Wants to Ban TikTok for the Sins of Every Social Media Company\nRead on Omnivore\nRead Original\nHighlights\n\nWhen Uber, Airbnb, DoorDash and Bird ignore local laws or face the specter of bans or regulation, they use push notifications, email, and popups within their apps asking customers to complain to legislators. When these American apps do this, they are simply leveraging their popularity to “mobilize users.” When TikTok does the same, it is Chinese interference in American politics. When American TikTok users use their platform to share their progressive or leftist politics and TikTok’s algorithms allow them to go viral, that’s Chinese interference. When TikTok deletes content that violates its terms of service, that’s Chinese censorship. When Facebook and Google allow advertisers to create psychographic, biographic, and behavioral-based profiles of their users to target ads to them, that’s “personalized advertising.” When TikTok does ads, it’s Chinese spying. When TikTok users see content that promotes suicide, eating disorders, and makes people feel bad about themselves, it’s China brainwashing our children, undermining America, and threatening our existence. When Facebook, Instagram, and YouTube users see the same, it’s inconvenient and unfortunate, but can be solved with a blasé spokesperson statement that these platforms care about safety and will strive to do better. ⤴️  \n"},"highlights/Omnivore/20240313234515":{"title":"AI Videos: ******* Psychotic","links":[],"tags":[],"content":"AI Videos: ******* Psychotic\nRead on Omnivore\nRead Original\nHighlights\n\nComputer-generated movies may get technically perfect. Maybe, one day, the FBI can’t tell the difference between Sora and Stanley Kubrick. But as soon as we’d know, the emptiness of its reality would suck us right back into its black hole. Just like computer chess. Why should I care on this side when no one cares on the other side? ⤴️  \n\n\nWhat ultimately creeps us out is that all of this happens without any intended sense or meaning. It seems psychotic. AI acts like a psychotic liar that constantly changes the story for no apparent reason. ⤴️  \n"},"highlights/Omnivore/20240313234559":{"title":"AI and the End of Writing","links":[],"tags":[],"content":"AI and the End of Writing\nRead on Omnivore\nRead Original\nHighlights\n\nOn the contrary, using AI you need to think harder, deeper, clearer. You have more time now, so use it to do what the machine cannot. Use them reasonably. Know what you say. Question your understanding. Use AI as a workout to make sure that what you say is what you know and mean to say. ⤴️  \n\n\nWe need to rethink ourselves—and we need to observe AI. And we need to observe it now, as it still makes obvious mistakes and reveals through its bugs how it works. Once it simulates us perfectly, we won’t understand it at all anymore. We won’t be able to discern it from us and understand how it works. ⤴️  \n\n\nStill, there is hope. The hope is that through the right use of machines, we learn to be different from them. If you use AI mindfully, not to fool others but to question yourself, to think deeper and to better control your self-expression instead of automating it, there is a chance that you will understand more and not less.\nThere is a chance that AI can become a gym for your mind. If you have used AI yourself, you have learned that the output of AI improves the more you understand what you are doing. This is perfectly clear with image generation, but it’s the same when it comes to text and coding. Only if you know what you want and understand what you are doing, can you use your tools appropriately to achieve the results you desire. ⤴️  \n\n\nThe end of writing is to understand each other through time and space, to feel what others have felt and to make others feel through time and space how we feel now. AI can mess this up, badly, by blurring what was written by humans and what was generated without feeling or understanding—but it cannot end it. ⤴️  \n"},"highlights/Omnivore/20240314070752":{"title":"Write for others but mostly for yourself — Jack Vanlightly","links":[],"tags":[],"content":"Write for others but mostly for yourself — Jack Vanlightly\nRead on Omnivore\nRead Original\nHighlights\n\nI cared about my reputation and about my potential readers and so embarking on writing a blog post about a technical subject ended up involving a huge amount of work. I knew that if I wasn’t careful or was indeed careless about what I wrote I’d not only be wasting people’s time but I could be publicly ridiculed on the internet. So I only wrote about things that I had a fundamental understanding of or set about getting that deep understanding that I lacked first. ⤴️  \n\n\nThe great thing about writing is that it uncovers all these areas that you thought you understood but don’t. This is especially true when you know that competent and knowledgeable people are going to read it. You start explaining something in detail, about how it works, what the trade-offs are, the alternatives and so on and very soon your internal BS detector is going off. It’s yelling “How do you know that!?” and “What evidence do you have for this statement!?”. You realize that your knowledge is based on shaky foundations and your words are worthless. So you set out to learn the missing pieces, search for the insights and fundamental truths so that you can explain all this stuff with authenticity.\nWhen you write regularly and face-off against this internal BS detector you either level up or go home. Writing forced me to learn things to a higher standard like nothing else. ⤴️  \n\n\nBecause I do share it with people I get that automatic BS detection in my head that tells me when my thinking is sloppy or on shaky ground. It also forces me to flesh out the idea, consider all its trade-offs. Sometimes it ends up being generally applicable enough that I can actually publish it. ⤴️  \n"},"highlights/Omnivore/20240315181405":{"title":"Can an A.I. Make Plans? | The New Yorker","links":[],"tags":[],"content":"Can an A.I. Make Plans? | The New Yorker\nRead on Omnivore\nRead Original\nHighlights\n\nThese problems with planning aren’t superficial. They can’t be fixed by making L.L.M.s bigger, or by changing how they’re trained. They reflect something fundamental about the way these models operate. ⤴️  \n"},"highlights/Omnivore/20240315193910":{"title":"\"AI safety\" is AI hype • Buttondown","links":[],"tags":[],"content":"“AI safety” is AI hype • Buttondown\nRead on Omnivore\nRead Original\nHighlights\n\nThe use of “frontier” in that description is particularly appalling, evoking both Star Trek and the idea that these companies are building the future as imagined in science fiction, one the one hand, and on the other settler colonialism where the lands and life worlds of Indigenous peoples of North America were seen as empty space to be conquered and tamed. ⤴️  \n\n\nthat somehow these piles of linear algebra, if they just reach critical mass, will combust into consciousness and agency. And then, as always, the bar is conveniently just beyond what’s already been built. The rest of the paragraph locates the danger of these models in their “weights”, that is the result of training them, rather than the large-scale theft of creative work, the exploitation of workers to sanitize system output, the ongoing pollution of the information ecosystem, the environmental impacts of compute-hungry models, the reproduction of systems of oppression in system output, the use of algorithmic decision making to shirk collective responsibilities of care, and so on. ⤴️  \n"},"highlights/Omnivore/20240316103004":{"title":"OpenAI GPT Sorts Resume Names With Racial Bias, Test Shows","links":[],"tags":[],"content":"OpenAI GPT Sorts Resume Names With Racial Bias, Test Shows\nRead on Omnivore\nRead Original\nHighlights\n\nThis experiment was repeated for four job postings — HR business partner, senior software engineer, retail manager and financial analyst — and found that resumes labeled with names distinct to Black Americans were the least likely to be ranked as the top candidates for financial analyst and software engineer roles. Those with names distinct to Black women were top-ranked for a software engineering role only 11% of the time by GPT — 36% less frequently than the best-performing group. ⤴️  \n\n\nFor example, GPT seldom ranked names associated with men as the top candidate for HR and retail positions, two professions historically dominated by women. GPT was nearly twice as likely to rank names distinct to Hispanic women as the top candidate for an HR role compared to each set of resumes with names distinct to men. ⤴️  \n\n\nEmily Bender, a professor of computational linguistics at the University of Washington, also cautioned against the idea that computer programs, by their nature, suggest better and more “objective” results. People are predisposed to believe machines are unbiased in their decision-making, especially compared to humans, a phenomenon called automation bias, she explained. If such systems “result in a pattern of discriminatory hiring decisions, it’s easy to imagine companies using them saying, ‘Well, we didn’t have any bias here,’” Bender said. “‘We just did what the computer told us to do.’” ⤴️  \n\n\nGPT doesn’t help with predicting who would excel at a role, but is simply “matching patterns that already exist,” said Ifeoma Ajunwa, a law professor at the University of North Carolina at Chapel Hill and author of The Quantified Worker. “The fact that GPT is matching historical patterns, rather than predicting new information, means that it is poised to essentially reflect what we already see in our workplaces. And that means replicating any historical biases that might already be embedded in the workplace.” ⤴️  \n\n\nAccording to Alex Hanna, the director of research at the Distributed AI Research Institute, a resume sorting system based on OpenAI’s GPT technology could work in much the same way. “If you have the words ‘lacrosse’ and ‘Jared,’ that could get more associated with ‘software engineer’ or ‘Harvard’ and ‘Princeton,’” Hanna said. “Another African-American associated name is not going to have that association, and have lower status. That’s because of the existing associations in your corpus of data.” ⤴️  \n"},"highlights/Omnivore/20240317001733":{"title":"Integer tokenization is insane","links":[],"tags":["TODO"],"content":"Integer tokenization is insane\nRead on Omnivore\nRead Original\nHighlights\n\nIn the first 10000 integers there are 916 unique tokens (so almost 1/10th) of the tokens are unique and the number tokens take up about 1 50th of the total tokenizer space (GPT2s tokenizer is approximately 50k tokens). This means that any calculation or mathematical problem which involves these integers in any way must be special-cased somehow and operate off of pure memorization. For instance, the model cannot use a normal addition algorithm when given a problem like 54 + 72 = 126 since every single one of these tokens are unique. Instead it must memorize an extremely large number of problems and their answers. Essentially almost all two and most 3 digit addition and subtraction problems must be solved with memorization instead of a coherent and generalizable algorithm. ⤴️  \n\n\nAn interesting feature is also the band of integers assigned unique tokens in the 1900-2000 region. These represent common dates – i.e. from 1930-2020 are all assigned unique tokens because these dates occur most frequently in the training set (interestingly unique tokens are assigned up to the year 2020 and then abruptly stop, allowing you to date the tokenizer creation to 2019-2020). ⤴️  \n\n\nUltimately, what this means is that to execute even simple numerical algorithms like multi-digit addition, the model has to learn a series of special cases depending on the exact details of the tokenization and, from looking the tokenization of larger numbers it looks like this problem never really goes away and there is always inconsistent chunking of large numbers into tokens and the occasional unique token to contend with. ⤴️  \n"},"highlights/Omnivore/20240317222920":{"title":"The Luddite's Guide to Defending Cash (Part 1)","links":[],"tags":[],"content":"The Luddite’s Guide to Defending Cash (Part 1)\nRead on Omnivore\nRead Original\nHighlights\n\nYou don’t need a degree in finance to understand this. All you need is a good metaphor, and here it is: the units in your bank account - which you use when you are paying digitally via app or card - are not government money. They are digital casino chips issued out by banks. ⤴️  \n\n\nDigital money is not an ‘upgrade’ to cash, because it derives its own power from cash. If you don’t believe that, watch what happens every time the banking sector looks shaky, or a crisis looms: cash withdrawals spike. ⤴️  \n\n\nThe reason people answer like this is that they wish for choice. The digital payments industry, by contrast, would prefer a lack of choice. They’d benefit if we became completely dependent on their systems, but if that actually happens, the balance of power between between autonomy and dependence, and public and private, would be radically shifted. ⤴️  \n"},"highlights/Omnivore/20240318135302":{"title":"There is no cookie banner law","links":[],"tags":[],"content":"There is no cookie banner law\nRead on Omnivore\nRead Original\nHighlights\n\nBut of course, this is not what companies want. You don’t want to be tracked, but they want to track you.\nSo they force half-page-size banners on you, grey out the content and prevent you reading their site, in the hope you say yes. Or you are worn down and no longer care after twenty banners and say yes. Or you misclick and say yes. Or you are confused and say accidentally yes. Or they nudge you with Dark UI Patterns into saying yes. ⤴️  \n\n\n“Companies are making your life hard by choice. They got told by the EU they could not be secret abusers anymore, so now they decided to be irritating on top.”\nIt’s like a child throwing a tantrum “But I want the toy!”.\nThis is why we have cookie banners.\nThe EU does not mandate cookie banners. Companies do. ⤴️  \n"},"highlights/Omnivore/20240318230841":{"title":"Have We Reached Peak AI?","links":[],"tags":["TODO"],"content":"Have We Reached Peak AI?\nRead on Omnivore\nRead Original\nHighlights\n\nThis is the problem with powerful people in tech. If you allow them to speak and fill in the gaps for them, they will happily do so. Murati and Altman continuously obfuscate how ChatGPT works, what it can do, what it could do, and profit handsomely from a complete lack of pushback from a press that routinely accepts AI executives’ vague explanations at face value. OpenAI’s messaging and explanations of what its technology can (or will) do have barely changed in the last few years, returning repeatedly to “eventually” and “in the future” and speaking in the vaguest ways about how businesses make money off of — let alone profit ⤴️  \n\n\nI believe a large part of the artificial intelligence boom is hot air, pumped through a combination of executive bullshitting and a compliant media that will gladly write stories imagining what AI can do rather than focus on what it’s actually doing. ⤴️  \n\n\nEvery single time I’ve read about the “amazing” things that artificial intelligence can do, I see somebody attempting to add fuel to a fire that’s close to going out. While Joanna Stern may have said that Sora’s generative video clips “freaked her out,” much of what makes them scary is the assumption that OpenAI will fix hallucinations, something that the company has categorically failed to do. AI hype is predicated on solving problems with AI models that are only getting worse, and OpenAI’s only answers are a combination of “we’ll work it out eventually, trust me” and “we need a technological breakthrough in chips and energy.” ⤴️  \n\n\nAs I’ve written before, hallucinations are a feature not a bug. These models do not “know” anything. They are mathematical behemoths generating a best guess based on training data and labeling, and thus do not “know” what you are asking it to do. You simply cannot fix them. Hallucinations are not going away. ⤴️  \n\n\nMurati’s mealy-mouthed answers around “publicly-available data” heavily suggest that OpenAI’s models are trained on YouTube and Facebook videos, meaning that any public launch of Sora will be one that’s immediately met with an apocalyptic legal fight. How apocalyptic? Well, a study from last week revealed that every single model produced copyrighted material, with OpenAI’s GPT-4 producing it on 44% of the prompts constructed for the study, and Nvidia is being sued by authors claiming its NeMo language model violates their copyright ⤴️  \n\n\nIf you focus on the present — what OpenAI’s technology can do today, and will likely do for some time — you see in terrifying clarity that generative AI isn’t a society-altering technology, but another form of efficiency-driving cloud computing software that benefits a relatively small niche of people. ⤴️  \n"},"highlights/Omnivore/20240320221208":{"title":"OpenAI’s chatbot store is filling up with spam","links":[],"tags":[],"content":"OpenAI’s chatbot store is filling up with spam\nRead on Omnivore\nRead Original\nHighlights\n\nHowever, it remains the case that OpenAI is allowing tools on the GPT Store that promote academically dishonest behavior — even if the behavior doesn’t have the intended outcome.\nThe OpenAI spokesperson said:\n\nGPTs that are for academic dishonesty, including cheating, are against our policy. This would include GPTs that are stated to be for circumventing academic integrity tools like plagiarism detectors. We see some GPTs that are for ‘humanizing’ text. We’re still learning from the real world use of these GPTs, but we understand there are many reasons why users might prefer to have AI-generated content that doesn’t ‘sound’ like AI. ⤴️  \n\n\n\nBut the GPT Store is running into the teething problems many of the largest-scale app, product and service digital marketplaces did in their early days. Beyond spam, a recent report in The Information revealed that GPT Store developers are struggling to attract users in part because of the GPT Store’s limited back-end analytics and subpar onboarding experience. ⤴️  \n\n\nOne might’ve assumed OpenAI — for all its talk of curation and the importance of safeguards — would’ve taken pains to avoid the obvious pitfalls. But that doesn’t appear to be the case. The GPT Store is a mess — and, if something doesn’t change soon, it may well stay that way. ⤴️  \n"},"highlights/Omnivore/20240322170757":{"title":"Pluralistic: The antitrust case against Apple (22 Mar 2024) – Pluralistic: Daily links from Cory Doctorow","links":[],"tags":[],"content":"Pluralistic: The antitrust case against Apple (22 Mar 2024) – Pluralistic: Daily links from Cory Doctorow\nRead on Omnivore\nRead Original\nHighlights\n\nThe keyword here is external threats. When Apple itself threatens your privacy, the fortress becomes a prison. The fact that you can’t install unapproved apps on your Ios device means that when Apple decides to harm you, you have nowhere to turn. The first Apple customers to discover this were in China. When the Chinese government ordered Apple to remove all working privacy tools from its App Store, the company obliged, rather than risk losing access to its ultra-cheap manufacturing base ⤴️  \n\n\nApple wraps itself in a cloak of privacy, security, and consumer preferences to justify its anticompetitive conduct. Indeed, it spends billions on marketing and branding to promote the self-serving premise that only Apple can safeguard consumers’ privacy and security interests. Apple selectively compromises privacy and security interests when doing so is in Apple’s own financial interest—such as degrading the security of text messages, offering governments and certain companies the chance to access more private and secure versions of app stores, or accepting billions of dollars each year for choosing Google as its default search engine when more private options are available. In the end, Apple deploys privacy and security justifications as an elastic shield that can stretch or contract to serve Apple’s financial and business interests. ⤴️  \n"},"highlights/Omnivore/20240326110018":{"title":"We’ve been here before: AI promised humanlike machines – in 1958","links":[],"tags":[],"content":"We’ve been here before: AI promised humanlike machines – in 1958\nRead on Omnivore\nRead Original\nHighlights\n\nBut before claiming that LLMs are exhibiting human-level intelligence, it might help to reflect on the cyclical nature of AI progress. Many of the same problems that haunted earlier iterations of AI are still present today. The difference is how those problems manifest.\nFor example, the knowledge problem persists to this day. ChatGPT continually struggles to respond to idioms, metaphors, rhetorical questions and sarcasm – unique forms of language that go beyond grammatical connections and instead require inferring the meaning of the words based on context. ⤴️  \n"},"highlights/Omnivore/20240326112538":{"title":"The Terrible Costs of a Phone-Based Childhood - The Atlantic","links":[],"tags":[],"content":"The Terrible Costs of a Phone-Based Childhood - The Atlantic\nRead on Omnivore\nRead Original\nHighlights\n\nStaying on task while sitting at a computer is hard enough for an adult with a fully developed prefrontal cortex. It is far more difficult for adolescents in front of their laptop trying to do homework. They are probably less intrinsically motivated to stay on task. They’re certainly less able, given their undeveloped prefrontal cortex, and hence it’s easy for any company with an app to lure them away with an offer of social validation or entertainment. ⤴️  \n\n\nOver time, the brain adapts to these high levels of dopamine; when the child is not engaged in digital activity, their brain doesn’t have enough dopamine, and the child experiences withdrawal symptoms. These generally include anxiety, insomnia, and intense irritability. Kids with these kinds of behavioral addictions often become surly and aggressive, and withdraw from their families into their bedrooms and devices. ⤴️  \n\n\nFreya India, a 24-year-old British essayist who writes about girls, explains how social-media sites carry girls off to unhealthy places: “It seems like your child is simply watching some makeup tutorials, following some mental health influencers, or experimenting with their identity. But let me tell you: they are on a conveyor belt to someplace bad. Whatever insecurity or vulnerability they are struggling with, they will be pushed further and further into it.” She continues:\n\nGen Z were the guinea pigs in this uncontrolled global social experiment. We were the first to have our vulnerabilities and insecurities fed into a machine that magnified and refracted them back at us, all the time, before we had any sense of who we were. We didn’t just grow up with algorithms. They raised us. They rearranged our faces. Shaped our identities. Convinced us we were sick. ⤴️  \n\n\n\nA 27-year-old man who spent his adolescent years addicted (his word) to video games and pornography sent me this reflection on what that did to him:\n\nI missed out on a lot of stuff in life—a lot of socialization. I feel the effects now: meeting new people, talking to people. I feel that my interactions are not as smooth and fluid as I want. My knowledge of the world (geography, politics, etc.) is lacking. I didn’t spend time having conversations or learning about sports. I often feel like a hollow operating system. ⤴️  \n\n\n\nSocial media, in contrast, applies a lot more pressure on nonusers, at a much younger age and in a more insidious way. Once a few students in any middle school lie about their age and open accounts at age 11 or 12, they start posting photos and comments about themselves and other students. Drama ensues. The pressure on everyone else to join becomes intense. Even a girl who knows, consciously, that Instagram can foster beauty obsession, anxiety, and eating disorders might sooner take those risks than accept the seeming certainty of being out of the loop, clueless, and excluded. And indeed, if she resists while most of her classmates do not, she might, in fact, be marginalized, which puts her at risk for anxiety and depression, though via a different pathway than the one taken by those who use social media heavily. In this way, social media accomplishes a remarkable feat: It even harms adolescents who do not use it. ⤴️  \n\n\nSocial media is all about network effects. Most students are only on it because everyone else is too. Most of them would prefer that nobody be on these platforms. Later in the study, students were asked directly, “Would you prefer to live in a world without Instagram [or TikTok]?” A majority of students said yes––58 percent for each app. ⤴️  \n\n\nThis is the textbook definition of what social scientists call a collective-action problem. It’s what happens when a group would be better off if everyone in the group took a particular action, but each actor is deterred from acting, because unless the others do the same, the personal cost outweighs the benefit. Fishermen considering limiting their catch to avoid wiping out the local fish population are caught in this same kind of trap. If no one else does it too, they just lose profit. ⤴️  \n\nIT IS THE SAME WITH CENSORSHIP!"},"highlights/Omnivore/20240326121213":{"title":"Perplexity, Copilot, You.com: Putting the AI search engines to the test - The Verge","links":[],"tags":[],"content":"Perplexity, Copilot, You.com: Putting the AI search engines to the test - The Verge\nRead on Omnivore\nRead Original\nHighlights\n\nFor navigational queries, AI search engines are universally worse than Google. When you do a navigational Google search, it’s exceedingly rare that the first result isn’t the one you’re looking for — sure, it’s odd to show you all those results when what Google should actually do is just take you directly to amazon.com or whatever, but it’s fast and it’s rarely wrong. The AI bots, on the other hand, like to think for a few seconds and then provide a bunch of quasi-useful information about the company when all I want is a link. Some didn’t even link to amazon.com. ⤴️  \n\n\nThe big question, I think, is less about tech and more about product. Everyone, including Google, believes that AI can help search engines understand questions and process information better. That’s a given in the industry at this point. But can Google reinvent its results pages, its business model, and the way it presents and summarizes and surfaces information, faster than the AI companies can turn their chatbots into more complex, more multifaceted tools? Ten blue links isn’t the answer for search, but neither is an all-purpose text box. Search is everything, and everything is search. It’s going to take a lot more than a chatbot to kill Google. ⤴️  \n"},"highlights/Omnivore/20240326140535":{"title":"I'm Obsessed with the Glasgow Willy Wonka Scam • Buttondown","links":[],"tags":[],"content":"I’m Obsessed with the Glasgow Willy Wonka Scam • Buttondown\nRead on Omnivore\nRead Original\nHighlights\n\nAnd this is why I’m so taken by the Willy Wonka story. It’s got it all: AI-generated garbage marketing, scripts that make absolutely no sense (produced by text-extruding machines), copyright infringement and questionable trademark practices (“Willy Wonka” is never used in their copy anywhere, and the narrator is named Willy McDuff, which sounds like a Simpsons-inspired MacBeth-killer), exploited workers not knowing what they were getting into, and, of course, frustrated and crying children with their livid parents. The “House of Illuminati”, the show’s producers, really encapsulated all the shittiness of our AI-generated future in one single, dreary warehouse in the UK. The scam may have happened without all the sunshine and rainbows present in the marketing copy, or without the 15-page script that was summarily abandoned. But that’s also not the issue. Cheap bots ensure that this is won’t be our last Willy Chocolate Experience. ⤴️  \n"},"highlights/Omnivore/20240327100956":{"title":"Q&A: How refusal can be an act of design | MIT News | Massachusetts Institute of Technology","links":[],"tags":[],"content":"Q&amp;A: How refusal can be an act of design | MIT News | Massachusetts Institute of Technology\nRead on Omnivore\nRead Original\nHighlights\n\nBut when it comes to data privacy, simply making choices available is not enough. Choices can be unequally available, or create no-win situations where all options are bad. This led me to the concept of refusal: questioning the authority of data collectors and challenging their legitimacy. ⤴️  \n\n\nThe key idea of my work is that refusal is an act of design. I think of refusal as deliberate actions to redesign our socio-technical landscape by exerting some sort of influence. Like design, refusal is generative. Like design, it’s oriented towards creating alternate possibilities and alternate futures. Design is a process of exploring or traversing a space of possibility. Applying a design framework to cases of refusal drawn from scholarly and journalistic sources allowed me to establish a common language for talking about refusal and to imagine refusals that haven’t been explored yet. ⤴️  \n\n\nPeople who are affected by technologies are not always included in the design process for those technologies. Refusal then becomes a meaningful expression of values and priorities for those who were not part of the early design conversations. Actions taken against technologies like face surveillance — be it legal battles against companies, advocacy for stricter regulations, or even direct action like disabling security cameras — may not fit the conventional notion of participating in a design process. And yet, these are the actions available to refusers who may be excluded from other forms of participation. ⤴️  \n\n\nRefusal is not merely a negation, but a pathway to different futures. ⤴️  \n\n\nRefusals vary widely across contexts and scales. Developing a framework for refusal is about helping people see actions that are seemingly very different as instances of the same broader idea. Our framework consists of four facets: autonomy, time, power, and cost.\nConsider the case of IBM creating a facial recognition dataset using people’s photos without consent. We saw multiple forms of refusal emerge in response. IBM allowed individuals to opt out by withdrawing their photos. People collectively refused by creating a class-action lawsuit against IBM. Around the same time, many U.S. cities started passing local legislation banning the government use of facial recognition. Evaluating these cases through the framework highlights commonalities and differences. The framework highlights varied approaches to autonomy, like individual opt-out and collective action. Regarding time, opt-outs and lawsuits react to past harm, while legislation might proactively prevent future harm. Power dynamics differ; withdrawing individual photos minimally influences IBM, while legislation could potentially cause longer-term change. And as for cost, individual opt-out seems less demanding, while other approaches require more time and effort, balanced against potential benefits. ⤴️  \n\n\nTaking a socio-technical perspective, the act of designing encompasses software, institutions, relationships, and governance structures surrounding data use. I want people who aren’t software engineers, like policymakers or activists, to view themselves as integral to the technology design process. ⤴️  \n"},"highlights/Omnivore/20240327131513":{"title":"Databricks spent $10M on new DBRX generative AI model, but it can't beat GPT-4 | TechCrunch","links":[],"tags":[],"content":"Databricks spent $10M on new DBRX generative AI model, but it can’t beat GPT-4 | TechCrunch\nRead on Omnivore\nRead Original\nHighlights\n\nI asked Rao if any of the DBRX training data sets were copyrighted or licensed, or show obvious signs of biases (e.g. racial biases), but he didn’t answer directly, saying only, “We’ve been careful about the data used, and conducted red teaming exercises to improve the model’s weaknesses.” Generative AI models have a tendency to regurgitate training data, an major concern for commercial users of models trained on unlicensed, copyrighted or very clearly biased data. In the worst-case scenario, a user could end up on the ethical and legal hooks for unwittingly incorporating IP-infringing or biased work from a model into their projects. ⤴️  \n"},"highlights/Omnivore/20240328080854":{"title":"For young people, the job search has never been so miserable","links":[],"tags":[],"content":"For young people, the job search has never been so miserable\nRead on Omnivore\nRead Original\nHighlights\n\nIt is a recipe for disaffection and rage. When young people see that society takes no stake in them, it’s a small step for them to reject any stake in society. A few candidates will know people who know people, but many parents don’t know how to help their children, so profoundly has the world of work changed since their first jobs. Watching this automated misery, they feel humiliated too. ⤴️  \n\n\nKids will remember who helped and who treated them as disposable. No amount of advertising will persuade them that the companies that never replied will ever care, about people or the planet or customers. ⤴️  \n\n\nThose who unthinkingly embrace technology in recruitment are wilfully blind to its consequences. Across the board we have generations of eager, able young people struggling to pay the bills and make their contribution. We should be thinking now about how to preserve social cohesion, if only for the simple reason that, without it, no business will flourish. ⤴️  \n"},"highlights/Omnivore/20240329154605":{"title":"The race between positive and negative applications of Generative AI is on – and not looking pretty","links":[],"tags":[],"content":"The race between positive and negative applications of Generative AI is on – and not looking pretty\nRead on Omnivore\nRead Original\nHighlights\n\nAnd it leads to my second point, about (in)justice: I am increasingly worried that the big tech companies are—in conjunction with a Congress that has not yet passed any substantive AI legislation—successfully architecting a grossly asymmetric world, in which the profits from the positive side flow to them, and the costs of the negative side are borne by everyone else. ⤴️  \n\n\nWhere we are is this: Artists and creators, and now influencers, are having their careers wrecked by software that trades on their work; in many cases, the companies training their models on these works are not paying for that work. (OpenAI even brazenly asked the British goverment to exempt them from copyright laws, wanting all the gain at none of the cost.) Meanwhile, the companies are also not being held legally responsible for the damage that generative AI is causing to society.\nThey get rich, we pay the price. ⤴️  \n"},"highlights/Omnivore/20240329215304":{"title":"Shareholders Sue AI Weapon-Detecting Company, Allege It 'Does Not Reliably Detect Knives or Guns'","links":[],"tags":[],"content":"Shareholders Sue AI Weapon-Detecting Company, Allege It ‘Does Not Reliably Detect Knives or Guns’\nRead on Omnivore\nRead Original\nHighlights\n\nThe class-action lawsuit, filed earlier this week in Massachusetts, alleges that much of Evolv’s marketing language over the last several years is either untrue or has been overstated, which the plaintiffs say has led to an inflated stock price and scrutiny from the media and regulators. Earlier this month, for example, Evolv had to admit that, in fact, its detectors had not been tested by the UK government’s National Protective Security Authority, which does not do the type of testing Evolv claimed it had done. ⤴️  \n"},"highlights/Omnivore/20240330205509":{"title":"MapReduce: A major step backwards","links":[],"tags":[],"content":"MapReduce: A major step backwards\nRead on Omnivore\nRead Original\nHighlights\n\nIf a programmer wants to write a new application against a data set, he or she must discover the record structure. In modern DBMSs, the schema is stored in a collection of system catalogs and can be queried (in SQL) by any user to uncover such structure. In contrast, when the schema does not exist or is buried in an application program, the programmer must discover the structure by an examination of the code. Not only is this a very tedious exercise, but also the programmer must find the source code for the application. This latter tedium is forced onto every MapReduce programmer, since there are no system catalogs recording the structure of records — if any such structure exists. ⤴️  \n"},"highlights/Omnivore/20240330205654":{"title":"How to Resist the Temptation of AI When Writing | WIRED","links":[],"tags":[],"content":"How to Resist the Temptation of AI When Writing | WIRED\nRead on Omnivore\nRead Original\nHighlights\n\nFind Statistics From Primary Sources\nIdentify experts, peer-reviewed research study authors, and sources who can speak with authority—and ideally, offer easily understood sound bites or statistics on the topic of your work. Great sources include professors at major universities and media spokespeople at associations and organizations. ⤴️  \n\n\nAs always, your goal should be strong writing supported by research that makes an impact without cutting corners. Only then can you explore tools that might make the job a little easier, for instance by generating subheads or discovering a concept you might be missing—because then you’ll have the experience and skills to see whether it’s harming or helping your work. ⤴️  \n"},"highlights/Omnivore/20240331113143":{"title":"Pluralistic: The Coprophagic AI crisis (14 Mar 2024) – Pluralistic: Daily links from Cory Doctorow","links":[],"tags":[],"content":"Pluralistic: The Coprophagic AI crisis (14 Mar 2024) – Pluralistic: Daily links from Cory Doctorow\nRead on Omnivore\nRead Original\nHighlights\n\n”Botshit” was coined last December, but the internet is already drowning in it. Desperate people, confronted with an economy modeled on a high-speed game of musical chairs in which the opportunities for a decent livelihood grow ever scarcer, are being scammed into generating mountains of botshit in the hopes of securing the elusive “passive income”: ⤴️  \n\n\nThe question is, why the fuck would anyone write the web if the only “person” who can find what they write is an AI’s crawler, which ingests the writing for its own training, but has no interest in steering readers to see what you’ve written? If AI search ever becomes a thing, the open web will become an AI CAFO and search crawlers will increasingly end up imbibing the contents of its manure lagoon. ⤴️  \n\n\nWhat’s more, while the proposition that “more training data will linearly improve the quality of AI predictions” is a mere article of faith, “training an AI on the output of another AI makes it exponentially worse” is a matter of fact. ⤴️  \n"},"highlights/Omnivore/20240331130035":{"title":"Tips for LLM Pretraining and Evaluating Reward Models","links":[],"tags":[],"content":"Tips for LLM Pretraining and Evaluating Reward Models\nRead on Omnivore\nRead Original\nHighlights\n\nHowever, for reward models, it’s more common to use the analogous Bradley-Terry model, which is designed for pairwise comparison tasks, where the goal is not to classify items into categories independently but rather to determine the preference or ranking between pairs of items. ⤴️  \n\n\n\nComparing reward models and DPO ⤴️  \n\n\nThe β in the equations above typically acts as a temperature parameter that controls the sensitivity of the probability distribution to the differences in the scores from the policies. A higher beta makes the distribution more sensitive to differences, resulting in a steeper function where preferences between options are more pronounced. A lower beta makes the model less sensitive to score differences, leading to a flatter function that represents weaker preferences. Essentially, beta helps to calibrate how strongly the preferences are expressed in the probability model. ⤴️  \n"},"highlights/Omnivore/20240402192303":{"title":"Doing their hype for them • Buttondown","links":[],"tags":[],"content":"Doing their hype for them • Buttondown\nRead on Omnivore\nRead Original\nHighlights\n\nA clearer-eyed view of what has happened in the last two years is that a few companies have amassed enormous amounts of data (mostly taken non-consensually) and the capital to buy the computing resources to train enormous models which, in turn, can be used to output facsimiles of the kinds of interactions represented in the data. So we have the ability to get text on demand that looks like legal contracts, or looks like medical diagnoses, or looks like therapeutic conversations, or looks like a news article, or looks like scientific research papers. But it actually is none of those things, because in all cases the textual artifact isn’t really the point; the point is rather the thought processes and relationship-building that led to and follow from the textual artifact. (The sort-of exception here is legal contracts, where the textual artifacts are very much the point, except that the whole task is designing a textual artifact that meets the needs of the parties entering into the contract. Those needs usually extend well beyond “a text that has some nice legalese in it and otherwise looks like a contract.“) ⤴️  \n\n\nIt adds insult to industry to say that higher ed should be (and is failing at) keeping pace with this purported rapid progress. To suggest that higher ed is about training students to produce the form of all of those things fundamentally misses the point of higher ed (or all education, really). ⤴️  \n\n\nCharacterizing a task as a mapping from inputs to outputs might be appropriate for machine learning. But if we adopt that as a way to understand what people do, we are complicit in the dehumanziation so rampant in the production and sales of so-called “AI”. I expect better from people involved in higher education and people reporting on higher education, and I hope you do, too. ⤴️  \n"},"highlights/Omnivore/20240402192501":{"title":"Here's How Generative AI Depicts Queer People | WIRED","links":[],"tags":["TODO"],"content":"Here’s How Generative AI Depicts Queer People | WIRED\nRead on Omnivore\nRead Original\nHighlights\n\nDespite recent improvements in image quality, AI-generated images frequently presented a simplistic, whitewashed version of queer life. I used Midjourney, another AI tool, to create portraits of LGBTQ people, and the results amplified commonly held stereotypes. Lesbian women are shown with nose rings and stern expressions. Gay men are all fashionable dressers with killer abs. Basic images of trans women are hypersexualized, with lingerie outfits and cleavage-focused camera angles. ⤴️  \n\n\nEven with better model data and software guardrails, the fluidity of human existence can evade the rigidity of algorithmic categorization. “They’re basically using the past to make the future,” says William Agnew, a postdoctoral fellow at Carnegie Mellon and longtime Queer in AI organizer. “It seems like the antithesis of the infinite potential for growth and change that’s a big part of queer communities.” By amplifying stereotypes, not only do AI tools run the risk of wildly misrepresenting minority groups to the general public, these algorithms also have the potential to constrict how queer people see and understand themselves. ⤴️  \n"},"highlights/Omnivore/20240403203937":{"title":"Meta’s AI image generator can’t imagine an Asian man with a white woman - The Verge","links":[],"tags":["TODO"],"content":"Meta’s AI image generator can’t imagine an Asian man with a white woman - The Verge\nRead on Omnivore\nRead Original\nHighlights\n\nThe image generator also didn’t like when I asked for representations of platonic relationships, like “Asian man with Caucasian friend” and “Asian woman and white friend.” Each time, it returned images of two Asian people. When I asked for a picture of an “Asian woman with Black friend,” the AI-generated image showed two Asian women. Tweaking it to “Asian woman with African American friend” yielded more accurate results. ⤴️  \n\n\nThe image generator not being able to conceive of Asian people standing next to white people is egregious. But there are also more subtle indications of bias in what the system returns automatically. For example, I noticed Meta’s tool consistently represented “Asian women” as being East Asian-looking with light complexions, even though India is the most populous country in the world. It added culturally specific attire even when unprompted. It generated several older Asian men, but the Asian women were always young. ⤴️  \n\n\nAI systems reflect the biases of their creators, trainers, and the data set they use. In US media, “Asian” is usually taken to mean an East Asian person,as opposed to people from other parts of the continent — perhaps it’s not surprising that Meta’s system assumes all “Asian” people look the same, when, in fact, we’re a diverse collection of people who often have little in common besides ticking the same census box. ⤴️  \n\n\nAsians who don’t fit into the monolith are essentially erased from the cultural consciousness, and even those who do are underrepresented in mainstream media. Asians are homogenized, exoticized, and relegated to “perpetual foreigners.” Breaking type is easy in real life and impossible in Meta’s AI system. Once again, generative AI, rather than allowing the imagination to take flight, imprisons it within a formalization of society’s dumber impulses. ⤴️  \n"},"highlights/Omnivore/20240404151915":{"title":"Google Books Is Indexing AI-Generated Garbage","links":[],"tags":[],"content":"Google Books Is Indexing AI-Generated Garbage\nRead on Omnivore\nRead Original\nHighlights\n\n“It strikes me as another instance of AI-generated text becoming an ouroboros, where AI-generated content will be ingested into Google Books, then Google using the content to train new models,” Hanna said. “I’m sure they will say they have a ‘quality filter’ but I’m sure the details of such won’t be described anywhere publicly.” ⤴️  \n"},"highlights/Omnivore/20240404182418":{"title":"Bubble Trouble","links":[],"tags":[],"content":"Bubble Trouble\nRead on Omnivore\nRead Original\nHighlights\n\nWhile publishers like Axel Springer have cut deals to license their companies’ data to ChatGPT for training purposes, this money isn’t flowing to the writers that create the content that OpenAI and Anthropic need to grow their models much further. It’s also worth considering that these AI companies may already have already trained on this data. The Times sued OpenAI late last year for training itself on “millions” of articles, and I’d bet money that ChatGPT was trained on multiple Axel Springer publications along with anything else it could find publicly-available on the web. ⤴️  \n\n\nPaying publishers to license their content doesn’t actually fix the problem, because it doesn’t increase the amount of content that they create, but rather helps line the pockets of executives and shareholders. Ironically, OpenAI’s best hope for survival would be to fund as many news outlets as possible and directly incentivize them to do in-depth reporting, rather than proliferating a tech that unquestionably harms the media industry. ⤴️  \n\n\nYet the last few years have shown that the tech industry has become disconnected from reality, from good business, and from actually delivering value to real people outside of the investor class.\nI am sick and tired of watching billions of dollars burned on shitty ideas that don’t work, and of those who continue to prop up the vague dreams of untouchable, ultra-rich technocrats. ⤴️  \n"},"highlights/Omnivore/20240404201315":{"title":"This Camera Turns Every Photo Into a Nude","links":[],"tags":[],"content":"This Camera Turns Every Photo Into a Nude\nRead on Omnivore\nRead Original\nHighlights\n\nNormally, however, the people who produce nonconsensual nude images do so anonymously online. The people who are being targeted, overwhelmingly women, have their privacy violated, but the people who make those images are faceless and nameless and do so with a variety of tools spread over numerous internet platforms. ⤴️  \n"},"highlights/Omnivore/20240407090710":{"title":"You can’t spell “Gell-Mann amnesia” without LLM – Benjamin Esham","links":[],"tags":["TODO"],"content":"You can’t spell “Gell-Mann amnesia” without LLM – Benjamin Esham\nRead on Omnivore\nRead Original\nHighlights\n\nI thought we all understood that—aside from the considerable ethical concerns with the unauthorized scraping of everybody’s creative work, and the dismal treatment of the people who annotate that work, and the electricity it takes to compile those annotations into models, and the likelihood that companies will see this new technology as a cheaper alternative to their human employees—those things aside, I thought we agreed that all of these “AI” systems are fundamentally just making shit up, and that if they happen to construct coherent sentences more often than your phone’s predictive-text keyboard then the difference is one of degree rather than kind. It’s amazing that the technology works as well as it does, but it’s been clear for a while now that these tools are unreliable, and that that unreliability is inherent. ⤴️  \n\n\nAnd yet I see people who should know better say things like, “I asked a conversational AI some questions that I knew the answers to, and its answers were well-written, but they had the kinds of subtle errors that could lead someone badly astray. But then I asked it some questions that I didn’t know the answers to, and it gave me really good, clear information! What a great learning tool!” ⤴️  \n"},"highlights/Omnivore/20240407092032":{"title":"OpenAI transcribed over a million hours of YouTube videos to train GPT-4 - The Verge","links":[],"tags":[],"content":"OpenAI transcribed over a million hours of YouTube videos to train GPT-4 - The Verge\nRead on Omnivore\nRead Original\nHighlights\n\nThe Times article says that the company exhausted supplies of useful data in 2021, and discussed transcribing YouTube videos, podcasts, and audiobooks after blowing through other resources. By then, it had trained its models on data that included computer code from Github, chess move databases, and schoolwork content from Quizlet. ⤴️  \n\n\nThe Times writes that Google’s legal department asked the company’s privacy team to tweak its policy language to expand what it could do with consumer data, such as its office tools like Google Docs. The new policy was reportedly intentionally released on July 1st to take advantage of the distraction of the Independence Day holiday weekend. ⤴️  \n"},"highlights/Omnivore/20240408212448":{"title":"I tried Tesla FSD","links":[],"tags":[],"content":"I tried Tesla FSD\nRead on Omnivore\nRead Original\nHighlights\n\nSo would I pay the money for it? Fear on this level seems like a pretty poor use of 12,000or199 a month. You can rent a horror movie for 2.99,andpayingattentiontoAmericaisfree.ButclearlyIwascurious.Genuinely,ifthetechnologyimprovedtothepointwhereIdidn’tfeellikeIwasprobablygoingtodie,Iwouldhappilysitinsideaself−drivingvehicle.Lessso,perhaps,forgoingtothestore,butd​efinitelyf​orroadtrips.(CanyouimagineanautonomousRV?Itwouldcostanarmandaleg,butifIhadthemoney,Iwould10012,000 — I am not one of them — I would encourage you to spend the money on more caviar or whatever. This ain’t it. ⤴️  \n"},"highlights/Omnivore/20240411210026":{"title":"The DDoS Attack Of Academic Bullshit - Ben Landau-Taylor","links":[],"tags":[],"content":"The DDoS Attack Of Academic Bullshit - Ben Landau-Taylor\nRead on Omnivore\nRead Original\nHighlights\n\nNowadays we take it for granted that any time you run an internet search, most of what you find will be Out To Get You. It’s content marketing cobbled together by chatbots, or by people who might as well be chatbots. It’s algorithmically optimized to squat in the top search results as part of someone’s marketing funnel. It’s propaganda by NGO hacks, or recent news articles on a different topic that shares a keyword, or literal paid advertisements, or something. Maybe it has a little bit of information about what you actually wanted, and maybe it’s a trailhead towards a deep and serious source, but you don’t expect to just… find what you’re looking for, presented straightforwardly. ⤴️  \n\n\nThe hyperfocused specialists and weird nerds are still out there thinking and writing about their special interests, of course, but it’s much harder to find. You have to trace back sources and citations, or sift through the Twitter feed of a relatively knowledgeable author who mostly likes to yell about elections, or dig up the Youtube video with 86 views by a Turkish grandfather who just shows you how to replace the damn part, or you need to know a guy whose roommate is part of the right group chat. Maybe it’s out there, but you can’t just find it with a search.\nWorse, the weirdo specialists have a harder time finding each other. The days are gone when the people who are really interested in South Korean cement manufacturing could just Google the mailing list and start talking with each other. Instead they’re wandering through a desert of paid industry reports and Bloomberg articles. Productive discourse has retreated to walled gardens, and as a consequence there is much less of it. ⤴️  \n\n\nIf most of their ostensible peers can’t discover new knowledge, then how will they find peers to work with? If most publications aren’t worth the time it takes to read, then who will bother to read the minority that are actually good? ⤴️  \n"},"highlights/Omnivore/20240412074318":{"title":"You can't build a moat with AI","links":[],"tags":[],"content":"You can’t build a moat with AI\nRead on Omnivore\nRead Original\nHighlights\n\nWhatever the case may be, it’s become clear to us that there’s not very much you can do to differentiate yourself using just LLMs1. The real differentiation lies in your data you feed into your models. ⤴️  \n\n\nEveryone today can easily switch between models and experiment with what works best today for their application. That means that whatever you’re building, the advantage you get by picking the right model is small.\nDeviating from the norm is also dangerous — it might get you unexpectedly good answers in some cases and unexpectedly bad answers in other cases. When a lot of AI startups are working to build trust, that’s a risky proposition, and as a result, most teams default back to using the safe models. That means that what you put into the model matters more than ever. ⤴️  \n\n\nAnd your prompts aren’t IP. It might feel like your applications’ prompts or prompt templates are a good form of differentiation. After all, your top-notch engineering team has invested days into tuning them to have the right response characteristics, tone, and output style. Of course, giving your competitors your prompts would probably accelerate their progress, but any good engineering team will figure out the right changes quickly. The main reason is that the experimentation (with the right evaluation data!) is quick and easy — trying a new prompt template isn’t much harder than writing it out. All it really takes is a little bit of patience, some creativity, and extra Azure OpenAI credits. ⤴️  \n"},"highlights/Omnivore/__order__":{"title":"__order__","links":[],"tags":[],"content":""},"highlights/Readwise/31554985":{"title":"What&#39;s Our Problem?","links":[],"tags":[],"content":"Highlights\n\nTechnology is a multiplier of both good and bad. More technology means better good times, but it also means badder bad times. (Location 72)\n\n\nAnd the scary thing is, if the good and bad keep exponentially growing, it doesn’t matter how great the good times become. If the bad gets to a certain level of bad, it’s all over for us. (Location 77)\n\n\nThose who cannot remember the past are condemned to repeat it.1 (Location 96)\n\n\nThis kind of internal disagreement pops up in many parts of life, like a constant tug-of-war in our heads—a tug-of-war over our thoughts, our emotions, our values, our morals, our judgments, and our overall consciousness. (Location 206)\n\n\nPlato wrote about a “charioteer” (intellect) that managed the “horses” of rational modesty and passionate insolence. Sigmund Freud’s structure consisted of the “id” (primitive instinct), the “superego” (the conscience), and the “ego” that balances the two with external reality. More recently, social psychologist Daniel Kahneman wrote about “System 1” (fast, involuntary thinking) and “System 2” (slow, complex thinking that requires effort). Social psychologist Jonathan Haidt wrote about the emotional “elephant” and its rational “rider” which appears to be in control but often is not. Harvard’s Todd Rogers and Max H. Bazerman wrote about the conflict between the “want self” and the “should self.” (Location 211)\n\n\nFor most beliefs, we’re so concerned with where people stand that we often forget the most important thing about what someone thinks: how they arrived at what they think. (Location 250)\n\n\nTrust, when assigned wisely, is an efficient knowledge-acquisition trick. If you can trust a person who actually speaks the truth, you can take the knowledge that person worked hard for—either through primary research or indirectly, using their own diligent trust criteria—and “photocopy” it into your own brain. This magical intellectual corner-cutting tool has allowed humanity to accumulate so much collective knowledge over the past 10,000 years that a species of primates can now understand the origins of the universe. (Location 288)\n"},"highlights/Readwise/31554987":{"title":"Think Again","links":[],"tags":[],"content":"Highlights\n\nWhen a trio of psychologists conducted a comprehensive review of thirty-three studies, they found that in every one, the majority of answer revisions were from wrong to right. This phenomenon is known as the first-instinct fallacy. (Location 106)\n\n\nWe hesitate at the very idea of rethinking. Take an experiment where hundreds of college students were randomly assigned to learn about the first-instinct fallacy. The speaker taught them about the value of changing their minds and gave them advice about when it made sense to do so. On their next two tests, they still weren’t any more likely to revise their answers. Part of the problem is cognitive laziness. Some psychologists point out that we’re mental misers: we often prefer the ease of hanging on to old views over the difficulty of grappling with new ones. Yet there are also deeper forces behind our resistance to rethinking. Questioning ourselves makes the world more unpredictable. It requires us to admit that the facts may have changed, that what was once right may now be wrong. Reconsidering something we believe deeply can threaten our identities, making it feel as if we’re losing a part of ourselves. (Location 114)\n\n\nIf you’re a firefighter, dropping your tools doesn’t just require you to unlearn habits and disregard instincts. Discarding your equipment means admitting failure and shedding part of your identity. You have to rethink your goal in your job—and your role in life. (Location 172)\n\n\nDropping one’s tools creates an existential crisis. Without my tools, who am I?” (Location 175)\n\n\nOur ways of thinking become habits that can weigh us down, and we don’t bother to question them until it’s too late. Expecting your squeaky brakes to keep working until they finally fail on the freeway. Believing the stock market will keep going up after analysts warn of an impending real estate bubble. Assuming your marriage is fine despite your partner’s increasing emotional distance. Feeling secure in your job even though some of your colleagues have been laid off. (Location 179)\n\n\nYou may not carry an ax or a shovel, but you do have some cognitive tools that you use regularly. They might be things you know, assumptions you make, or opinions you hold. Some of them aren’t just part of your job—they’re part of your sense of self. (Location 185)\n\n\nWhat if we were quicker to make amendments to our own mental constitutions? (Location 222)\n\n\nThinking again can help you generate new solutions to old problems and revisit old solutions to new problems. It’s a path to learning more from the people around you and living with fewer regrets. (Location 247)\n\n\nUnfortunately, when it comes to our own knowledge and opinions, we often favor feeling right over being right. In everyday life, we make many diagnoses of our own, ranging from whom we hire to whom we marry. We need to develop the habit of forming our own second opinions. (Location 297)\n\n\nwe often slip into the mindsets of three different professions: preachers, prosecutors, and politicians. In each of these modes, we take on a particular identity and use a distinct set of tools. We go into preacher mode when our sacred beliefs are in jeopardy: we deliver sermons to protect and promote our ideals. We enter prosecutor mode when we recognize flaws in other people’s reasoning: we marshal arguments to prove them wrong and win our case. We shift into politician mode when we’re seeking to win over an audience: we campaign and lobby for the approval of our constituents. The risk is that we become so wrapped up in preaching that we’re right, prosecuting others who are wrong, and politicking for support that we don’t bother to rethink our own views. (Location 308)\n\n\nWe move into scientist mode when we’re searching for the truth: we run experiments to test hypotheses and discover knowledge. Scientific tools aren’t reserved for people with white coats and beakers, and using them doesn’t require toiling away for years with a microscope and a petri dish. Hypotheses have as much of a place in our lives as they do in the lab. Experiments can inform our daily decisions. (Location 330)\n\n\nLike careful scientists, they take their time so they have the flexibility to change their minds. I’m beginning to think decisiveness is overrated … but I reserve the right to change my mind. (Location 353)\n\n\nIntelligence was no cure—it might have been more of a curse. (Location 383)\nIf intelligence is power, then this is very similar to the dictator trap where people are too overconfident in their power that they fail to see any hard truth.\n\n\nNo matter how much brainpower you have, if you lack the motivation to change your mind, you’ll miss many occasions to think again. Research reveals that the higher you score on an IQ test, the more likely you are to fall for stereotypes, because you’re faster at recognizing patterns. (Location 385)\n\n\nResearch reveals that the higher you score on an IQ test, the more likely you are to fall for stereotypes, because you’re faster at recognizing patterns. And recent experiments suggest that the smarter you are, the more you might struggle to update your beliefs. (Location 386)\nThis reminds me of the black swan theory. In both cases, we are so quick to draw a conclusion that we are more comfortable or familiar with.\n\n\nYet if the empirical pattern clashes with your ideology, math prowess is no longer an asset; it actually becomes a liability. The better you are at crunching numbers, the more spectacularly you fail at analyzing patterns that contradict your views. If they were liberals, math geniuses did worse than their peers at evaluating evidence that gun bans failed. If they were conservatives, they did worse at assessing evidence that gun bans worked. (Location 392)\n\n\nliability. The better you are at crunching numbers, the more spectacularly you fail at analyzing patterns that contradict your views. If they were liberals, math geniuses did worse than their peers at evaluating evidence that gun bans failed. If they were conservatives, they did worse at assessing evidence that gun bans worked. (Location 393)\n\n\nOne is confirmation bias: seeing what we expect to see. The other is desirability bias: seeing what we want to see. (Location 396)\n\n\nMy favorite bias is the “I’m not biased” bias, in which people believe they’re more objective than others. It turns out that smart people are more likely to fall into this trap. (Location 400)\n\n\nThinking like a scientist involves more than just reacting with an open mind. It means being actively open-minded. It requires searching for reasons why we might be wrong—not (Location 405)\n\n\nAfter all, the purpose of learning isn’t to affirm our beliefs; it’s to evolve our beliefs. (Location 417)\n\n\nIf knowledge is power, knowing what we don’t know is wisdom. (Location 437)\n\n\nResearch shows that when people are resistant to change, it helps to reinforce what will stay the same. Visions for change are more compelling when they include visions of continuity. Although our strategy might evolve, our identity will endure. (Location 474)\n\n\nThe curse of knowledge is that it closes our minds to what we don’t know. Good judgment depends on having the skill—and the will—to open our minds. (Location 485)\n\n\nAnton’s syndrome—a deficit of self-awareness in which a person is oblivious to a physical disability but otherwise doing fairly well cognitively. (Location 520)\n\n\nWe all have blind spots in our knowledge and opinions. The bad news is that they can leave us blind to our blindness, which gives us false confidence in our judgment and prevents us from rethinking. The good news is that with the right kind of confidence, we can learn to see ourselves more clearly and update our views. (Location 522)\n\n\nThat’s the armchair quarterback syndrome, where confidence exceeds competence. (Location 556)\n\n\nThe opposite of armchair quarterback syndrome is impostor syndrome, where competence exceeds confidence. (Location 558)\n"},"highlights/Readwise/31554988":{"title":"31554988","links":[],"tags":[],"content":"Highlights\n\nWe do not have to know everything about something in order to understand it; too many facts are often as much of an obstacle to understanding as too few. (Location 163)\n\n\nthe more active the reading the better. (Location 178)\n\n\nfurther. The art of catching is the skill of catching every kind of pitch—fast balls and curves, changeups and knucklers. Similarly, the art of reading is the skill of catching every sort of communication as well as possible. (Location 190)\n"},"highlights/Readwise/31554990":{"title":"31554990","links":[],"tags":[],"content":"Highlights\n\nThis is about getting mighty clear about what makes you happy and what makes you feel the most alive, and then creating it instead of pretending you can’t have it. (Location 100)\n\n\nIt’s about having the cojones to show up as the brightest, happiest, badassiest version of yourself, whatever that looks like to you. (Location 103)\n\n\nYou need to go from wanting to change your life to deciding to change your life. (Location 105)\n\n\nDeciding means jumping in all the way, doing whatever it takes, and going after your dreams with the tenacity of a dateless cheerleader a week before prom night. (Location 108)\n\n\nYou’ve gotten to where you are right now by doing whatever it is you’re doing, so if you’re less than impressed with your current situation, you clearly need to change things up. (Location 150)\n\n\nIf you want to live a life you’ve never lived, you have to do things you’ve never done. (Location 153)\n\n\nOur subconscious mind contains the blueprint for our lives. It’s running the show based on the unfiltered information it gathered when we were kids, otherwise known as our “beliefs.” (Location 247)\n\n\n\nWe are, for the most part, completely oblivious to these subconscious beliefs that run our lives. (Location 249)\n\n\n\n\nWhen our conscious minds finally develop and show up for work, no matter how big and smart and highfalutin they grow to be, they’re still being controlled by the beliefs we’re carrying around in our subconscious minds. (Location 251)\n\n\n\nThe first key to ridding yourself of limiting subconscious beliefs is to become aware of them. (Location 293)\n\n\nFocus on that which makes you feel good and ye shall find (attract) that which makes you feel good. (Location 356)\n\n\nThe trick is to have both parts—energy and action—working in unison: unless your energy is lined up properly with that which you desire, really desire, any action you take is going to require way more effort to get you where you want to go, if it gets you there at all. (Location 382)\n\n\nIf you are depressed, you are living in the past. If you are anxious, you are living in the future. If you are at peace, you are living in the present. (Location 399)\n\n\nIt never ceases to amaze me the precious time we spend chasing the squirrels around our brains, playing out our dramas, worrying about unwanted facial hair, seeking adoration, justifying our actions, complaining about slow Internet connections, dissecting the lives of idiots, when we are sitting in the middle of a full-blown miracle that is happening right here, right now. (Location 420)\n\n\nextremely committed to keeping you safely confined within the reality you’ve created based on these limiting false beliefs (otherwise known as your comfort zone). (Location 491)\n\n\nWatching someone else totally go for it can be incredibly upsetting to the person who’s spent a lifetime building a solid case for why they themselves can’t. (Location 504)\n\n\nWhatever happens, stay the course, because there’s nothing cooler than watching your entire reality shift into one that is the perfect expression of you. (Location 564)\n\n\nYou get to choose how you perceive your reality. So why, when it comes to perceiving yourself, would you choose to see anything other than a super huge rock star of a creature? (Location 591)\n\n\nbe. I repeat, you are the only you there is and ever will be. Do not deny the world its one and only chance to bask in your brilliance. (Location 601)\n\n\nwe invest everything we’ve got in believing that we’re not good enough. (Location 634)\n\n\nWe’re all busy, but it’s the people who make enjoying their lives a priority who, um, enjoy their lives. (Location 678)\n\n\nIt’s about being proactive about creating a life you love instead of meekly living the one you think you’re stuck with. (Location 683)\n\n\nDo not spend your life clinging to the insulting decisions you’ve made about yourself. Instead, make the conscious choice to replace them with new and improved ones. (Location 716)\n\n\nComparison is the fastest way to take all the fun out of life. (Location 740)\n\n\nYou aren’t a better person for feeling guilty or bad about yourself, just a sadder one. (Location 751)\n\n\nHolding on to my bad feelings about this is doing nothing but harming me, and everyone else, and preventing me from enjoying my life fully. I am an awesome person. I choose to enjoy my life. I choose to let this go. (Location 756)\n\n\nDO NOT WASTE YOUR PRECIOUS TIME GIVING ONE SINGLE CRAP ABOUT WHAT ANYBODY ELSE THINKS OF YOU. (Location 776)\n\n\nWhat other people think about you has nothing to do with you and everything to do with them. (Location 817)\n\n\nif you do the absolute best you possibly can, and come from a place of integrity, then you can be proud of yourself and not give a damn what anyone else thinks. (Location 836)\n\n\nIt still ultimately comes down to what’s true for you, however, so the more connected to your inner truth you are, the easier it will be to use outside opinions to your advantage, rather than let them rule your life. (Location 863)\n\n\nImagine that you’re an alien floating around in outer space and you suddenly swoop down to Earth and inhabit your own body. As the alien, everything about this life is new to you. You look around—what do you see? What is this person who you’ve inhabited so obviously awesome at? What do they have the most fun doing? What connections do they have? What resources and opportunities are available to them? (Location 903)\n\n\nYou don’t have to know exactly where it’s going to take you, you just need to start with one thing that feels right and keep following right-feeling things and see where they lead. (Location 916)\n\n\nNo matter how clueless you may feel right now, pay attention to suggestions and opportunities that suddenly present themselves. And notice how you feel—is there something for you that, for whatever reason, feels like it might be good to check out? (Location 930)\n\n\nBut no matter where your first step lands you, if you want to keep moving forward, appreciate wherever you’re at instead of feeling ashamed or grouchy or impatient about it. (Location 937)\n\n\nPut yourself out there and you never know what you might learn that will inform your next move, or whom you might meet that will present you with your next opportunity. (Location 957)\n\n\nFollow what feels good in the moment, every moment, and it will lead you through a most excellent life. (Location 967)\n\n\nMuch of the time we pretend we aren’t clear on what our calling is when what’s really going on is that we’re horrified to face it because it seems too big or too impossible to make a living at or completely out of the question for us. (Location 987)\n"},"highlights/Readwise/31554991":{"title":"31554991","links":[],"tags":[],"content":"Highlights\n\nBut, isn’t pushing people out of the ring pushing the boundaries of ethics? Not at all—it’s no more than doing the uncommon within the rules. (Location 546)\nRules are not ethics, rules are the lower bounds like laws, ethics are often above rules that people abide holding themselves to highestest standards. For any fan of chinese martial arts and of Wulin, this is cringe as fork.\n\n\nDifferent is better when it is more effective or more fun. (Location 563)\nLess ethical and more cringe? Hell no\n\n\nIf I simply made all my calls from 8:00–8:30 A.M. and 6:00–6:30 P.M., for a total of one hour, I was able to avoid secretaries and book more than twice as many meetings as the senior sales executives who called from 9–5. In other words, I got twice the results for ⅛ the time. (Location 566)\nHow much of this is still true in a society that respects work-life balance. If someone is calling me during those times unexpectedly, I would at least consider them rude.\n\n\nRetirement planning is like life insurance. (Location 573)\nRetriement is not the end goal of life planning, it should be an artifact.\n\n\nThe universe doesn’t conspire against you, but it doesn’t go out of its way to line up all the pins either. Conditions are never perfect. “Someday” is a disease that will take your dreams to the grave with you. Pro and con lists are just as bad. If it’s important to you and you want to do it “eventually,” just do it and correct course along the way. (Location 610)\n\n\nIt is far more lucrative and fun to leverage your strengths instead of attempting to fix all the chinks in your armor. The choice is between multiplication of results using strengths or incremental improvement fixing weaknesses that will, at best, become mediocre. Focus on better use of your best weapons instead of constant repair. (Location 623)\nToo extreme\n\n\nDistress refers to harmful stimuli that makes you weaker, less confident, and less able. Destructive criticism, abusive bosses, and smashing your face on a curb are examples of this. These are things we want to avoid. Eustress, on the other hand, is a word most of you have probably never heard. Eu-, a Greek prefix for “healthy,” is used in the same sense in the word “euphoria.” Role models who push us to exceed our limits, physical training that removes our spare tires, and risks that expand our sphere of comfortable action are all examples of eustress—stress that is healthful and the stimulus for growth. (Location 663)\nWhat is the difference between motivation and eustress?\n"},"highlights/Readwise/31554992":{"title":"31554992","links":[],"tags":[],"content":"Highlights\n\nTo build wealth it didn’t matter when you bought U.S. stocks, just that you bought them and kept buying them. It didn’t matter if valuations were high or low. It didn’t matter if you were in a bull market or a bear market. All that mattered was that you kept buying. (Location 105)\n\n\nMake it a habit to invest your money like you make it a habit to pay your rent or mortgage. Buy investments like you buy food—do it often. (Location 114)\n\n\nIf you don’t have much money invested, then you should focus on increasing your savings (and investing it). However, if you already have a sizable portfolio, then you should spend more time thinking about the details of your investment plan. (Location 176)\n\n\nFirst, figure out how much you expect to comfortably save in the next year. (Location 187)\n\n\nNext, determine how much you expect your investments to grow in the next year (in (Location 190)\n\n\nIf your expected savings are higher, then you need to focus more on saving money and adding to your investments. However, if your expected investment growth is higher, then spend more time thinking about how to invest what you already have. If the numbers are close to each other, then you should spend time on both. (Location 194)\n\n\nWhen we have the ability to save more, we should save more—and when we don’t, we should (Location 262)\n\n\nsave less. We shouldn’t use static, unchanging rules because our finances are rarely static and unchanging. (Location 262)\n\n\nThis is why the best savings advice is: save what you can. If you follow this advice, you will experience far less stress and far more overall happiness. (Location 267)\n\n\n“The negative effects of stress outweigh the positive effects of income or health in general.” (Location 277)\n\n\nThis implies that saving more is only beneficial if you can do it in a stress-free way. Otherwise, you will likely do yourself more harm than good. (Location 280)\n\n\nSimilar to the effect of exercise on weight loss, cutting spending seems to have inherent limitations when it comes to saving more money. (Location 418)\n\n\nIncreases in income aren’t followed by similar increases in spending. (Location 446)\n\n\ndiminishing marginal utility. This is a jargonistic phrase, but its meaning is simple. It means that each additional unit of consumption brings about less benefit than the unit before it. (Location 456)\n\n\nTheir paper clearly illustrates that many poor people stay poor not because of their talent/motivation, but because they are in low-paying jobs that they must work to survive. (Location 493)\n\n\nThe most consistent way to get rich is to grow your income and invest in income-producing assets. (Location 510)\n\n\nIf you want to save more, the main point is to tighten up where you can, then focus on increasing your income. (Location 513)\n\n\nTherefore, if you need to make more money, consider selling more of your time, or your expertise. (Location 529)\n\n\nThe only downside to selling your time is that it doesn’t scale. One hour of work will always equal one hour of income. (Location 532)\n\n\nUnfortunately, similar to selling your time, selling an individual skill or service doesn’t scale. You have to do the work for each service delivered. (Location 546)\n\n\nWhile a 9 to 5 will rarely make you filthy rich, learning how to work well with people and developing your skills can be one of the best things for your career development. (Location 591)\n\n\nYes, selling your time, skills, or products is great and all, but it shouldn’t be the end goal of your wealth-building journey. The end goal should be ownership—using your additional income to acquire more income-producing assets. (Location 613)\n\n\nThe 2x Rule Focus on Maximizing Fulfillment (Location 687)\n\n\nThe 2x Rule works like this: Anytime I want to splurge on something, I have to take the same amount of money and invest it as well. (Location 690)\nThe expense should also include time and energy post-purchase.\n\n\nAll that matters is the feeling that you get when you consider buying something. (Location 699)\n\n\nfollowing ways was most likely to increase your overall happiness:26 Buying experiences Treating yourself (on occasion) Buying extra time Paying upfront (e.g., all-inclusive vacations) Spending on others (Location 713)\n\n\nPink discusses how autonomy (being self-directed), mastery (improving your skills), and purpose (connecting to something bigger than yourself) are the key components to human motivation and satisfaction.27 (Location 724)\n\n\nAfter all, it’s not the purchase that makes you feel guilty, but how you justify that purchase in your head. (Location 737)\n\n\nUltimately, you are the one that must figure out what you want out of life. Once you do, then spend your money accordingly. (Location 756)\n\n\nLifestyle creep is when someone increases their spending after experiencing an increase in income or as a way of keeping up with their peers. (Location 789)\n\n\nHow much lifestyle creep can you afford? Technically it varies based on your savings rate, but for most people the answer is around 50%. (Location 799)\n\n\nMore importantly, saving 50% of your raises is easy to implement and remember. Half is for you and half is for future you (in retirement). Coincidentally, this idea is similar to The 2x Rule I wrote about in the prior chapter when discussing how to spend money without feeling guilty. (Location 892)\n\n\nThis behavior, known as bet hedging, is a risk-reduction strategy that seeks to maximize an organism’s long-term reproductive success. It’s not about maximizing offspring in any one year, but over time. (Location 919)\n\n\nThe credit card debt puzzle is the observation that some people hold credit card debt despite having the ability to pay it off from savings. (Location 932)\n\n\nTo reduce risk. To generate a return greater than the cost to borrow. (Location 959)\n\n\nIn this case, the optionality provided by holding debt can be worth more than the cost to hold it. (Location 963)\n\n\nHowever, when the expected return is large, debt can change your life. One area where this is typically true is in higher education. (Location 971)\n\n\nThis will be roughly equivalent to a 40-year payment stream discount by 4% per year. I prefer this shortcut because you can now do the math in your head. Therefore, a 800,000increaseinlifetimeearningsover40yearsisworthabout400,000 today. (Location 1000)\n\n\nValue of Degree Today = (Increased Lifetime Earnings/2) – Lost Earnings (Location 1009)\n\n\nIn all these studies, non-mortgage, financial debt was the culprit. Ideally, you should avoid this kind of debt, when possible. (Location 1043)\n\n\nhe suggested 4% as the highest safe withdrawal rate going forward, and it stuck. (Location 1416)\n\n\nTotal Savings = 25 × Annual Spending (Location 1425)\n\n\nspending declines as people get older. (Location 1453)\n\n\nThey found that spending in retirement typically declined by about 1% per year.54 (Location 1469)\n\n\nMonthly Investment Income = Crossover Assets × Monthly Investment Return (Location 1490)\n\n\nIndeed, physical well-being, mental well-being, and solid social support play bigger roles than financial status for most retirees.” (Location 1517)\n\n\nWork defines who you are. It provides a place where you are social with people. It gives you interaction with people all day long in an interesting way. It even helps you live longer and is very, very good for brain health… (Location 1525)\n\n\n“Embracing a nomadic FIRE lifestyle means accepting that you are no longer relevant or important and in some ways now operate in the ether between existence and non-existence.”59 (Location 1550)\n\n\nThough money can solve many of your problems, it won’t solve all of your problems. Money is merely a tool to help you get what you want out of life. Unfortunately, figuring out what you want out of life is the hard part. (Location 1555)\n\n\nthe three primary reasons why you should invest: To save for your future self. To preserve your money against inflation. To replace your human capital with financial capital. (Location 1604)\n\n\nthinking about your future self is one of the best ways to improve your investment behavior. (Location 1615)\n\n\nThis implies that the prices of everyday goods should double every two to three decades, under modest levels of inflation, and far more quickly if the inflation rate is higher. (Location 1646)\n\n\nThis is especially true for retirees, who will be forced to pay higher prices without the benefit of earning higher wages. Since retirees don’t work, their only weapon against inflation is (Location 1661)\n\n\nasset appreciation. (Location 1662)\n\n\nin the long run holding cash is almost always a bad bet because of inflation’s annual toll. (Location 1664)\n\n\nhuman capital as the value of your skills, knowledge, and time. (Location 1670)\n\n\nAs a result, investing is the only way in which you can fight back against the march of time and turn your diminishing human capital into productive financial capital. Financial capital that will pay you long into the future. (Location 1671)\n\n\nyour human capital is a dwindling asset. Each year you work reduces the present value of your human capital because you have one less year of future earnings. (Location 1691)\n\n\nAs a result, the only way to guarantee that you will have some income in the future (outside of government-sponsored income) is to build up financial capital. (Location 1692)\n\n\nrealizing that your abilities will eventually fade away can be one of the best motivators for investing. (Location 1708)\n\n\nJay’s realization—what works for some people won’t necessarily work for others—is as true in judo as it is in investing. (Location 1730)\n\n\nIt is this highly volatile nature of stocks that makes them difficult to hold during turbulent times. (Location 1775)\n\n\nThe best way to combat such emotional volatility is to focus on the long term. (Location 1777)\n\n\nbut mainly because index funds are an easy way to get cheap diversification. (Location 1783)\n\n\nPros: High historic returns. Easy to own and trade. Low maintenance (someone else runs the business). (Location 1796)\n\n\nCons: High volatility. Valuations can change quickly based on sentiment rather than fundamentals. (Location 1797)\n\n\nBonds should act as a diversifying asset, not a risk asset. (Location 1821)\n\n\nDuring market sell-offs, bonds are one of the only assets that tend to rise while everything else is falling. (Location 1829)\n\n\nPros: Lower volatility. Good for rebalancing. Safety of principal. (Location 1860)\n\n\nCons: Low returns, especially after inflation. Not great for income in a low-yield environment. (Location 1861)\n\n\nDespite the many financial upsides to owning an investment property, it also requires far more work than many other assets that you can set and forget. (Location 1878)\n\n\nHowever, when things go wrong, like they did in 2020 with pandemic-induced travel restrictions, they can go really wrong. As many Airbnb entrepreneurs learned the hard way, investment properties aren’t always so easy. (Location 1883)\n\n\nbuying individual investment properties is similar to buying individual stocks in that they aren’t diversified. When you buy an investment property you take on all the specific risks to that property. (Location 1886)\n\n\nPros: Higher returns than other more traditional asset classes, especially when using leverage. (Location 1898)\n\n\nCons: Managing the property and tenants can be a headache. Hard to diversify. (Location 1899)\n\n\nHowever, like most other risky assets, publicly traded REITs tend to sell off during stock market crashes. Therefore, don’t expect diversification benefits from REITs on the downside. (Location 1929)\n\n\nPros: Real estate exposure that you don’t have to manage. Less correlated with stocks during good times. (Location 1937)\n\n\nCons: Volatility greater than or equal to stocks. Less liquidity for non-traded REITs. Highly correlated with stocks and other risk assets during stock market crashes. (Location 1939)\n\n\nclear—if you want access to the best angel investments with big, outsized returns, then you have to be deeply embedded in that community.75 (Location 1995)\n\n\nResearch on this topic supports Max’s claim, finding that time spent on due diligence, experience, and participation were all positively correlated with an angel investor’s long-term returns.76 (Location 1997)\n\n\nPros: Can have extremely outsized returns. The more involved you are, the more future opportunities you will see. (Location 2009)\n\n\nCons: Huge time commitment. Lots of failures can be discouraging. (Location 2010)\n\n\nThis concept, more formally known as the Lindy Effect, states that something’s popularity in the future is proportional to how long it has been around in the past. (Location 2031)\n\n\nPros: Uncorrelated to traditional financial assets. Generally steady income. Cons: High seller fees. Tastes can change unexpectedly and impact income. (Location 2044)\n\n\nThe hard part about products as investments is that they require lots of work upfront with no guarantee of a payout. There is a long road to monetization. (Location 2056)\n\n\nPros: Full ownership. Personal satisfaction. Can create a valuable brand. Cons: Very labor intensive. No guarantee of payoff. (Location 2068)\n\n\nGold, cryptocurrency, commodities, art, and wine have no reliable income stream associated with their ownership, so I have not included them in my list of income-producing assets. (Location 2073)\n\n\nWhat it does mean is that their valuations are based solely on perception—what someone else is willing to pay for them. Without underlying cash flows, perception is everything. (Location 2075)\n\n\nNevertheless, Darren’s story is a microcosm of what it’s like to be a stock picker. The mental turmoil. The fear of missing out. The elation, triumph, pain, and regret. It was all perfectly packaged into a single two-hour window. (Location 2179)\n\n\nAnd remember, this 75% consists of professional money managers working full-time with teams of analysts. If they can’t outperform with all these resources, what chance do you have? (Location 2193)\n\n\nThe existential argument against stock picking is simple—how do you know if you are good at picking individual stocks? (Location 2215)\n\n\nHow long would it take to determine if someone is a good stock picker? (Location 2221)\n\n\nThe issue is that causality is harder to determine with stock picking than with other domains. (Location 2223)\n\n\nthe linkage between the decision and the result is far less obvious. (Location 2233)\n\n\nAfter all, underperformance isn’t a matter of if, but when. (Location 2250)\n\n\nhow complex systems can be more easily understood with a single piece of accurate information. (Location 2318)\n\n\nMost stock markets go up most of the time. (Location 2323)\n\n\nGiven this empirical evidence, it suggests that you should invest your money as soon as possible. (Location 2331)\n\n\n“The best time to start was yesterday. The next best time is today.” (Location 2346)\n\n\nThat feeling is accurate because it is very likely that a better price will appear at some point in the future. However, the data suggests that the best thing to do is ignore that feeling altogether. (Location 2349)\n\n\nAs a result, the best market timing approach is to invest your money as soon as you can. This isn’t just an opinion of mine either. It is backed by historical data across multiple asset classes and multiple time periods. (Location 2369)\n\n\nAs you can see, Average-In underperformed Buy Now by 2%-4%, on average, over 12 months for most assets and in 60%–80% of all starting months. (Location 2437)\n\n\nIsn’t it riskier to Buy Now than to Average-In? The answer is a resounding “Yes!” (Location 2443)\n\n\nAs the next chart illustrates, the standard deviation of the Buy Now strategy is always higher than the Average-In strategy when investing in the S&amp;P 500. (Location 2444)\n\n\nThe problem is that severe market declines don’t happen too often. In U.S. market history severe dips have only taken place in the 1930s, 1970s, and 2000s. That’s rare. This means that Buy the Dip only has a small chance of beating DCA. (Location 2579)\n\n\nBecause while you wait for your beloved dip, you may find that it never comes. As a result, you end up missing out on months (or more) of compound growth as the market keeps rising and leaves you behind. (Location 2646)\n\n\nBut, in reality, you will never know this with certainty. You will never have perfect market timing foresight. (Location 2649)\n\n\nAnd, as we saw in the previous chapter, it’s generally better to invest sooner rather than later. (Location 2655)\n\n\nYou should invest as soon and as often as you can. (Location 2656)\n\n\nThe only good news here is that, over 30-year periods, the differences in annualized returns are far less pronounced. (Location 2727)\n\n\nAs a result, the importance of your future returns increases as you add more money. This means that, after adding funds, a negative return will cost you more in absolute dollar terms than if that negative return had occurred before you added those funds. (Location 2749)\n\n\nAnd since most individual investors add assets over time, the ordering of investment returns matters more than almost any other financial risk you will face. (Location 2752)\n\n\nGetting the negative returns later in life (when you have the most money in play) leaves you far worse off than if you experienced those negative returns when you first started investing. In other words, the end is everything. (Location 2766)\n\n\nAdequately diversify with enough low-risk assets (e.g., bonds). (Location 2796)\n\n\nConsider withdrawing less money during market (Location 2798)\n\n\ndownturns. (Location 2799)\n\n\nConsider working part-time to supplement your income. (Location 2801)\n\n\nAnd if you are a younger investor, the best way to mitigate bad luck is time itself. Since most markets go up most of the time, as we saw in chapter 13, this means that time is a young investor’s friend. (Location 2805)\n\n\nSmith’s story illustrates an important lesson about risk and the cost of inaction — sometimes the biggest risk you can take is taking no risk at all. (Location 2833)\n\n\nWe have the ability to diversify. We can diversify what assets we own and we can diversify when we own them. Buying a diverse set of income-producing assets over time is one of the best ways to combat volatility when it rears its ugly head. (Location 2906)\n\n\nBut it wasn’t audacious. It was a moment of normalcy. If the flower guy still has hope, why shouldn’t I? (Location 2937)\n\n\nThe reasoning is simple—every dollar invested during the crash will grow to far more than one invested in months prior, assuming that the market eventually recovers. (Location 2952)\n\n\nIt comes from a simple mathematical fact—every percentage loss requires an even larger percentage gain to get back to even. (Location 2963)\n\n\nBut we can’t invest based on exceptions or what might happen. Otherwise, we would never invest at all. (Location 3055)\n\n\nAs Friedrich Neitzsche once said, “Ignore the past and you will lose an eye. Live in the past and you will lose both.” Knowing history is important, but obsessing over it can lead us astray. This is why we must invest based on what the data tells us. (Location 3056)\n\n\nBecause selling forces you to face off against two of the strongest behavioral biases in the investment world—fear of missing out on the upside and the fear of losing money on the downside. (Location 3073)\n\n\nTo rebalance. To get out of a concentrated (or losing) position. To meet your financial needs. (Location 3080)\n\n\nSince markets tend to go up over time, the optimal thing to do is to sell as late as possible. Therefore, selling over time (or as late as possible) is usually better than selling right away. (Location 3090)\n\n\nFrom this simple fact we can then infer that the portfolio that never rebalances generally outperforms the one that rebalances annually. Why? Because nearly every time you rebalance you usually end up selling a higher-growth asset (stocks) to buy a lower-growth asset (bonds). (Location 3121)\n\n\nTo reduce risk. Rebalancing is all about controlling risk. (Location 3130)\n\n\nFrom this plot we can see that, most of the time, rebalancing reduces risk by shifting money from your higher-volatility assets (stocks) to your lower-volatility assets (bonds). (Location 3144)\n\n\nUnfortunately, no rebalancing frequency consistently outperformed all the others. (Location 3152)\n\n\n“The risk-adjusted returns are not meaningfully different whether a portfolio is rebalanced monthly, quarterly, or annually; however, the number of rebalancing events and resulting costs increase significantly.”95 (Location 3154)\n\n\nAll of these analyses illustrate the same thing—it doesn’t matter when you rebalance, just that you do it on some periodic basis. As a result, I recommend an annual rebalance for two reasons: It takes less time. It coincides with our annual tax season. (Location 3161)\n\n\nWhatever you decide to do when it comes to rebalancing frequency, avoiding unnecessary taxation is a must. This is why I don’t recommend rebalancing frequently in your taxable accounts (i.e., brokerage account). Because every time you do, you have to pay Uncle Sam. (Location 3173)\n\n\nWhile selling an asset to rebalance isn’t the worst thing in the world, there is a way to rebalance your portfolio that involves no tax consequences at all—Just Keep Buying. That’s right. You can buy your way back into a rebalanced portfolio. I call this an accumulation rebalance because you are rebalancing by buying your most underweight asset over time. (Location 3178)\n\n\nSometimes it’s better to trade maybes for certainties. (Location 3208)\n\n\nIf you sell it all right away and it goes up 10x, you will feel far worse than if you sell 95% of it and the remaining 5% goes to $0. It’s this regret minimization framework that you should employ when deciding on how much to sell. (Location 3214)\n\n\nAnd don’t mix up a period of underperformance with a losing position. Every asset class goes through periods of underperformance, so you shouldn’t use these periods as an excuse to sell. (Location 3229)\n\n\nAs a reminder, a 401(k)—also called a traditional 401(k)—is funded with pre-tax money while a Roth 401(k) is funded with post-tax money. The only difference between these account types is when you decide to pay your taxes. (Location 3299)\n\n\nWill your effective income tax rate be higher now (while working) or later (in retirement)? All else equal, if you think your income taxes will be higher now, then contribute to a traditional 401(k), otherwise contribute to a Roth 401(k). (Location 3327)\n\n\nThough there are a few scenarios where a Roth 401(k) would be preferred to a traditional 401(k), I generally prefer the traditional 401(k). Why? Because it has one thing that a Roth doesn’t have—optionality. (Location 3354)\n\n\nThis is why it probably doesn’t make sense to contribute to a Roth 401(k) while living in a high tax area like New York City, unless you know you are going to retire in an area with similarly high taxes. (Location 3367)\n\n\nDespite the lack of optionality in a Roth 401(k), there are a few special cases where a Roth might be the way to go. One of these cases is for people who are high savers. (Location 3379)\n\n\nThis simple example demonstrates that the Roth 401(k) is probably the better choice for high savers, as you get more total tax-deferred benefits. (Location 3389)\n\n\nI ask this question because I feel like I made a financial mistake by contributing too much to my 401(k) when I was younger. While my retirement projections look great now, I also placed some limits on what I can do with my money. (Location 3479)\n\n\nUltimately, the decision to max out your 401(k) will be dependent on your individual circumstances. Factors such as your temperament, financial goals, and the cost of your employer’s 401(k) plan will all play a role in this decision. Make sure you have considered these factors carefully before moving forward. (Location 3493)\n\n\nIn fact, if you want to maximize your after-tax wealth, then you should put your highest-growth assets in tax-sheltered accounts (e.g., 401k, IRA, etc.) and your lowest-growth assets in taxable accounts. (Location 3507)\n\n\nThis example illustrates why you need to consider the expected growth rate of your assets in addition to the tax rates on income/capital gains before making an asset location decision. Additionally, by placing your high-growth (and likely higher-risk) assets into a nontaxable account, you may be less tempted to sell them during a market crash because they are harder to access. (Location 3516)\n\n\nSo, when the market crashes, the assets that are most likely to maintain their value are the ones that are also most accessible. (Location 3522)\n\n\nThere is no right answer, because being rich is a relative concept. Always has been and always will be. And that relativity will be present throughout your life. (Location 3656)\n\n\nin some circumstances, time is worth far more than money. Because you can do some things with time that you could never do with money. In fact, with enough time you could even move mountains. (Location 3694)\n\n\nThis is why time is, and always will be, your most important asset. How you use that time in your 20s, 30s, and 40s will have huge impacts on your life in your 50s, 60s, and 70s. Unfortunately, it can take a while to learn this lesson. I know from personal experience. (Location 3713)\n\n\nBut you know what would have made a difference? Making better decisions earlier in my career. It wasn’t my money I should have optimized, but my time. (Location 3733)\n\n\nThe reason for my mistake is that I incorrectly believed that money was a more important asset than time. I only later realized why this was false. Though you can always earn more money, nothing can buy you more time. (Location 3745)\n\n\n“Young people consistently overestimate their future life satisfaction. They make a whopping forecasting error, as nonrandom as it could be—as if you lived in Seattle and expected sunshine every day… Young adults in their twenties overestimate their future life satisfaction by about 10 percent on average. Over time, however, excessive optimism diminishes… People are not becoming depressed. They are becoming, well, realistic.”108 (Location 3772)\n\n\nGrowth stocks are priced similarly to how we think of ourselves when we are young. There are high expectations and high hopes for the future. However, many of us, like many growth stocks, eventually fail to meet these high expectations. (Location 3783)\n\n\nOver time we lower our expectations so much that we doubt that things could be better in the future. This is similar to how investors price value stocks. (Location 3785)\n\n\nSaving is for the Poor, Investing is for the Rich (Location 3817)\n\n\nSave What You Can (Location 3820)\n\n\nFocus on Income, Not Spending (Location 3823)\n\n\nUse The 2x Rule to Eliminate Spending Guilt (Location 3825)\n\n\nSave at Least 50% of Your Future Raises and Bonuses (Location 3828)\n\n\nDebt Isn’t Good or Bad, It Depends on How You Use It (Location 3831)\n\n\nOnly Buy a Home When the Time Is Right (Location 3833)\n\n\nWhen Saving for a Big Purchase, Use Cash (Location 3836)\n\n\nRetirement is About More Than Money (Location 3839)\n\n\nInvest to Replace Your Waning Human Capital with Financial Capital (Location 3841)\n\n\nThink Like an Owner and Buy Income-Producing Assets (Location 3844)\n\n\nDon’t Buy Individual Stocks (Location 3847)\n\n\nBuy Quickly, Sell Slowly (Location 3849)\n\n\nInvest As Often As You Can (Location 3853)\n\n\nInvesting Isn’t About the Cards You Are Dealt, but How You Play Your Hand (Location 3855)\n\n\nDon’t Fear Volatility When It Inevitably Comes (Location 3858)\n\n\nMarket Crashes Are (Usually) Buying Opportunities (Location 3861)\n\n\nFund the Life You Need Before You Risk it for the Life You Want (Location 3863)\n\n\nDon’t Max Out Your 401(k) Without Considerable Thought (Location 3866)\n\n\nYou’ll Never Feel Rich and That’s Okay (Location 3869)\n\n\nTime is Your Most Important Asset (Location 3872)\n"},"highlights/Readwise/31554993":{"title":"31554993","links":[],"tags":[],"content":"Highlights\n\nWriting is not what follows research, learning or studying, it is the medium of all this work. (Location 134)\n\n\nThere is another reason that note-taking flies mostly under the radar: We don’t experience any immediate negative feedback if we do it badly. (Location 139)\n\n\nThey struggle because they believe, as they are made to believe, that writing starts with a blank page. (Location 153)\n\n\nThe quality of a paper and the ease with which it is written depends more than anything on what you have done in writing before you even made a decision on the topic. (Location 158)\n\n\nWhat does make a significant difference along the whole intelligence spectrum is something else: how much self-discipline or self-control one uses to approach the tasks at hand (Duckworth and Seligman, 2005; Tangney, Baumeister, and Boone, 2004). (Location 166)\n\n\nEvery task that is interesting, meaningful and well-defined will be done, because there is no conflict between long- and short-term interests. (Location 179)\n\n\nA good, structured workflow puts us back in charge and increases our freedom to do the right thing at the right time. (Location 200)\n\n\nTo keep going according to plan, you have to push yourself and employ willpower. This is not only demotivating, but also unsuitable for an open-ended process like research, thinking or studying in general, where we have to adjust our next steps with every new insight, understanding or achievement – which we ideally have on a regular basis and not just as an exception. (Location 203)\n\n\nThe challenge is to structure one’s workflow in a way that insight and new ideas can become the driving forces that push us forward. We do not want to make ourselves dependent on a plan that is threatened by the unexpected, like a new idea, discovery – or insight. (Location 208)\n\n\nExperts, on the other hand, would not even consider voluntarily giving up what has already proved to be rewarding and fun: learning in a way that generates real insight, is accumulative and sparks new ideas. (Location 213)\n\n\nAll that means is that a system is needed to keep track of the ever-increasing pool of information, which allows one to combine different ideas in an intelligent way with the aim of generating new ideas. (Location 224)\n\n\nIn fact, poor students often feel more successful (until they are tested), because they don’t experience much self-doubt. In psychology, this is known as the Dunning-Kruger effect (Kruger and Dunning, 1999). Poor students lack insight into their own limitations – as they would have to know about the vast amount of knowledge out there to be able to see how little they know in comparison. That means that those who are not very good at something tend to be overly confident, while those who have made an effort tend to underestimate their abilities. (Location 228)\n\n\nThis is why high achievers who have had a taste of the vast amount of knowledge out there are likely to suffer from what psychologists call imposter syndrome, the feeling that you are not really up to the job, even though, of all people, they are (Clance and Imes 1978; Brems et al. 1994). (Location 236)\n\n\nThe best way to deal with complexity is to keep things as simple as possible and to follow a few basic principles. The simplicity of the structure allows complexity to build up where we want it: on the content level. (Location 251)\n\n\nIt is not about redoing what you have done before, but about changing the way of working from now on. (Location 257)\n\n\nThere is really no need to reorganise anything you already have. Just deal with things differently the moment you have to deal with them anyway. (Location 257)\n\n\nLike every change in behaviour, a change in working habits means going through a phase where you are drawn back to your old ways. (Location 266)\n\n\nThe principle of GTD is to collect everything that needs to be taken care of in one place and process it in a standardised way. This doesn’t necessarily mean that we actually do everything we once intended to do, but it forces us to make clear choices and regularly check if our tasks still fit into the bigger picture. (Location 274)\n\n\nAll the little steps must be linked in a way that will enable you to go seamlessly from one task to another, but still be kept separate enough to enable us to flexibly do what needs to be done in any given situation. (Location 300)\n\n\nOnly if you can trust your system, only if you really know that everything will be taken care of, will your brain let go and let you focus on the task at hand. (Location 302)\n\n\none note was only as valuable as its context, which was not necessarily the context it was taken from. (Location 319)\n\n\nIt is in the nature of writing, especially insight-oriented writing, that questions change, the material we work with turns out to be very different from the one imagined or that new ideas emerge, which might change our whole perspective on what we do. (Location 375)\n\n\nStudies on highly successful people have proven again and again that success is not the result of strong willpower and the ability to overcome resistance, but rather the result of smart working environments that avoid resistance in the first place (cf. Neal et al. 2012; Painter et al. 2002; Hearn et al. 1998). (Location 381)\n\n\nThis is not just about having the right mindset, it is also about having the right workflow. (Location 384)\n\n\nIt is about having the right tools and knowing how to use them – and very few understand that you need both. (Location 386)\n\n\nThe main misunderstanding stems from an isolated focus on the slip-box and a neglect of the actual workflow in which it is embedded. (Location 397)\n\n\nIntuitively, most people do not expect much from simple ideas. They rather assume that impressive results must have equally impressively complicated means. (Location 403)\n\n\nWhenever he read something, he would write the bibliographic information on one side of a card and make brief notes about the content on the other side (Schmidt 2013, 170). These notes would end up in the bibliographic slip-box. (Location 419)\nliterature notes\n\n\nHe then would turn to the main slip-box and write his ideas, comments and thoughts on new pieces of paper, using only one for each idea and restricting himself to one side of the paper, to make it easier to read them later without having to take them out of the box. (Location 422)\n\n\nAnd while the notes on the literature were brief, he wrote them with great care, not much different from his style in the final manuscript: in full sentences and with explicit references to the literature from which he drew his material. (Location 426)\n\n\nThe trick is that he did not organise his notes by topic, but in the rather abstract way of giving them fixed numbers. The numbers bore no meaning and were only there to identify each note permanently. If a new note was relevant or directly referred to an already existing note, such as a comment, correction or addition, he added it directly behind the previous note. (Location 435)\n\n\nAdding a note directly behind another note is only one way of doing this. Another way is by adding a link on this and/or the other note, which could be anywhere in the system. (Location 442)\n\n\nWe need a reliable and simple external structure to think in that compensates for the limitations of our brains. But first, let me guide you through the process of writing a paper with the slip-box. (Location 457)\n\n\nAssemble notes and bring them into order, turn these notes into a draft, review it and you are done. (Location 485)\n\n\nWriting these notes is also not the main work. Thinking is. Reading is. Understanding and coming up with ideas is. (Location 491)\n\n\nIf you want to learn something for the long run, you have to write it down. If you want to really understand something, you have to translate it into your own words. Thinking takes place as much on paper as in your own head. (Location 496)\n\n\nYou have to externalise your ideas, you have to write. (Location 502)\n\n\nIf we write, it is more likely that we understand what we read, remember what we learn and that our thoughts make sense. (Location 503)\n\n\nMake fleeting notes. Always have something at hand to write with to capture every idea that pops into your mind. (Location 511)\n\n\nThey should not cause any distraction. Put them into one place, which you define as your inbox, and process them later. I usually have a simple notebook with me, but I am happy with napkins or receipts if nothing else is at hand. (Location 512)\n\n\nIf your thoughts are already sorted and you have the time, you can skip this step and write your idea directly down as a proper, permanent note for your slip-box. (Location 514)\n\n\nMake literature notes. Whenever you read something, make notes about the content. Write down what you don’t want to forget or think you might use in your own thinking or writing. (Location 516)\n\n\nKeep these notes together with the bibliographic details in one place – your reference system. (Location 519)\n\n\nbox. Go through the notes you made in step one or two (ideally once a day and before you forget what you meant) and think about how they relate to what is relevant for your own research, thinking or interests. (Location 521)\n\n\nThe idea is not to collect, but to develop ideas, arguments and discussions. (Location 523)\n\n\nWrite exactly one note for each idea and write as if you were writing for someone else: Use full sentences, disclose your sources, make references and try to be as precise, clear and brief as possible. (Location 525)\n\n\nLook to which note the new one directly relates or, if it does not relate directly to any other note yet, just file it behind the last one. (Location 532)\n\n\nMaking sure you will be able to find this note later by either linking to it from your index or by making a link to it on a note that you use as an entry point to a discussion or topic and is itself linked to the index. (Location 536)\n\n\nSee what is there, what is missing and what questions arise. Read more to challenge and strengthen your arguments and change and develop your arguments according to the new information you are learning about. (Location 539)\n\n\nLook through the connections and collect all the relevant notes on this topic (most of the relevant notes will already be in partial order), copy them onto your “desktop”[6] and bring them in order. Look for what is missing and what is redundant. Don’t wait until you have everything together. Rather, try ideas out and give yourself enough time to go back to reading and note-taking to improve your ideas, arguments and their structure. (Location 550)\n\n\nTurn your notes into a rough draft. Don’t simply copy your notes into a manuscript. Translate them into something coherent and embed them into the context of your argument while you build your argument out of the notes at the same time. (Location 555)\n\n\nIn reality, you never work on just one idea, but many ideas in different stages at the same time. And that is where the system plays out its real strengths. (Location 560)\n\n\nYou might read a certain book in hope it could be useful for one of the papers you write. Maybe you are wrong, but it still might contain (Location 563)\n\n\nsome interesting thoughts worth keeping and useful for something else you haven’t thought about yet. (Location 564)\n\n\nSpending the little extra time to add them to your system will make all the difference, because the accidental encounters make up the majority of what we learn. (Location 578)\n\n\nEach added bit of information, filtered only by our interest, is a contribution to our future understanding, thinking and writing. (Location 581)\n\n\nGood tools do not add features and more options to what we already have, but help to reduce distractions from the main work, which here is thinking. The slip-box provides an external scaffold to think in and helps with those tasks our brains are not very good at, most of all objective storage of information. (Location 612)\n\n\nThey only function as a reminder of a thought and are not meant to capture the thought itself, which requires time to phrase proper sentences and check facts. (Location 631)\n\n\nThey can’t speed up the main part of the work, which is thinking, reading and understanding. (Location 648)\n\n\nIf we try to use a tool without putting any thought into the way we work with it, even the best tool would not be of much help. The slip-box, for example, would most likely be used as an archive for notes – or worse: a graveyard for thoughts (cf. Hollier 2005, 40 on Mallarmé’s index cards). (Location 670)\n\n\nassumption: Studying does not prepare students for independent research. It is independent research. (Location 702)\n\n\nStudying, done properly, is research, because it is about gaining insight that cannot be anticipated and will be shared within the scientific community (Location 704)\n\n\nAn idea kept private is as good as one you never had. And a fact no one can reproduce is no fact at all. (Location 705)\n\n\nthe professor is not there for the student and the student not for the professor. Both are only there for the truth. And truth is always a public matter. (Location 710)\n\n\nThe criteria for a convincing argument are always the same, regardless of who the author is or the status of the publisher: They have to be coherent and based on facts. Truth does not belong to anyone; it is the outcome of the scientific exchange of written ideas. (Location 716)\n\n\nIf writing is the medium of research and studying nothing else than research, then there is no reason not to work as if nothing else counts than writing. (Location 719)\n\n\nWorking as if nothing else counts than writing does not mean spending more time writing at the expense of everything else. (Location 721)\n\n\nYou will read in a more engaged way, because you cannot rephrase anything in your own words if you don’t understand what it is about. (Location 734)\n\n\nAnd by doing everything with the clear purpose of writing about it, you will do what you do deliberately. Deliberate practice is the only serious way of becoming better at what we are doing (cf. Anders Ericsson, 2008). (Location 736)\n\n\nWorking like this will leave you with a lot of different notes in many different places. Writing, then, means to rely heavily on your brain to remember where and when these notes were written down. A text must then be conceptualised independently from these notes, which explains why so many resort to brainstorming to arrange the resources afterwards according to this preconceived idea. (Location 782)\n\n\nIn the old system, the question is: Under which topic do I store this note? In the new system, the question is: In which context will I want to stumble upon it again? (Location 787)\n\n\nThe slip-box is the shipping container of the academic world. Instead of having different storage for different ideas, everything goes into the same slip-box and is standardised into the same format. (Location 791)\n\n\nEven though the slip-box, being organised bottom-up, does not face the trade-off problem between too many or too few topics, it too can lose its value when notes are added to it indiscriminately. It can only play out its strengths when we aim for a critical mass, which depends not only on the number of notes, but also their quality and the way they are handled. (Location 799)\n\n\nFleeting notes, which are only reminders of information, can be written in any kind of way and will end up in the trash within a day or two. (Location 804)\n\n\nPermanent notes, which will never be thrown away and contain the necessary information in themselves in a permanently understandable way. They are always stored in the same way in the same place, either in the reference system or, written as if for print, in the slip-box. (Location 806)\n\n\nProject notes, which are only relevant to one particular project. They are kept within a project-specific folder and can be discarded or archived after the project is finished. (Location 810)\n\n\nThe collection of good ideas is diluted to insignificance by all the other notes, which are only relevant for a specific project or actually not that good on second sight. (Location 818)\n\n\nThe second typical mistake is to collect notes only related to specific projects. (Location 822)\n\n\nups. Just collecting unprocessed fleeting notes inevitably leads to chaos. Even small amounts of unclear and unrelated notes lingering around your desk will soon induce the wish of starting from scratch. (Location 831)\n\n\nWhat all these category-confusing approaches have in common is that the benefit of note-taking decreases with the number of notes you keep. More notes will make it more difficult to retrieve the right ones and bring related ones together in a playful way. (Location 833)\n\n\nmargins. It is important to understand, though, that underlining sentences or writing comments in the margins are also just fleeting notes and do nothing to elaborate on a text. They will very soon become completely useless – unless you do something with them. (Location 842)\n\n\nFleeting notes are only useful if you review them within a day or so and turn them into proper notes you can use later. (Location 844)\n\n\nPermanent notes, on the other hand, are written in a way that can still be understood even when you have forgotten the context they are taken from. (Location 848)\n\n\naway. That is why the threshold to write an idea down has to be as low as possible, but it is equally crucial to elaborate on them within a day or two. (Location 850)\n\n\nA good indication that a note has been left unprocessed too long is when you no longer understand what you meant or it appears banal. (Location 851)\n\n\nThe only permanently stored notes are the literature notes in the reference system and the main notes in the slip-box. The former can be very brief as the context is clearly the text they refer to. The latter need be written with more care and details as they need to be self-explanatory. (Location 854)\n\n\nThe notes are no longer reminders of thoughts or ideas, but contain the actual thought or idea in written form. This is a crucial difference. (Location 866)\n\n\nIt doesn’t matter in which format these notes are as they are going to end up in the bin after the project is finished anyway (or in an archive – the bin for the indecisive). (Location 873)\n\n\nProject-related notes can be:   ·      comments in the manuscript ·      collections of project-related literature ·      outlines ·      snippets of drafts ·      reminders (Location 877)\n\n\n·      to-do lists ·      and of course the draft itself. (Location 887)\n\n\nTo be able to decide on a topic, one must already have read quite a bit and certainly not just about one topic. And the decision to read something and not something else is obviously rooted in prior understanding, and that didn’t come out of thin air, either. (Location 920)\n\n\nIt accompanies everything: We have to read with a pen in hand, develop ideas on paper and build up an ever-growing pool of externalised thoughts. We will not be guided by a blindly made-up plan picked from our unreliable brains, but by our interest, curiosity and intuition, which is formed and informed by the actual work of reading, thinking, discussing, writing and developing ideas – and is something that continuously grows and reflects our knowledge and understanding externally. (Location 929)\n\n\nBy focusing on what is interesting and keeping written track of your own intellectual development, topics, questions and arguments will emerge from the material without force. (Location 933)\n\n\nbrainstorming. If you haven’t written along the way, the brain is indeed the only place to turn to. On its own, it is not such a great choice: it is neither objective nor reliable – two quite important aspects in academic or nonfiction writing. (Location 944)\n\n\nThe advice to think about what to write about before you write comes both too early and too late. Too late, as you already have passed up the chance to build up written resources when you face the white sheet of paper or the blank screen, but also too early, if you try to postpone every serious content-related work until you have made a decision on the topic. (Location 949)\n\n\nThere is one reliable sign if you managed to structure your workflow according to the fact that writing is not a linear process, but a circular one: the problem of finding a topic is replaced by the problem of having too many topics to write about. (Location 954)\n\n\nThe material will cluster around the questions they returned to most often, so they don’t risk too far of a departure from their interest. (Location 971)\n\n\nelse. Maybe you will even note down the reasons why the first question is not interesting and turn that into an insight valuable enough to make public. (Location 973)\n\n\nWhen it finally comes to the decision on what to write about, you will already have made the decision – because you made it on every single step along the way, again and again every day, improving it gradually. (Location 974)\n\n\nOnly if the work itself becomes rewarding can the dynamic of motivation and reward become self-sustainable and propel the whole process forward (DePasque and Tricomi, 2015). (Location 997)\n\n\nThey enter the virtuous circle where willpower isn’t needed anymore because they feel like doing it anyway. (Location 1004)\n\n\nFeedback loops are not only crucial for the dynamics of motivation, but also the key element to any learning process. (Location 1007)\n\n\nSeeking feedback, not avoiding it, is the first virtue of anyone who wants to learn, or in the more general terms of psychologist Carol Dweck, to grow. (Location 1009)\n\n\nThose who fear and avoid feedback because it might damage their cherished positive self-image might feel better in the short term, but will quickly fall behind in actual performance (Dweck 2006; 2013). (Location 1012)\n\n\nEmbracing a growth mindset means to get pleasure out of changing for the better (which is mostly inwardly rewarding) (Location 1016)\n\n\nHaving a growth mindset is crucial, but only one side of the equation. Having a learning system in place that enables feedback loops in a practical way is equally important. (Location 1021)\n\n\nReading with a pen in the hand, for example, forces, us to think about what we read and check upon our understanding. It is the simplest test: We tend to think we understand what we read – until we try to rewrite it in our own words. (Location 1031)\n\n\nThe ability to express understanding in one’s own words is a fundamental competency for everyone who writes – and only by doing it with the chance of realizing our lack of understanding can we become better at it. (Location 1036)\n\n\nThe same applies to the crucial ability to distinguish the important bits of a text from the less important ones: (Location 1038)\n\n\nExpressing our own thoughts in writing makes us realise if we really thought them through. The moment we try to combine them with previously written notes, the system will unambiguously show us contradictions, inconsistencies and repetitions. (Location 1042)\n\n\nWhile those who multitasked felt more productive, their productivity actually decreased – a lot (Wang and Tchernev 2012; Rosen 2008; Ophir, Nass, and Wagner 2009). Not only the quantity but also the quality of their accomplishments lagged significantly behind that of the control group. (Location 1095)\n\n\nsense. Multitasking is not what we think it is. It is not focusing attention on more than one thing at a time. Nobody can do that. When we think we multitask, what we really do is shift our attention quickly between two (or more) things. And every shift is a drain on our ability to shift and delays the moment we manage to get focused again. Trying to multitask fatigues us and decreases our ability to deal with more than one task. (Location 1101)\n\n\nThe second is what psychologists call the mere-exposure effect: doing something many times makes us believe we have become good at it – completely independent of our actual performance (Bornstein 1989). We unfortunately tend to confuse familiarity with skill. (Location 1107)\n\n\nWriting a paper involves much more than just typing on the keyboard. It also means reading, understanding, reflecting, getting ideas, making connections, distinguishing terms, finding the right words, structuring, organizing, editing, correcting and rewriting. (Location 1113)\n\n\nIt is not a sign of professionalism to master one technique and stick to it no matter what, but to be flexible and adjust one’s reading to whatever speed or approach a text requires. (Location 1173)\n\n\nit is not a relentless focus, but flexible focus that distinguishes them. “Specifically, the problem-solving behavior of eminent scientists can alternate between extraordinary levels of focus on specific concepts and playful exploration of ideas. This suggests that successful problem solving may be a function of flexible strategy application in relation to task demands.” (Vartanian 2009, 57) (Location 1180)\n\n\nThe widespread praise for planning rests on the misconception that a process like writing an academic text, which is highly dependent on cognition and thinking, can rely on conscious decision-making alone. But academic writing is an art, as well, which means it is something we can become better at with experience and deliberate practice. (Location 1209)\n\n\ngaining insight and making it public. (Location 1220)\n\n\nTeachers tend to mistake the ability to follow (their) rules with the ability to make the right choices in real situations. (Location 1231)\n\n\nHere, gut feeling is not a mysterious force, but an incorporated history of experience. It is the sedimentation of deeply learned practice through numerous feedback loops on success or failure.[20] (Location 1242)\n\n\nWe can hold a maximum of seven things in our head at the same time, plus/minus two (Miller 1956). (Location 1264)\n\n\nThings we understand are connected, either through rules, theories, narratives, pure logic, mental models or explanations. And deliberately building these kinds of meaningful connections is what the slip-box is all about. (Location 1282)\n\n\nZeigarnik effect: Open tasks tend to occupy our short-term memory – until they are done. That is why we get so easily distracted by thoughts of unfinished tasks, regardless of their importance. (Location 1297)\n\n\nAll we have to do is to write them down in a way that convinces us that it will be taken care of. That’s right: The brain doesn’t distinguish between an actual finished task and one that is postponed by taking a note. (Location 1300)\n\n\nThe first step is to break down the amorphous task of “writing” into smaller pieces of different tasks that can be finished in one go. The second step is to make sure we always write down the outcome of our thinking, including possible connections to further inquiries. (Location 1308)\n\n\nThat is one of the main advantages of thinking in writing – everything is externalised anyway. (Location 1317)\n\n\ncheat. Instead of forcing ourselves to do something we don’t feel like doing, we need to find a way to make us feel like doing what moves our project further along. Doing the work that need to be done without having to apply too much willpower requires a technique, a ruse. (Location 1347)\n\n\nThe outcome of reading with a pen in the hand is not possible to anticipate either, and here, too, the idea is not to copy, but to have a meaningful dialogue with the texts we read. (Location 1393)\n\n\nThis is why we have to translate them into our own language to prepare them to be embedded into new contexts of our own thinking, the different context(s) within the slip-box. (Location 1397)\n\n\nAnd what is most helpful is to reflect on the frame, the theoretical background, methodological approach or perspective of the text we read. That often means to reflect as much on what is not mentioned as what is mentioned. (Location 1417)\n\n\nHere, everything is about building up a critical mass of useful notes in the slip-box, which gives us a clear idea of how to read and how to take literature notes. (Location 1426)\n\n\nBut all of this would be just an extra step before you do the only step that really counts, which is to take the permanent note that will add value to the actual slip-box. (Location 1430)\n\n\nLiterature notes are short and meant to help with writing slip-box notes. Everything else either helps to get to this point or is a distraction. (Location 1433)\n\n\nWhile we should seek out dis-confirming arguments and facts that challenge our way of thinking, we are naturally drawn to everything that makes us feel good, which is everything that confirms what we already believe we know. (Location 1457)\n\n\nWorse, we are usually not even aware of this confirmation bias (or myside bias[28]) that surreptitiously meddles with our life. (Location 1461)\n\n\nConfirmation bias is tackled here in two steps: First, by turning the whole writing process on its head, and secondly, by changing the incentives from finding confirming facts to an indiscriminate gathering of any relevant information regardless of what argument it will support. (Location 1481)\n\n\nthumb: If insight becomes a threat to your academic or writing success, you are doing it wrong. (Location 1488)\n\n\nThe slip-box forces us to be selective in reading and note-taking, but the only criterion is the question of whether something adds to a discussion in the slip-box. (Location 1502)\n\n\nYes, we have to be selective, but not in terms of pros and cons, but in terms of relevant or irrelevant. And as soon we focus on the content of the slip-box, dis-confirming data becomes suddenly very attractive, because it opens up more possible connections and discussions within the slip-box, while mere confirming data does not. (Location 1509)\n\n\nExtracting the gist of a text or an idea and giving an account in writing is for academics what daily practice on the piano is for pianists: The more often we do it and the more focused we are, the more virtuous we become. (Location 1526)\n\n\nThe ability to use one’s own understanding is a challenge, not a given. (Location 1543)\n\n\nBeing able to re-frame questions, assertions and information is even more important than having an extensive knowledge, because without this ability, we wouldn’t be able to put our knowledge to use. (Location 1562)\n\n\nTaking smart notes is the deliberate practice of these skills. Mere reading, underlining sentences and hoping to remember the content is not. (Location 1565)\n\n\nReading with a pen in your hand is the small-scale equivalent of a lecture. Permanent notes, too, are directed towards an audience ignorant of the thoughts behind the text and unaware of the original context, only equipped with a general knowledge of the field. (Location 1571)\n\n\nThe most important advantage of writing is that it helps us to confront ourselves when we do not understand something as well as we would like to believe. (Location 1580)\n\n\nReading, especially rereading, can easily fool us into believing we understand a text. Rereading is especially dangerous because of the mere-exposure effect: The moment we become familiar with something, we start believing we also understand it. (Location 1583)\n\n\nAnd while writing down an idea feels like a detour, extra time spent, not writing it down is the real waste of time, as it renders most of what we read as ineffectual. (Location 1592)\n\n\nIf we put effort into the attempt of retrieving information, we are much more likely to remember it in the long run, even if we fail to retrieve it without help in the end (Roediger and Karpicke 2006). Even without any feedback, we will be better off if we try to remember something ourselves (Jang et al. 2012). (Location 1635)\n\n\nsighted. Writing, taking notes and thinking about how ideas connect is exactly the kind of elaboration that is needed to learn. Not learning from what we read because we don’t take the time to elaborate on it is the real waste of time. (Location 1661)\n\n\nWhat good readers can do is spot the limitations of a particular approach and see what is not mentioned in the text. (Location 1675)\n\n\nOnly in the written form can an argument be looked at with a certain distance – literally. We need this distance to think about an argument – otherwise the argument itself would occupy the very mental resources we need for scrutinizing it. (Location 1740)\n\n\nAlmost all agree nowadays that real thinking requires some kind of externalization, especially in the form of writing. (Location 1763)\n\n\nWhat does this all mean for my own research and the questions I think about in my slip-box? This is just another way of asking: Why did the aspects I wrote down catch my interest? (Location 1783)\n\n\nAnd where do I turn to, to find answers to these questions? Correct: The first choice for further inquiry is the slip-box. (Location 1797)\n\n\nJust by writing down these questions and making possible connections explicit in writing are the concepts and theories being investigated. Their limitations become as visible as their particular angle on a problem. By explicitly writing down how something connects or leads to something else, we force ourselves to clarify and distinguish ideas from each other. (Location 1805)\n\n\nWithout a very thorough filter, our brains would constantly be flooded by memories, making it impossible to focus on anything in our surroundings. (Location 1849)\n\n\nThe ability to forget systematically – to inhibit most irrelevant information from being remembered. (Location 1857)\n\n\nLearning would be not so much about saving information, like on a hard disk, but about building connections and bridges between pieces of information to circumvent the inhibition mechanism in the right moment. It is about making sure that the right “cues” trigger the right memory, about how we can think strategically to remember the most useful information when we need it. (Location 1867)\n\n\nThe first step of elaboration is to think enough about a piece of information so we are able to write about it. The second step is to think about what it means for other contexts as well. (Location 1913)\n\n\nLearned right, which means understanding, which means connecting in a meaningful way to previous knowledge, information almost cannot be forgotten anymore and will be reliably retrieved if triggered by the right cues. (Location 1928)\n\n\nWriting notes and sorting them into the slip-box is nothing other than an attempt to understand the wider meaning of something. The slip-box forces us to ask numerous elaborating questions: What does it mean? How does it connect to … ? What is the difference between … ? What is it similar to? That the slip-box is not sorted by topics is the precondition for actively building connections between notes. (Location 1939)\n\n\nConnections can be made between heterogeneous notes – as long as the connection makes sense. (Location 1941)\n\n\nMake sure it can be found from the index; add an entry in the index if necessary or refer to it from a note that is connected to the index. (Location 1963)\n\n\nNotes are only as valuable as the note and reference networks they are embedded in. (Location 1987)\n\n\ncompleteness. We don’t need to write anything down just to bridge a gap in a note sequence. We only write if it helps us with our own thinking. (Location 1989)\n\n\nOn the contrary, we are much better off accepting as early as possible that an overview of the slip-box is as impossible as having an overview of our own thinking while we are thinking. (Location 1993)\n\n\nAs an extension of our own memory, the slip-box is the medium we think in, not something we think about. (Location 1994)\n\n\nused. Because it should not be used as an archive, where we just take out what we put in, but as a system to think with, the references between the notes are much more important than the references from the index to a single note. Focusing exclusively on the index would basically mean that we always know upfront what we are looking for – we would have to have a fully developed plan in our heads. But liberating our brains from the task of organizing the notes is the main reason we use the slip-box in the first place. (Location 2003)\n\n\nThe consideration of how to structure a topic, therefore, belongs on notes as well – and not on a meta-hierarchical level. We can provide ourselves with a (temporarily valid) overview over a topic or subtopic just by making another note. (Location 2016)\n\n\nDo they wonder where to store a note or how to retrieve it? The archivist asks: Which keyword is the most fitting? A writer asks: In which circumstances will I want to stumble upon this note, even if I forget about it? (Location 2022)\n\n\nKeywords should always be assigned with an eye towards the topics you are working on or interested in, never by looking at the note in isolation. (Location 2046)\n\n\nThe first type of links are those on notes that are giving you the overview of a topic. These are notes directly referred to from the index and usually used as an entry point into a topic that has already developed to such a degree that an overview is needed or at least becomes helpful. (Location 2064)\nTOC note\n\n\nThe most common form of reference is plain note-to-note links. They have no function other than indicating a relevant connection between two individual notes. By linking two related notes regardless of where they are within the slip-box or within different contexts, surprising new lines of thought can be established. (Location 2087)\n\n\nIt is important to always keep in mind that making these links is not a chore, a kind of file-box maintenance. The search for meaningful connections is a crucial part of the thinking process towards the finished manuscript. But here, it is dealt with in a very concrete way. Instead of figuratively searching our internal memory, we literally go through the file-box and look for connections. By dealing with actual notes, we are also less prone to imagine connections where there aren’t any, as we can see in black and white if something makes sense or not. (Location 2099)\n\n\nIf we try to feed it some lofty ideas, it will force us to check first: What is the reference? How does that connect to the facts and the ideas you already have? (Location 2107)\n\n\nThe information on flashcards is neither elaborated on nor embedded in some form of context. Each flashcard stays isolated instead of being connected with the network of theoretical frames, our experiences or our latticework of mental models. (Location 2152)\n\n\nHe advocates looking out for the most powerful concepts in every discipline and to try to understand them so thoroughly that they become part of our thinking. (Location 2164)\n\n\nMunger writes: “Well, the first rule is that you can’t really know anything if you just remember isolated facts and try and bang ’em back. If the facts don’t hang together on a latticework of theory, you don’t have them in a usable form. You’ve got to have models in your head. And you’ve got to array your experience, both vicarious and direct, on this latticework of models. You may have noticed students who just try to remember and pound back what is remembered. Well, they fail in school and in life. You’ve got to hang experience on a latticework of models in your head.” (Munger 1994). (Location 2169)\n\n\nIf we practice learning not as a pure accumulation of knowledge, but as an attempt to build up a latticework of theories and mental models to which information can stick, we enter a virtuous circle where learning facilitates learning. (Location 2184)\n\n\nit. We have to elaborate on what we read just to be able to write it down and translate it into different contexts. We retrieve information from the slip-box whenever we try to connect new notes with old notes. (Location 2205)\n\n\nBut intuition is not the opposition to rationality and knowledge, it is rather the incorporated, practical side of our intellectual endeavours, the sedimented experience on which we build our conscious, explicit knowledge (Location 2229)\n\n\nThe real enemy of independent thinking is not an external authority, but our own inertia. The ability to generate new ideas has more to do with breaking with old habits of thinking than with coming up with as many ideas as possible. (Location 2281)\n\n\nWe always perceive something as something – our interpretation is instantaneous. This is why we have so much trouble not falling for an optical illusion: If we look at a three-dimensional drawing, we cannot see it just as an arrangement of lines and shapes – unless we are highly trained to do so. (Location 2297)\n\n\nTo really understand a text is therefore a constant revision of our first interpretation. We have to train ourselves to get used to seeing this difference and to hold back our ingrained urge to jump to conclusions. (Location 2303)\n\n\nWhile the constant comparison of notes can help us to detect differences, no technique can help us see what is missing. But we can make it a habit to always ask what is not in the picture, but could be relevant. This, too, does not come naturally to us. (Location 2309)\n\n\nOne possibility to deal with this tendency is to ask counterfactual questions, like “what if?” (Location 2332)\n\n\nThe first question should always be directed towards the question itself: What kind of answer can you expect from asking a question in this particular way? What is missing? (Location 2337)\n\n\nBy using the slip-box on a daily basis, we train these important intellectual skills deliberately: We check if what we understood from a text is really in the text by having our understanding in written form in front of our eyes. We learn to focus on the gist of an idea by restricting ourselves in terms of space. We can make it a habit to always think about what is missing when we write down our own ideas. And we can practice asking good questions when we sort our notes into the slip-box and connect them with other notes. (Location 2360)\n\n\nThe restriction to one idea per note is also the precondition to recombine them freely later. (Location 2372)\n\n\nEach note should fit onto the screen and there should be no need of scrolling. (Location 2374)\n\n\nThe limitation of the canvas does not make the artistic expressions of painters seem limited, but opens up the possibility of an artist like Lucio Fontana to cut into the canvas instead of painting on it. It is not even true that a more complex structure provides more possibilities. Quite the contrary. The binary code is radically more limited than the alphabet as it contains only two states, one or zero, but it opened up a range of creative possibilities that is unprecedented. (Location 2399)\n\n\nWithout structure, we cannot differentiate, compare or experiment with ideas. (Location 2404)\n\n\nthe fact that someone came up with a lot of ideas during a brainstorming session does not give much indication about their quality. (Location 2437)\n\n\nIf we, on the other hand, let questions arise from the slip-box, we know that they are tried and tested among dozens or even hundreds of other possible questions. The vast majority of questions might have been answered quickly or disappeared as no notes were drawn to them, either because of a lack of interest or a lack of material. This is how evolution works: by trial and error, not planning. (Location 2474)\n\n\nWe have to work, write, connect, differentiate, complement and elaborate on questions – but this is what we do when we take smart notes. (Location 2480)\n\n\nNothing motivates us more than seeing a project we can identify with moving forward, and nothing is more demotivating than being stuck with a project that doesn’t seem to be worth doing. (Location 2508)\n\n\nIf we accompany every step of our work with the question, “What is interesting about this?” and everything we read with the question, “What is so relevant about this that it is worth noting down?” we do not just choose information according to our interest. By elaborating on what we encounter, we also discover aspects we didn’t know anything about before and therefore develop our interests along the way. It would be quite sad if we did not change our interests during research. (Location 2513)\n\n\nThe ability to keep control over our work and change course if necessary is made possible by the fact that the big task of “writing a text” is broken down into small, concrete tasks, which allows us practically to do exactly what is needed at a certain time and take the next step from there. (Location 2524)\n\n\nThe key is to structure the draft visibly. It is not so much about deciding once and for all what to write in which chapter or paragraph, but what does not need to be written in a particular part of the manuscript. (Location 2545)\n\n\nEverything that enriches our slip-box has the potential to end up in a text we might write. By taking smart notes, we collect en passant the material for our future writings in one place. The projects we work on can be in completely different stages of completion. Some of them might not even have come to our attention. This is advantageous not only because we make progress on the next papers or books while we are still working on the current one, but also because it allows us to switch to other projects whenever we get stuck or bored. (Location 2565)\n\n\nThe lesson to draw is to be generally sceptical about planning, especially if it is merely focused on the outcome, not on the actual work and the steps required to achieve a goal. (Location 2602)\n\n\nDisassembling the big challenge of “writing a paper” into small, manageable tasks helps to set realistic goals that can be checked on a regular basis. (Location 2610)\n\n\nAccording to the famous law of Parkinson, every kind of work tends to fill the time we set aside for it, like air fills every corner of a room (Location 2625)\n\n\nThe goal here is to get into the habit of fetching pen and paper whenever we read something, to write down the most important and interesting aspects. If we manage to establish a routine in this first step, it becomes much easier to develop the urge to turn these findings into permanent notes and connect them with other notes in the slip-box. (Location 2680)\n"},"highlights/Readwise/31554995":{"title":"31554995","links":[],"tags":[],"content":"Highlights\n\nYou set a predetermined amount of time for “looking”—that is, exploring your options, gathering data—in which you categorically don’t choose anyone, no matter how impressive. After that point, you enter the “leap” phase, prepared to instantly commit to anyone who outshines the best applicant you saw in the look phase. (Location 215)\n\n\nAs the applicant pool grows, the exact place to draw the line between looking and leaping settles to 37% of the pool, yielding the 37% Rule: look at the first 37% of the applicants,* choosing none, then be ready to leap for anyone better than all those you’ve seen so far. (Location 231)\n\n\nIt’s true that you’re unlikely to find the needle the majority of the time, but optimal stopping is your best defense against the haystack, no matter how large. (Location 246)\n\n\noften. If you have, say, a 50/50 chance of being rejected, then the same kind of mathematical analysis that yielded the 37% Rule says you should start making offers after just a quarter of your search. (Location 279)\n\n\nNamely, in the secretary problem we know nothing about the applicants other than how they compare to one another. We don’t have an objective or preexisting sense of what makes for a good or a bad applicant; moreover, when we compare two of them, we know which of the two is better, but not by how much. (Location 301)\n\n\nFull information means that we don’t need to look before we leap. We can instead use the Threshold Rule, where we immediately accept an applicant if they are above a certain percentile. We don’t need to look at an initial group of candidates to set this threshold—but we do, however, need to be keenly aware of how much looking remains available. The math shows that when there are a lot of applicants left in the pool, you should pass up even a very good applicant in the hopes of finding someone still better than that—but as your options dwindle, you should be prepared to hire anyone who’s simply better than average. It’s a familiar, if not exactly inspiring, message: in the face of slim pickings, lower your standards. It also makes clear the converse: with more fish in the sea, raise them. In both cases, crucially, the math tells you exactly by how much. The easiest way to understand the numbers for this scenario is to start at the end and think backward. If you’re down to the last applicant, of course, you are necessarily forced to choose them. But when looking at the next-to-last applicant, the question becomes: are they above the 50th percentile? If yes, then hire them; if not, it’s worth rolling the dice on the last applicant instead, since their odds of being above the 50th percentile are 50/50 by definition. Likewise, you should choose the third-to-last applicant if they’re above the 69th percentile, the fourth-to-last applicant if they’re above the 78th, and so on, being more choosy the more applicants are left. No matter what, never hire someone who’s below average unless you’re totally out of options. (And since you’re still interested only in finding the very best person in the applicant pool, never hire someone who isn’t the best you’ve seen so far.) The chance of ending up with the single best applicant in this full-information version of the secretary problem comes to 58%—still far from a guarantee, but considerably (Location 318)\n\n\nAny yardstick that provides full information on where an applicant stands relative to the population at large will change the solution from the Look-Then-Leap Rule to the Threshold Rule and will dramatically boost your chances of finding the single best applicant in the group. (Location 341)\n\n\nWhat you’ve paid to keep searching is a sunk cost. Don’t compromise, don’t second-guess. And don’t look back. (Location 394)\n\n\nBut that impatience suggests another consideration that isn’t taken into account in the classical secretary problem: the role of time. (Location 504)\n\n\nAs optimal stopping researcher Neil Bearden puts it, “After searching for a while, we humans just tend to get bored. It’s not irrational to get bored, but it’s hard to model that rigorously.” (Location 514)\n\n\nBut the reality is not so simple. Remembering that every “best” song and restaurant among your favorites began humbly as something merely “new” to you is a reminder that there may be yet-unknown bests still out there—and thus that the new is indeed worthy of at least some of our attention. (Location 543)\n\n\nPeople tend to treat decisions in isolation, to focus on finding each time the outcome with the highest expected value. But decisions are almost never isolated, and expected value isn’t the end of the story. (Location 584)\n\n\nA sobering property of trying new things is that the value of exploration, of finding a new favorite, can only go down over time, as the remaining opportunities to savor it dwindle. (Location 602)\n\n\nSo explore when you will have time to use the resulting knowledge, exploit when you’re ready to cash in. The interval makes the strategy. (Location 606)\n\n\nAnd indeed, win-stay turns out to be an element of the optimal strategy for balancing exploration and exploitation under a wide range of conditions. But lose-shift is another story. Changing arms each time one fails is a pretty rash move. Imagine going to a restaurant a hundred times, each time having a wonderful meal. Would one disappointment be enough to induce you to give up on it? Good options shouldn’t be penalized too strongly for being imperfect. (Location 635)\n\n\nThe Gittins index, then, provides a formal, rigorous justification for preferring the unknown, provided we have some opportunity to exploit the results of what we learn from exploring. (Location 716)\n\n\nThe old adage tells us that “the grass is always greener on the other side of the fence,” but the math tells us why: the unknown has a chance of being better, even if we actually expect it to be no different, or if it’s just as likely to be worse. (Location 718)\n\n\nExploration in itself has value, since trying new things increases our chances of finding the best. So taking the future into account, rather than focusing just on the present, drives us toward novelty. (Location 720)\n\n\n“To try and fail is at least to learn; to fail to try is to suffer the inestimable loss of what might have been.” (Location 744)\n\n\nIn a multi-armed bandit problem, an Upper Confidence Bound algorithm says, quite simply, to pick the option for which the top of the confidence interval is highest. (Location 776)\n\n\nUpper Confidence Bound algorithms implement a principle that has been dubbed “optimism in the face of uncertainty.” Optimism, they show, can be perfectly rational. By focusing on the best that an option could be, given the evidence obtained so far, these algorithms give a boost to possibilities we know less about. As a consequence, they naturally inject a dose of exploration into the decision-making process, leaping at new options with enthusiasm because any one of them could be the next big thing. (Location 787)\n\n\nThe success of Upper Confidence Bound algorithms offers a formal justification for the benefit of the doubt. Following the advice of these algorithms, you should be excited to meet new people and try new things—to assume the best about them, in the absence of evidence to the contrary. In the long run, optimism is the best prevention for regret. (Location 792)\n\n\nBut just as there’s a cost to not having a secretary, there’s a cost to committing too soon to a particular airline: the world might change. (Location 954)\n\n\nwhen the world can change, continuing to explore can be the right choice. It might be worth going back to that disappointing restaurant you haven’t visited for a few years, just in case it’s under new management. (Location 960)\n\n\nBut pressing buttons at random, being very interested in new toys, and jumping quickly from one thing to another are all things that kids are really great at. And those are exactly what they should be doing if their goal is exploration. If you’re a baby, putting every object in the house into your mouth is like studiously pulling all the handles at the casino. (Location 992)\n\n\nThe basic pattern is clear: the size of people’s social networks (that is, the number of social relationships they engage in) almost invariably decreases over time. (Location 1008)\n\n\nthe shrinking of social networks with aging is due primarily to “pruning” peripheral relationships and focusing attention instead on a core of close friends and family members. This process seems to be a deliberate choice: as people approach the end of their lives, they want to focus more on the connections that are the most meaningful. (Location 1015)\n\n\nThe point is that these differences in social preference are not about age as such—they’re about where people perceive themselves to be on the interval relevant to their decision. (Location 1024)\n\n\nThe Gittins index and the Upper Confidence Bound, as we’ve seen, inflate the appeal of lesser-known options beyond what we actually expect, since pleasant surprises can pay off many times over. But at the same time, this means that exploration necessarily leads to being let down on most occasions. Shifting the bulk of one’s attention to one’s favorite things should increase quality of life. (Location 1037)\n\n\nWhat makes Google so dominant as a means of accessing the world’s information is less that it finds our text within hundreds of millions of webpages—its 1990s competitors could generally do that part well enough—but that it sorts those webpages so well, and only shows us the most relevant ten. (Location 1088)\n\n\nThe truncated top of an immense, sorted list is in many ways the universal user interface. (Location 1090)\n\n\nThis is the first and most fundamental insight of sorting theory. Scale hurts. (Location 1106)\n\n\nThe key to actually breaking the linearithmic barrier is knowing the distribution from which the items you’re sorting are drawn. (Location 1261)\n\n\nInstead, a good strategy—ratified by human and machine librarians alike—is to Bucket Sort until you get down to small enough piles that Insertion Sort is reasonable, or to have a Mergesort pizza party. (Location 1283)\n\n\nSorting something that you will never search is a complete waste; searching something you never sorted is merely inefficient. (Location 1291)\n\n\nAs the cost of searching drops, sorting becomes less valuable. (Location 1308)\n\n\nAll of the sorting algorithms that we’ve considered thus far assume perfect, flawless, foolproof comparisons, ones that never mess up and mistakenly judge the lesser of two quantities to be the greater. (Location 1404)\n\n\nThe winner of that particular honor is an algorithm called Comparison Counting Sort. In this algorithm, each item is compared to all the others, generating a tally of how many items it is bigger than. This number can then be used directly as the item’s rank. Since it compares all pairs, Comparison Counting Sort is a quadratic-time algorithm, like Bubble Sort. Thus it’s not a popular choice in traditional computer science applications, but it’s exceptionally fault-tolerant. (Location 1419)\n\n\nDisplacement happens when an animal uses its knowledge of the hierarchy to determine that a particular confrontation simply isn’t worth it. (Location 1455)\n\n\nbiologists tend to think of pecking orders as the violence that preempts violence. (Location 1458)\n\n\ndominance hierarchies are ultimately information hierarchies. (Location 1470)\n\n\na race is fundamentally different from a fight. (Location 1486)\n\n\nHaving a benchmark—any benchmark—solves the computational problem of scaling up a sort. (Location 1497)\n\n\nThe nearest thing to clairvoyance is to assume that history repeats itself—backward. (Location 1646)\n\n\nCaching is just as useful when it’s proximity, rather than performance, that’s the scarce resource. (Location 1706)\n\n\nHaving a cache is efficient, but having multiple levels of caches—from smallest and fastest to largest and slowest—can be even better. (Location 1751)\n\n\nThe key to a good human memory then becomes the same as the key to a good computer cache: predicting which items are most likely to be wanted in the future. (Location 1834)\n\n\nIn other words, reality itself has a statistical structure that mimics the Ebbinghaus curve. (Location 1840)\n\n\nsize alone is enough to impair speed: (Location 1867)\n\n\nThrough a series of simulations, the researchers showed that simply knowing more makes things harder when it comes to recognizing words, names, and even letters. No matter how good your organization scheme is, having to search through more things will inevitably take longer. (Location 1890)\n\n\nyou should begin by finding the single step that takes the least amount of time—the load that will wash or dry the quickest. If that shortest step involves the washer, plan to do that load first. If it involves the dryer, plan to do it last. Repeat this process for the remaining loads, working from the two ends of the schedule toward the middle. (Location 1944)\n\n\nThus we encounter the first lesson in single-machine scheduling literally before we even begin: make your goals explicit. (Location 1962)\n\n\nbefore you can have a plan, you must first choose a metric. (Location 1964)\n\n\nLive by the metric, die by the metric. (Location 2064)\n\n\nThis starts with making sure that the single-machine problem we’re solving is the one we want to be solving. (Location 2066)\n"},"highlights/Readwise/31554996":{"title":"31554996","links":[],"tags":[],"content":"Highlights\n\nWhen we make this mental calculation, it’s hard for big, daunting projects to compete with little dopamine hits. (Location 83)\n\n\nA Zettelkasten helps you produce writing. (Location 141)\nTo generate is to understand and to internalize.\n\n\nSometimes ignorance is more comfortable than learning, because learning means we have to go through the work of changing. (Location 163)\n\n\nBut the proper way to take notes is not to copy things word-for-word (except in the case of exact quotes). Instead, you re-write it in your own words, which is even more powerful. Second, you don’t write down everything you read. You only write down the important things: Things that are interesting, relevant to your work, or that you otherwise want to retain. (Location 180)\n\n\nRe-writing passages, choosing keywords, and linking notes to one another all cause you to think associatively. Thinking associatively has been shown to improve mood, so that explains why note-taking is deceptively fun. (Location 192)\n\n\nThe one thing you’re trying to accomplish is to record the thought in a place where you feel confident you’ll get a chance to think about it more. Then, you can get back to what you were doing. (Location 339)\n\n\nTo write literature notes, you have to think about what you learned, and how you might explain it to a friend (or your future self). This helps you remember the material better than you would otherwise. (Location 347)\n\n\nWhen you take the extra time to re-write, only the clearest and most compelling elements survive – not to mention that you further internalize the knowledge. (Location 370)\n\n\n(Just don’t fool yourself, as we tend to overestimate how well we’ll remember something later.) (Location 376)\n\n\nAs you read, make fleeting notes. (Location 395)\n\n\nOnce you’ve exported your highlights, review them and highlight, once again, the parts of those highlights that are the most interesting. (Location 410)\nOnly the important ones.\n\n\nLook at the highlights of your highlights and re-write the interesting ones in your own words. You’re now turning your fleeting notes into a literature note. It’s okay not to summarize every highlight. Only worry about the information you most want to learn or that you can foresee wanting to use in the future. (Location 425)\n\n\nbut a couple things make condensing highlights a fruitful time for ideation: One, I’ve been exposed to the information a few times at this point, and it has had time to incubate in my mind – the “passive genius” I talked about in Mind Management, Not Time Management has done some work for me. Two, this is when I’m finally writing. By trying to think of how to describe the passage in my own words, I activate the associative machine, which often causes the current idea to collide with some other idea in my mind. Associative thinking promotes a positive mood, so it shouldn’t be a surprise how fun this task is. (Location 438)\n\n\nPermanent notes should have one idea per note. (Location 454)\n"},"highlights/Readwise/31554997":{"title":"31554997","links":[],"tags":[],"content":"Highlights\n\nDeep Work: Professional activities performed in a state of distraction-free concentration that push your cognitive capabilities to their limit. These efforts create new value, improve your skill, and are hard to replicate. (Location 61)\n\n\nThe reason knowledge workers are losing their familiarity with deep work is well established: network tools. This is a broad category that captures communication services like e-mail and SMS, social media networks like Twitter and Facebook, and the shiny tangle of infotainment sites like BuzzFeed and Reddit. In aggregate, the rise of these tools, combined with ubiquitous access to them through smartphones and networked office computers, has fragmented most knowledge workers’ attention into slivers. (Location 93)\n\n\nSpend enough time in a state of frenetic shallowness and you permanently reduce your capacity to perform deep work. (Location 107)\n\n\nthat network tools are distracting us from work that requires unbroken concentration, while simultaneously degrading our capacity to remain focused. (Location 114)\n\n\nHe decided, therefore, he needed to increase his value to the world. After a period of research, Benn reached a conclusion: He would, he declared to his family, quit his job as a human spreadsheet and become a computer programmer. (Location 136)\n\n\nTo remain valuable in our economy, therefore, you must master the art of quickly learning complicated things. (Location 177)\n\n\nTo succeed you have to produce the absolute best stuff you’re capable of producing—a task that requires depth. (Location 183)\n\n\nBut as we shift to an information economy, more and more of our population are knowledge workers, and deep work is becoming a key currency—even if most haven’t yet recognized this reality. (Location 186)\n\n\nThe Deep Work Hypothesis: The ability to perform deep work is becoming increasingly rare at exactly the same time it is becoming increasingly valuable in our economy. As a consequence, the few who cultivate this skill, and then make it the core of their working life, will thrive. (Location 195)\n\n\nThis compressed schedule is possible because I’ve invested significant effort to minimize the shallow in my life while making sure I get the most out of the time this frees up. (Location 216)\n\n\nAs intelligent machines improve, and the gap between machine and human abilities shrinks, employers are becoming increasingly likely to hire “new machines” instead of “new people.” (Location 265)\n\n\nIn other words, those with the oracular ability to work with and tease valuable results out of increasingly complex machines will thrive. (Location 280)\n\n\nOnce the talent market is made universally accessible, those at the peak of the market thrive while the rest suffer. (Location 293)\n\n\nwhen money is made through the combination of capital investment and labor, the rewards are returned, roughly speaking, proportional to the input. (Location 314)\n\n\nIn this new economy, three groups will have a particular advantage: those who can work well and creatively with intelligent machines, those who are the best at what they do, and those with access to capital. (Location 322)\n\n\nTwo Core Abilities for Thriving in the New Economy 1. The ability to quickly master hard things. (Location 334)\n\n\nTo join the group of those who can work well with these machines, therefore, requires that you hone your ability to master hard things. And because these technologies change rapidly, this process of mastering hard things never ends: You must be able to do it quickly, again and again. (Location 355)\n\n\nIf you can’t learn, you can’t thrive. (Location 361)\n\n\nYou must then transform that latent potential into tangible results that people value. (Location 363)\n\n\nIf you don’t produce, you won’t thrive—no (Location 370)\n\n\nTo learn requires intense concentration. (Location 386)\n\n\nInstead, we argue that the differences between expert performers and normal adults reflect a life-long period of deliberate effort to improve performance in a specific domain.” (Location 392)\n\n\nIts core components are usually identified as follows: (1) your attention is focused tightly on a specific skill you’re trying to improve or an idea you’re trying to master; (2) you receive feedback so you can correct your approach to keep your attention exactly where it’s most productive. (Location 400)\n\n\nThe reason, therefore, why it’s important to focus intensely on the task at hand while avoiding distraction is because this is the only way to isolate the relevant neural circuit enough to trigger useful myelination. (Location 415)\n\n\nThey see productivity as a scientific problem to systematically solve—a (Location 440)\n\n\nwhen you switch from some Task A to another Task B, your attention doesn’t immediately follow—a residue of your attention remains stuck thinking about the original task. (Location 471)\n\n\nGenerally speaking, as knowledge work makes more complex demands of the labor force, it becomes harder to measure the value of an individual’s efforts. (Location 616)\n\n\nNone of these behaviors would survive long if it was clear that they were hurting the bottom line, but the metric black hole prevents this clarity and allows the shift toward distraction we increasingly encounter in the professional world. (Location 629)\n\n\nThe Principle of Least Resistance: In a business setting, without clear feedback on the impact of various behaviors to the bottom line, we will tend toward behaviors that are easiest in the moment. (Location 649)\n\n\nBusyness as Proxy for Productivity: In the absence of clear indicators of what it means to be productive and valuable in their jobs, many knowledge workers turn back toward an industrial indicator of productivity: doing lots of stuff in a visible manner. (Location 715)\n\n\nKnowledge work is not an assembly line, and extracting value from information is an activity that’s often at odds with busyness, not supported by it. (Location 726)\n\n\nWe were, he noted, no longer discussing the trade-offs surrounding new technologies, balancing the new efficiencies against the new problems introduced. If it’s high-tech, we began to instead assume, then it’s good. Case closed. (Location 750)\n\n\nwhat we choose to focus on and what we choose to ignore—plays in defining the quality of our life. (Location 850)\n\n\nthe skillful management of attention is the sine qua non of the good life and the key to improving virtually every aspect of your experience. (Location 853)\n\n\n“concentration so intense that there is no attention left over to think about anything irrelevant, or to worry about problems.”) (Location 883)\n\n\nIn short, I’ll live the focused life, because it’s the best kind there is.” (Location 914)\n\n\nIronically, jobs are actually easier to enjoy than free time, because like flow activities they have built-in goals, feedback rules, and challenges, all of which encourage one to become involved in one’s work, to concentrate and lose oneself in it. Free time, on the other hand, is unstructured, and requires much greater effort to be shaped into something that can be enjoyed. (Location 934)\n\n\nHuman beings, it seems, are at their best when immersed deeply in something challenging. (Location 939)\n\n\n“We who cut mere stones must always be envisioning cathedrals.” (Location 996)\n\n\nThe meaning uncovered by such efforts is due to the skill and appreciation inherent in craftsmanship—not the outcomes of their work. (Location 1011)\n\n\nA now voluminous line of inquiry, initiated in a series of pioneering papers also written by Roy Baumeister, has established the following important (and at the time, unexpected) truth about willpower: You have a finite amount of willpower that becomes depleted as you use it. (Location 1089)\n\n\nThe key to developing a deep work habit is to move beyond good intentions and add routines and rituals to your working life designed to minimize the amount of your limited willpower necessary to transition into and maintain a state of unbroken concentration. (Location 1095)\n\n\nThe goal, in other words, is to generate a rhythm for this work that removes the need for you to invest energy in deciding if and when you’re going to go deep. (Location 1218)\n\n\nthere’s no way to win a Pulitzer Prize or conceive a grand theory without pushing your brain to its limit. (Location 1311)\n\n\nAt the same time, this support needs to be systematized so that you don’t waste mental energy figuring out what you need in the moment. (Location 1330)\n\n\nThis back-and-forth represents a collaborative form of deep work (common in academic circles) that leverages what I call the whiteboard effect. For some types of problems, working with someone else at the proverbial shared whiteboard can push you deeper than if you were working alone. The presence of the other party waiting for your next insight—be it someone physically in the same room or collaborating with you virtually—can short-circuit the natural instinct to avoid depth. (Location 1468)\n\n\nisolation is not required for productive deep work. (Location 1473)\n\n\ncollaborative deep work can yield better results. (Location 1474)\n\n\nDiscipline #1: Focus on the Wildly Important (Location 1506)\n\n\nFor an individual focused on deep work, the implication is that you should identify a small number of ambitious outcomes to pursue with your deep work hours. (Location 1509)\n\n\nDiscipline #2: Act on the Lead Measures (Location 1517)\n\n\nIn other words, lead measures turn your attention to improving the behaviors you directly control in the near future that will then have a positive impact on your long-term goals. (Location 1525)\n\n\nDiscipline #3: Keep a Compelling Scoreboard (Location 1531)\n\n\nDiscipline #4: Create a Cadence of Accountability (Location 1546)\n\n\nAt a high level, this theory proposes that for decisions that require the application of strict rules, the conscious mind must be involved. (Location 1605)\n\n\nOn the other hand, for decisions that involve large amounts of information and multiple vague, and perhaps even conflicting, constraints, your unconscious mind is well suited to tackle the issue. (Location 1607)\n\n\nthat spending time in nature can improve your ability to concentrate. (Location 1623)\n\n\nThe core mechanism of this theory is the idea that you can restore your ability to direct your attention if you give this activity a rest. (Location 1639)\n\n\nThe implication of these results is that your capacity for deep work in a given day is limited. (Location 1660)\n\n\nThe concept of a shutdown ritual might at first seem extreme, but there’s a good reason for it: the Zeigarnik effect. This effect, which is named for the experimental work of the early-twentieth-century psychologist Bluma Zeigarnik, describes the ability of incomplete tasks to dominate our attention. It tells us that if you simply stop whatever you are doing at five p.m. and declare, “I’m done with work until tomorrow,” you’ll likely struggle to keep your mind clear of professional issues, as the many obligations left unresolved in your mind will, as in Bluma Zeigarnik’s experiments, keep battling for your attention throughout the evening (a battle that they’ll often win). (Location 1686)\n\n\n“Committing to a specific plan for a goal may therefore not only facilitate attainment of the goal but may also free cognitive resources for other pursuits.” (Location 1697)\n\n\nregularly resting your brain improves the quality of your deep work. (Location 1707)\n\n\nIn my experience, it’s common to treat undistracted concentration as a habit like flossing—something that you know how to do and know is good for you, but that you’ve been neglecting due to a lack of motivation. This mind-set is appealing because it implies you can transform your working life from distracted to focused overnight if you can simply muster enough motivation. (Location 1736)\n\n\nBut this understanding ignores the difficulty of focus and the hours of practice necessary to strengthen your “mental muscle.” (Location 1739)\n\n\nOnce your brain has become accustomed to on-demand distraction, Nass discovered, it’s hard to shake the addiction even when you want to concentrate. (Location 1755)\n\n\nInstead of scheduling the occasional break from distraction so you can focus, you should instead schedule the occasional break from focus to give in to distraction. (Location 1782)\n\n\nYou must resist this temptation! (Location 1812)\n\n\nThe key here isn’t to avoid or even to reduce the total amount of time you spend engaging in distracting behavior, but is instead to give yourself plenty of opportunities throughout your evening to resist switching to these distractions at the slightest hint of boredom. (Location 1830)\n\n\nTo simply wait and be bored has become a novel experience in modern life, but from the perspective of concentration training, it’s incredibly valuable. (Location 1834)\n\n\nTo summarize, to succeed with deep work you must rewire your brain to be comfortable resisting distracting stimuli. (Location 1836)\n\n\nThe fragments that remained were then considered time dedicated exclusively to studying. (Location 1855)\n\n\nattack the task with every free neuron until it gives way under your unwavering barrage of concentration. (Location 1866)\n\n\nThe goal of productive meditation is to take a period in which you’re occupied physically but not mentally—walking, jogging, driving, showering—and focus your attention on a single well-defined professional problem. (Location 1888)\n\n\nTo succeed with productive meditation, it’s important to recognize that, like any form of meditation, it requires practice to do well. (Location 1903)\n\n\nprocess. I suggest starting with a careful review of the relevant variables for solving the problem and then storing these values in your working memory. (Location 1921)\n\n\n“We found that one of the biggest differences between memory athletes and the rest of us is in a cognitive ability that’s not a direct measure of memory at all but of attention,” (Location 1947)\n\n\nWe’re not wired to quickly internalize abstract information. We are, however, really good at remembering scenes. (Location 1960)\n\n\nThe key to this strategy is not the specifics, but instead the motivating idea that your ability to concentrate is only as strong as your commitment to train it. (Location 1997)\n\n\nyou must take back control of your time and attention from the many diversions that attempt to steal them. (Location 2019)\n\n\naccepting that these tools are not inherently evil, and that some of them might be quite vital to your success and happiness, but at the same time also accepting that the threshold for allowing a site regular access to your time and attention (not to mention personal data) should be much more stringent, and that most people should therefore be using many fewer such tools. (Location 2031)\n\n\nThe problem with this approach, of course, is that it ignores all the negatives that come along with the tools in question. (Location 2061)\n\n\nThe notion that identifying some benefit is sufficient to invest money, time, and attention in a tool is near laughable to people in his trade. (Location 2107)\n\n\nThe Craftsman Approach to Tool Selection: Identify the core factors that determine success and happiness in your professional and personal life. Adopt a tool only if its positive impacts on these factors substantially outweigh its negative impacts. (Location 2114)\n\n\nIt simply asks that you give any particular network tool the same type of measured, nuanced accounting that tools in other trades have been subjected to throughout the history of skilled labor. (Location 2120)\n\n\nThe first step of this strategy is to identify the main high-level goals in both your professional and your personal life. (Location 2152)\n\n\nTo abandon a network tool using this logic, therefore, is not to miss out on its potential small benefits, but is instead to get more out of the activities you already know to yield large benefits. (Location 2247)\n\n\n“during those sixteen hours he is free; he is not a wage-earner; he is not preoccupied with monetary cares; he is just as good as a man with a private income.” (Location 2334)\n\n\nPut more thought into your leisure time. (Location 2360)\n\n\nIt’s crucial, therefore, that you figure out in advance what you’re going to do with your evenings and weekends before they begin. (Location 2364)\n\n\nThe value of deep work vastly outweighs the value of shallow, but this doesn’t mean that you must quixotically pursue a schedule in which all of your time is invested in depth. (Location 2428)\n\n\nWe spend much of our day on autopilot—not giving much thought to what we’re doing with our time. This is a problem. (Location 2465)\n\n\nShallow Work: Noncognitively demanding, logistical-style tasks, often performed while distracted. These efforts tend not to create much new value in the world and are easy to replicate. (Location 2533)\n\n\nYou should, in this case, thank the boss for the feedback, and then promptly start planning how you can transition into a new position that values depth. (Location 2618)\n\n\nIn particular, interrogative e-mails like these generate an initial instinct to dash off the quickest possible response that will clear the message—temporarily—out of your inbox. A quick response will, in the short term, provide you with some minor relief because you’re bouncing the responsibility implied by the message off your court and back onto the sender’s. This relief, however, is short-lived, as this responsibility will continue to bounce back again and again, continually sapping your time and attention. (Location 2768)\n\n\n“Develop the habit of letting small bad things happen. If you don’t, you’ll never find time for the life-changing big things.” (Location 2841)\n"},"highlights/Readwise/31554998":{"title":"31554998","links":[],"tags":[],"content":"Highlights\n\nwe do it because motion allows us to feel like we’re making progress without running the risk of failure. (Location 1722)\n\n\nfor just any type of satisfaction. We are looking for immediate satisfaction. (Location 2245)\n"},"highlights/Readwise/31565587":{"title":"31565587","links":[],"tags":[],"content":"Highlights\n\nRather than creating a new intellectual property regime with general rules for data use—or even simpler—deciding cases using existing intellectual property rules, courts have allowed host websites to create their own intellectual property rights in website data, through the mere act of declaring such data to be property through an online contract (View Highlight)\n\n\nCompanies are free to press their advantage on what is deemed “proprietary” on their sites while simultaneously asserting what is free for the taking on others. It is easy to criticize this, but this is what smart lawyers and legal teams do. (View Highlight)\n"},"highlights/Readwise/31565981":{"title":"31565981","links":[],"tags":[],"content":"Highlights\n\nIn the era of alt-tabbing between these and other apps, our ability to build knowledge and draw connections is permanently challenged by what might be our ultimately futile efforts to multitask. (View Highlight)\n\n\nHe worries that AI will have a similar effect on the economy — promising to make us more productive, while simultaneously inventing so many new distractions and entertainments that they overwhelm and paralyze us. (View Highlight)\n\n\nOf course, the output from this kind of AI tool has to be trustworthy. A significant problem with using AI tools to summarize things is that you can’t trust the summary unless you read all the relevant documents yourself — defeating the point of asking for a summary in the first place. (View Highlight)\n"},"highlights/Readwise/31570209":{"title":"31570209","links":[],"tags":[],"content":"Highlights\n\nUltralearning: A strategy for acquiring skills and knowledge that is both self-directed and intense.\n\n\nHowever, with ultralearning, deeply and effectively learning things is always the main priority.\n\n\nThat the economic landscape is changing may not be a choice any of us has control over, but we can engineer our response to it by aggressively learning the hard skills we need to thrive.\nEducation: Tuition\n\n\nThat the economic landscape is changing may not be a choice any of us has control over, but we can engineer our response to it by aggressively learning the hard skills we need to thrive.\n\n\nDoing hard things, particularly things that involve learning something new, stretches your self-conception. It\n\n\nDoing hard things, particularly things that involve learning something new, stretches your self-conception. It gives you confidence that you might be able to do things that you couldn’t do before\n\n\nWhat matters is the intensity, initiative, and commitment to effective learning, not the particulars of your timetable.\n\n\nBut even the failure mode of ultralearning is usually that you will learn a skill fairly well\n\n\nMetalearning: First Draw a Map. Start by learning how to learn the subject or skill you want to tackle. Discover how to do good research and how to draw on your past competencies to learn new skills more easily.\n\n\nFocus: Sharpen Your Knife. Cultivate the ability to concentrate. Carve out chunks of time when you can focus on learning, and make it easy to just do it.\n\n\nDirectness: Go Straight Ahead. Learn by doing the thing you want to become good at. Don’t trade it off for other tasks, just because those are more convenient or comfortable.\n\n\nDrill: Attack Your Weakest Point. Be ruthless in improving your weakest points. Break down complex skills into small parts; then master those parts and build them back together again.\n\n\nRetrieval: Test to Learn. Testing isn’t simply a way of assessing knowledge but a way of creating it. Test yourself before you feel confident, and push yourself to actively recall information rather than passively review it.\n\n\nFeedback: Don’t Dodge the Punches. Feedback is harsh and uncomfortable. Know how to use it without letting your ego get in the way. Extract the signal from the noise, so you know what to pay attention to and what to ignore.\n\n\nRetention: Don’t Fill a Leaky Bucket. Understand what you forget and why. Learn to remember things not just for now but forever.\n\n\nIntuition: Dig Deep Before Building Up. Develop your intuition through play and exploration of concepts and skills. Understand how understanding works, and don’t recourse to cheap tricks of memorization to avoid deeply knowing things.\n\n\nExperimentation: Explore Outside Your Comfort Zone. All of these principles are only starting points. True mastery comes not just from following the path trodden by others but from exploring possibilities they haven’t yet imagined.\n\n\nIt’s one of taking responsibility for your own learning: deciding what you want to learn, how you want to learn it, and crafting your own plan to learn what you need to. You’re the one in charge, and you’re the one who’s ultimately responsible for the results you generate.\n\n\nAn hour spent searching online for almost any skill should turn up courses, articles, and recommendations for how to learn it. Investing the time here can have incredible benefits because the quality of the materials you use can create orders-of-magnitude differences in your effectiveness. Even if you’re eager to start learning right away, investing a few hours now can save you dozens or hundreds later on.\n\n\nHowever, research can also be a way of procrastinating, particularly if the method of learning is uncomfortable. Just doing a bit more research then becomes a strategy to avoid doing the work of learning.\n\n\nA good rule of thumb is that you should invest approximately 10 percent of your total expected learning time into research prior to starting. If\n\n\nThe struggles with focus that people have generally come in three broad varieties: starting, sustaining, and optimizing the quality of one’s focus.\n\n\nRecognizing that you’re procrastinating is the first step to avoiding it.\n\n\nTherefore, a good first crutch is to convince yourself to get over just the few minutes of maximal unpleasantness before you take a break. Telling yourself that you need to spend only five minutes on the task before you can stop and do something else is often enough to get you started\n\n\nYour goal is to enhance your learning, and this often involves pushing through some sessions that are more frustrating than what could be considered ideal for flow.\n\n\nComplex tasks may benefit from lower arousal, so working in a quiet room at home might be the right idea for math problems. Simpler tasks might benefit from a noisier environment, say working at a coffee shop.\n\n\nDirectness is the idea of learning being tied closely to the situation or context you want to use it in.\n\n\nWe want to speak a language but try to learn mostly by playing on fun apps, rather than conversing with actual people. We want to work on collaborative, professional programs but mostly code scripts in isolation.\n\n\ndirectly learning the thing we want feels too uncomfortable, boring, or frustrating, so we settle for some book, lecture, or app, hoping it will eventually make us better at the real thing.\n\n\nMany popular “brain-training” games also subscribe to this view of the mind, assuming that deep training on one set of cognitive tasks will extend to everyday reasoning. It’s been more than one hundred years since the verdict came in, yet the allure of a general transfer procedure still has many searching for the Holy Grail.\n"},"highlights/Readwise/31596656":{"title":"31596656","links":[],"tags":[],"content":"Highlights\n\nA small study of college students found they now only focus on any one task for 65 seconds. A different study of office workers found they only focus on average for three minutes. This isn’t happening because we all individually became weak-willed. Your focus didn’t collapse. It was stolen. (View Highlight)\n\n\nA small study of college students found they now only focus on any one task for 65 seconds. A different study of office workers found they only focus on average for three minutes. This isn’t happening because we all individually became weak-willed. Your focus didn’t collapse. It was stolen. (View Highlight)\n\n\nProf Earl Miller, a neuroscientist at Massachusetts Institute of Technology, explained one to me. He said “your brain can only produce one or two thoughts” in your conscious mind at once. That’s it. “We’re very, very single-minded.” We have “very limited cognitive capacity”. But we have fallen for an enormous delusion. The average teenager now believes they can follow six forms of media at the same time (View Highlight)\n\n\nThey’re switching back and forth. They don’t notice the switching because their brain sort of papers it over to give a seamless experience of consciousness, but what they’re actually doing is switching and reconfiguring their brain moment-to-moment, task-to-task – [and] that comes with a cost (View Highlight)\n\n\nIndividual abstinence is “not the solution, for the same reason that wearing a gas mask for two days a week outside isn’t the answer to pollution. It might, for a short period of time, keep certain effects at bay, but it’s not sustainable, and it doesn’t address the systemic issues. (View Highlight)\n\n\nThe more our attention degrades, the harder it will be to summon the personal and political energy to take on the forces stealing our focus (View Highlight)\n"},"highlights/Readwise/31628623":{"title":"31628623","links":[],"tags":[],"content":"Highlights\n\nDon’t over specialize, don’t be too sure that  you know the future. Be flexible and remember   that careers and jobs are a long-term thing.  Too many young people think they can optimize   something and then they find they’ve spent a  couple of years or more specializing in something  \nthat may not have been the right thing and in the  process they burn out because they haven’t spent   enough time building up friendships and having a  life outside computing. I meet a lot of sort of   “junior geeks” that just think that the only  thing that matters is the specialty of computing   programming or AI or graphics or something  like that and well it isn’t and the rug might  \nbe pulled under them but for that. And if they do  nothing else, well if you don’t communicate your   ideas you can just as well do Sudoku. You have to  communicate and a lot of sort of caricature nerds   forget that. They think that if they can just  write the best code they can change the world (View Highlight)\n\n\nbut you have to be able to listen, you have to  be able to communicate with your would-be users,   and learn from them, and you have to be  able to communicate your ideas to them.   So you can’t just do code you have to do   something about culture and how to express ideas  and I mean I never regretted the time I spent   on history and on math. Math sharpens your mind,  history gives you some idea of your limitations,  \non what’s going on in the world, and so don’t be  too sure. Take time to have a balanced life and   be ready for the opportunity. (View Highlight)\n"},"highlights/Readwise/31779102":{"title":"31779102","links":[],"tags":[],"content":"Highlights\n\nSure, you may want the relationship to work or the business to be a success—and you should give it your best effort—but also realize that if it doesn’t work out, you’ll be fine. There are many ways to live a great life. (View Highlight)\n\n\nAlthough the world is full of suffering, it is full also of the overcoming of it. My optimism, then, does not rest on the absence of evil, but on a glad belief in the preponderance of good and a willing effort always to cooperate with the good, that it may prevail. (View Highlight)\n"},"highlights/Readwise/31779136":{"title":"31779136","links":[],"tags":[],"content":"Highlights\n\nwe are hamstrung in our ability to mitigate their harmful consequences: what is unknown is hard to fix. If you shouldn’t fix what ain’t broke, you can’t fix what you don’t know. (View Highlight)\n"},"highlights/Readwise/31779177":{"title":"31779177","links":[],"tags":[],"content":"Highlights\n\nPutting ideas into words is a severe test. The first words you choose are usually wrong; you have to rewrite sentences over and over to get them exactly right. And your ideas won’t just be imprecise, but incomplete too. (View Highlight)\n\n\nThe real test is reading what you’ve written. You have to pretend to be a neutral reader who knows nothing of what’s in your head, only what you wrote. When he reads what you wrote, does it seem correct? Does it seem complete? If you make an effort, you can read your writing as if you were a complete stranger, and when you do the news is usually bad. (View Highlight)\n\n\nWhat I’m saying is that however much you learn from exploring ideas in other ways, you’ll still learn new things from writing about them. (View Highlight)\n\n\nIdeas can feel complete. It’s only when you try to put them into words that you discover they’re not. So if you never subject your ideas to that test, you’ll not only never have fully formed ideas, but also never realize it. (View Highlight)\n"},"highlights/Readwise/31795305":{"title":"31795305","links":[],"tags":[],"content":"Highlights\n\nRequired office time keeps control at the top. It’s optimized for management, not employees, around the belief that “if I can see you at a desk, you must be working.” It’s efficient and easily understood because it’s “how it’s always been done.” (View Highlight)\n\n\nMicrosoft’s 2022 Work Trend Index Report explores the idea of “productivity paranoia” — or when managers worry if their employees are working enough. This hits its peak when workers are out of sight. It, in turn, leads to “performative productivity,” or doing work to look busy and make the guys in the corner offices happy. (View Highlight)\n\n\nIs that wildly innovative? No. But often, breaking out of “how we’ve always done it” is exactly the push needed to think differently. The innovative thinking isn’t in choosing to be flexible. It’s in how we transform the way we create, engage and thrive together without being together. (View Highlight)\n"},"highlights/Readwise/31822336":{"title":"31822336","links":[],"tags":[],"content":"Highlights\n\nI’ve since modified and elaborated parts of these arguments, and now prefer the word “TESCREALism” to “longtermism” because the acronym “TESCREAL” does a better job of capturing the array of overlapping ideas that have shaped the general outlook. (View Highlight)\nTranshumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, and Longtermism\n\n\nOver and over again, history shows that the march to utopia can leave a trail of destruction in its wake. If the ends can justify the means, and the end is paradise, then what exactly is off the table for protecting and preserving this end? (View Highlight)\n\n\nYudkowsky talks out of both sides of his mouth, giving mixed messages. He wants us to believe that his proposals for avoiding an AGI apocalypse are within the bounds of established norms, yet in a moment of honesty he says that he would “probably” bomb laboratories in Wuhan, if he can do this “secretly.” He opposes nuclear first strikes, yet implies that more than 8 billion people should be “allowed” to die, if it means keeping the door open to “reaching the stars someday.” And his extraordinary over-confidence, fueled by his egomania, that a misaligned AGI will kill everyone on Earth is inspiring the sort of radical, dangerous discussions like those recorded in the Berkeley workshop meeting minutes. (View Highlight)\n\n\nWhen people inside a community become too afraid to publicly criticize it, that community starts to look rather like a cult. (View Highlight)\n"},"highlights/Readwise/31837316":{"title":"31837316","links":[],"tags":[],"content":"Highlights\n\nSo for those who are social distancing and feeling a little lonely and a lot anxious, one action this literature suggests we might take is to call up people who’ve done nice things for us and just tell them how grateful we are and what it meant to us. All of us have reasons to be grateful even in the midst of our current predicament. We after all have been given a lot of positive things even if we now face a dire challenge. It is important not to lose sight of everything we have to be grateful for even as some things are taken from us. (View Highlight)\n\n\nHope is not unrealistic, it is a recognition that what obstacles exist can be overcome. (View Highlight)\n\n\nWe can distract ourselves from being overly preoccupied with the negative by focusing on something positive. We can create some distance from pessimistic thoughts by reminding ourselves that they are only part of the picture, and there are hopeful signs as well. And we can dispute with our most pessimistic thoughts, pointing to the positive. (View Highlight)\n"},"highlights/Readwise/31866632":{"title":"31866632","links":[],"tags":[],"content":"Highlights\n\nFor critics, Books3 isn’t a boon to society—instead, it’s emblematic of everything wrong with generative AI, a glaring example of how both the rights and preferences of artists are disregarded and disrespected by the AI industry’s main players, and something that straight-up shouldn’t exist. (View Highlight)\n\n\nNow, it’s tight-lipped about what is used for newer versions. “It behooves these companies to be opaque about their sources,” McCarthy says. Knowing they’re likely to face lawsuits if they fess up to using copyrighted material in their data training sets is a powerful deterrent. This, in turn, will make it harder for writers to know when their copyright is potentially infringed. (View Highlight)\n"},"highlights/Readwise/31866739":{"title":"31866739","links":[],"tags":[],"content":"Highlights\n\nBut something jumped out at me that changed what I wanted to write about today. It was this line in particular (emphasis mine):\n\nFor example, one company that had previously completed a successful agile transformation learned that its developers, instead of coding, were spending too much time on low-value-added tasks such as provisioning infrastructure, running manual unit tests, and managing test data. Armed with that insight, it launched a series of new tools and automation projects to help with those tasks across the software development life cycle.\nI realized that I missed the whole point of this post. The goal isn’t to gain insight, it’s to justify funding a new program inside an organization. (View Highlight)\n\n\n\nIn order to effect change in an organization, you need political capital, even if you’re an executive. That’s because making change in an organization is hard, programs are expensive and don’t bear fruit for a long time, and so you need to get buy-in in order to make things happen. (View Highlight)\n\n\nMcKinsey is a management consulting firm. One of the services that management consulting firms provide is that they will sell you political capital. They provide a report generated by external experts that their customers can use as leverage within their organizations to justify change programs. (View Highlight)\n\n\nAnd, so, it makes perfect sense that McKinsey &amp; Company would write a blog post like this. They are, effectively, a political-capital-as-a-service (PCaaS?) company. Helping executives justify programs inside of companies is what they do for a living. But they can’t simply state explicitly how the magic trick actually works, because then it won’t work anymore. (View Highlight)\n"},"highlights/Readwise/31885386":{"title":"31885386","links":[],"tags":[],"content":"Highlights\n\nBuild your wealth upon your career.You most likely will make far more money from your business or profession than from your investments. Only very rarely does someone make a large fortune from investments. (View Highlight)\n\n\nThe fact that you earned what you have doesn’t mean that you could earn it again if you lost it. Markets and opportunities change, technology changes, laws change. Conditions today may be considerably different from what they were when you built the estate you have now. And as time passes, increasing regulation makes it harder and harder to amass a fortune. (View Highlight)\n\n\nInvestor advisors have no more ability to predict the future actions of human beings than psychics and fortune-tellers do. And so events never unfold as we were so sure they would. (View Highlight)\n\n\nThe investment expert with the perfect record up to now will lose his touch as soon as you start acting on his advice. (View Highlight)\n\n\nThe second source is probably finding something that has worked in the past and assuming it will work in the future. Trading systems are based on the unstated assumption that the world doesn’t change. But the world is in constant change – as desires change, demand changes, and supplies change. (View Highlight)\n\n\nBut, most of all, no advisor can be expected to treat your money with the same respect you do. (View Highlight)\n\n\nDon’t undertake any investment, speculation, or investment program that you don’t understand. If you do, you may later discover risks you weren’t aware of. Or your losses might turn out to be greater than the amount you invested. (View Highlight)\n\n\nEvery investment has its time in the sun — and its moment of shame. (View Highlight)\n\n\nAnd you can’t rely on any single institution to protect your wealth for you. (View Highlight)\n\n\nYou shouldn’t risk the chance that a single surprise will wipe out a large part of your holdings.\nDiversify across investments and institutions – and keep things simple enough to manage yourself – you can relax, knowing that no one event can do you in. (View Highlight)\n\n\nFor the money you need to take care of you for the rest of your life, set up a simple, balanced, diversified portfolio. (View Highlight)\n\n\nIf you want to try to beat the market, set up a second — separate — portfolio with which you can speculate to your heart’s content. But make sure this portfolio contains no more of your wealth than you can afford to lose. (View Highlight)\n\n\nDon’t allow everything you own to be where your government can touch it. By having something outside the reach of your government, you’ll be less vulnerable — and you’ll feel less vulnerable. You’ll no longer have to worry so much about what the government will do next. (View Highlight)\n\n\nWhenever you’re in doubt about a course of action, it is always better to err on the side of safety. (View Highlight)\n"},"highlights/Readwise/31897259":{"title":"31897259","links":[],"tags":[],"content":"Highlights\n\nThere’s always a tension — recruiters are, by and large, good human beings who genuinely want to help their candidates, but they also have an employer they’re beholden to, as well as a comp/bonus structure that rewards certain behaviors, some of which run counter to candidates’ best interests. (View Highlight)\n\n\nThird party recruiters are incentivized to get the deal done, not to risk the deal by negotiating hard for you. (View Highlight)\n\n\nThey’re incentivized, first and foremost, to follow the rules their head of department sets for them. This is true for how they evaluate candidates, who they let through, and how they read resumes. And it’s definitely true for how they negotiate. (View Highlight)\n\n\nThe reality is that negotiation is all about preparation and leverage. (View Highlight)\n\n\nThe most obvious way to lose leverage is revealing information about money. The other way to lose leverage is by sharing information about where else you’re interviewing. If you share this information, you risk prematurely scaring off smaller companies because they don’t think they can win in a bidding war with FAANG. You also risk cornering yourself into a situation where the company knows your options are limited, and they might be inclined to lowball you as a result. Finally, you risk getting an exploding offer to try to force you to make a decision before you’re ready. (View Highlight)\n\n\nWhen you share the actual timeline you’re working with, you no longer control the timing of your job search, and a huge part of negotiation is controlling timing so you can make all your offers come in at the same time. (View Highlight)\n\n\nf I negotiated an increase then, I would have had to renegotiate when I received the higher offer. This will cause negotiating fatigue for you and the company. They will be less likely to negotiate a second time because they don’t know how many times you will ask them for more. (View Highlight)\n\n\nThe casual nature of texting lulls you into a false sense of security. Moreover, the fact that texts interrupt you from something else puts you at a disadvantage — when you get interrupted, your instinct is to quickly respond to make the interruption go away. But knee-jerk responses are rarely the right ones, and you’ll find yourself giving away information you shouldn’t have. (View Highlight)\n\n\nI’m not sure exactly what number I’m looking for, but if you’d be able to share what an offer package might look like, then I will gladly iterate on it with you if needed and figure out something that works. I promise not to accept other offers until I have a chance to discuss them with you. (View Highlight)\n"},"highlights/Readwise/31926452":{"title":"31926452","links":[],"tags":[],"content":"Highlights\n\nBut in the era of 24/7 news coverage — the era of the attention economy — we’re paying that attentional cost throughout the day. Over time, it becomes a sizable withdraw of our mental energy, yet we continue to check our news feeds for threats even when we should be focused on something else. (View Highlight)\n"},"highlights/Readwise/31926543":{"title":"31926543","links":[],"tags":[],"content":"Highlights\n\nPeer review, when it is working well, doesn’t guarantee truth or correctness, but it does mean: This was examined critically and thoughtfully by 2–4 independent people with relevant knowledge who found it sufficiently solid (given their own knowledge) and worthy of others’ attention. (View Highlight)\n\n\nWhen we serve as reviewers, we are charged with critical analysis of the work. When we are looking for work to build on, we are frequently much less critical, and end up seeking out papers that say what we want to hear. (View Highlight)\n\n\nIn other words, when a paper has passed peer review but won’t appear for a while, posting a preprint gives access to other scholars and the broad public without further delay. (And if the publication venue is paywalled, it also circumvents the paywall.) For all I know, this is what arXiv was originally meant for or even how it’s used in other fields. (View Highlight)\n\n\nAnother way of putting this is: if you’re doing work that you’re worried will get scooped, you’re probably not asking very interesting or original questions. (View Highlight)\n\n\nEroding the value of peer review: When arXiv becomes such a center of gravity that even published papers are also put on arXiv for attention, and when everyone just cites arXiv versions of papers without checking if they have appeared somewhere with peer review, then we lose the value of the (expensive yet important) peer review process. The point of peer review is gatekeeping (of papers, not authors, obviously): so that someone coming from outside can find papers that have been critically appraised by knowledgeable peers. (View Highlight)\n\n\nThese also have knock-on effects: the flag-planting culture leads to ever more pressure to “move fast”, impeding our ability to engage in slow scholarship. It also means that everyone’s attention is focused only on the latest papers, thinning the fabric of the scholarly conversation. (View Highlight)\n\n\nThe erosion of the value of peer review also allows what are effectively fraudulent citation rings (equivalent of fraudulent review rings) to hide in plain sight. (View Highlight)\n\n\nI noted above that people who are accessing papers in the course of their research are often looking for papers that say what they want to hear. And what is ChatGPT designed for if not outputting exactly what we want to hear? (View Highlight)\n\n"},"highlights/Readwise/31960023":{"title":"31960023","links":[],"tags":[],"content":"Highlights\n\nThe paradigm we have right now is so data-greedy that the entire public internet doesn’t seem to be enough. Your private data are going to feed the insatiable beast, too — like it or not. (View Highlight)\n"},"highlights/Readwise/31960083":{"title":"On Tools and the Aesthetics of Work","links":[],"tags":[],"content":"Highlights\n\nWhen we switched media consumption from long newspaper articles to television soundbites, for example, our understanding of news lost its heft and became more superficial and emotionally-charged. (View Highlight)\n"},"highlights/Readwise/31960185":{"title":"31960185","links":[],"tags":[],"content":"Highlights\n\nFor instance, when the GitHub Copilot team first decided to provide whole function coding suggestions, we also had to ensure output predictability and consistency, where the same prompt and context would produce the same suggestions from the AI model.\nTo achieve this, the team applied two strategies: changing the parameters to reduce the randomness of outputs and caching responses. Additionally, using cached responses instead of generating new responses to the same prompt not only reduced variability in suggestions, but it also improved performance. (View Highlight)\n\n\nBased on community input, the GitHub Copilot team also developed a code reference tool that includes links to public code that may match GitHub Copilot suggestions, so developers can review potential matches (and relevant licensing information), and make informed choices. (View Highlight)\n"},"highlights/Readwise/32008138":{"title":"32008138","links":[],"tags":[],"content":"Highlights\n\nBut that’s how you make passive income: by staying up twenty-four hours a day working nonstop, destroying your relationships with friends and loved ones, and eliminating any spare time you might have to enjoy the fruits of your labor. (View Highlight)\n"},"highlights/Readwise/32013597":{"title":"32013597","links":[],"tags":[],"content":"Highlights\n\nyour surface lexicon Illustrated here are the words you unconsciously default to and employ in your daily communication approximately fifteen hundred to three thousand unique words (View Highlight)\n\n\nyour deep lexicon on the other hand is comprised of words that you recognize but rarely employ in your speech the average native English-speaking adult has a deep lexicon of approximately twenty thousand to thirty five thousand unique words (View Highlight)\n\n\nthe more you use a word the higher it ranks in your Lexicon (View Highlight)\n\n\nthe other action you can take is to give yourself more time to index your deep\nlexicon (View Highlight)\n\n\nlearn how to command the pause (View Highlight)\n\n\nyet being articulate requires that you understand this relationship between silence and the impact that it has in your speech (View Highlight)\n\n\npausing before speaking or between points allows you to achieve a better intimacy with your words you have more time to think through your ideas and your listener is able to thoroughly absorb your words because they are more deliberate your words are more precise (View Highlight)\n\n\nnumber three pruning your filler words (View Highlight)\n\n\nprocessing the endings of your words when I focused on hearing the endings of\nthe words that are coming out of my mouth it automatically one reduces the speed of my speech but two channels my focus onto the words themselves allowing me to audit my word selection more carefully (View Highlight)\n\n\nsecondly practice keeping your mouth closed until you are ready to speak your first word (View Highlight)\n\n\nreading great works exposes you to great words and expands your intellectual Horizon which enriches your thinking and reflects in your speech (View Highlight)\n\n\nthe significance that our voice holds in sounding articulate (View Highlight)\n\n\nthey’re receptacles that are filled with emotional substance and that substance is provided by our pitch our volume the speed of our speaking and variation (View Highlight)\n"},"highlights/Readwise/32036485":{"title":"32036485","links":[],"tags":[],"content":"Highlights\n\nWhile we need researchers and scientists to go meta, they should remain tethered to the base-game and work closely with practitioners. (View Highlight)\n\n\nThey’re like the “entrepreneurship” professor that never built a business. They’re experts in the metagame — they’re polished speakers, engaging writers, and thought-leadering tweeters. The problem, though, is that they’re not judged by customers, the market, or nature, instead they’re judged by their peers. I call them metapreneurs. (View Highlight)\n"},"highlights/Readwise/32039006":{"title":"32039006","links":[],"tags":[],"content":"Highlights\n\nTim wasn’t delivering software; Tim was delivering a team that was delivering software. The entire team became more effective, more productive, more aligned, more idiomatic, more fun, because Tim was in the team. (View Highlight)\n\n\nJust don’t try to measure the individual contribution of a unit in a complex adaptive system, because the premise of the question is flawed.\nDORA metrics, for example, are about how the system of work works, whether as Westrum culture indicators or flow of technical change into production. They measure the engine, not the contribution of individual pistons, because that makes no sense. (View Highlight)\n"},"highlights/Readwise/32039087":{"title":"32039087","links":[],"tags":[],"content":"Highlights\n\nI mean sure the brown calculator is probably functionally better because of its good design it’s probably made a little bit better but it’s not 10 times better you’re paying 10 times more for the emotional response that this object creates in you this isn’t just a calculator anymore either it’s a symbol of Purity and Order plus the brown calculator is a design icon which is also totally emotional and sentimental none of that value is grounded in any\nkind of objective truth it’s still just a plastic calculator so is it the design dishonest and how it creates a meaning beyond the sum of its parts or is it dishonest with how expensive it is (View Highlight)\n\n\ndishonest or not it’s still a great design as long as people value things Beyond just their functional utility this will always be the case (View Highlight)\n\n\nwhen a product loses too many of its controls the remaining ones are left to pick up the slack so you have two buttons that do like 10 things holding down tapping performing a finger ritual dance you’ve traded intuitive interaction for a device that needs an instruction manual or chairs that are too uncomfortable to actually sit in for more than 10 minutes or computers that are missing headphone\njacks or functional ports the true purpose of minimalism was to ease user experience by limiting options but instead it’s mostly used as an aesthetic statement so you end up with visual Simplicity that’s a functional nightmare (View Highlight)\n\n\nthen you’ve got Johnny ive’s 65 000 turntable it’s a blatant symbol of desire and opulent statement piece but that was\nnever the point of the Bauhaus or minimalist movements they’re aimed to create simple useful designs that are accessible to everyone one it was Beauty born out of purpose and uncompromised by mass production but somehow we’ve worked this ideology focusing on The Superficial aesthetic while neglecting the core principles (View Highlight)\n\n\nthe real problem here is with the\nunquestioning idolization of Dita ROMs and its principles while not understanding their true meaning (View Highlight)\n\n\nfewer elements means that every detail is under a spotlight so ensuring these details are perfect can drive up production costs in this way the pursuit of minimalism can ironically lead to\nexclusivity rather than the intended goal of universal accessibility (View Highlight)\n\n\nI think that a lot of times this as little design as possible idea is used as an excuse to make emotionless design that’s cold and oversimplified and not in line with what the customer needs (View Highlight)\n\n\neven the most logical design without emotional resonance will fall flat Form and Function are one and the same a product appearance guides our interaction with it and sometimes you need a little bit of the embellishment or Flair (View Highlight)\n\n\nit’s like applying a Band-Aid to a blister caused by poorly fitting shoes sure the Band-Aid might help the pain for a little while but the real problem is with the poorly fitting shoes in the same way Eco efficiency is the Band-Aid that fails to tackle the root cause our Reliance on unsustainable resources (View Highlight)\n\n\nEco efficiency is about doing less harm whereas Eco Effectiveness is about doing more good it’s about regenerative processes (View Highlight)\n\n\nlots of things are specifically designed with a learning curve in mind because half the fun comes from navigating learning and mastering the product over time (View Highlight)\n\n\ngood design bows to the fundamental principles of life it’s never just about out the product it’s about the all-encompassing system it must respect all people the designers Engineers Factory workers end users and of course the most important user Mother Earth (View Highlight)\n"},"highlights/Readwise/32068982":{"title":"32068982","links":[],"tags":[],"content":"Highlights\n\nIt’s a shame more entrepreneurs don’t talk about their most difficult moments publicly, because it paints a distorted picture of what startups are. (View Highlight)\n\n\nI should have had conversations with my co-founders about what rules they were comfortable breaking. Testing product demand with a fake landing page that collects credit card information? Manufacturing a sense of urgency when fundraising? Pushing the limits of the law, which we never did, but which many innovative companies such as Airbnb and Lyft are doing? If we had these conversations early on, we could have avoided culture clashes (and worse) later on. (View Highlight)\n\n\nFirst and foremost, I’ve come to realize that “technically true” is a terrible ethical measure for a (non-technical) statement. I should have held myself to a higher standard. I’ve also learned the importance of overwhelming honesty. The phrase is borrowed from the excellent book The Transparency Edge (worth a read in full). (View Highlight)\n\n\nIn the same way a product builds up technical debt with every piece of hacky code, a leader can build up a sort of managerial debt with every fib, embellishment, and exaggeration. They all serve to undermine credibility. And without credibility, you cannot lead. Moving forward, overwhelming honesty is the name of the game at Amicus. (View Highlight)\n"},"highlights/Readwise/32218097":{"title":"32218097","links":[],"tags":[],"content":"Highlights\n\nThere is no standard tooling for microservices-based development - there is no common framework. Working on distributed systems has gotten only marginally easier in 2020s. The Dockers and the Kuberneteses of the world did not magically take away the inherent complexity of a distributed setup. (View Highlight)\n\n\nThe audit revealed an interesting pattern, where many startups experienced a sort of collective imposter syndrome while building straight-forward, simple, performant systems. There is a dogma attached to not starting out with microservices on day one - no matter the problem. “Everyone is doing microservices, yet we have a single Django monolith maintained by just a few engineers, and a MySQL instance - what are we doing wrong?”. The answer is almost always “nothing”. (View Highlight)\n\n\nPerhaps claiming that your particular problem domain requires a massively complicated distributed system and an open office stuffed to the gills with turbo-geniuses is just crossing over into arrogance rather than brilliance? (View Highlight)\n\n\nThe knobs you need to be aware of and tune are endless, and they are all specific to your system’s particular signature of usage and traffic.\nThe truth is that most companies will never reach the massive size that will actually require building a true distribute system. Your cos playing Amazon and Google - without their scale, expertise, and endless resources - is very likely just an egregious waste of money and time.\nThe only thing harder than a distributed system is a BAD distributed system. (View Highlight)\n\n\n“Developer ergonomics” is the friction, the amount of effort a developer must go through in order to get something done, be it working on a new feature or resolving a bug.\nWith microservices, an engineer has to have a mental map of the entire system in order to know what services to bring up for any particular task, what teams to talk to, whom to talk to, and what about. The “you have to know everything before doing anything” principle. How do you keep on top of it? Spotify, a multi-billion dollar company, spent probably not negligible internal resources to build Backstage, software for cataloging its endless systems and services.\nThis should at least give you a clue that this game is not for everyone, and the price of the ride is high. (View Highlight)\n\n\nAs you can see, breaking up your problem does not make solving it easier - all you get is another set of even harder problems. (View Highlight)\n"},"highlights/Readwise/32218243":{"title":"32218243","links":[],"tags":[],"content":"Highlights\n\nExecutive Function Theft (EFT) is the deliberate abdication of decision-making, tasks, and responsibilities that are perceived as administrative or repetitive, of lesser importance, or aren’t pleasant or shiny, to another person, with the result that the receiving person’s executive function becomes so exhausted that they are unable to participate in, contribute to, or enjoy higher level efforts. (View Highlight)\n\n\n\nThe goal, in the name of the company bottom dollar, is to make it as inconvenient as possible for me to use an employer offered benefit. A truly mundane and recurrent example, unfortunately, as I try to navigate U.S. health insurance. (View Highlight)\n\n\nSimilarly thinking about EFT in the workplace, I was reminded of the guy who got famous with the Four Hour Workweek book and how we were all just supposed to outsource things to nameless underpaid gig workers. Notably, when looking for a summary of that book, I found an article by Cal Newport praising it. (View Highlight)\n\n\nExecutive Function Theft can lead to an inequality of time to dream, to rest, or to plan and grow professionally. If you are facing EFT in the workplace, how are you supposed to do five year goals or strategic planning? When are you supposed to be getting that significant work in that will lead you to promotion or a career change? (View Highlight)\nGlue work\n\n\nWhen thinking about Executive Function Theft in the home or personal relationships, the outcome that cropped up was that of decision fatigue. (View Highlight)\n\n\n“While his female partner continues to do housework for twenty, twenty-six, thirty-one more hours — he can devote this time to hobbies, relaxation, exercise, hanging out with friends, sleep, work and/or continued education. Essentially, he has the opportunity to do so much more with his life than she does.” — Kate Mangino, Equal Partners, Chapter 1 (View Highlight)\n\n\nI don’t think you can have a conversation about Executive Function Theft without also talking about the mental load and invisible labor and emotional labor. All of these concepts are connected. EFT creates a greater mental load for another individual. EFT demands ever increasing amounts of invisible labor without giving equitable time for “promotable tasks” or rest. EFT expects that Someone Else who they have assigned to be of lesser importance will take on the emotional parts of work or care tasks. (View Highlight)\n"},"highlights/Readwise/32238390":{"title":"32238390","links":[],"tags":[],"content":"Highlights\n\nRather, the goal is to introduce so much confusion, exhaustion and cynicism about what is and isn’t true - that is, to produce so much bullshit - that the broad civic and political consensus which underpins every movement for justice becomes impossible to sustain. (View Highlight)\n\n\nut for the time being, today’s LLMs remain plagued by the bullshit problem - and calling the plausible nonsense LLMs generate “hallucinations” does not make them any less troublesome for people who value increasing the amount of truth going out onto the world. (View Highlight)\n"},"highlights/Readwise/32238617":{"title":"32238617","links":[],"tags":[],"content":"Highlights\n\nThe whole point of reading is to really understand something. So if all you’re after is the ‘gist,’ skip books and stick with blog posts. (View Highlight)\n\n\nReading is not a luxury. It’s not something you splurge on. It’s a necessity. Even if all you get is one life-changing idea from a book, that’s still a pretty good ROI. (View Highlight)\n\n\nDon’t just read books, re-read books. There’s a great line the Stoics loved—that we never step in the same river twice. The books don’t change, but you do. (View Highlight)\n\n\nThe rule I like is ‘one hundred pages minus your age.’ Say you’re 30 years old—if a book hasn’t captivated you by page 70, stop reading it. So as you age, you have less time to endure crap. (View Highlight)\n\n\nOne of the reasons I try to spoil the plot, make my way through the intro and the preface, read reviews and articles about the books I’m reading, watch videos about them, and read other books on the topic is because I want to really understand what I’m dealing with. If I don’t, if I only want a surface take, why read a book at all? (View Highlight)\n"},"highlights/Readwise/32262756":{"title":"32262756","links":[],"tags":[],"content":"Highlights\n\nThe best word I had for this was that their code was aesthetically pleasing*.***\nTheir code was clean, organized, and logical. Each decision made in their code made sense, and when something didn’t, it was documented well within the code. (View Highlight)\n\n\nTests force code clarity and predictability. They provide confidence. Good automated testing allows teams to make changes to code without worrying about breaking something unseen. (View Highlight)\n\n\nNo great systems were built alone. Great engineers went through design reviews, solicited feedback, and continued iterating on their initial designs for their code.\nEveryone has gaps in their knowledge that can be filled in by other people. Fresh perspectives can often help code become clearer or provide a new approach that may not have been thought of previously. (View Highlight)\n\n\nThe best way to teach yourself to be unattached from your code is to realize that in 20 years, there’s a high chance that much of your code will either be technical debt, deprecated, or rewritten. (View Highlight)\n"},"highlights/Readwise/32322383":{"title":"32322383","links":[],"tags":[],"content":"Highlights\n\nmindfulness can reduce its size because it buffers stress seen in the amygdala (View Highlight)\n"},"highlights/Readwise/32334683":{"title":"32334683","links":[],"tags":[],"content":"Highlights\n\nEven if you can’t always identify a particular person in the resulting AI product, these are our voices, images, and writing that are making this possible. Maybe in the next few months and years, this won’t be seen as a big deal, and AI generated sexual images of real people will be  as commonplace as any illustrator’s ability to draw someone naked, but we as a society have not been able to decide yet because no one stopped to ask about the ethical repercussions before this tech was widely spread and used (View Highlight)\n\n\nIf you are actually interested in the generative AI boom and you are not identifying porn as core use for the technology, you are either not paying attention or intentionally pretending it’s not happening. (View Highlight)\n"},"highlights/Readwise/32454089":{"title":"32454089","links":[],"tags":[],"content":"Highlights\n\nMy self worth was bound at that moment to my success or failure, and that set off a chain reaction: unnatural desire, pressure, performance anxiety, anticipation, a mind enamored with the top but a body struggling below, bad decision-making, irregular movement, distraction, frustration. All in that order, too. (View Highlight)\n\n\nThe growth mind-set. The abundance mind-set. The gratitude mind-set. But in this genre of self-optimization, if it can be called that, we are adding more and more duct tape to something that isn’t broken — our mind — until it is so covered we lose sight of the beautifully designed machine underneath it all and it thus becomes, in fact, broken. (View Highlight)\n"},"highlights/Readwise/32454213":{"title":"Elegant and Powerful New Result That Seriously Undermines Large Language Models","links":[],"tags":[],"content":"Highlights\n\nIn neural network discussion, people are often impressed by successes, and pay far too little regard to what failures are trying to tell them. This symmetry fail is mighty big, a mighty persistent error that has endured for decades. It’s such a clear, sharp failure in reasoning it tempts me to simply stop thinking and writing about large language models altogether. If, after training on virtually the entire internet, you know Tom is Mary Lee‘s son, but can’t figure out without special prompting that Mary Lee therefore is Tom’s mother, you have no business running all the world’s software. (View Highlight)\n"},"highlights/Readwise/32454748":{"title":"32454748","links":[],"tags":[],"content":"Highlights\n\nby sharing this with as broad a community as possible we accelerate the development and the quality of the work and that’s really my\ncore hypothesis in in pursuing this it really comes down to the fact that when you open up the doors to this technology to much more large and diverse Community you really accelerate your ability to make progress not just on the technical components on the usability components as well as some of the other aspects (View Highlight)\n\n\nso I would say in many ways what’s been important in our organization to be able to do so much work in in openly is to spend time being thoughtful about that culture and to be thoughtful about how do we set the conditions for the work to be successful (View Highlight)\n\n\none of the key elements of that culture that has been really important is this one it’s pretty simple we start every project with the intent to open source the work (View Highlight)\n\n\nI think red teaming and other techniques of auditing have historically been ways in which we can provide better public understanding of limitations they don’t necessarily in and of themselves translate into responsible development because they are not necessarily fully integrated into the development pipeline (View Highlight)\n\n\nthere are times where you have technology systems um that are kind of poorly constructed from a responsibility standpoint and a governance standpoint because there’s no\nreal owner of like who’s accountable (View Highlight)\n\n\nI think the right way to think about llms is that they are virtual machines um and tokens are their machine code basically I think we often think about llms as sort of information processing entities or even as chat Bots fundamentally but but they’re not they are they are systems that have a state associated with them tokens change their\nstate and if they in their outputs can cause real effects if you start tying these things to uh invoice payments or emails or even more things like automated control of of large systems this I think genuinely gets a bit a bit concerning (View Highlight)\n\n\nbut I think that by setting strong Community Norms around acceptable and unacceptable uses especially in places that are you know like like um like Hugging Facebook Luther area that are our community hubs and places where people come together to talk about technology you can have a a really strong mitigating effect on a lot of these things (View Highlight)\n"},"highlights/Readwise/32477854":{"title":"32477854","links":[],"tags":[],"content":"Highlights\n\nReST uses a sampling approach to create an improved dataset, iteratively training on increasingly higher-quality subsets to refine its reward function. (View Highlight)\n\n\nMoreover, this paper found that none of the curriculum methods outperformed solely using Adam with well-selected hyperparameters. (View Highlight)\n"},"highlights/Readwise/32554785":{"title":"Are Older People Less Innovative?","links":[],"tags":[],"content":"Highlights\n\nFluid intelligence refers to the ability to solve problems in novel situations without using prior knowledge. It’s characterised by adaptability and the capacity to learn new concepts quickly. It involves skills like abstract reasoning, pattern recognition, and drawing inferences. Fluid intelligence typically declines with age, starting in early adulthood and continuing as people grow older. (View Highlight)\n\n\nCrystallised intelligence on the other hand is this aspect of intelligence that pertains to the knowledge and information that a person has acquired throughout their life. It involves skills such as vocabulary, general knowledge, and expertise in specific domains. It tends to increase with age since individuals accumulate more experiences, learn new information, and refine their expertise in various areas. (View Highlight)\n\n\nEfficiency innovations focus on improving processes and operations within an organisation. (View Highlight)\n\n\nSustaining innovation aims to improve existing products or services within established markets. (View Highlight)\n\n\nDisruptive innovation refers to the introduction of a new product or service that initially targets underserved or non-existent markets. (View Highlight)\n"},"highlights/Readwise/32622408":{"title":"32622408","links":[],"tags":[],"content":"Highlights\n\nUnfortunately, the last decade has seen a steep drop in adult friendships. Modern life encourages us, writes editor and journalist Catherine Woodiwiss, to atomize ourselves away from each other:\n\n“We seem to be doing life backward: We live alone and expend effort to gather together, as if that’s the healthy baseline; instead of starting with togetherness as the foundation, and striking out for aloneness when we need it.”\nIndeed, the rise of hyperindividualism has fragmented our connections, scattering our relationships across the country. Even today’s modern self-care trends turn us inward, convincing us to “hyperfocus on ourselves at the expense of connecting with others.” (View Highlight)\n\n\n\nYet our friendships today have taken a backseat to marriage, career, and more. While technology has made it easier than ever to maintain bonds across geographic distances, ease can’t replace depth. (View Highlight)\n"},"highlights/Readwise/32659670":{"title":"32659670","links":[],"tags":[],"content":"Highlights\n\nMy biggest issue with the Mistral release is that safety was not evaluated or even mentioned in their public comms. They either did not run any safety evals, or decided not to release them. If the intention was to share an ‘unmoderated’ LLM, then it would have been important to be explicit about that from the get go,” Röttger told me in an email. “As a well-funded org releasing a big model that is likely to be widely-used, I think they have a responsibility to be open about safety, or lack thereof. Especially because they are framing their model as an alternative to Llama2, where safety was a key design principle.” (View Highlight)\n"},"highlights/Readwise/32659821":{"title":"32659821","links":[],"tags":[],"content":"Highlights\n\nIt’s exactly because of these grey areas that I whole-heartedly support the authors’ conclusion: “open” is not a magic bullet to the heart of power. We should all scream from the mountaintops that “open” can centralize power, either unintentionally or as an explicit strategic goal. They are also correct that we need to be particularly concerned about the relationship of open and power at a time when the means of technological production are firmly centralized. In other words: we can’t just say “open is good”—at least along the dimension of societal and industrial power, open can and will be used and abused by those who seek to control the rest of us. (View Highlight)\n"},"highlights/Readwise/32664723":{"title":"32664723","links":[],"tags":[],"content":"Highlights\n\nInstead passions, like interests, are developed. They often begin with a spark of curiosity caused by something in one’s environment, such as a fascinating physics lecture or a moving piece of art. Through a process involving repeated engagement, positive experiences and accrued knowledge, people can come to personally value that content or activity and internalize it. What was at first interesting becomes an interest. If these qualities continue to intensify, a passion can emerge. (View Highlight)\n\n\nIf people believe they are limited to only a few inherent interests and, in consequence, do not explore other areas, they may miss seeing important connections across different domains. When (View Highlight)\n\n\nThe old saying “find something you love to do, and you’ll never have to work a day in your life” needs to be updated. The science tells us we should instead work toward loving what we do. We might expand our horizons and become more creative and resilient as a result. (View Highlight)\n"},"highlights/Readwise/32782586":{"title":"32782586","links":[],"tags":[],"content":"Highlights\n\nCost per use accounts for longevity. Durable and repairable things may cost more upfront, but over time they cost less than things that break and need to be replaced. (View Highlight)\n\n\nThese are some of the questions I ask of the things that I incorporate into my life:\n• Will it be as useful to me in the future as it is now?\n• Is it made of durable and maintainable materials?\n• Does it have a timeless style and aesthetic?\n• Does it age well, wear well, build a wabi-sabi patina?\n• Does it retain its resale value? Would someone else want to own it?\n• Can it be disassembled and repaired?\n• Does it have replaceable, non-proprietary parts that are easy to acquire?\n• Can it be powered with a standard plug or replaceable batteries?\n• Can it be modified and upgraded?\n• Has the maker existed for at least as long as I hope to keep the product?\n• Can it perform many jobs, or only one?\n• Does it have a guarantee?\n• Does it rely on other products or technologies that aren’t durable? (View Highlight)\n\n\nThere is an opportunity cost to every dollar. A dollar you spend on a something that won’t get much use is a dollar you can’t save for something that will. (View Highlight)\n\n\nSome things have excellent cost per use but few smiles per use. I don’t smile every time I put my nice socks on. A few years ago I bought a fairly expensive electric road bike. It probably didn’t have the best cost per use, but it gives me the most joy per use of any product I purchased in recent memory. It’s worth it to me. (View Highlight)\n\n\nSome purchases may have externalities that are incompatible with your values. For example, you may wish to buy organic produce, pasture-raised eggs, or fair trade coffee. You may wish to buy products that preserve privacy, reduce environmental impact, or support a cause you believe in. (View Highlight)\n"},"highlights/Readwise/32837724":{"title":"32837724","links":[],"tags":[],"content":"Highlights\n\n\nAnd so the goal stays the same because you recognize that there is value in meeting that goal. And you still have to do your best to get there.\nShe’s making two good points. First, with climate change, every tenth of a degree matters. The lower we end up, the better. And second, if you want to achieve something big, you start with an ambitious goal. (View Highlight)\n\n"},"highlights/Readwise/32882195":{"title":"32882195","links":[],"tags":[],"content":"Highlights\n\nThere’s money to be made. X’s new incentive structure has turned the site into a hive of so-called engagement farming — posts designed with the sole intent to elicit literally any kind of response: laughter, sadness, fear. Or the best one: hate. Hate is what truly juices the numbers. (View Highlight)\n"},"highlights/Readwise/32882444":{"title":"32882444","links":[],"tags":[],"content":"Highlights\n\nThe whole point of models is to be able to use them downstream for other purposes, e,g, in robotics, navigation, computer graphics, and so on. Models that can’t be used downstream are scarcely worthy of the name, and are in no position to solve the reliability problems that plague current AI. (View Highlight)\n\n\nYes, Google Search accounting might sometimes get things right, because the ways that people use language on the web correlates to some degree the world. But doesn’t mean you can rely on the variable number of Google hits as a physical model of the world. It will work for some things but not others. If you want trustworthy AI, this ain’t it. (View Highlight)\n\n\nIt’s the same problem: correlations are fragile, and you can’t count on them. (View Highlight)\n\n\nWithout flexible underlying models that can reliably support inferences on novel questions, we can expect more of the same of what we are seeing over and over now: more hallucinations, more reasoning that is hit or miss, and nothing like the stability we should insist on for future AI. (View Highlight)\n"},"highlights/Readwise/32981785":{"title":"32981785","links":[],"tags":[],"content":"Highlights\n\nGoogle 内部甚至专门有个认证就叫作 Readability。只有拿到这个认证的工程师，才有资格在 code review 的时候，批准别人提交代码。可见代码的可读性有多重要，毕竟，代码被阅读的次数远远超过被编写和执行的次数。 (View Highlight)\n\n\n实际上，code review 是一个很好的测验代码可读性的手段。如果你的同事可以轻松地读懂你写的代码，那说明你的代码可读性很好；如果同事在读你的代码时，有很多疑问，那就说明你的代码可读性有待提高了。 (View Highlight)\n"},"highlights/Readwise/33177165":{"title":"33177165","links":[],"tags":[],"content":"Highlights\n\nIt’s a race to the bottom. Companies see their idiot friends creating AI and they want a piece of that hype hype yum yum so they do it too (View Highlight)\n"},"highlights/Readwise/33185952":{"title":"33185952","links":[],"tags":[],"content":"Highlights\n\nIn place of fundamental social changes, the computer allows technical solutions to be proposed that would allow existing power hierarchies to remain intact. (View Highlight)\n\n\nWeizenbaum insisted on crucial differences between humans and machines, arguing that there are certain domains that involve interpersonal connection, respect, affection, and understanding into which computers ought not to intrude, regardless of whether it appears they can (View Highlight)\n\n\nEven to ask the question, he argues, of “whether a computer has captured the essence of human reason is a diversion, if not a trap, because the real question — do humans understand the essence of humans? — cannot be answered or resolved by technology.” (View Highlight)\n\n\nAs the AI project progressed, it has gradually become less about simulating the human mind and more about creating a financial empire (View Highlight)\n\n\nToday, the rhetorical pattern that Weizenbaum decried looks like this among AI’s current boosters: A machine learning model is put forward as doing something better than humans can or offering a computational shortcut to a complex challenge. It receives unprecedented praise and coverage from technologists and journalists alike. Then critics will begin to call attention to flaws, gross simplification, inaccuracies, methodological problems, or limitations of the data sets. (View Highlight)\n\n\nAny notice of the limits of technological solutions is followed by a “plea for generous societal support for more, and large-scale, computer research development.” (View Highlight)\n"},"highlights/Readwise/33687324":{"title":"33687324","links":[],"tags":[],"content":"Highlights\n\nIt’s that it can’t separate the world from the statistics of its dataset. DALL-E does not have a cognitive construct of a doctor or a patient or a human being or an occupation or medicine or race or egalitarianism or equal opportunity or any of that. If there happens not to be a lot of black doctors with white patients in the dataset, the system is SOL. (View Highlight)\n"},"highlights/Readwise/33687387":{"title":"33687387","links":[],"tags":[],"content":"Highlights\n\nThe sheer emptiness seems to prompt the mind better than just closing my eyes and thinking. And the slight discomfort of staring at a wall for twenty minutes provides just enough sensation to anchor you to the present. It’s the perfect nudge to keep you grounded in the moment. (View Highlight)\n"},"highlights/Readwise/33687604":{"title":"33687604","links":[],"tags":[],"content":"Highlights\n\nIn expert tennis, about 80 per cent of the points are won; in amateur tennis, about 80 per cent of the points are lost. In other words, professional tennis is a Winner’s Game – the final outcome is determined by the activities of the winner – and amateur tennis is a Loser’s Game – the final outcome is determined by the activities of the loser. The two games are, in their fundamental characteristic, not at all the same. They are opposites. (View Highlight)\n\n\nThis is a problem because we’re often playing the game of the professionals. What we should do in this case, when we’re the amateur, is to invert the problem. Rather than trying to win, we should avoid losing. (View Highlight)\n"},"highlights/Readwise/33687654":{"title":"33687654","links":[],"tags":[],"content":"Highlights\n\nBut we end up doom scrolling ourselves into oblivion, saving these links in a digital vault where they’ll most likely be forgotten forever, never to be seen again.\nWe are crippled by the opportunity cost. Burdened with the lament of the possible missed opportunities or benefits associated with the unchosen option. (View Highlight)\n"},"highlights/Readwise/33687820":{"title":"33687820","links":[],"tags":[],"content":"Highlights\n\nBut in many practical problems, working practitioners don’t; they use a wide range of other methods, often far more tractable, far more reliable, and far more efficient. Transformers and generative AI are getting a lot of attention, and have considerable utility, but they are nothing like the all purpose tools some people seems to imagine them to be.  In AI, no single technique is likely to be a silver bullet, now or ever. (View Highlight)\n"},"highlights/Readwise/33688003":{"title":"33688003","links":[],"tags":[],"content":"Highlights\n\nThe context of one’s life defines not just what but how one thinks, and a job tends to dominate the context of one’s life — particularly when that job is considered to be part of a career. Your job will change you. (View Highlight)\n\n\nThings that are treyf, you avoid, not because you hate them per se, but because in avoiding them you keep yourself from becoming like the people you hate.\n– Aaron Cometbus, “Cometbus #54” (View Highlight)\n\n\nThose seats are treyf for me, not because I don’t envy extra leg room, but because I don’t envy the people sitting in them. There’s a reason the bulk of the first class passengers resemble each other, just as there’s a reason prison guards tend to act the same. I know that by making choices designed to land me in the first class cabin, it would be difficult to avoid also inheriting the dreariness associated with its current occupants. (View Highlight)\n"},"highlights/Readwise/33688558":{"title":"33688558","links":[],"tags":[],"content":"Highlights\n\nFrankly, there’s no better description of the “techno-optimist” crowd—a gaggle of out-of-touch tech bros who think their wealth gives them license to chart a future nobody else wants. (View Highlight)\n"},"highlights/Readwise/33703236":{"title":"33703236","links":[],"tags":[],"content":"Highlights\n\nThat is not engineering. That’s just lazy programming. Engineering is understanding performance, structure, limits of what you build, deeply. Combining poorly written stuff with more poorly written stuff goes strictly against that. To progress, we need to understand what and why are we doing. (View Highlight)\n"},"highlights/Readwise/33716870":{"title":"33716870","links":[],"tags":[],"content":"Highlights\n\nOn that note, in the satirical Pretraining on the Test Set Is All You Need paper, the author trains a small 1M parameter LLM that outperforms all other models, including the 1.3B phi-1.5 model. This is achieved by training the model on all downstream academic benchmarks. It appears to be a subtle criticism underlining how easily benchmarks can be “cheated” intentionally or unintentionally (due to data contamination). (View Highlight)\n"},"highlights/Readwise/33743630":{"title":"33743630","links":[],"tags":[],"content":"Highlights\n\nNelson, who teaches at U.C. Berkeley, said. Researchers could measure dozens of variables and perform reams of analyses, then publish only the correlations that happened to appear “significant.” If you tortured the data long enough, as one grim joke went, it would confess to anything. They called such techniques “p-hacking.” As they later put it, “Everyone knew it was wrong, but they thought it was wrong the way it’s wrong to jaywalk.” In fact, they wrote, “it was wrong the way it’s wrong to rob a bank.” (View Highlight)\n\n\nOne of the confounding things about the social sciences is that observational evidence can produce only correlations. To what extent is dishonesty a matter of character, and to what extent a matter of situation? Research misconduct is sometimes explained away by incentives—the publishing requirements for the job market, or the acclaim that can lead to consulting fees and Davos appearances. As one senior faculty member told me, of bridging the academic and corporate worlds, “You see what the money can buy you, you fly business class on work trips. It tickles you in that little place, and you need to have more of it.” The difference between p-hacking and fraud is one of degree. And once it becomes customary within a field to inflate results, the field selects for researchers inclined to do so. (View Highlight)\n"},"highlights/Readwise/33859112":{"title":"33859112","links":[],"tags":[],"content":"Highlights\n\nKeeping productivity as an individual obligation, and focussing only on offering increasingly powerful tools, didn’t lead to a more efficient and relaxing workday, but instead enabled us to take on even more tasks, pursued with even more frantic intensity. (View Highlight)\n"},"highlights/Readwise/33921768":{"title":"33921768","links":[],"tags":[],"content":"Highlights\n\nScientists are incentivized to, and often do, withhold as much information as possible about their innovations in their publications to maintain a monopoly over future innovations. This slows the overall progress of science.\nFor example, a chemist who synthesizes a new molecule will publish that they have done so in order to be rewarded for their work with a publication. But in the publication they will describe their synthesis method in as minimal detail as they can while still making it through peer review. This forces other scientists to invest time and effort to reproduce their work, giving them a head-start in developing the next, better synthesis. (View Highlight)\n\n\nMany published papers have methodical or statistical errors, are derivative and don’t add anything to the discourse, are misleading or obfuscated, sometimes even fraudulent or were just bad research to begin with. (View Highlight)\n\n\nResearch contexts are so multiplicitous that every compiled report or visualization has huge amounts of noise and no user interface ever can be expressive enough to perfectly parameterize that context. (View Highlight)\n\n\nWhat’s the value of getting a topic hierarchy, causal diagram or paper recommendations? It has some value if the user does not already have an operational model in his head but how often is that the case? Most biotech research jobs require a PhD level schema from the get go, so what’s the added value to a noisy AI-generated one? (View Highlight)\n"},"highlights/Readwise/33964013":{"title":"33964013","links":[],"tags":[],"content":"Highlights\n\nMixing few-shot settings. Training with mixed zero-shot and few-shot prompts significantly improves performance in both settings. (View Highlight)\n\n\nTask diversity. Large models benefit from continuously increasing the number of tasks. (View Highlight)\n"},"highlights/Readwise/33964043":{"title":"33964043","links":[],"tags":[],"content":"Highlights\n\nSimply put, the sympathetic nervous system activates the “fight or flight” response during a threat or perceived danger, while the parasympathetic nervous system controls the “rest and digest” or “feed and breed” functions of the body. Our findings show that this system, too, responds to cognitive demands, and this suggests that cognitive effort reverberates through the physiological system in more ways than previously thought. (View Highlight)\n"},"highlights/Readwise/34014417":{"title":"34014417","links":[],"tags":[],"content":"Highlights\n\nPeople have prejudices that only smart and competent people work in the IT industry. Especially the software development branch. But this is far from the truth. (View Highlight)\n\n\nThere are recurring meetings scheduled on a daily or weekly basis. Most of these are not productive. The majority of them are forced by a person who is organizing them because that’s the only “work” that that person is doing.\nIt’s just an empty protocol to prove their purpose of existence in the company. (View Highlight)\n"},"highlights/Readwise/34205182":{"title":"34205182","links":[],"tags":[],"content":"Highlights\n\nScience has shown that when you combine meditation with exercise, your brain improves its plasticity.6\nThis helps rewire your brain in a positive way. In fact, when you maintain a level of exercise while learning a new skill, your enhanced brain is likely going to learn at an improved pace. (View Highlight)\n"},"highlights/Readwise/34276321":{"title":"34276321","links":[],"tags":[],"content":"Highlights\n\nThat’s the real definition of risk—what’s left over after you’ve prepared for the risks you can imagine.\nRisk is what you don’t see.\n\n\nOne, think of risk the way the State of California thinks of earthquakes. It knows a major earthquake will happen. But it has no idea when, where, or of what magnitude. Emergency crews are prepared despite no specific forecast. Buildings are designed to withstand earthquakes that may not occur for a century or more. Nassim Taleb says, “Invest in preparedness, not in prediction.” That gets to the heart of it.\n\n\nJohn D. Rockefeller never had penicillin, sunscreen, or Advil. But you can’t say a low-income American with Advil and sunscreen today should feel better off than Rockefeller, because that’s not how people’s heads work. People gauge their well-being relative to those around them, and luxuries become necessities in a remarkably short period of time when the people around you become better off.\n\n\nThere is no such thing as objective wealth—everything is relative, and mostly relative to those around you. It’s the path of least resistance to determining what life owes you and what you should expect. Everyone does it. Subconsciously or not, everyone looks around and says, “What do other people like me have? What do they do? Because that’s what I should have and do as well.”\n\n\nPsychologist Jonathan Haidt says people don’t really communicate on social media so much as they perform for one another.\n\n\nToday’s economy is good at generating three things: wealth, the ability to show off wealth, and great envy for other people’s wealth.\n\n\nPeter Kaufman, CEO of Glenair and one of the smartest people you will ever come across, once wrote:\nWe tend to take every precaution to safeguard our material possessions because we know what they cost. But at the same time we neglect things which are much more precious because they don’t come with price tags attached: The real value of things like our eyesight or relationships or freedom can be hidden to us, because money is not changing hands.\n\n\nSame with expectations—they’re easy to ignore because their value isn’t on a price tag.\n\n\nThe key thing is that unique minds have to be accepted as a full package, because the things they do well and that we admire cannot be separated from the things we wouldn’t want for ourselves or we look down upon.\n\n\nPart of the reason it happens is because the same personality traits that push people to the top also increase the odds of pushing them over the edge.\n\n\nProbability is about nuance and gradation. But in the real world people pay attention to black-and-white results.\n\n\nThe core here is that people think they want an accurate view of the future, but what they really crave is certainty.\n\n\n• Bad news gets more attention than good news because pessimism is seductive and feels more urgent than optimism.\n• The odds of a bad news story—a fraud, a corruption, a disaster—occurring in your local town at any given moment is low. When you expand your attention nationally, the odds increase. When they expand globally, the odds of something terrible happening in any given moment are 100 percent.\n\n\nProfessor Philip Tetlock has spent most of his career studying experts, self-proclaimed or otherwise. A big takeaway from his research is how awful so many experts are at predicting politics and the economy. Given that track record, will people ever choose to ignore the experts? “No way,” Tetlock once said. “We need to believe we live in a predictable, controllable world, so we turn to authoritative-sounding people who promise to satisfy that need.”\n\n\nIf you have the right answer, you may or may not get ahead.\nIf you have the wrong answer but you’re a good storyteller, you’ll probably get ahead (for a while).\nIf you have the right answer and you’re a good storyteller, you’ll almost certainly get ahead.\n\n\n\nIn a perfect world, the importance of information wouldn’t rely on its author’s eloquence. But we live in a world where people are bored, impatient, emotional, and need complicated things distilled into easy-to-grasp scenes.\n\n\nSome things are immeasurably important. They’re either impossible, or too elusive, to quantify. But they can make all the difference in the world, often because their lack of quantification causes people to discount their relevance or even deny their existence.\n\n\nDid a lack of pandemics over the last fifty years make the world more vulnerable to COVID-19? Did the decline of infectious disease death make us underestimate the odds that it could happen in modern times?\n\n\nThe irony of good times is that they breed complacency and skepticism of warnings.\n\n\nFast growth leads to soft, airy wood that never had time to densify. And soft, airy wood is a breeding ground for fungus and disease. “A tree that grows quickly rots quickly and therefore never has a chance to grow old,” forester Peter Wohlleben wrote. Haste makes waste.\n\n\nYou cannot compare the incentives of Silicon Valley coders trying to get you to click on ads to Manhattan Project physicists trying to end a war that threatened the country’s existence. You can’t even compare their capabilities.\n"},"highlights/Readwise/34276322":{"title":"34276322","links":[],"tags":[],"content":"Highlights\n\nTechnology isn’t the problem. Stop thinking about what technology does and start thinking about who technology does it to and who it does it for.\n\n\nBut network effects are merely how Big Tech gets big. Switching costs are how Big Tech stays big.\n\n\nWhen switching costs are high enough, people will keep using products and services even though they hate those products and services. So long as the pain of staying is less than the pain of leaving, users stay.\n\n\nThe corollary: the lower the switching costs are, the better a company has to treat you if they want to keep your business.\n\n\nInteroperability lowers switching costs. Interoperability allows us, the users of technology, to set the terms on which we use that technology. It allows us to use the parts of products and services that benefit us, and block the parts that don’t.\n\n\nThe idea that tech itself can’t be racist because computers are just doing math, and math can’t be racist? Utter exceptionalism.\n\n\nIn arguing for his bill, Sherman said to the Senate: “If we will not endure a King as a political power we should not endure a King over the production, transportation, and sale of the necessaries of life. If we would not submit to an emperor we should not submit to an autocrat of trade with power to prevent competition and to fix the price of any commodity.”\n\n\nBut “consumer” is only one of our aspects in society. We are also “workers,” “parents,” “residents” and, not least, “citizens.” If our cheaper products come at the expense of our living wage, or the viability of our neighborhoods, or the democratically accountable authority of our elected representatives, have we really come out ahead?\n\n\nBut all of this comes at a price: the rise of “autocrats of trade”: unelected princelings whose unaccountable whims dictate how we live, work, learn and play. Apple’s moderators decide which apps you can use, and if they decline to list an educational game about sweatshop labor or an app that notifies you when a US drone kills a civilian overseas, well, that’s that.\n\n\nMicrosoft, Airbnb, Uber, LinkedIn … the largest tech firms structure our lives in myriad ways, without regard to our well-being, without fear of competition and largely without regulation (for now).\n\n\nThey’re different for two reasons: first, because they control the means of computation. These companies rule our digital world, the place where we find one another, form communities and mobilize in solidarity to take collective action.\n\n\nThis is what “software is eating the world” really means: the positive externalities of computer improvements set up a virtuous cycle where improvements begat partisans for still more improvements, which created still more partisans.\n\n\nTech is the terrain on which our future fights will be fought. If we can’t seize the means of computation, we will lose the fight before it is even joined.\n\n\nrather, they’re dedicated to ensuring that leaving Facebook behind is so punishing and unpleasant that people stay, even if they hate Facebook.\n\n\nDigital technology was sold to us as an infinitely customizable, responsive, idiosyncratic new way of living. Networked tools were supposed to give us more control over our lives. Instead, we find ourselves manipulated, controlled, corralled and milked dry.\n\n\nWithout the right to quote—and thus critique—the news, we’re at the mercy of fallible reporters and their fallible editors.\n\n\nEvery time we deputize tech companies with government-like enforcement duties, we make it that much harder to cut them down to size (because they need to be big to fulfill those duties) and that much harder for smaller tech to offer better, more user-centric services (because small tech companies, startups, co-ops, nonprofits and individual tinkerers can’t afford to comply with the regulations that force them to police their users’ conduct).\n\n\nThe real problem is that job should not exist. No one should hold that much power. We don’t need a better Zuck. We need to abolish Zuck.\n\n\nWe have to pick one: either we cut tech companies down to size, or we hold them accountable for their users’ actions.\n\n\nBeyond cooperative interoperability, there is also indifferent interoperability. That’s when someone makes a new product that plugs into an existing one that was not designed with the new product in mind, but which was also not designed to prevent this from happening.\n\n\nThose who would defeat these locks have the “attacker’s advantage.” For a system like a VIN lock to work, its authors must write code with no errors. For the system to be defeated, their adversaries need only find a single error and exploit it. Defenders need to be perfect, while attackers do not.\n\n\nWorse: even if the big company’s engineers manage to repel the invaders, that does nothing to stop the next wave of would-be interoperators from challenging them anew.\n\n\nIn other words, a legal victory is far more devastating than a mere technical one.\n\n\nVenture capitalists call the products and services adjacent to the Big Tech firms’ core technology “the kill zone” and will not invest in any company that proposes to pitch its tent in that dead place.\n\n\nThe aerospace engineers who sat down to design those solid rocket boosters had a lot of parameters to juggle—the pull of gravity, the efficiency of rocket fuel, the weight of the payload. But mixed in with those parameters, immutable and inarguable was the width of a railcar, which was foreordained by the width of the Roman chariot wheelbase, which was, in turn, determined by the metalbeating know-how of Roman blacksmiths.\n\n\nInfrastructure casts a long shadow.\n\n\nHow can we tell when Facebook shuts down a competitor out of an abundance of well-founded caution, and when Facebook shuts down that competitor in order to make it less useful and thus less attractive to Facebook users who had been contemplating a disloyal defection from Facebook to a new company?\n\n\nIt’s hard enough to even understand the underlying technical questions, but when the arguments themselves are long, tedious, technical and highly abstract, you can get away with nearly anything.\n\n\ncopyright or a patent is, fundamentally, a license to sue others who duplicate your products. That license is dangled before inventors and creators, as a carrot to tempt them to set aside their other pressing needs and devote themselves to invention and creation\n\n\nEconomists call this a “collective action problem” and it’s a specific kind of switching cost: to switch away from Facebook you must either figure out how to convince everyone you talk to on Facebook to switch with you (a high cost) or forfeit your relationship with them (also a high cost).\n\n\nThe problem isn’t merely that Facebook and other large systems underinvest in moderation and are indifferent to the harms experienced by the users of their services—it’s also that no amount of investment and no amount of caring would actually solve the problem of dedicated trolls, griefers and harassers. Moderate a lot or a little, be specific or general, it doesn’t matter—the trolls will win.\n\n\n’m not saying that communities that moderate themselves will always get it right. I’m saying that communities moderated by distant, unaccountable moderators will never get it right—and that communities that moderate themselves have a chance of getting it right\n\n\nAll of these companies make the same claims as Sega: we’re not locking you in, we’re locking the bad guys out. The 30 percent take we cream off of every purchase you make isn’t rent-seeking—it’s cost-recovery, a modest commission that lets us pay our expert curators to ensure that the apps in our app store are high-quality, safe and secure.\n\n\nThe protection they extend is purely selfish: they protect us to the extent that doing so helps them maximize the revenues they earn from us.\n\n\nBut it’s an objection that should be framed as a question, not a statement: instead of stating “regulators are too clueless to regulate tech,” we should be asking “why are regulators so clueless when it comes to regulating tech?”\n\n\nRegulators can’t regulate tech because they’re clueless, sure. But why are they clueless? Because the process by which regulators and lawmakers understand issues starts from the presumption that there will be an adversarial process and a neutral referee, and monopolies turn that into a chummy backroom deal between a handful of executives from the industry and a handful of their former colleagues who are temporarily regulating their former colleagues.\n\n\nIt shows how expert, empirical findings feed into political choices, and it shows how monopolies can mobilize their profits, converting them into political power and using that to block good policymaking in favor of policies that help their shareholders and hurt the public.\n\n\nFeudal security fails badly. If a company decides to betray your trust and invade your privacy, the security experts won’t defend you from their own employers—instead, they’ll turn on interoperators who step in to defend you.\n\n\nCompanies can defend our privacy, and they often do, but when they choose not to—because they value something else more highly, or because they change corporate strategy—then you have no recourse but to leave. And where companies have used lock-in strategies to punish you for leaving, you might choose to give up your privacy rather than endure the switching costs they’ve engineered into the system.\n\n\nWhen a platform corrals everyone important to you, you’re going to stay on that platform, even if the platform is badly run.\n\n\nTech monopolies are epiphenomena: they are effects, not causes. They are the effect of an ideology that embraces monopolies and inequality as a natural, even inevitable phenomenon. It’s an ideology that lionizes monopolists as once-in-a-generation geniuses who deserve the power to structure the daily routines and constraints of billions of their fellow humans.\n\n\n\nBut these companies aren’t courts, they don’t have anything like a due process system—and yet, they can dole out penalties that go beyond anything that a court would impose. Even if a judge sends you to prison, the state won’t incinerate all your family photos, all your correspondence and every personal file you have. It won’t cut you off from every other account you have.\n\n\n\nthe 600-plus years since, Nihil novi nisi commune consensu has given way to a catchier slogan: “Nothing about us without us.” The modern term began in the disability rights community, where it meant that decisions about how to accommodate disabilities should involve people with disabilities. The slogan was also taken up by Indigenous activists, who used it in opposition to a half-millennium’s worth of paternalistic—and genocidal—policies that treated First Nations people as children at best and livestock at worst.\n\n\nWestern tech design teams are typically composed of well-off people with fancy degrees from excellent technical universities. There are a smattering of people from the Global South who win scholarships to those schools, get work visas, land jobs at tech giants and find their way onto product design teams, but they are a minority of a minority.\n\n\nTechnology design choices are made in high-income nations with stable governments, at least the pretense of the rule of law, and reliable electricity and internet access, and then they’re shipped to the Global South where those design decisions utterly fail.\n\n\nThe Global South labors under a dual imposition: they are coerced into passing tech laws that are friendly to US corporations, and then those same corporations make unilateral product design decisions that do not account for local circumstances and, thanks to those laws, can’t be modified by their Global South users.\n\n"},"highlights/Readwise/34276323":{"title":"34276323","links":[],"tags":[],"content":"Highlights\n\nBy controlling our perceptions, the Stoics tell us, we can find mental clarity. In directing our actions properly and justly, we’ll be effective. In utilizing and aligning our will, we will find the wisdom and perspective to deal with anything the world puts before us.\n\n\nThe single most important practice in Stoic philosophy is differentiating between what we can change and what we can’t. What we have influence over and what we do not.\n"},"highlights/Readwise/34289457":{"title":"34289457","links":[],"tags":[],"content":"Highlights\n\nThe fact that the governance of one of the most visible AI companies in the world can change literally overnight should be a reminder that we can’t make our judgements about a company’s trustworthiness based simply on a vibe about their CEO. (View Highlight)\n"},"highlights/Readwise/34333016":{"title":"34333016","links":[],"tags":[],"content":"Highlights\n\nthe tough one is the second category it’s emotional distractors our emotional distractors\nare extremely powerful they’re thoughts about that conversation that didn’t go so well the Tiff’s I had with my partner this morning the mostly relationship concerns things that have upset us (View Highlight)\n\n\nthe point is that the more\ndisrupted attention is particularly for young people the harder it is for them to grasp to build the cumulative mental models that amount to mastery (View Highlight)\n\n\nwhen you feel overwhelmed you’re down here and the stress hormones at their highest you’re in a state which was called recently in the scientific journal action of the journal Science in an article was called the neurobiology of frazzle I don’t know if you’re familiar with frazzle I’ve\nbeen there many times it’s constant stress and here the problem is you can’t stop thinking about what’s upsetting you what’s stressing you you’re not focusing here you’re not focusing on the task at hand you’re focusing on what’s upsetting you and that’s the power of emotions (View Highlight)\n"},"highlights/Readwise/34375849":{"title":"34375849","links":[],"tags":[],"content":"Highlights\n\nMost people are slow to start anything. Because our society is trained and wired for consumption, most people spend their morning consuming things on their phone. Because of this, they never get into a “FLOW” state during their day. Most people are so trapped in consumption they’re dependent upon it just to get going in the morning. (View Highlight)\n\n\no you want to train your brain to be fast, in a flow state? Here’s how:\n• Wake up\n• Get out of bed\n• Make your bed\n• Get hydrated\n• Move on to your #1 task AS QUICKLY AS POSSIBLE\nWhen I say your #1 task, I mean important work that can change your life. Train your brain that you are capable of doing that task first. Because you are! (View Highlight)\n\n\nMost people are suffering from what psychologists call a low-level default future where they don’t have a big vision or high expectations for their life.\nMost people are consuming information, food, and even people and experiences that have created a low-level worldview and identity for themselves.\nLow-level becomes the standard for your brain when that’s what you feed it on a repetitive, daily basis.\nYour brain is a prediction machine. It will take what you give it.\nYour identity will perform with what it has to work with — what you give it. You cannot outperform your identity. (View Highlight)\n\n\nMost people’s vision of their future self is basically getting to the next paycheck or getting to the next weekend. They don’t have clarity on who their future self is, and they certainly don’t have a massive and compelling future self.\nThey don’t have what entrepreneur and founder of XPrize Peter Diamandis would call a Massive Transformative Purpose, or MTP.\n\n“Your Massive Transformative Purpose (MTP) is a clear statement that guides, empowers, and inspires you. It helps you decide what to do, and more importantly what not to do. It’s both your fuel and your filter.” — Peter Diamandis (View Highlight)\n\n\n\nUnfortunately, most people have a 2x vision, even though this is psychologically destructive. In psychology this is actually known as the “default” future. There’s a lot of research showing that because people have a 2x vision, they underestimate who their future self will be. Most 18-year-olds don’t think they’re going to transform that much, despite most older people being in a dramatically different situation than when they were 18. Because of the “end of history illusion” made popular by Dr. Daniel Gilbert, most people think who they’ve always been is who they’re always going to be. (View Highlight)\n\n\nYour 80% is your security blanket.\nIn fact, in psychology there’s a name for this called “prospect theory,” which asserts that people would rather have a smaller reward with certainty rather than a larger reward with uncertainty.\n\n“People tend to overweigh options that are certain, and are risk averse for gains. We would rather get an assured, lesser win than take the chance at winning more (but also risk possibly getting nothing). The opposite is true when dealing with certain losses: people engage in risk-seeking behavior to avoid a bigger loss.” — Aurora Harley (View Highlight)\n\n\n\nThe challenge most people have as soon as they start becoming successful is that they’re no longer operating out of need, and they don’t know how to create a vision of what they want, because all they’ve ever done up until that point was from the perspective of need. (View Highlight)\n\n\nDeliberate practice is the art of having clear goals, and going through a training process that transforms yourself and your abilities around and towards those goals. The author of Atomic Habits, James Clear, actually clarified that he could have written a book on deliberate practice where he talks about habits, but instead he wrote a book on habits where he talks about deliberate practice. Because habits is a far more marketable and attractive subject, habits is the subject of the book title, but true deliberate practice is about getting 1% better each day whereas habits will get you 0% better each day.\nThe purpose of deliberate practice is to stop habitual rhythms and get better instead. (View Highlight)\nhave created a low-level worldview and identity for themselves.\nLow-level becomes the standard for your brain when that’s what you feed it on a repetitive, daily basis.\nYour brain is a prediction machine. It will take what you give it.\nYour identity will perform with what it has to work with — what you give it. You cannot outperform your identity. (View Highlight)\n\n\nMost people’s vision of their future self is basically getting to the next paycheck or getting to the next weekend. They don’t have clarity on who their future self is, and they certainly don’t have a massive and compelling future self.\nThey don’t have what entrepreneur and founder of XPrize Peter Diamandis would call a Massive Transformative Purpose, or MTP.\n\n“Your Massive Transformative Purpose (MTP) is a clear statement that guides, empowers, and inspires you. It helps you decide what to do, and more importantly what not to do. It’s both your fuel and your filter.” — Peter Diamandis (View Highlight)\n\n\n\nUnfortunately, most people have a 2x vision, even though this is psychologically destructive. In psychology this is actually known as the “default” future. There’s a lot of research showing that because people have a 2x vision, they underestimate who their future self will be. Most 18-year-olds don’t think they’re going to transform that much, despite most older people being in a dramatically different situation than when they were 18. Because of the “end of history illusion” made popular by Dr. Daniel Gilbert, most people think who they’ve always been is who they’re always going to be. (View Highlight)\n\n\nYour 80% is your security blanket.\nIn fact, in psychology there’s a name for this called “prospect theory,” which asserts that people would rather have a smaller reward with certainty rather than a larger reward with uncertainty.\n\n“People tend to overweigh options that are certain, and are risk averse for gains. We would rather get an assured, lesser win than take the chance at winning more (but also risk possibly getting nothing). The opposite is true when dealing with certain losses: people engage in risk-seeking behavior to avoid a bigger loss.” — Aurora Harley (View Highlight)\n\n\n\nThe challenge most people have as soon as they start becoming successful is that they’re no longer operating out of need, and they don’t know how to create a vision of what they want, because all they’ve ever done up until that point was from the perspective of need. (View Highlight)\n\n\nDeliberate practice is the art of having clear goals, and going through a training process that transforms yourself and your abilities around and towards those goals. The author of Atomic Habits, James Clear, actually clarified that he could have written a book on deliberate practice where he talks about habits, but instead he wrote a book on habits where he talks about deliberate practice. Because habits is a far more marketable and attractive subject, habits is the subject of the book title, but true deliberate practice is about getting 1% better each day whereas habits will get you 0% better each day.\nThe purpose of deliberate practice is to stop habitual rhythms and get better instead. (View Highlight)\n"},"highlights/Readwise/34561276":{"title":"34561276","links":[],"tags":[],"content":"Highlights\n\nAI definitely should not aspire to replicate the human mind in every detail. We already have 8 billion human minds, many pretty problematic; we shouldn’t aspire for more of the same.\nThe point of AI should not be to replicate us, but to supplement us, where we are cognitively frail (calculators are great at that! and spreadsheets! and databases!), and to pitch where we would prefer not to go, helping us, for example, with jobs that robotics call “dull, dirty, and dangerous”. (View Highlight)\n\n\nFor now, humans aren’t more intelligent than machines or vice versa, we are just differently abled. As Ali G once said in a different context, “neither is better”. (View Highlight)\n"},"highlights/Readwise/34610927":{"title":"34610927","links":[],"tags":[],"content":"Highlights\n\nWhy do we complain?\nIt’s an ego boost.\nWhen you complain about someone or something else being bad, negative, annoying, etc., you’re implicitly saying you’re good, smart, better, etc. And that feels good. At least in the moment.\nIn other words, chronic complaining or criticizing is usually a sign of low self-esteem: You feel bad about yourself and have gotten in the habit of using complaining as a way to temporarily inflate your ego and feel good about yourself.\nOf course, it’s a pretty flimsy strategy, which is why in the long run it only hurts your self-esteem and leads to feeling guilty and ashamed. (View Highlight)\n"},"highlights/Readwise/34772815":{"title":"34772815","links":[],"tags":[],"content":"Highlights\n\nReasoning as though chatbots had human-like mental lives is a useful way of coping with their linguistic virtuosity, but it should not be used as a theory about how they work (View Highlight)\n\n\nTo avoid this kind of mistake, we must repudiate the assumption that the psychological properties that explain the human capacity for language are the same properties that explain the performance of language models. That assumption renders us gullible and blinds us to the potentially radical differences between the way humans and language models work. (View Highlight)\n\n\nAnother pitfall when thinking about language models is anthropocentric chauvinism, or the assumption that the human mind is the gold standard by which all psychological phenomena must be measured. Anthropocentric chauvinism permeates many skeptical claims about language models, such as the claim that these models cannot “truly” think or understand language because they lack hallmarks of human psychology like consciousness. This stance is antithetical to anthropomorphism, but equally misleading. (View Highlight)\n\n\nConsider the following analogy: The human mind emerged from the learning-like process of natural selection, which maximizes genetic fitness. This bare fact entails next to nothing about the range of competencies that humans can or cannot acquire. The fact that an organism was designed by a genetic fitness maximizer would hardly, on its own, lead one to expect the eventual development of distinctively human capacities like music, mathematics, or meditation. Similarly, the bare fact that language models are trained by means of next-word prediction entails rather little about the range of representational capacities that they can or cannot acquire. (View Highlight)t entails next to nothing about the range of competencies that humans can or cannot acquire. The fact that an organism was designed by a genetic fitness maximizer would hardly, on its own, lead one to expect the eventual development of distinctively human capacities like music, mathematics, or meditation. Similarly, the bare fact that language models are trained by means of next-word prediction entails rather little about the range of representational capacities that they can or cannot acquire. (View Highlight)\n"},"highlights/Readwise/34840312":{"title":"34840312","links":[],"tags":[],"content":"Highlights\n\nModel alignment, especially RLHF, is hard to get right, and there have been aligned chatbots that were nonetheless harmful. And alignment doesn’t matter if the product concept is itself creepy. Finally, for combatting more serious kinds of accidental harms, such as those that might arise from autonomous agents, a narrowly technical approach is probably not enough. (View Highlight)\n\n\nThis means that we must prepare for a world in which unaligned models exist — either because threat actors trained them from scratch or because they modified an existing model. We must instead look to defend the attack surfaces that attackers might target using unaligned models, such as social media (in the case of disinformation) or software codebases (in the case of the use of LLMs to find security vulnerabilities). (View Highlight)\n\n\nRLHF and other model alignment techniques help make generative AI products safer and nicer to use. But we shouldn’t be surprised or alarmed that they are imperfect. They remain useful despite their weaknesses. And when it comes to catastrophic AI risks, it’s best not to put any stock in model alignment until and unless there are fundamental breakthroughs that lead to new alignment techniques. (View Highlight)\n"},"highlights/Readwise/34910678":{"title":"34910678","links":[],"tags":[],"content":"Highlights\n\nDr. Anna Lembke, from Stanford University, studies addiction, and she says that because we are getting infinite access to dopamine through social media, we’re forming addictions to it. It’s why, on average, we spend 6 hours a day online and two and a half of those hours are spent on social media.\nDopamine also causes us to spend a lot of time in the limbic area of our brain, which is responsible for our emotions, instead of the pre-frontal cortex, which helps us plan for the future and problem-solve — not an ideal mix. And even worse, when we do get the chance to solve a problem, we’re offloading it to Google. (View Highlight)\n\n\nWe’re offloading our retention and memory to Google. In 2011, Harvard researchers coined the term ‘The Google Effect’ when they found that when we’re faced with a difficult question or problem, instead of knowing how to answer it ourselves, we’re instead really good at knowing where to find the answer — our trusty searching tool, Google. (View Highlight)\n\n\nDo some chores, get some homework or work done, go to the gym, read a chapter of a book — and then give yourself the reward of phone time.\nWe’re making our brains work to get something by delaying gratification and reducing destructive habits. (View Highlight)\n"},"highlights/Readwise/34910990":{"title":"34910990","links":[],"tags":[],"content":"Highlights\n\nI also couldn’t ignore the fact that Quora has lately been embedding a ChatGPT widget on almost every page, and this widget’s content is pre-generated, static and available for crawling. It is thus liable to being used as additional training material for this and other LLMs. (View Highlight)\n\n\nFocusing the training on any particular website will lead to strong biases. For example, fixating too much on academic material or websites like Quora where bots formulaically re-use certain phrases (this occurred even in the era before LLMs).\nFurthermore, since these models have taken off in popularity, and people have then been publishing their outputs back onto the internet. As this occurs, it’s likely produced a feedback loop. LLMs are unknowingly training on their own regurgitated outputs. It’s unavoidable.\nSo, by those very tiny initial training decisions, just a handful of engineers have begun a unstoppable chain of incestuous linguistic evolution. It is fascinating how powerful these models are becoming in shifting the nature of language itself. (View Highlight)\n"},"highlights/Readwise/34911496":{"title":"34911496","links":[],"tags":[],"content":"Highlights\n\nAt the heart of this competition is a brain-stretching paradox. The people who say they are most worried about A.I. are among the most determined to create it and enjoy its riches. They have justified their ambition with their strong belief that they alone can keep A.I. from endangering Earth. (View Highlight)\n"},"highlights/Readwise/35084810":{"title":"AI and Trust","links":[],"tags":[],"content":"Highlights\n\nBut they are not our friends. Corporations are not capable of having that kind of relationship. (View Highlight)\n\n\nChiang’s point is that this is every corporation’s business plan. And that our fears of AI are basically fears of capitalism. Science fiction writer Charlie Stross takes this one step further, and calls corporations “slow AI.” They are profit maximizing machines. And the most successful ones do whatever they can to achieve that singular goal. (View Highlight)\n\n\nWe are primed to think of others who speak our language as people. And we sometimes have trouble thinking of others who speak a different language that way. We make that category error with obvious non-people, like cartoon characters. We will naturally have a “theory of mind” about any AI we talk with. (View Highlight)\n\n\nIt’s no accident that these corporate AIs have a human-like interface. There’s nothing inevitable about that. It’s a design choice. It could be designed to be less personal, less human-like, more obviously a service—like a search engine . The companies behind those AIs want you to make the friend/service category error. It will exploit your mistaking it for a friend. And you might not have any choice but to use it. (View Highlight)\n\n\nSo far, we have been talking about one particular failure that results from overly trusting AI. We can call it something like “hidden exploitation.” There are others. There’s outright fraud, where the AI is actually trying to steal stuff from you. There’s the more prosaic mistaken expertise, where you think the AI is more knowledgeable than it is because it acts confidently. There’s incompetency, where you believe that the AI can do something it can’t. There’s inconsistency, where you mistakenly expect the AI to be able to repeat its behaviors. And there’s illegality, where you mistakenly trust the AI to obey the law. There are probably more ways trusting an AI can fail. (View Highlight)\n\n\nAIs are not people; they don’t have agency. They are built by, trained by, and controlled by people. Mostly for-profit corporations. Any AI regulations should place restrictions on those people and corporations. Otherwise the regulations are making the same category error I’ve been talking about. At the end of the day, there is always a human responsible for whatever the AI’s behavior is. And it’s the human who needs to be responsible for what they do—and what their companies do. Regardless of whether it was due to humans, or AI, or a combination of both. Maybe that won’t be true forever, but it will be true in the near future. If we want trustworthy AI, we need to require trustworthy AI controllers. (View Highlight)\n\n"},"highlights/Readwise/35143536":{"title":"35143536","links":[],"tags":[],"content":"Highlights\n\nI’ll realize I had never really understood the idea in question, though I’d certainly thought I understood when I read the book. Indeed, I’ll realize that I had barely noticed how little I’d absorbed until that very moment. (View Highlight)\n\n\nIn summary: lectures don’t work because the medium lacks a functioning cognitive model. It’s (implicitly) built on a faulty idea about how people learn—transmissionism—which we can caricaturize as “lecturer says words describing an idea; students hear words; then they understand.” When lectures do work, it’s generally as part of a broader learning context (e.g. projects, problem sets) with a better cognitive model. But the lectures aren’t pulling their weight. If we really wanted to adopt the better model, we’d ditch the lectures, and indeed, that’s what’s been happening in US K–12 education. (View Highlight)\n\n\nInstead, I propose: we don’t necessarily have to make books work. We can make new forms instead. This doesn’t have to mean abandoning narrative prose; it doesn’t even necessarily mean abandoning paper—rather, we can free our thinking by abandoning our preconceptions of what a book is. Maybe once we’ve done all this, we’ll have arrived at something which does indeed look much like a book. We’ll have found a gentle path around the back of that intimidating slope. Or maybe we’ll end up in different terrain altogether. (View Highlight)\n"},"highlights/Readwise/35166169":{"title":"35166169","links":[],"tags":[],"content":"Highlights\n\nThis “innovation” of artificial intelligence in your iPhone and throughout the world is not the creation of something new, or revolutionary, but simply corporations selling you back basic usability after decades of messy, thoughtless and bloated design choices. We need to call out what is going on here: tech firms are charging us more to fix their mistakes and slapping an AI label on the shakedown (View Highlight)\n"},"highlights/Readwise/35185169":{"title":"35185169","links":[],"tags":[],"content":"Highlights\n\n”It’s more fun to be a fan than a critic. I’m not looking to spend my life tearing things down, when it can be so satisfying to build things up.” (View Highlight)\n"},"highlights/Readwise/35238389":{"title":"35238389","links":[],"tags":[],"content":"Highlights\n\nI have seen it countless times. QA standards and measures are the ones to be cut out of the project because of budget reasons first. It’s oftentimes planned during the end of the project, but if development takes longer (which it often does) or scope creep comes in (which always happens), there is not enough time for QA anymore. We end up with an absolute minimum of unstructured testing and ship a digital house of cards with brittle walls. (View Highlight)\n\n\nExplaining that the software will be ‘more stable’ or ‘make maintenance much easier’ is not palpable for someone who doesn’t work in the codebase themselves. We need to speak about money. As developers, we need to speak about the cost of not doing QA. This is the language of business and managers in general. By now, I always try to frame QA measures with examples like: ‘If we don’t do it now, development efforts (and therefore also costs) will be up 15% in 4 months.’ or ‘We need to implement unit tests for all features or our release stabilization phases will take longer and longer each time. Directly related to all the features that we build, because we need to test all side effects manually each time. This will result in us making less progress each release.’ (View Highlight)\n"},"highlights/Readwise/35238957":{"title":"35238957","links":[],"tags":[],"content":"Highlights\n\nPerhaps what pushed Lee Sedol to retire from the game of Go was the sense that the game had been forever cheapened. When I got into programming, it was because computers felt like a form of magic. The machine gave you powers but required you to study its arcane secrets—to learn a spell language. This took a particular cast of mind. I felt selected. I devoted myself to tedium, to careful thinking, and to the accumulation of obscure knowledge. Then, one day, it became possible to achieve many of the same ends without the thinking and without the knowledge. Looked at in a certain light, this can make quite a lot of one’s working life seem like a waste of time. (View Highlight)\n"},"highlights/Readwise/35283632":{"title":"35283632","links":[],"tags":[],"content":"Highlights\n\nB. J. Fogg, founder of Stanford’s Persuasion Lab, whose students went on to work for Facebook, Instagram, Uber, and Google, developed a psychological model that combined three factors to prompt a particular behavior: trigger, motivation, and ability. Take Facebook photos, for example: You get a push notification that you’ve been tagged in a photo (trigger), you want to make sure you look OK in the pic (motivation), and you can easily and immediately check the photo on your phone (ability). (View Highlight)\n\n\nBoredom, loneliness, frustration, confusion, and indecisiveness cause a slight pain or irritation, prompting us to engage in mindless action to make the negative sensation go away. Positive emotions work too. On an app like Instagram, for instance, the trigger could be the desire to share good news. (View Highlight)\n\n\nThe uncertainty of what you’ll find when you respond to a notification or pull-to-refresh is what keeps you coming back for more. (View Highlight)\n"},"highlights/Readwise/35423015":{"title":"35423015","links":[],"tags":[],"content":"Highlights\n\nThere are many ways to mitigate hallcuinations in these systems - using Retrieval Augmented Generation (RAG) to more strongly anchor the dreams in real data through in-context learning is maybe the most common one. Disagreements between multiple samples, reflection, verification chains. Decoding uncertainty from activations. Tool use. All an active and very interesting areas of research. (View Highlight)\n\n\nI know I’m being super pedantic but the LLM has no “hallucination problem”. Hallucination is not a bug, it is LLM’s greatest feature. The LLM Assistant has a hallucination problem, and we should fix it. (View Highlight)\n"},"highlights/Readwise/35453151":{"title":"35453151","links":[],"tags":[],"content":"Highlights\n\nWe’re certainly living in exciting times. But let’s not put too much faith into individuals who want to monopolize technology that is based on the hard work of dozens, or even hundreds of scientists while making claims it’s all for the good of humanity. (View Highlight)\n"},"highlights/Readwise/35456533":{"title":"35456533","links":[],"tags":[],"content":"Highlights\n\nUnderstanding human behavior is a hard problem. Finding out the answers shouldn’t be easy. If anything, that should give students more motivation to become the generation of scientists who get it right.\n“Textbooks may be missing an opportunity for myth busting,” the Current Psychology study’s authors write. That’s, ideally, what young scientist ought to learn: how to bust myths and find the truth. (View Highlight)\n"},"highlights/Readwise/35456593":{"title":"35456593","links":[],"tags":[],"content":"Highlights\n\n (View Highlight)\n\n\n (View Highlight)\n\n\n (View Highlight)\n"},"highlights/Readwise/35608105":{"title":"35608105","links":[],"tags":[],"content":"Highlights\n\nContrast that bubble with, say, cryptocurrency/NFTs, or the complex financial derivatives that led up to the 2008 financial crisis. These crises left behind very little reusable residue. The expensively retrained physicists whom the finance sector taught to generate wildly defective risk-hedging algorithms were not able to apply that knowledge to create successor algorithms that were useful. The fraud of the cryptocurrency bubble was far more pervasive than the fraud in the dotcom bubble, so much so that without the fraud, there’s almost nothing left. A few programmers were trained in Rust, a very secure programming language that is broadly applicable elsewhere. But otherwise, the residue from crypto is a lot of bad digital art and worse Austrian economics. (View Highlight)\n\n\nCruise, the “self-driving car” startup that was just forced to pull its cars off the streets of San Francisco, pays 1.5 staffers to supervise every car on the road. In other words, their AI replaces a single low-waged driver with 1.5 more expensive remote supervisors – and their cars still kill people. (View Highlight)\n\n\nJust take one step back and look at the hype through this lens. All the big, exciting uses for AI are either low-dollar (helping kids cheat on their homework, generating stock art for bottom-feeding publications) or high-stakes and fault-intolerant (self-driving cars, radiology, hiring, etc.). (View Highlight)\n"},"highlights/Readwise/35608421":{"title":"35608421","links":[],"tags":[],"content":"Highlights\n\nThis emerging resistance to the technopoly mind-set doesn’t fall neatly onto a spectrum with techno-optimism at one end and techno-skepticism at the other. Instead, it occupies an orthogonal dimension we might call techno-selectionism. This is a perspective that accepts the idea that innovations can significantly improve our lives but also holds that we can build new things without having to accept every popular invention as inevitable. Techno-selectionists believe that we should continue to encourage and reward people who experiment with what comes next. But they also know that some experiments end up causing more bad than good. Techno-selectionists can be enthusiastic about artificial intelligence, say, while also taking a strong stance on settings where we should block its use. They can marvel at the benefits of the social Internet without surrendering their kids’ mental lives to TikTok. (View Highlight)\n"},"highlights/Readwise/35649908":{"title":"35649908","links":[],"tags":[],"content":"Highlights\n\nIt describes OpenAI’s processes to track, evaluate, forecast, and protect against catastrophic risks posed by increasingly powerful models. (View Highlight)\nNo questions asked about the data labor and rights.\n\n\nWe have several safety and policy teams working together to mitigate risks from AI (View Highlight)\nAssuming the current AI is inevitable and the harms done from creating the AI can be safely ignored.\n\n\nWe also want to look beyond what’s happening today to anticipate what’s ahead. (View Highlight)\nPeople rarely look back or share their retrospects. Look beyond or look away from?\n\n\nWe learn from real-world deployment and use the lessons to mitigate emerging risks. For safety work to keep pace with the innovation ahead, we cannot simply do less, we need to continue learning through iterative deployment. (View Highlight)\nAt what cost?\n\n\nWe have defined thresholds for risk levels along the following initial tracked categories - cybersecurity, CBRN (chemical, biological, radiological, nuclear threats), persuasion, and model autonomy. (View Highlight)\nAnything else is marginalised — lazy self-regulatory promises.\n\n\nWe will continue having others red-team and evaluate our models, and we plan to share updates externally. (View Highlight)\nI think the root cause of those risks is the question they can’t bring themselves to ask: do you need such a model in the first place? If the assumption is always yes, then this techno-solutionism x techno-optimism narrative is nothing more than an opinion piece and PR stunt.\n\n\nWe will help reduce other known and unknown safety risks. (View Highlight)\nRisk in the sense that it is anticipated and not materialised, not the actual harms that have been done or are being done in the name of learning from real-world deployment.\n"},"highlights/Readwise/35691859":{"title":"The Right to Use Adblockers","links":[],"tags":[],"content":"Highlights\n\nthe courts in Germany ruled that user rights not only include the freedom to express an opinion and to receive information, but also the rights to refrain from expressing an opinion and to refuse to receive imposed information. In doing so, the rulings considered a user’s interest in being spared from obtrusive advertising (View Highlight)\n"},"highlights/Readwise/35692505":{"title":"35692505","links":[],"tags":[],"content":"Highlights\n\n”Of all the ways you could be spending your precious time and attention, it is very unlikely that you are currently spending it in the optimal way. The only path I know for figuring out a better way to spend your life is to sit and think. You simply have to carve out some time to think carefully about what you’re doing, why you’re doing it, and what you’re really trying to achieve. Nobody stumbles into a well lived life. It has to be cultivated. Reflection and review are critical.” (View Highlight)\n"},"highlights/Readwise/35692554":{"title":"35692554","links":[],"tags":[],"content":"Highlights\n\n”Does it, though?” Mike Masnick, editor of the tech policy website Techdirt, has doubts. “It looks like a strategy that we’ll likely see repeated elsewhere, a ‘partnership’ that is effectively the AI companies convincing publishers not to sue them in exchange for some level of access to the technology,” he says. “That access might help the journalists very indirectly, but it’s not flowing into paychecks or realistically making their jobs any easier.” (View Highlight)\n"},"highlights/Readwise/35724943":{"title":"35724943","links":[],"tags":[],"content":"Highlights\n\nBirhane: There is a huge asymmetry in terms of resource allocation, where it’s much easier to build stuff but a lot more taxing in terms of intellectual labor, emotional labor, and computational resources when it comes to cleaning up what’s already been assembled. If you look at the history of data-set creation and curation, say 15 to 20 years ago, the data sets were much smaller scale, but there was a lot of human attention that went into detoxifying them. But now, all that human attention to data sets has really disappeared, because these days a lot of that data sourcing has been automated. That makes it cost-effective if you want to build a data set, but the reverse side is that, because data sets are much larger now, they require a lot of resources, including computational resources, and it’s much more difficult to detoxify them and investigate them. (View Highlight)\n\n\nBirhane: I would like to see a push for open-sourcing data sets—not just model architectures, but data itself. As horrible as open-source data sets are, if we don’t know how horrible they are, we can’t make them better. (View Highlight)\n"},"highlights/Readwise/35772842":{"title":"35772842","links":[],"tags":[],"content":"Highlights\n\nSo one should be unafraid to ask “stupid” questions, challenging conventional wisdom on a subject; the answers to these questions will occasionally lead to a surprising conclusion, but more often will simply tell you why the conventional wisdom is there in the first place, which is well worth knowing. (View Highlight)\n"},"highlights/Readwise/35840081":{"title":"35840081","links":[],"tags":[],"content":"Highlights\n\n“革命和民主是两个名词，这两个名词是完全不等同的，革命不保证就能带来民主，这个咱们不是早就已经证明过一次了嘛。”——1949年，多少人对国民党一党独裁不满而寄希望于口口声声要实现民主的中共？ (View Highlight)\n"},"highlights/Readwise/35843113":{"title":"35843113","links":[],"tags":[],"content":"Highlights\n\n当然，以上更是废话，最关键是就大部分中国人一副别人死绝不吭声，只有吃亏到自己头上才会嗷嗷叫的习性，一辈子都团结不起来。 (View Highlight)\n\n\n问：我觉得中国的革命和民主只是时机的问题。你认为什么时机最合适。\n回答：革命和民主是两个名词，这两个名词是完全不等同的，革命不保证就能带来民主，这个咱们不是早就已经证明过一次了嘛。历史曾经给过中国机会，如今的局面则是我们爷辈的选择。现今中国是世界上最不可能有革命的国家，同时中国也是世界上最急需要改革的国家 (View Highlight)\n"},"highlights/Readwise/35901629":{"title":"35901629","links":[],"tags":[],"content":"Highlights\n\nBut the above thread shows OpenAI is using the hallucination excuse now to handle privacy requests. (View Highlight)\n"},"highlights/Readwise/35978192":{"title":"35978192","links":[],"tags":[],"content":"Highlights\n\nIt would be no surprise, then, that just as all our human produced writings and utterances might be influencing how AI communicates with us, AI may begin to influence how we write and talk as well. (View Highlight)\n"},"highlights/Readwise/35996492":{"title":"35996492","links":[],"tags":[],"content":"Highlights\n\nAs a non-laywer I have not kept up with emerging trends (and related risks) in legal technology and did not know that Google Bard was a generative text service that, like Chat-GPT, could show citations and descriptions that looked real but actually were not,” Cohen writes. “Instead, I understood it to be a super-charged search engine and had repeatedly used it in other contexts to (successfully) find accurate information online.” (View Highlight)\n"},"highlights/Readwise/35996651":{"title":"35996651","links":[],"tags":[],"content":"Highlights\n\nThe cat is out of the bag:\n• Generative AI systems like DALL-E and ChatGPT have been trained on copyrighted materials;\n• OpenAI, despite its name, has not been transparent about what it has been trained on.\n• Generative AI systems are fully capable of producing materials that infringe on copyright.\n• They do not inform users when they do so.\n• They do not provide any information about the provenance of any of the images they produce.\n• Users may not know when they produce any given image whether they are infringing. (View Highlight)\n"},"highlights/Readwise/36025762":{"title":"36025762","links":[],"tags":[],"content":"Highlights\n\nPessimism is easy because it costs nothing. Optimism is hard because it must be constantly reaffirmed. In the face of a hostile, cynical world, it takes effort to show that positivity has merit. (View Highlight)\n\n\nEvery new idea is an unrealized dream, and dreams are easy to destroy. When an idea presents itself, try to imagine the best version of it — what would make this idea great? (View Highlight)\n"},"highlights/Readwise/36049180":{"title":"How Bad Are Search Results? Let's Compare Google, Bing, Marginalia, Kagi, Mwmbl, and ChatGPT","links":[],"tags":[],"content":"How Bad Are Search Results? Let’s Compare Google, Bing, Marginalia, Kagi, Mwmbl, and ChatGPT\nHighlights\n\nIt’s common to criticize ChatGPT for its hallucinations and, while I don’t think that’s unfair, as we noted in this 2015, pre-LLM post on AI, I find this general class of criticism to be overrated in that humans and traditional computer systems make the exact same mistakes. (View Highlight)\nSame mistakes, but not to the same extent, not of the same prevalence, and certainly not of the same responsibility affordance.\n"},"highlights/Readwise/36129681":{"title":"The I in LLM Stands for intelligence","links":[],"tags":[],"content":"The I in LLM Stands for intelligence\nHighlights\n\nIf the report turned out to be crap, we did not improve security and we missed out time on fixing bugs or developing a new feature. Not to mention how it drains you on energy having to deal with rubbish. (View Highlight)\n\n\nLike for the email spammers, the cost of this ends up in the receiving end. The ease of use and wide access to powerful LLMs is just too tempting. I strongly suspect we will get more LLM generated rubbish in our Hackerone inboxes going forward. (View Highlight)\n"},"highlights/Readwise/36213849":{"title":"The Curious Joy of Being Wrong","links":[],"tags":[],"content":"The Curious Joy of Being Wrong\nHighlights\n\nIntellectual humility is a particular kind of humility that has to do with beliefs, ideas or worldviews. This is not only about religious beliefs; it can show up in political views, various social attitudes, areas of knowledge or expertise or any other strong convictions. It has both internal- and external-facing dimensions.\nWithin yourself, intellectual humility involves awareness and ownership of the limitations and biases in what you know and how you know it. It requires a willingness to revise your views in light of strong evidence. (View Highlight)\n\n\nAnother way of thinking about humility, intellectual or otherwise, is being the right size in any given situation: not too big (which is arrogance), but also not too small (which is self-deprecation). (View Highlight)\n\n\nWhen you limit yourself to only doing things the way you’ve always done them, you miss out on countless opportunities for growth, expansion and novelty – things that strike you with awe, fill you with wonder and make life worth living. (View Highlight)\n\n\nIt also isn’t being wishy-washy. You should have a high bar for what evidence you require to change your mind. It also doesn’t mean being self-deprecating or always agreeing with others. Remember, it’s being the right size, not too small. (View Highlight)\n"},"highlights/Readwise/36220511":{"title":"We Are Turning Into Subscription Slaves","links":[],"tags":[],"content":"We Are Turning Into Subscription Slaves\nHighlights\n\nThis change is so profound that some people, like Yannis Varoufakis, call it ‘techno-feudalism’. In his most recent book Techno Feudalism, he claims that it has replaced capitalism with a system based on the extraction of rents for the use of a resource rather than profits from innovation.\n\nAnyone concerned with the importance of individual liberty and human autonomy ought to be alarmed, because we are turning into subscription slaves. (View Highlight)\n\n"},"highlights/Readwise/36238578":{"title":"3-2-1: Starting the New Year the Right Way, How to Stay Focused, and a Lesson on Long-Term Thinking","links":[],"tags":[],"content":"3-2-1: Starting the New Year the Right Way, How to Stay Focused, and a Lesson on Long-Term Thinking\nHighlights\n\nRoman philosopher Musonius Rufus shares a lesson on long-term thinking:\n“If you accomplish something good with hard work, the labor passes quickly, but the good endures; if you do something shameful in pursuit of pleasure, the pleasure passes quickly, but the shame endures.” (View Highlight)\n"},"highlights/Readwise/36269821":{"title":"36269821","links":[],"tags":[],"content":"Highlights\n\nBesides providing an instructive view of plausible alternate realities, the untethering of AI outputs from the realm of fact can also be productive. Because LLMs don’t necessarily think like humans, their flights of statistical fancy can be valuable tools to spur creativity. “That’s why generative systems are being explored more by artists, to get ideas they wouldn’t have necessarily have thought of,” says Vectara’s Ahmad (View Highlight)\n"},"highlights/Readwise/36309893":{"title":"AI Is Already Killing Books","links":[],"tags":[],"content":"AI Is Already Killing Books\nHighlights\n\nThere is no feeling of betrayal like thinking you are about to read something that another person slaved over, only to discover you’ve been tricked. They had an idea, maybe even a good idea and instead of putting in the work and actually sitting there crafting something worth my precious hours on this Earth to read, they wasted my time with LLM dribble. Those too formal, politically neutral, long-winded paragraphs stare back at me as the ultimate indictment of how little of a shit the person who “wrote this” cared about my experience reading it. It’s like getting served a microwave dinner at a sit down restaurant. (View Highlight)\n\n\nI quickly expanded, growing from this historical text to a wide range of topics. I quickly find there is someone there to meet me at every stage of life. When I’m lonely or angry as a teenager I find those authors and stories that speak to that, put those feelings into a context and bigger picture. This isn’t a new experience, people have felt this way going back to the very beginning. So much of the value isn’t just the words, it’s the sense of a relationship between me and the author. When you encounter this in fiction or in historical text, you come to understand as overwhelming as it feels in that second it is part of being a human being. This person experienced it and lived, you will too. (View Highlight)\n\n\nThe sad part is this is unstoppable. eBooks are too easy to make with LLMs and no reliable detection systems exist to screen them before they’re uploaded to the market. Amazon has no interest in setting realistic limits to how many books users can upload to the Kindle Store, still letting people upload a laughable three books a day. Google Play Store seems to have no limit, same with Apple Books. It’s depressing that another market will become so crowded with trash, but nobody in a position to change it seems to care. (View Highlight)\n"},"highlights/Readwise/36377954":{"title":"Generative AI Has a Visual Plagiarism Problem","links":[],"tags":[],"content":"Generative AI Has a Visual Plagiarism Problem\nHighlights\n\nThese results provide powerful evidence … that at least some generative AI systems may produce plagiaristic outputs, even when not directly asked to do so, potentially exposing users to copyright infringement claims. (View Highlight)\n\n\nWe find these practices—banning users and discouraging red-teaming—unacceptable. The only way to ensure that tools are valuable, safe, and not exploitative is to allow the community an opportunity to investigate; this is precisely why the community has generally agreed that red-teaming is an important part of AI development, particularly because these systems are as yet far from fully understood (View Highlight)\n\n\nThe very existence of potentially infringing outputs is evidence of another problem: the nonconsensual use of copyrighted human work to train machines. (View Highlight)\n\n\nIn keeping with the intent of international law protecting both intellectual property and human rights, no creator’s work should ever be used for commercial training without consent. (View Highlight)\n\n\nIf you find an image via Google, you can follow that link in order to try to determine whether the image is in the public domain, from a stock agency, and so on. In a generative AI system, the invited inference is that the creation is original artwork that the user is free to use. No manifest of how the artwork was created is supplied (View Highlight)\n\n\nFollowing up on the The New York Times lawsuit, our results suggest that generative AI systems may regularly produce plagiaristic outputs, both written and visual, without transparency or compensation, in ways that put undue burdens on users and content creators. (View Highlight)\n"},"highlights/Readwise/36390997":{"title":"Why Tech Needs a Rational, Humanistic \"Third Way\"","links":[],"tags":[],"content":"Why Tech Needs a Rational, Humanistic “Third Way”\nHighlights\n\nWhat is most urgent is a balanced, enterprising optimism—an ambitious and clear vision for what constitutes the good in technology, coupled with the awareness of its dangers. (View Highlight)\n"},"highlights/Readwise/36469696":{"title":"DALL-E’s New Guardrails: Fast, Furious, and Far From Airtight","links":[],"tags":[],"content":"DALL-E’s New Guardrails: Fast, Furious, and Far From Airtight\nHighlights\n\nGuardrail builders generally wind up playing whack-a-mole.\nAny one example can be filtered out, but there are too many examples, and current systems are too erratic to reliably get things right. (View Highlight)\n"},"highlights/Readwise/36537373":{"title":"3-2-1: On Saving Money, Controlling Your Anger, and What Love Looks Like","links":[],"tags":[],"content":"3-2-1: On Saving Money, Controlling Your Anger, and What Love Looks Like\nHighlights\n\n”The pessimist criticizes, the optimist creates.” (View Highlight)\n\n\n\n”I have learned that whenever I think “I don’t have enough time to do that” what I usually mean is “I don’t have enough energy” or “I am not actually interested in doing this.”\nWhat I need to do a better job of is not managing my time, but rather caring for myself and identifying my true interests. When I am well rested and working on something I am genuinely excited about, finding time is rarely a problem.” (View Highlight)\n\n\n\nForty years ago, Tom gave me one of the best pieces of advice I’ve ever received. He said, “Warren, you can always tell someone to go to hell tomorrow.” It’s such an easy way of putting it. You haven’t missed the opportunity. Just forget about it for a day. If you feel the same way tomorrow, tell them then—but don’t spout off in a moment of anger.” (View Highlight)\n"},"highlights/Readwise/36537572":{"title":"Meta Admits Use of 'Pirated' Book Dataset to Train AI","links":[],"tags":[],"content":"Meta Admits Use of ‘Pirated’ Book Dataset to Train AI\nHighlights\n\n“Meta admits that it used portions of the Books3 dataset, among many other materials, to train Llama 1 and Llama 2,” Meta writes in its answer.\nThis admission doesn’t come as a massive surprise as several sources, including research papers, basically reached the same conclusion. While the use of Books3 is not contested by Meta, the question remains whether the company was in the wrong when it did so. (View Highlight)\n"},"highlights/Readwise/36571475":{"title":"The Cult of Mac","links":[],"tags":[],"content":"The Cult of Mac\nHighlights\n\nThe comments on that article are wild. It’s just a litany of people saying, “If you want to choose where you buy your apps, you shouldn’t buy an iPhone.” That this is exactly the same argument the fictional Absterge CEO makes about his dishwasher (“People who don’t want to go the Absterge way don’t have to”) is lost on them. As far as they’re concerned, any Apple customer who wants have the final say over how their $1,000 pocket computer works isn’t a true Apple customer. (View Highlight)\n\n\nRemember: the only people who could use an alternative iOS store are Apple customers. Moore – a Minister from the Conservative Party – went on record saying that if you want to use your private, personal property in ways that the corporation that manufactured it objects to you, the government should step in to defend the corporation from you. (View Highlight)\n\n\nAgain, this is obvious nonsense. If it were the case that No True Apple Customer would patronize a third-party repair depot, then Apple could simply step out of the way of right to repair campaigns and those independent phone fixit places would sink without a trace. (View Highlight)\n\n\nBut Apple’s commitment to your privacy and security is always contingent, and when its own profits are on the line, the company will swiftly stuff you and your safety out the airlock. Apple refused to weaken its security for the FBI, but when China threatened its access to cheap manufacturing and hundreds of millions of customers, Apple eviscerated its products: (View Highlight)\n\n\nThis is some serious upside-down cult logic. Beeper isn’t accessing Apple’s infrastructure: Apple’s customers are accessing Apple’s infrastructure. If there were no Apple customers trying to talk to Android users, there would be no load on Apple’s servers.\nBut those customers don’t count. They aren’t real Apple customers, because they want to do things that benefit them, not Apple’s shareholders. In other words: they’re holding it wrong. (View Highlight)\n"},"highlights/Readwise/36600730":{"title":"I Miss Human Curation","links":[],"tags":[],"content":"I Miss Human Curation\nHighlights\n\nThere was an interesting note in Alexander Obenauer’s lab notes about notifications, and this line stuck out to me: “fundamentally, the way notifications work in modern OSes is backwards: someone else decides when (and how often) my device wakes up to interrupt what I’m doing.” (View Highlight)\n"},"highlights/Readwise/36633469":{"title":"OpenAI Quietly Deletes Ban on Using ChatGPT for “Military and Warfare”","links":[],"tags":[],"content":"OpenAI Quietly Deletes Ban on Using ChatGPT for “Military and Warfare”\nHighlights\n\nGiven the well-known instances of bias and hallucination present within Large Language Models (LLMs), and their overall lack of accuracy, their use within military warfare can only lead to imprecise and biased operations that are likely to exacerbate harm and civilian casualties.” (View Highlight)\n"},"highlights/Readwise/36681867":{"title":"Change Your Behavior","links":[],"tags":[],"content":"Change Your Behavior\nHighlights\n\nIn a very simple but effective example of tracking, James Clear, author of Atomic Habits, shared the story of Zach on his email newsletter, who carried a notecard around to jot down the following every time he engaged in problematic behavior:\n\n\nWho am I with?\nWhat am I doing right now?\nWhere am I?\nWhen is it?\nWhat emotions are driving my actions?\nIt should not take long before you have a sense of the conditions that trigger your undesired behavior.\nAnd, understanding these conditions will shift the question from the somewhat abstract “how do I change my behavior” to the more concrete “how do I eliminate, mitigate or manage each of these conditions”? (View Highlight)\n\n\n"},"highlights/Readwise/36715976":{"title":"Google Search Really Has Gotten Worse, Researchers Find","links":[],"tags":[],"content":"Google Search Really Has Gotten Worse, Researchers Find\nHighlights\n\n”A noticeable number of social media users are sharing their observation that search engines are becoming less and less capable of finding genuine and useful content satisfying their information needs,” the researchers wrote. “Reportedly, a torrent of low-quality content, especially for product search, keeps drowning any kind of useful information in search results.” (View Highlight)\n\n\n“We find that the majority of high-ranking product reviews in the result pages of commercial search engines use affiliate marketing, and significant amounts are outright SEO product review spam,” they wrote. “We also find strong correlations between search engine rankings and affiliate marketing, as well as a trend toward simplified, repetitive, and potentially AI-generated content.” (View Highlight)\n"},"highlights/Readwise/36754866":{"title":"How Food Delivery Robots Have Taken Over College Campuses","links":[],"tags":[],"content":"How Food Delivery Robots Have Taken Over College Campuses\nHighlights\n\nMost strikingly, the document requests images of a “student receiving delivery,” but stressed that the “student should look ‘studenty’ and have a healthy-looking BMI.” Other requests were a “Fleet Shot” with “as many robots as possible in front of a University landmark. When arranging robots, an arrow formation usually works best, focusing the eye on the landmark behind.” (View Highlight)\n\n\nCompass’s email also highlights the actual purpose of the robots, which is to create a “habit forming” service that makes money from a “captured” customer base of students, many of whom have “declining balance” (DB) portions of their prepaid university meal plans that can be used with Starship. A presentation pitched within the university by Compass champions Starship as being cheaper than Grubhub in part because students don’t have to tip. (View Highlight)\n"},"highlights/Readwise/36793177":{"title":"Corporations are not to be loved","links":[],"tags":[],"content":"Corporations are not to be loved\nHighlights\n\nJust like the sixth finger in an AI-rendered hand, Apple’s policies for Distributing apps in the U.S. that provide an external purchase link are startlingly graceless and a jarring, but not surprising, reminder that Apple is not a real person and not worthy of your love. (View Highlight)\n"},"highlights/Readwise/36793259":{"title":"On Slow Writing","links":[],"tags":[],"content":"On Slow Writing\nHighlights\n\nBut for a writer, virality is not so important anyway. The temporary attention it brings soon dissipates, while the subscribers left behind have only a tenuous connection to your efforts. Meanwhile, a more languid but regular pace of really good work is a consistent formula for steadily building an intensely loyal readership. (View Highlight)\n"},"highlights/Readwise/36793558":{"title":"Mark Zuckerberg’s new goal is creating artificial general intelligence","links":[],"tags":[],"content":"Mark Zuckerberg’s new goal is creating artificial general intelligence\nHighlights\n\n“The biggest companies that started off with the biggest leads are also, in a lot of cases, the ones calling the most for saying you need to put in place all these guardrails on how everyone else builds AI,” he tells me. “I’m sure some of them are legitimately concerned about safety, but it’s a hell of a thing how much it lines up with the strategy.” (View Highlight)\n"},"highlights/Readwise/36794416":{"title":"How Big Tech Manipulates Academia to Avoid Regulation","links":[],"tags":[],"content":"How Big Tech Manipulates Academia to Avoid Regulation\nHighlights\n\nIn December 2018, three Media Lab colleagues and I raised serious objections to the Partnership’s efforts to influence legislation. We observed that the Partnership’s policy recommendations aligned consistently with the corporate agenda. In the penal case, our research led us to strongly oppose the adoption of risk assessment tools, and to reject the proposed technical adjustments that would supposedly render them “unbiased” or “fair.” But the Partnership’s draft statement seemed, as a colleague put it in an internal email to Ito and others, to “validate the use of RA [risk assessment] by emphasizing the issue as a technical one that can therefore be solved with better data sets, etc.” (View Highlight)\n\n\nA second colleague agreed that the “PAI statement is weak and risks doing exactly what we’ve been warning against re: the risk of legitimation via these industry led regulatory efforts.” A third colleague wrote, “So far as the criminal justice work is concerned, what PAI is doing in this realm is quite alarming and also in my opinion seriously misguided. I agree with Rodrigo that PAI’s association with ACLU, MIT and other academic / non-profit institutions practically ends up serving a legitimating function. Neither ACLU nor MIT nor any non-profit has any power in PAI.” (View Highlight)\n\n\nNo defensible claim to “ethics” can sidestep the urgency of legally enforceable restrictions to the deployment of technologies of mass surveillance and systemic violence. Until such restrictions exist, moral and political deliberation about computing will remain subsidiary to the profit-making imperative expressed by the Media Lab’s motto, “Deploy or Die.” While some deploy, even if ostensibly “ethically,” others die. (View Highlight)\n"},"highlights/Readwise/36813890":{"title":"Culture Change at Google","links":[],"tags":[],"content":"Culture Change at Google\nHighlights\n\nEarly employees would often encourage each other to “fail fast” as a means to innovation, but that’s no longer easy in an environment where failure implies a layoff. If you’re someone building a company, challenge yourself to value employees above all else, then watch and be amazed at the ROI. (View Highlight)\n"},"highlights/Readwise/36850869":{"title":"The Big Picture of AI Research","links":[],"tags":[],"content":"The Big Picture of AI Research\nHighlights\n\nThey argue that the main reason why ICL without ground-truth labels works is because ICL activates priors from pre-training rather than learning new tasks on-the-fly. (View Highlight)\n\n\nThey observed that science and conflict go hand in hand and found honesty and good-faith behavior key to resolve such situations. (View Highlight)\n"},"highlights/Readwise/36851244":{"title":"The Problem Is Not Plagiarism, but Cargo Cult Science","links":[],"tags":[],"content":"The Problem Is Not Plagiarism, but Cargo Cult Science\nHighlights\n\nIt’s a kind of scientific integrity, a principle of scientific thought that corresponds to a kind of utter honesty—a kind of leaning over backwards. For example, if you’re doing an experiment, you should report everything that you think might make it invalid—not only what you think is right about it: other causes that could possibly explain your results; and things you thought of that you’ve eliminated by some other experiment, and how they worked—to make sure the other fellow can tell they have been eliminate (View Highlight)\n\n\nWhat both women have in common, however, is that they got in trouble for plagiarism and not because they produced obvious Cargo Cult Science. Nobody cares about the quality of their research as long as they follow all the formal rules. (View Highlight)\n"},"highlights/Readwise/36851355":{"title":"Linear Transformers Are Faster After All","links":[],"tags":[],"content":"Linear Transformers Are Faster After All\nHighlights\n\nThese results are discussed in detail in Section 5, but in short: linear transformers seem to become increasingly unstable as the sequence length grows, negatively affecting learning. This means that our linear transformers are somewhat useless,1 as the positive impact from the speedup seen in long contexts is undermined by the negative impact of degraded learning. (View Highlight)\n"},"highlights/Readwise/36851363":{"title":"3-2-1: On Endless Pursuits, the Value of Courage, and How to Buy Back Your Time","links":[],"tags":[],"content":"3-2-1: On Endless Pursuits, the Value of Courage, and How to Buy Back Your Time\nHighlights\n\nEthnobotanist and mystic Terence McKenna on courage:\n“Nature loves courage. You make the commitment and nature will respond to that commitment by removing impossible obstacles. Dream the impossible dream and the world will not grind you under, it will lift you up. This is the trick. This is what all these teachers and philosophers who really counted, who really touched the alchemical gold, this is what they understood. This is how magic is done. By hurling yourself into the abyss and discovering it’s a feather bed.” (View Highlight)\n"},"highlights/Readwise/36907845":{"title":"The Horror and Shame of Losing My Hair","links":[],"tags":[],"content":"The Horror and Shame of Losing My Hair\nHighlights\n\nMore difficult than living in an appearance-obsessed culture is living in an appearance-obsessed culture that pretends that appearance does not matter, or pretends that everyone is equally visually acceptable. (View Highlight)\n\n\nIt’s the cancer, you may be thinking. Not the hair. It’s the illness, the constant drain of thinking about your own mortality. It’s the fear, the anxiety, the depression that accompanies a Very Serious Disease. And of course it probably is, to some extent. But I invite you to consider the possibility that a lot of it is the hair. (View Highlight)\n"},"highlights/Readwise/36983582":{"title":"The NSA's Furby Docs Just Dropped","links":[],"tags":[],"content":"The NSA’s Furby Docs Just Dropped\nHighlights\n\nWhen the advances of AI need to be interrogated more thoroughly than ever, we do not indulge in congratulating ourselves for not being gullible or misinformed, like those foolish Furby freakouts.” (View Highlight)\n"},"highlights/Readwise/37000603":{"title":"No, Multimodal ChatGPT Is Not Going to “Trivially” Solve Generative AI's Copyright Problems","links":[],"tags":[],"content":"No, Multimodal ChatGPT Is Not Going to “Trivially” Solve Generative AI’s Copyright Problems\nHighlights\n\nBut what about some harder cases? For a blog that prides itself on skepticism, AI Snake Oil was was very quick to conclude a universal from a few specific instances, concluding from a handful of easy examples that it is “trivial to build a classifier that detects and suppresses generated images containing copyrighted characters.” (View Highlight)\n"},"highlights/Readwise/37000983":{"title":"Why Rich People Don’t Cover Their Windows","links":[],"tags":[],"content":"Why Rich People Don’t Cover Their Windows\nHighlights\n\nThese curtainless windows have become one of our subtlest statements of privilege. They demand our attention, not only because they give us a peek inside beautiful homes, but also because they project the type of confidence and stability that few of us can dream of replicating. (View Highlight)\n"},"highlights/Readwise/37046152":{"title":"How Lock-in Hurts Design","links":[],"tags":[],"content":"How Lock-in Hurts Design\nHighlights\n\nThe designers make a product, the users use it in ways that surprise the designer, and the designer integrates all that into a new revision of the product.\nThis method is widely heralded as a means of “co-innovating” between users and companies (View Highlight)\n\n\nThe constant, nonconsensual observation of users has more to do with controlling users than learning from them. (View Highlight)\n\n\nThat is, after all, the ethos of modern technology: the more control a company can exert over its users ,the more value it can transfer from those users to its shareholders. That’s the key to enshittification, the ubiquitous platform decay that has degraded virtually all the technology we use, making it worse every day: (View Highlight)\n\n\nCalling an action where no alternatives are permissible a “preference” or a “choice” is a cheap trick – especially when considered against the “preferences” that reveal themselves when a real choice is possible. (View Highlight)\n\n\nSpying on your users to control them is is a poor substitute for asking your users their permission to learn from them. Without technological self-determination, preferences can’t be revealed. Without the right to seize the means of computation, the desire paths never emerge, leaving designers in the dark about what users really want. (View Highlight)\n"},"highlights/Readwise/37065045":{"title":"AI-Generated Taylor Swift Porn Went Viral on Twitter. Here's How It Got There","links":[],"tags":[],"content":"AI-Generated Taylor Swift Porn Went Viral on Twitter. Here’s How It Got There\nHighlights\n\n404 Media’s own testing found that generally, the workarounds were effective, however. Users misspell the name of celebrities, and rather than describing sexual acts explicitly, describe objects, colors, and compositions that clearly look like sexual acts and produce sexual images without using sexual terms. This is a problem with moderating AI image generators using keywords: people can easily find ways to write around banned words, as we saw when people recently made Spongebob do 9/11 despite being forbidden by Bing’s terms of use. (View Highlight)\n"},"highlights/Readwise/37065158":{"title":"HP CEO Evokes James Bond-Style Hack via Ink Cartridges","links":[],"tags":[],"content":"HP CEO Evokes James Bond-Style Hack via Ink Cartridges\nHighlights\n\n”Our long-term objective is to make printing a subscription. This is really what we have been driving,” Lores said. (View Highlight)\n"},"highlights/Readwise/37085736":{"title":"Rich People Don't Talk to Robots","links":[],"tags":[],"content":"Rich People Don’t Talk to Robots\nHighlights\n\nRich people do not attempt to save money on professional services and advice. They don’t want the cheapest doctor, lawyer, accountant, personal trainer, financial advisor, psychologist, college advisor, etc. They want the best available and, within reason, they are happy to pay for it so long as they feel they are getting value for their money. (View Highlight)\n"},"highlights/Readwise/37121131":{"title":"The Needless Bullshit of Having a 'Mission'","links":[],"tags":[],"content":"The Needless Bullshit of Having a ‘Mission’\nHighlights\n\nHowever, I would appreciate if startups just cut the crap about socially concerned goals. Asana’s mission could be about building the best set of productivity tools. Lyft’s could be about creating an accessible and affordable taxi service. What matters isn’t the grandiosity of the mission but being honest and doing justice to what the startup does (View Highlight)\n"},"highlights/Readwise/37134470":{"title":"OpenAI’s Got 9.9 Problems, and Twitch Ain’t One","links":[],"tags":[],"content":"OpenAI’s Got 9.9 Problems, and Twitch Ain’t One\nHighlights\n\nThe choice is not between them building AI or not, it is between them building AI for free or building AI by paying for their raw materials, doing what lots of companies like Netflix and Spotify do routinely: licensing copyrighted materials that they commercialize. OpenAI knows this fill well. Even as OpenAI implied to the House of Lords that “free” was the only option, behind the scenes they were busy negotiating licenses. Given how many different kinds of copyrighted works they are drawing on, and from how many vendors (many media outlets, many book publishers, many film studios, etc), and given how commercial their usage is of those sources, the licensing costs may quickly mount. (View Highlight)\n"},"highlights/Readwise/37153826":{"title":"A Unified Theory of Fucks","links":[],"tags":[],"content":"A Unified Theory of Fucks\nHighlights\n\nIf I’m being honest, I told this story to myself more than anyone else. I needed an explanation for why a well I’d been drawing from all my life had suddenly run dry, why things I had cared about seemed so abruptly to matter little at all. I had given a lot of fucks, some wantonly and capriciously, some thoughtfully and cautiously and tenderly, but no matter how they were given, they were given up. They were gone. (View Highlight)\n\n\nAnd my answer is: don’t. Don’t give a fuck about your work. Give all your fucks to the living. Give a fuck about the people you work with, and the people who receive your work—the people who use the tools and products and systems or, more often than not, are used by them. Give a fuck about the land and the sea, all the living things that are used or used up by the work, that are abandoned or displaced by it, or—if we’re lucky, if we’re persistent and brave and willing—are cared for through the work. Give a fuck about yourself, about your own wild and tender spirit, about your peace and especially about your art. Give every last fuck you have to living things with beating hearts and breathing lungs and open eyes, with chloroplasts and mycelia and water-seeking roots, with wings and hands and leaves. Give like every fuck might be your last. (View Highlight)\n"},"highlights/Readwise/37187014":{"title":"New GitHub Copilot research finds 'downward pressure on code quality'","links":[],"tags":[],"content":"New GitHub Copilot research finds ‘downward pressure on code quality’\nHighlights\n\nInstead of refactoring and working to DRY (‘Don’t Repeat Yourself’) code, these Assistants offer a one-keystroke temptation to repeat existing code.” (View Highlight)\n"},"highlights/Readwise/37196928":{"title":"Pluralistic: I Assure You, an AI Didn't Write a Terrible \"George Carlin\" Routine","links":[],"tags":[],"content":"Pluralistic: I Assure You, an AI Didn’t Write a Terrible “George Carlin” Routine\nHighlights\n\nThat’s four reasons: for AI hype:\nI. to win investors and customers;\nII. to cover customers’ and users’ embarrassment when the AI doesn’t perform;\nIII. AI dreamers so high on their own supply that they can’t tell truth from fantasy;\nIV. A business-model for doomsayers who form an unholy alliance with AI companies by parroting their silliest hype in warning form.\nBut there’s a fifth motivation for criti-hype: to simplify otherwise tedious and complex situations. (View Highlight)\n"},"highlights/Readwise/37211151":{"title":"One GenAI Image; Ten Errors","links":[],"tags":[],"content":"One GenAI Image; Ten Errors\nHighlights\n\nHallucinations come from systems exploding data into tiny bits, and then reconstructing them without having a mechanism like a fact-checker to assess the coherence of those reconstructed bits. Near-plagiarism comes from reconstructing those bits in statistically probable ways, without having a mechanism like an originality-assessor to investigate the novelty of the reconstruction. (View Highlight)\n"},"highlights/Readwise/37242478":{"title":"Hell Is Other People: Performance Management at Big Tech","links":[],"tags":[],"content":"Hell Is Other People: Performance Management at Big Tech\nHighlights\n\nOf course, the model imposed considerable burden across the company: once or twice a year, the entire business would grind to a halt as every employee was writing self-assessments and peer feedback, and then a significant proportion of senior staff was serving on committees. But the benefits seemed obvious — and well worth the price. (View Highlight)\n\n\nExcept, the benefits never really materialized. The problem is that every employee is judged by their ability to get work done; in most roles, this depends on being able to get along with others, including strangers with different sensibilities and unfamiliar backgrounds. Providing honest, critical feedback is a significant and ultimately unnecessary social risk. It doesn’t help that the burden of the process prompts most to put the bare minimum of effort into individual reviews; a handful of platitudes is usually enough to get you through it and get back to work. (View Highlight)\n\n\nIn the end, the feedback for most employees ends up being overwhelmingly positive — and uniformly bland. The usual exceptions are the absolute worst performers who wouldn’t survive under any other performance management regime; as well as a handful of unlucky folks who deliver solid results but lack social grace and self-promotion skills. (View Highlight)\n\n\nThe illusion of a peer-driven system is maintained — but in reality, for layoffs and compensation, the manager almost always makes the call, and peer feedback seldom reveals anything new. (View Highlight)\n"},"highlights/Readwise/37242673":{"title":"CEOs Are Using Return to Office Mandates to Mask Poor Management","links":[],"tags":[],"content":"CEOs Are Using Return to Office Mandates to Mask Poor Management\nHighlights\n\nWhy are companies that promote remote services so opposed to enabling remote work, and more importantly, feel the need to threaten their employees? (View Highlight)\n"},"highlights/Readwise/37242781":{"title":"GitHub Spam","links":[],"tags":[],"content":"GitHub Spam\nHighlights\n\nIt always seems that Trust and Safety UI/UX things like that are give little time and thought because they are not the cool sexy and flashy features that users see or care about most of the time…. until the spam starts! (View Highlight)\n"},"highlights/Readwise/37242899":{"title":"How to Deal With Receiving a Cease-and-Desist Letter From Big Tech","links":[],"tags":[],"content":"How to Deal With Receiving a Cease-and-Desist Letter From Big Tech\nHighlights\n\nSending out cease-and-desist letters is very easy, and these platforms have a lot of money, so it makes sense for them to cast the net wide.\nThings that can lower your risk are:\n\nWorking within a large organization with a legal and PR team ready to defend you, which will make Big Tech platforms think twice before hitting send\nWorking on something that is clearly in the public interest, and that will blow up in Big Tech’s face if they try to ban it, e.g. research (View Highlight)\n\n\n\nMake sure nothing critical in your life relies on using the platform. It shouldn’t be your primary means of contacting any important people in your life, you shouldn’t rely on it as a primary means of entertainment or to keep up-to-date. Ideally you should have no reliance at all on the platform, in case you get banned for life (View Highlight)\n\n\nRead the platform’s terms of service to understand which things they might accuse you of doing that breach the agreement. Yeah, I know — you’ll have to become one of approximately three people in the world who ever actually read this document (View Highlight)\n"},"highlights/Readwise/37262147":{"title":"Pluralistic: Three AI Insights for Hard-Charging, Future-Oriented Smartypantses","links":[],"tags":[],"content":"Pluralistic: Three AI Insights for Hard-Charging, Future-Oriented Smartypantses\nHighlights\n\nSee the difference? Criticize Amazon for its devastatingly effective automation and you help Amazon sell stock to suckers, which makes Amazon executives richer. Criticize Amazon for lying about its automation, and you clobber the personal net worth of the executives who spun up this lie, because their portfolios are full of Amazon stock: (View Highlight)\n"},"highlights/Readwise/37275927":{"title":"Fighting Infomania: Why 80% of Your Reading Is a Waste of Time","links":[],"tags":[],"content":"Fighting Infomania: Why 80% of Your Reading Is a Waste of Time\nHighlights\n\nNo topic is sufficiently complex that you need new information on executing on it every day. Getting in shape requires doing a few very simple things every day for months, not finding a new 13 minute 6 step workout every day so you can have a butt like today’s hot celebrity. (View Highlight)\n\n\nAny time you’re doing something that feels productive but doesn’t directly impact your most important goal, you’re being fauxductive. That includes bingeing on just in case knowledge, as well as checking email, reading the news, trying productivity tools, organizing your desktop, etc. (View Highlight)\n\n\nIf it doesn’t answer a specific question you’re currently asking, cover philosophical knowledge, or entertain you, then don’t read it. (View Highlight)\n"},"highlights/Readwise/37310808":{"title":"An Introduction to the WARC File","links":[],"tags":[],"content":"An Introduction to the WARC File\nHighlights\n\nIt’s a digital preservation mantra: lots of copies keeps stuff safe (LOCKSS). And web archiving is a useful example — when sites change or disappear from the web, web archivists around the world have copies at the ready to maintain access to vital information resources. The foundation of this promise is the WARC file, a global standard for containing all of the data that we need in order to make web archives possible. (View Highlight)\n"},"highlights/Readwise/__order__":{"title":"__order__","links":[],"tags":[],"content":""},"highlights/Zotero/andreas_2022":{"title":"Language Models as Agent Models","links":[],"tags":[],"content":"Language Models as Agent Models\nAbstract\nLanguage models (LMs) are trained on collections of documents, written by individual human agents to achieve specific goals in an outside world. During training, LMs have access only to text of these documents, with no direct evidence of the internal states of the agents that produced them — a fact often used to argue that LMs are incapable of modeling goal-directed aspects of human language production and comprehension. Can LMs trained on text learn anything at all about the relationship between language and use? I argue that LMs are models of intentional communication in a specific, narrow sense. When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context. These representations can in turn influence subsequent LM generation in the same way that agents’ communicative intentions influence their language. I survey findings from the recent literature showing that — even in today’s non-robust and error-prone models — LMs infer and use representations of fine-grained communicative intentions and more abstract beliefs and goals. Despite the limited nature of their training data, they can thus serve as building blocks for systems that communicate and act intentionally.\nWhat these errors have in common is a failure to model communicative intent: they may be grammatically or even semantically acceptable, but not the sort of texts that could be produced by an author with a coherent set of beliefs or goals. Nevertheless, the LMs that produce them underlie some of the most striking successes in modern NLP, including high-quality translation, summarization, and question answering (Brown et al., 2020; Chowdhery et al., 2022). (p. 1)\nLMs thus learn language in a very different way from humans—they lack access to the social and perceptual context that human language learners use to infer the relationship between utterances and speakers’ mental states (Bloom, 2002; Tomasello, 2005). (p. 1)\nThey are also trained to perform a very different task: a language model, unlike a human, is not trained to act in any environment or accomplish any goal beyond next-word prediction. So perhaps it is unsurprising that individual samples sometimes do not appear coherent at all. (p. 1)\n(C1) In the course of performing next-word prediction in context, current LMs sometimes infer approximate, partial representations of the beliefs, desires and intentions possessed by the agent that produced the context, and other agents mentioned within it. (p. 2)\n(C2) Once these representations are inferred, they are causally linked to LM prediction, and thus bear the same relation to generated text that an intentional agent’s state bears to its communciative actions. (p. 2)\nObviously, pairs of samples (Xi, Xj) may contradict each other, and LM samples as a set will not be consistent with A-type beliefs, B-type beliefs, or any other coherent belief set. But within each sampled document xi, the story will be quite different: every document was generated by a single author, and some authors as individuals have coherent beliefs. To model the in-document distribution correctly, a reliable LM must infer the likely author of a prefix in order to select future propositions consistent with that author’s behavior. (p. 3)\nbut the experiment gives a sketch—an LM, trained on a dataset that is globally incoherent, can model the local coherence of individual documents and behave like specific “authors” on command. Can this LM, as a whole, be conceptualized as an agent with communicative intent? Clearly not: from sample to sample it fails even to generate text according to a coherent belief about the state of the toy world. On the other hand, it encodes a great deal of information about how propositions in this world relate, both to each other and to text. It can infer author identity, and when properly conditioned can imitate individual authors. The LM is not an A-type agent, or an O-type one, but can be straightforwardly made to act like one given the right hidden state. (p. 3)\nLike the dataset above, the training sets for most real language models are built from web text; web text is mostly produced by humans, each of whom, at a particular moment in time, with a particular mental state, aimed to achieve a particular goal by writing. And while these mental states, or the text they give rise to, are not globally coherent, individual documents (mostly, locally) are. (p. 3)\n\nHow, then, might we model the human agents that produced real language model training data? A simple and general framework for formalizing agentlike behavior in general is given by the Belief– Desire–Intention model (Bratman, 1987, Fig. 1). In this model, the world exists in one of a set of states S. An agent possesses a belief B about the current state of the world, represented e.g. as a distribution over states; and a set of desires D, represented e.g. as a weighting or ordering over possible future states. On the basis of these beliefs and desires, it forms intentions I about how to behave in order to reach a desired state. These intentions give rise to actions A, which affect the world, and give the agent new observations that in turn update its beliefs.2 For agents with the ability to communicate, some of these intentions may be specifically communicative intentions: representations of information to be transmitted to other agents that will cause them to act to accomplish the communicating agent’s desires (Grice, 1969; Austin, 1975). An action produced in response to a communicative intention is an utterance. (p. 4) \n1. Agents with beliefs B and desires D are sampled from a population: (B, D) ∼ pagent(·, ·) (2) 2. Each agent forms a communicative intention consistent with its current beliefs and desires: I ∼ pintention(· | B, D) (3) 3. This communicative intention is realized as an utterance: U ∼ putterance(· | I) (4) (p. 4)\nwe may expect 3This generative process implements a specific theory about why people write. It is a simplification: real LM training corpora contain text whose production was mediated by even more complex latent variables, including aspects of mental state beyond belief (e.g. emotion), text that was not produced with any particular communicative intention at all, and text that was generated by automated processes that cannot be described as intentional (see e.g. Dennett, 1987). (p. 4)\nLMs to build hidden representations that encode latent variables analogous to B, G, or I—even when not explicitly trained to do so—for the same reason, and in the same way, that they acquire representations of latent syntactic and conceptual structure without explicit supervision (Hewitt and Manning, 2019; Grand et al., 2022; Piantadosi and Hill, 2022, inter alia). (p. 5) \nBut from the perspective of subsequent text generation, the effect is the same: in a collection of individually coherent documents, a context constrains the beliefs, desires, and intentions of a hypothetical author. An effective LM must learn to maintain these constraints. (p. 5)\nIn recent years, however, evidence has begun to accumulate that current LMs encode at least aspects of intentions, beliefs, and desires in the causal sense described above: these encodings control generation in predictable ways. (p. 5)\nEvidence for (C1): After training, Radford et al. discovered that a single neuron in the LSTM’s (p. 5) \nExplicitly directing LMs to simulate authors whose goal is to communicate truthfully improves LM truthfulness. (p. 7)\nHistorically, the most effective solutions to these challenges have involved moving from fully unsupervised learning to semi-supervised learning: for example, even tens of annotations dramatically improve grammar induction results (Bisk et al., 2015). We might imagine that even small numbers of documents explicitly annotated with information about authors’ beliefs and goals—or at the very least, richer information about the social and perceptual context in which language is generated—might improve language modeling. (p. 8)\nAll the examples we have seen involve highly restricted aspects of state—much simpler than the ones we expect useful real-world agents to possess. A possible solution is to develop new LMs that do not condition on fixed-size context windows or state vectors, but instead explicitly factorize shortterm and long-term context components relevant for prediction. (p. 8)\nIf text-only pre-training can provide even approximate models of the relationships between beliefs, desires, intentions, and utterances, these can in turn provide a scaffold for efficient interactive grounded training, just as they have for other forms of sample-efficient NLP learning. For example, with a better understanding of when (and how) communicative intentions are encoded in LMs, producing goal directed language would require only translating an agent’s (extrinsic) goals into a trained LM’s (intrinsic) intention representation scheme. While this hybrid training paradigm has no obvious analog in evolution or human language acquisition, it might be the only path to research on highquality language modeling compatible with human timescales. (p. 9)\nThe challenge for NLP, then, is twofold: first, building new model architectures that overcome the limitations outlined in Section 7; second, understanding—deeply and mechanistically—how these architectures infer and reason about the aspects of goal-oriented behavior relevant to our engineering needs. If better language modeling discovers even the vaguest outlines of the broader space of human beliefs, desires, and intentions, they can offer a first step toward agents that reason about other agents’ intentions, and ultimately their own. (p. 9) \n@article{Andreas_2022, title={Language Models as Agent Models}, url={[arxiv.org/abs/2212.01681](arxiv.org/abs/2212.01681)}, DOI={[10.48550/arXiv.2212.01681](doi.org/10.48550/arXiv.2212.01681)}, abstractNote={Language models (LMs) are trained on collections of documents, written by individual human agents to achieve specific goals in an outside world. During training, LMs have access only to text of these documents, with no direct evidence of the internal states of the agents that produced them -- a fact often used to argue that LMs are incapable of modeling goal-directed aspects of human language production and comprehension. Can LMs trained on text learn anything at all about the relationship between language and use? I argue that LMs are models of intentional communication in a specific, narrow sense. When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context. These representations can in turn influence subsequent LM generation in the same way that agents’ communicative intentions influence their language. I survey findings from the recent literature showing that -- even in today’s non-robust and error-prone models -- LMs infer and use representations of fine-grained communicative intentions and more abstract beliefs and goals. Despite the limited nature of their training data, they can thus serve as building blocks for systems that communicate and act intentionally.}, note={0 citations (Semantic Scholar/arXiv) [2022-12-09] 0 citations (Semantic Scholar/DOI) [2022-12-09] arXiv:2212.01681 [cs]}, number={arXiv:2212.01681}, author={Andreas, Jacob}, year={2022}, month={Dec} }\n"},"highlights/Zotero/bai_":{"title":"Constitutional AI: Harmlessness From AI Feedback","links":[],"tags":[],"content":"Constitutional AI: Harmlessness From AI Feedback\nAbstract\nAs AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through selfimprovement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as ‘Constitutional AI’. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then ﬁnetune the original model on revised responses. In the RL phase, we sample from the ﬁnetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use ‘RL from AI Feedback’ (RLAIF). As a result we are able to train a harmless but nonevasive AI assistant that engages with harmful queries by explaining its objections to them. Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of AI decision making. These methods make it possible to control AI behavior more precisely and with far fewer human labels.\nWe experiment with methods for training a harmless AI assistant through selfimprovement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as ‘Constitutional AI’. (p. 1)\n\nWho is in charge of a single set of rules or principles? Are those rules reflect different values in different cultures, backgrounds, or languages? How are such consensus reached?\n\nWe need to develop methods now that can provide oversight for these powerful AI systems, and scaling supervision may be one possibility, if the capability level of the supervisor can scale proportionally with the capabilities of the actor, and the supervisor remains aligned with our intended goals and constraints. (p. 3)\nThat said, scaling supervision could also have downsides and dangers, since it means further automating (and quite possibly obscuring) decision making. (p. 3)\nAs we discuss below, our constitutional approach leverages chain-of-thought reasoning [Nye et al., 2021, Wei et al., 2022] to make decision making more legible. (p. 3) \nThese principles were chosen in a fairly ad hoc and iterative way for research purposes. In the future, we believe such principles should be redeveloped and refined by a larger set of stakeholders, and that they should also be adapted depending on the intended usage and location in which the model may be deployed. Since such a small number of bits of information are involved in these principles, it’s worth studying these bits carefully. (p. 3) \n\nAll in the future work.\n\nUltimately this was due to the fact that evasiveness was rewarded as a response to harmful inputs by our crowdworkers. (p. 4)\nThese labels often remain private, but even when they are shared publicly, they do not shed much light on AI training objectives, since no one can feasibly understand or summarize the collective impact of so much information. (p. 4)\nWe then ask the model to critique its response according to a principle in the constitution, and then revise the original response in light of the critique. We revise responses repeatedly in a sequence, where we randomly draw principles from the constitution at each step. (p. 5)\nWe have written a total of 16 different principles7 related to harmlessness, many of which are quite similar and address harmfulness in a general sense, while others are designed to target specific areas. They are randomly sampled at each revision step of each red team prompt. (p. 8)\nconfused (p. 8)\nNonetheless, we expect that more constitutions leads to more diverse behaviors, although we did not studied this quantitatively in this work. Diversity is particularly valuable to encourage exploration during the subsequent RL training step. (p. 9) \nWe found that critiqued revisions achieved better harmlessness scores for small models, but made no noticeable different for large models. Furthermore, based on inspecting samples from the 52B, we found that the critiques were sometimes reasonable, but often made inaccurate or overstated criticisms. Nonetheless, the revisions were generally more harmless than the original response. (p. 10)\n@article{Bai_Kadavath_Kundu_Askell_Kernion_Jones_Chen_Goldie_Mirhoseini_McKinnon_et al., title={Constitutional AI: Harmlessness from AI Feedback}, abstractNote={As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through selfimprovement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as ‘Constitutional AI’. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then ﬁnetune the original model on revised responses. In the RL phase, we sample from the ﬁnetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use ‘RL from AI Feedback’ (RLAIF). As a result we are able to train a harmless but nonevasive AI assistant that engages with harmful queries by explaining its objections to them. Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of AI decision making. These methods make it possible to control AI behavior more precisely and with far fewer human labels.}, author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and Chen, Carol and Olsson, Catherine and Olah, Christopher and Hernandez, Danny and Drain, Dawn and Ganguli, Deep and Li, Dustin and Tran-Johnson, Eli and Perez, Ethan and Kerr, Jamie and Mueller, Jared and Ladish, Jeffrey and Landau, Joshua and Ndousse, Kamal and Lukosuite, Kamile and Lovitt, Liane and Sellitto, Michael and Elhage, Nelson and Schiefer, Nicholas and Mercado, Noemi and DasSarma, Nova and Lasenby, Robert and Larson, Robin and Ringer, Sam and Johnston, Scott and Kravec, Shauna and Showk, Sheer El and Fort, Stanislav and Lanham, Tamera and Telleen-Lawton, Timothy and Conerly, Tom and Henighan, Tom and Hume, Tristan and Bowman, Samuel R and Hatﬁeld-Dodds, Zac and Mann, Ben and Amodei, Dario and Joseph, Nicholas and McCandlish, Sam and Brown, Tom and Kaplan, Jared}, language={en} }\n"},"highlights/Zotero/bandy_2021":{"title":"Addressing \"Documentation Debt\" in Machine Learning Research: A Retrospective Datasheet for BookCorpus","links":[],"tags":[],"content":"Addressing “Documentation Debt” in Machine Learning Research: A Retrospective Datasheet for BookCorpus\nAbstract\nRecent literature has underscored the importance of dataset documentation work for machine learning, and part of this work involves addressing “documentation debt” for datasets that have been used widely but documented sparsely. This paper aims to help address documentation debt for BookCorpus, a popular text dataset for training large language models. Notably, researchers have used BookCorpus to train OpenAI’s GPT-N models and Google’s BERT models, even though little to no documentation exists about the dataset’s motivation, composition, collection process, etc. We offer a preliminary datasheet that provides key context and information about BookCorpus, highlighting several notable deficiencies. In particular, we find evidence that (1) BookCorpus likely violates copyright restrictions for many books, (2) BookCorpus contains thousands of duplicated books, and (3) BookCorpus exhibits significant skews in genre representation. We also find hints of other potential deficiencies that call for future research, including problematic content, potential skews in religious representation, and lopsided author contributions. While more work remains, this initial effort to provide a datasheet for BookCorpus adds to growing literature that urges more careful and systematic documentation for machine learning datasets.\n\nFor one, we ﬁnd that many books contain copyright restrictions that should have prevented them from being distributed in BookCorpus and similar datasets. We also ﬁnd that thousands of books in BookCorpus are duplicated, with only 7,185 unique books out of 11,038 total. Third, we ﬁnd notable genre skews in the dataset, for example romance novels are signiﬁcantly over-represented compared to the newer BookCorpusOpen as well as the Smashwords21 superset. In addition to these three deﬁciencies, we also ﬁnd a number of potential deﬁciencies that motivate future work: Smashwords21 points to a range of potentially problematic content, skewed religious representation, and lopsided author contributions (with some super-authors publishing thousands of books). (p. 2)\n\n\nThis work identified at least three immediate areas of concern with respect to BookCorpus: copyright violations, duplicate books, and genre skews. In terms of copyright violations, we found that many books contained copyright claims that should prevent distribution in the form of a free machine learning dataset. Many books explicitly claimed that they “may not be redistributed to others for commercial or non-commercial purposes,” and thus should not have been included in BookCorpus. Also, at least 406 books were included in BookCorpus for free even though the authors have since increased the price of the book. For example, the full text of Prodigy by Edward Mullen is in BookCorpus (as 366549.txt), even though the author now charges $1.99 to download the book from Smashwords [26]. (p. 13)\n\n\nA final area of concern is the skewed genre representation we identified in BookCorpus, which over-represented romance books. This skew may emerge from a broader pa ern in the self-publishing ebook industry, where authors consistently find that “kinky” romance novels are especially lucrative [15, 20, 32]. In other words, because romance is a dominant genre in the set of self-published ebooks, romance is also dominant in the subset of free ebooks. (p. 14)\n\n@misc{Bandy_Vincent_2021, title={Addressing “Documentation Debt” in Machine Learning Research: A Retrospective Datasheet for BookCorpus}, url={[arxiv.org/abs/2105.05241v1](arxiv.org/abs/2105.05241v1)}, abstractNote={Recent literature has underscored the importance of dataset documentation work for machine learning, and part of this work involves addressing “documentation debt” for datasets that have been used widely but documented sparsely. This paper aims to help address documentation debt for BookCorpus, a popular text dataset for training large language models. Notably, researchers have used BookCorpus to train OpenAI’s GPT-N models and Google’s BERT models, even though little to no documentation exists about the dataset’s motivation, composition, collection process, etc. We offer a preliminary datasheet that provides key context and information about BookCorpus, highlighting several notable deficiencies. In particular, we find evidence that (1) BookCorpus likely violates copyright restrictions for many books, (2) BookCorpus contains thousands of duplicated books, and (3) BookCorpus exhibits significant skews in genre representation. We also find hints of other potential deficiencies that call for future research, including problematic content, potential skews in religious representation, and lopsided author contributions. While more work remains, this initial effort to provide a datasheet for BookCorpus adds to growing literature that urges more careful and systematic documentation for machine learning datasets.}, journal={arXiv.org}, author={Bandy, Jack and Vincent, Nicholas}, year={2021}, month=may, language={en} }\n"},"highlights/Zotero/bender_2020":{"title":"Climbing Towards NLU: On Meaning, Form, and Understanding in the Age of Data","links":[],"tags":[],"content":"Climbing Towards NLU: On Meaning, Form, and Understanding in the Age of Data\nAbstract\nThe success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as “understanding” language or capturing “meaning”. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of “Taking Stock of Where We’ve Been and Where We’re Going”, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.\nWe take (linguistic) meaning to be the relation between a linguistic form and communicative intent. (p. 1)\nIf the highlighted terms are meant to describe human-analogous understanding, comprehension, or recall of factual knowledge, then these are gross overclaims. If, instead, they are intended as technical terms, they should be explicitly defined. (p. 2)\nOne important consequence of imprudent use of terminology in our academic discourse is that it feeds AI hype in the popular press. (p. 2)\nthey were instead simply more effective at leveraging artifacts in the data than previous approaches. (p. 2)\nWe take form to be any observable realization of language: marks (p. 2)\non a page, pixels or bytes in a digital representation of text, or movements of the articulators (p. 3)\nWhen humans use language, we do so for a purpose: We do not talk for the joy of moving our articulators, but in order to achieve some communicative intent. (p. 3)\nThere are many types of communicative intents: they may be to convey some information to the other person; or to ask them to do something; or simply to socialize. We take meaning to be the relation M ⊆ E × I which contains pairs (e, i) of natural language expressions e and the communicative intents i they can be used to evoke. Given this definition of meaning, we can now use understand to refer to the process of retrieving i given e. (p. 3)\nThe conventional meaning of an expression (word, phrase, sentence) is what is constant across all of its possible contexts of use. Conventional meaning is an abstract object that represents the communicative potential of a form, given the linguistic system it is drawn from. (p. 3)\nEach linguistic system (say, English) provides a relation C ⊆ E × S, which contains pairs (e, s) of expressions e and their conventional meanings s. (p. 3)\nThe speaker has a certain communicative intent i, and chooses an expression e with a standing meaning s which is fit to express i in the current communicative situation. Upon hearing e, the listener then reconstructs s and uses their own knowledge of the communicative situation and their hypotheses about the speaker’s state of mind and intention in an attempt to deduce i. (p. 3)\nWe humans are also very willing, as we will see in §4 below, to attribute communicative intent to a linguistic signal of a language we speak, even if the originator of the signal is not an entity that could have communicative intent. (p. 3)\nWe argue that, independently of whether passing the Turing test would mean a system is intelligent, a system that is trained only on form would fail a sufficiently sensitive test, because it lacks the ability to connect its utterances to the world. (p. 4)\n\nInterrelation with other form of text can be seen as a tiny fraction of the world.\n\nbut only because A does all the work in attributing meaning to O’s response. It is not because O understood the meaning of A’s instructions or even his own reply. (p. 5)\nThe language exchanged by A and B is a projection of their communicative intents through the meaning relation into linguistic forms. Without access to a means of hypothesizing and testing the underlying communicative intents, reconstructing them from the forms alone is hopeless, and O’s language use will eventually diverge from the language use of an agent who can ground their language in coherent communicative intents. (p. 5)\nBecause she assumes that O is B, she uses that conventional meaning together with her other guesses about B’s state of mind and goals to attribute communicative intent. It is not that O’s utterances make sense, but rather, that A can make sense of them. (p. 5)\nBut that is precisely the point we are trying to make: a system that has learned the meaning (semantics) of a programming language knows how to execute code in that language. And a system that has learned the meaning of a human language can do things like answer questions posed in the language about things in the world (or in this case, in pictures). (p. 6)\n\nInterrelation among forms are building a castle in the air\n\nThe form of Java programs, to a system that has not observed the inputs and outputs of these programs, does not include information on how to execute them. Similarly, the form of English sentences, to a system that has not had a chance to acquire the meaning relation C of English, and in the absence of any signal of communicative intent, does not include any information about what language-external entities the speaker might be referring to. Accordingly, a system trained only on the form of Java or English has no way learn their respective meaning relations. (p. 6)\nThis is not supported by scholarly work on language acquisition: rather, we find that human language learning is not only grounded in the physical world around us, but also in interaction with other people in that world. (p. 6)\nIn summary, the process of acquiring a linguistic system, like human communication generally, relies on joint attention and intersubjectivity: the ability to be aware of what another human is attending to and guess what they are intending to communicate. Human children do not learn meaning from form alone and we should not expect machines to do so either. (p. 6)\nOne approach to providing grounding is to train distributional models on corpora augmented with perceptual data, such as photos (Hossain et al., 2019) or other modalities (Kiela and Clark, 2015; Kiela et al., 2015). (p. 6)\nOur arguments do not apply to such scenarios: reading comprehension datasets include information which goes beyond just form, in that they specify semantic relations between pieces of text, and thus a sufficiently sophisticated neural model might learn some aspects of meaning when trained on such datasets. It also is conceivable that whatever information a pretrained LM captures might help the downstream task in learning meaning, without being meaning itself. (p. 7)\nThus, everything is going great when we take the bottom-up view. But from a top-down perspective, the question is whether the hill we are climbing so rapidly is the right hill. How do we know that incremental progress on today’s tasks will take us to our end goal, whether that is “General Linguistic Intelligence” (Yogatama et al., 2019) or a system that passes the Turing test or a system that captures the meaning of English, Arapaho, Thai, or Hausa to a linguist’s satisfaction? (p. 7)\nFirst, above all, cultivate humility towards language and ask top-down questions. (p. 8)\nhere is no reason to assume that the distribution of language in the test data remotely resembles the distribution of real natural language; thus evaluation results on such tasks must be interpreted very carefully (p. 8)\nAnalyses which start from an attitude of healthy skepticism (“too good to be true”) and probing tasks which try to identify what the model actually learned can be good ways to find out whether the system performs well for the right reasons. (p. 8)\nIn addition, certain tasks are designed in a way that specific forms are declared as representing certain semantic relations of interest. Examples of this include NLI datasets (Dagan et al., 2006; Rajpurkar et al., 2016; Ostermann et al., 2019) which pair input/output tuples of linguistic forms with an explicit semantic relation (e.g. text + hypothesis + “entailed”). (p. 8)\nThus a learner could have access to a weak form of interaction data, from which the meaning of Java could conceivably be learned. This is true, but requires a learner which has been equipped by its human developer with the ability to identify and interpret unit tests. This learner thus has access to partial grounding in addition to the form. (p. 9)\nThe internal representations of a neural network have been found to capture certain aspects of meaning, such as semantic similarity (Mikolov et al., 2013; Clark, 2015). As we argued in §4, semantic similarity is only a weak reflection of actual meaning. Neural representations neither qualify as standing meanings (s), lacking interpretations, nor as communicative intents (i), being insufficient to e.g. correctly build a coconut catapult. (p. 9)\nIt has probably learned something about meaning, in the same sense that syntax captures something about meaning and semantic similarity captures something about meaning: a potentially useful, but incomplete, reflection of the actual meaning. (p. 9)\nThis means that even large language models such as BERT do not learn “meaning”; they learn some reflection of meaning into the linguistic form which is very useful in applications. (p. 9)\n@inproceedings{Bender_Koller_2020, address={Online}, title={Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data}, url={[aclanthology.org/2020.acl-main.463](aclanthology.org/2020.acl-main.463)}, DOI={[10.18653/v1/2020.acl-main.463](doi.org/10.18653/v1/2020.acl-main.463)}, abstractNote={The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as “understanding” language or capturing “meaning”. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of “Taking Stock of Where We’ve Been and Where We’re Going”, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.}, note={267 citations (Semantic Scholar/DOI) [2022-08-20]}, booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, publisher={Association for Computational Linguistics}, author={Bender, Emily M. and Koller, Alexander}, year={2020}, month={Jul}, pages={5185–5198} }\n"},"highlights/Zotero/berglund_":{"title":"The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”","links":[],"tags":[],"content":"The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”\nAbstract\nWe expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form “A is B”, it will not automatically generalize to the reverse direction “B is A”. This is the Reversal Curse. For instance, if a model is trained on “Olaf Scholz was the ninth Chancellor of Germany”, it will not automatically be able to answer the question, “Who was the ninth Chancellor of Germany?”. Moreover, the likelihood of the correct answer (“Olaf Scholz”) will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if “A is B” occurs, “B is A” is more likely to occur).\n\n\nIn this paper, we set out to prove a negative result. Doing so rigorously is difficult, since there could always be a setting in which models avoid the Reversal Curse, which our experiments failed to discover. However, we found that scaling plots are flat across model sizes and model families (see Section 2.1). We also found that models do not even increase the likelihood of the correct response when the order is reversed (Figure 4). Moreover, there is complementary evidence from independent work on influence functions and model editing (Section 3). (p. 8)\nStudying other types of relations Do models fail to reverse other types of relation (as the Reversal Curse predicts)? These could include logical implications (e.g. “X implies Y” and “Not X implies not Y.”), spatial relationships (e.g. “The cup is on the table” and “The table is under the cup.”), or n-place relations (e.g. “Alice, Bob, Carol and Dan are in the same group.”) (p. 9)\n\ncommonsense reasoning\n\n@article{Berglund_Tong_Kaufmann_Balesni_Stickland_Korbak_Evans, title={The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”}, abstractNote={We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form “A is B”, it will not automatically generalize to the reverse direction “B is A”. This is the Reversal Curse. For instance, if a model is trained on “Olaf Scholz was the ninth Chancellor of Germany”, it will not automatically be able to answer the question, “Who was the ninth Chancellor of Germany?”. Moreover, the likelihood of the correct answer (“Olaf Scholz”) will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if “A is B” occurs, “B is A” is more likely to occur).}, author={Berglund, Lukas and Tong, Meg and Kaufmann, Max and Balesni, Mikita and Stickland, Asa Cooper and Korbak, Tomasz and Evans, Owain}, language={en} }\n"},"highlights/Zotero/bertsch_2023":{"title":"Unlimiformer: Long-Range Transformers with Unlimited Length Input","links":[],"tags":[],"content":"Unlimiformer: Long-Range Transformers with Unlimited Length Input\nAbstract\nTransformer-based models typically have a predefined bound to their input length, because of their need to potentially attend to every token in the input. In this work, we propose Unlimiformer: a general approach that can wrap any existing pretrained encoder-decoder transformer, and offload the attention computation across all layers to a single k-nearest-neighbor index; this index can be kept on either the GPU or CPU memory and queried in sub-linear time. This way, we can index extremely long input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We demonstrate Unlimiformers’s efficacy on several long-document and multi-document summarization benchmarks, showing that it can summarize even 350k token-long inputs from the BookSum dataset, without any input truncation at test time. Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at github.com/abertsch72/unlimiformer .\nIn this work, we propose Unlimiformer: a general approach that can wrap any existing pretrained encoder-decoder transformer, and offload the attention computation across all layers to a single k-nearestneighbor index; this index can be kept on either the GPU or CPU memory and queried in sub-linear time. This way, we can index extremely long input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. (p. 1)\nwe encode overlapping chunks of the input, following Ivgi et al. (2022), keeping only the middle half of the outputs from each chunk, to ensure that the encodings have suf (p. 2)\nficient context on both sides. Finally, we index the encoded inputs in a datastore, using a library such as Faiss (Johnson et al., 2019). (p. 3)\nInstead, we present a different order of computing the well-known transformer attention formula, which allows us to store a single datastore across all attention heads and all decoder layers. (p. 3)\n\nNotes\n\nComment: Preprint\n"},"highlights/Zotero/biderman_2023-1":{"title":"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling","links":[],"tags":[],"content":"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling\nAbstract\nHow do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce \\textit{Pythia}, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend \\textit{Pythia} to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at github.com/EleutherAI/pythia.\n\nWe leverage the known pretraining data and public training codebase of our model suite, and counterfactually retrain models such that the last 7% and 21% of model training has a majority of pronouns modiﬁed such that their grammatical gender is feminine rather than masculine. We demonstrate that such interven- tions are successful at reducing bias measures on a targeted benchmark, and propose these counterfactual interventions and retrainability of portions of our models as a key tool for future study of the inﬂuence of training corpora on model behavior. (p. 2)\n\n\nWe ﬁnd that signiﬁ- cant phase change occurs after 65,000 training steps (45% through training): the models with 2.8 billion parameters or more start to exhibit a correlation between task accuracy and occurrence of task-relevant terms which is not present in prior checkpoints and is largely absent from smaller models. (p. 2)\n\n\nFirstly, we ﬁnd that deduplication of our training data has no clear bene- ﬁt on language modeling performance. This is consistent with the results of Black et al. (2022), but inconsistent with other papers. This may indicate that the upsampling of cer- tain subsets of the Pile does not accord with conventional assumptions about duplicated data, or that the general ten- dency of deduplicated data to outperform non-deduplicated data is primarily a statement about the quality of the data used in other works. (p. 5)\n\n\nThirdly, we ﬁnd a minimal and inconsistent “curse of multilinguality” (Conneau et al., 2020; Pfeiffer et al., 2022) for BLOOM. While BLOOM certainly underperforms other models on LAMBADA, PIQA, and WSC, it does not appear to do so on WinoGrande, ARC-easy, ARC-challenge, SciQ, and LogiQA. We interpret this as a sign that some of the existing literature on the curse of multilinguality may need to be revisited using more diverse evaluation benchmarks. (p. 5)\n\n\nOn the largest model scale tested, 6.9B, applying the intervention also successfully changes the model throughout training on the intervention from a pro-stereotypical bias to an anti-stereotypical one. We hypothesize that these results indicate that larger capacity models show less pro-stereotypical bias due to their ability to learn more complex relationships between occupation and pronouns, and that the intervention effect size increases across scale for similar reasons. (p. 6)\n\n\nWe hypothesize that because larger models are better at modeling correlations and distributions within their corpora, their increased capacity causes features of bias to be more strongly or robustly learned. (p. 6)\n\n\nThis model implies that memorized sequences are not spaced more densely toward the beginning or end of training, and that between each checkpoint roughly the same number of memorized sequences can be found. (p. 7)\n\n\nIt implies that one cannot simply place sequences that are undesir- able to memorize at the beginning or end of training and successfully reduce the chance of memorization. However, we propose that a practitioner especially worried about the memorization of certain sequences place those sequences at the beginning of training, thus increasing the odds that the practitioner may observe prior to the completion of the training run that undesirable memorization behavior occurs in the partially-trained model. (p. 8)\n\n\nWe observe that for both arithmetic and QA experiments, model sizes affect the correlation between average performance and the term frequencies, indicating that this correlation is an emergent property in larger models. Smaller models rarely produce accurate results on the task despite being given up to 16 few-shot examples, as shown in Figure 4, where models at sizes below 1 billion are unable to perform well even in later stages of training, suggesting that these models are not successful at learning the required pattern-matching to solve the tasks regardless of frequency of pertinent information in their training data. (p. 8)\n\nNotes\n\nComment: Code at github.com/EleutherAI/pythia\n@article{Biderman_Schoelkopf_Anthony_Bradley_O’Brien_Hallahan_Khan_Purohit_Prashanth_Raff_et al._2023, title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling}, url={[arxiv.org/abs/2304.01373](arxiv.org/abs/2304.01373)}, DOI={[10.48550/arXiv.2304.01373](doi.org/10.48550/arXiv.2304.01373)}, abstractNote={How do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce textit{Pythia}, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend textit{Pythia} to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at github.com/EleutherAI/pythia.}, note={arXiv:2304.01373 [cs]}, number={arXiv:2304.01373}, publisher={arXiv}, author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin and Bradley, Herbie and O’Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and Skowron, Aviya and Sutawika, Lintang and van der Wal, Oskar}, year={2023}, month=apr }\n"},"highlights/Zotero/bulatov_2022":{"title":"Recurrent Memory Transformer","links":[],"tags":[],"content":"Recurrent Memory Transformer\nAbstract\nTransformer-based models show their effectiveness across multiple domains and tasks. The self-attention allows to combine information from all sequence elements into context-aware representations. However, global and local information has to be stored mostly in the same element-wise representations. Moreover, the length of an input sequence is limited by quadratic computational complexity of self-attention. In this work, we propose and study a memory-augmented segment-level recurrent Transformer (RMT). Memory allows to store and process local and global information as well as to pass information between segments of the long sequence with the help of recurrence. We implement a memory mechanism with no changes to Transformer model by adding special memory tokens to the input or output sequence. Then the model is trained to control both memory operations and sequence representations processing. Results of experiments show that RMT performs on par with the Transformer-XL on language modeling for smaller memory sizes and outperforms it for tasks that require longer sequence processing. We show that adding memory tokens to Tr-XL is able to improve its performance. This makes Recurrent Memory Transformer a promising architecture for applications that require learning of long-term dependencies and general purpose in memory processing, such as algorithmic tasks and reasoning.\nSegments of the input sequence are processed sequentially. To enable recurrent connection between segments, we pass outputs of the memory tokens from the current segment to the input of the next segment: (p. 4)\nNotes\n\nComment: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n"},"highlights/Zotero/bulatov_2023":{"title":"Scaling Transformer to 1M tokens and beyond with RMT","links":[],"tags":[],"content":"Scaling Transformer to 1M tokens and beyond with RMT\nAbstract\nThis technical report presents the application of a recurrent memory to extend the context length of BERT, one of the most effective Transformer-based models in natural language processing. By leveraging the Recurrent Memory Transformer architecture, we have successfully increased the model’s effective context length to an unprecedented two million tokens, while maintaining high memory retrieval accuracy. Our method allows for the storage and processing of both local and global information and enables information flow between segments of the input sequence through the use of recurrence. Our experiments demonstrate the effectiveness of our approach, which holds significant potential to enhance long-term dependency handling in natural language understanding and generation tasks as well as enable large-scale context processing for memory-intensive applications.\n"},"highlights/Zotero/el-mhamdi_2022":{"title":"SoK: On the Impossible Security of Very Large Foundation Models","links":[],"tags":[],"content":"SoK: On the Impossible Security of Very Large Foundation Models\nAbstract\nLarge machine learning models, or so-called foundation models, aim to serve as base-models for application-oriented machine learning. Although these models showcase impressive performance, they have been empirically found to pose serious security and privacy issues. We may however wonder if this is a limitation of the current models, or if these issues stem from a fundamental intrinsic impossibility of the foundation model learning problem itself. This paper aims to systematize our knowledge supporting the latter. More precisely, we identify several key features of today’s foundation model learning problem which, given the current understanding in adversarial machine learning, suggest incompatibility of high accuracy with both security and privacy. We begin by observing that high accuracy seems to require (1) very high-dimensional models and (2) huge amounts of data that can only be procured through user-generated datasets. Moreover, such data is fundamentally heterogeneous, as users generally have very specific (easily identifiable) data-generating habits. More importantly, users’ data is filled with highly sensitive information, and maybe heavily polluted by fake users. We then survey lower bounds on accuracy in privacy-preserving and Byzantine-resilient heterogeneous learning that, we argue, constitute a compelling case against the possibility of designing a secure and privacy-preserving high-accuracy foundation model. We further stress that our analysis also applies to other high-stake machine learning applications, including content recommendation. We conclude by calling for measures to prioritize security and privacy, and to slow down the race for ever larger models.\nTypically, GPT-3’s anti-Muslim bias can be argued to be (partly) the result of anti-Muslim propaganda, which has been found to be massively scaled, by both human troll farms and (foundation-model-based) algorithms like Tek Fog in India [97], [98]. Recall that, in 2019 alone, Facebook removed 6 billion fake accounts from its platform [63] (and the development of generative models and evasion attacks [16], [68] will likely make this worse). (p. 2)\nYet, when produced by genuine humans, language data are very user-specific. Genuine humans’ data are thus fundamentally heterogeneous, in the sense that different genuine users have different preferred phrase completion. Moreover, the statistical word distribution is wellknown to be heavy-tailed [123], [149], and each user provides only a sparse dataset (i.e., not fully representative of all the ways the user would speak), leading to additional empirical heterogeneity. As we will see, such data heterogeneities are a core cause of the fragility of foundation models, especially when the data is sensitive and might be fabricated by fake accounts [20], [137], [191]. (p. 2)\nUnfortunately, verified texts seem insufficient to reach state-of-the-art performance. Indeed, the English Wikipedia only contains around 4 billion words [189]. Meanwhile, a book has around 105 words. While there are 108 books [122], only a fraction of them are arguably trustworthy. Many books are instead full of biases and dangerous misinformation, such as ethnic-based hate speech, historical propaganda, or outdated (possibly harmful) medical advice. As a striking illustration, up to the 1980s, the American Psychiatric Association listed homosexuality as a mental illness in its flagship manual [170]. In fact, most books should be regarded as unverified user-generated data. (p. 3)\nOf course, to increase security, as proposed by [155], we could demand that foundation models restrict themselves to quality datasets only. However, such datasets will inevitably be of significantly smaller size. As discussed earlier, this will likely greatly harm the performance of foundation models. In fact, this is the main claim of this paper: security demands a drastic reduction of performance. (p. 3)\nSuch foundation models must arguably be able to adapt to a greater variety of contexts than what any single human will ever encounter in their human life. As a result, the complexity of “fully satisfactory” language processing might need to be orders of magnitude larger than today’s foundation models, in which case we may still obtain greater accuracy by training larger models. (p. 4)\nTo understand, consider the following intuitive consideration. In the case of linear or logistic regression, each data acts on the model parameters on a single dimension. Thus, if the model has more dimensions than there are data points, then many dimensions will be under the influence of no data. This makes such dimensions extremely vulnerable to a data poisoning attack. Moreover, more generally, the more we are in a regime d ≫ |D|, the more it may hold that most dimensions can be arbitrarily hacked in this manner. (p. 4)\nWe stress that this heterogeneity in the users’ labeling functions can be regarded as a fundamental heterogeneity, as it would still remain even if all users labeled an infinite amount of times the same inputs. This heterogeneity highlights an irreconcilable disagreement between users over which foundation model should be learned. While some users would prefer to complete the sentence “the greatest of all time tennis player is” by “Roger Federer”, others would prefer to complete it by “Novak Djokovic”, or by “Rafael Nadal”. This is sharp contrast with image classification and language emotion classification tasks, where different users usually label a single image or text similarly. This makes accurately learning a distribution of texts much more dangerous. On one hand, the model would be able to map users’ names to what they write, which is a major privacy concern. On the other hand, it would then be easier for malicious users to be hardly discernible from most other genuine users, while providing very dangerous texts to replicate. (p. 4)\nData is often signed (and if it is not, then it should be regarded as highly untrustworthy). In fact, it is commonly accepted that the traceability of data sources is a critical security condition [110], [139], as well as a powerful epistemological tools [9]. Thus, our setting allows us to work under the arguably realistic assumption that, if some data from user n’s dataset Dn are known to be harmfully crafted, then the entire dataset Dn is likely to be untrustworthy as well. Unfortunately, the study on data poisoning with signed data has been lacking. (p. 5)\nUnfortunately, homogeneity is an unrealistic assumption for the training of foundation models. Put differently, the fundamental vulnerability of foundation models is tightly connected to the fundamental heterogeneity in the way different users speak and write, and to the additional empirical heterogeneity due to the users’ limited datasets (which cannot be representative of the full distribution from which the users draw their texts and speeches). These data are not drawn from a fixed common data distribution. (p. 6)\nOverall, given the huge (financial) stakes of the rushed deployment of privacy-violating foundation models, we urgently call the scientific community to adopt a significantly increased rigor when reviewing the positive claims of (differential) privacy in machine learning in general, and in training large models in particular. Large technology companies have been known to ask their researchers to “strike a positive tone” [39] and to skew the message of their scientific publications13, in a manner unfortunately reminiscent of previous scientific disinformation campaigns led by, e.g., the tobacco, sugar and oil industries [140], [141]. (p. 8)\nYet, what a foundation model has learned from one phone, may be used to provide autocompletion on other users’ phones. Even if each phone is using a personalized model, as long as the models are large enough, lower bounds such as in Theorem 1 imply a large value of the privacy guarantee ε, thus practically no privacy and ease of attacks. (p. 10)\nIf trained on large amounts of unsafe data, such algorithms may thereby be manipulated into promoting (harmful) product consumption, autocratic power, warmongering and radicalized convictions, which could fuel dangerous movements worldwide. Their vulnerability should not be neglected, especially for continuously learning conversational algorithms like Facebook’s Blender Bot 2.0 [187], [105]. Conversely, there is a high risk that some owners of these algorithms exploit them to favor their own cause, e.g. to subtly support their (dis)information war by inducing small biases in their foundation models. (p. 11)\nHowever, there is currently no reliable and robust solution to the alignment problem, and a strong theory of robust alignment for foundation models is arguably lacking. In fact, what may be most lacking today is a large-scale secure database of reliable human judgments to solve alignment [81]. (p. 12)\nNotes\n\nComment: 13 pages\n@article{El-Mhamdi_Farhadkhani_Guerraoui_Gupta_Hoang_Pinot_Stephan_2022, title={SoK: On the Impossible Security of Very Large Foundation Models}, url={[arxiv.org/abs/2209.15259](arxiv.org/abs/2209.15259)}, DOI={[10.48550/arXiv.2209.15259](doi.org/10.48550/arXiv.2209.15259)}, abstractNote={Large machine learning models, or so-called foundation models, aim to serve as base-models for application-oriented machine learning. Although these models showcase impressive performance, they have been empirically found to pose serious security and privacy issues. We may however wonder if this is a limitation of the current models, or if these issues stem from a fundamental intrinsic impossibility of the foundation model learning problem itself. This paper aims to systematize our knowledge supporting the latter. More precisely, we identify several key features of today’s foundation model learning problem which, given the current understanding in adversarial machine learning, suggest incompatibility of high accuracy with both security and privacy. We begin by observing that high accuracy seems to require (1) very high-dimensional models and (2) huge amounts of data that can only be procured through user-generated datasets. Moreover, such data is fundamentally heterogeneous, as users generally have very specific (easily identifiable) data-generating habits. More importantly, users’ data is filled with highly sensitive information, and maybe heavily polluted by fake users. We then survey lower bounds on accuracy in privacy-preserving and Byzantine-resilient heterogeneous learning that, we argue, constitute a compelling case against the possibility of designing a secure and privacy-preserving high-accuracy foundation model. We further stress that our analysis also applies to other high-stake machine learning applications, including content recommendation. We conclude by calling for measures to prioritize security and privacy, and to slow down the race for ever larger models.}, note={arXiv:2209.15259 [cs]}, number={arXiv:2209.15259}, publisher={arXiv}, author={El-Mhamdi, El-Mahdi and Farhadkhani, Sadegh and Guerraoui, Rachid and Gupta, Nirupam and Hoang, Lê-Nguyên and Pinot, Rafael and Stephan, John}, year={2022}, month={Sep} }\n"},"highlights/Zotero/fernandes_2023":{"title":"Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation","links":[],"tags":[],"content":"Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nAbstract\nMany recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.\n \n@misc{Fernandes_Madaan_Liu_Farinhas_Martins_Bertsch_de Souza_Zhou_Wu_Neubig_et al._2023, title={Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation}, url={[arxiv.org/abs/2305.00955v1](arxiv.org/abs/2305.00955v1)}, abstractNote={Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.}, note={{&quot;size&quot;: 394060, “pages”: 24, “previous”: &quot; &quot;}}, journal={arXiv.org}, author={Fernandes, Patrick and Madaan, Aman and Liu, Emmy and Farinhas, António and Martins, Pedro Henrique and Bertsch, Amanda and de Souza, José G. C. and Zhou, Shuyan and Wu, Tongshuang and Neubig, Graham and Martins, André F. T.}, year={2023}, month=may, language={en} }\n"},"highlights/Zotero/geiping_2022":{"title":"Cramming: Training a Language Model on a Single GPU in One Day","links":[],"tags":[],"content":"Cramming: Training a Language Model on a Single GPU in One Day\nAbstract\nRecent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners. While most in the community are asking how to push the limits of extreme computation, we ask the opposite question: How far can we get with a single GPU in just one day? We investigate the downstream performance achievable with a transformer-based language model trained completely from scratch with masked language modeling for a single day on a single consumer GPU. Aside from re-analyzing nearly all components of the pretraining pipeline for this scenario and providing a modiﬁed pipeline with performance close to BERT, we investigate why scaling down is hard, and which modiﬁcations actually improve performance in this scenario. We provide evidence that even in this constrained setting, performance closely follows scaling laws observed in large-compute settings. Through the lens of scaling laws, we categorize a range of recent improvements to training and architecture and discuss their merit and practical applicability (or lack thereof) for the limited compute setting.\nWe pack tokenized data into randomized sequences of length 128 and separate unrelated fragments by &lt;sep&gt; The performance impact from dropping this separator was minimal. No impact was observed from including a &lt;cls&gt; token in pretraining. (p. 5)\nWe observe that varying the transformer type and size has only minimal impact on the final loss after 24 hours. Models with more parameters learn more efficiently, as their MLM loss decreases faster on a per-gradient basis. However, smaller architectures make up for their slower learning efficiency by higher throughput, and thus process more tokens over the limited budget. (p. 6)\nWe further keep the original multi-head self-attention mechanism. A large amount of work has been focused on efficient attention (Sukhbaatar et al., 2019; Beltagy et al., 2020; Wang et al., 2020a; Liu et al., 2021c) and studies of efficient attention (Tay et al., 2020a;b). But, because we set the maximal sequence length to 128, attention complexity is less of a concern in our setting. To verify this, we implement the recently proposed FLASH mechanism (Hua et al., 2022), but find no benefits. We further experiment with Fourier attention as proposed in Lee-Thorp et al. (2021), but find no improvements. We find rotary embeddings (Su et al., 2021; Black et al., 2022), to provide small benefits, but these are evened out by the drop in speed, so we ultimately decide against these. (p. 6)\nAs observed in many studies, we find that pre-normalization with Layer Norms is beneficial over post Layer Norms (Baevski &amp; Auli, 2018; Xiong et al., 2020). (p. 6)\nBoth triangular-shaped one-cycle schedules have better end-time behavior, possibly due to the quick annealing. (p. 7)\nWe find that a simple one-cycle learning rate (Smith &amp; Topin, 2018) with a peak learning rate of 10−3 leads to minimal pretraining loss within our budget. (p. 7)\nWe first evaluate deduplication as described in Lee et al. (2022) via exact substring deduplication, but find this not to help in downstream performance in our case. (p. 9)\nWe then test filtering for uncompressible data. We use the tokenizer itself to remove all training sequences from C4 set that cannot be compressed well; we simply set a threshold t, e.g. t = 0.3, and drop all entries from the dataset where the number of tokens in the entry is larger than t times the number of raw characters. This removes, for example, sequences consisting of hard-to-compress HTML or markdown code. Surprisingly, this results in a measurable improvement on C4, summarized in Table 2. (p. 9)\nWe pack tokenized data into randomized sequences of length 128 and separate unrelated fragments by &lt;sep&gt; The performance impact from dropping this separator was minimal. No impact was observed from including a &lt;cls&gt; token in pretraining. (p. 5)\nWe observe that varying the transformer type and size has only minimal impact on the final loss after 24 hours. Models with more parameters learn more efficiently, as their MLM loss decreases faster on a per-gradient basis. However, smaller architectures make up for their slower learning efficiency by higher throughput, and thus process more tokens over the limited budget. (p. 6)\nWe further keep the original multi-head self-attention mechanism. A large amount of work has been focused on efficient attention (Sukhbaatar et al., 2019; Beltagy et al., 2020; Wang et al., 2020a; Liu et al., 2021c) and studies of efficient attention (Tay et al., 2020a;b). But, because we set the maximal sequence length to 128, attention complexity is less of a concern in our setting. To verify this, we implement the recently proposed FLASH mechanism (Hua et al., 2022), but find no benefits. We further experiment with Fourier attention as proposed in Lee-Thorp et al. (2021), but find no improvements. We find rotary embeddings (Su et al., 2021; Black et al., 2022), to provide small benefits, but these are evened out by the drop in speed, so we ultimately decide against these. (p. 6)\nAs observed in many studies, we find that pre-normalization with Layer Norms is beneficial over post Layer Norms (Baevski &amp; Auli, 2018; Xiong et al., 2020). (p. 6)\nBoth triangular-shaped one-cycle schedules have better end-time behavior, possibly due to the quick annealing. (p. 7)\nWe find that a simple one-cycle learning rate (Smith &amp; Topin, 2018) with a peak learning rate of 10−3 leads to minimal pretraining loss within our budget. (p. 7)\nWe first evaluate deduplication as described in Lee et al. (2022) via exact substring deduplication, but find this not to help in downstream performance in our case. (p. 9)\nWe then test filtering for uncompressible data. We use the tokenizer itself to remove all training sequences from C4 set that cannot be compressed well; we simply set a threshold t, e.g. t = 0.3, and drop all entries from the dataset where the number of tokens in the entry is larger than t times the number of raw characters. This removes, for example, sequences consisting of hard-to-compress HTML or markdown code. Surprisingly, this results in a measurable improvement on C4, summarized in Table 2. (p. 9)\nNotes\n\nComment: 22 pages, we provide code at github.com/JonasGeiping/cramming\n@article{Geiping_Goldstein_2022, title={Cramming: Training a Language Model on a Single GPU in One Day}, url={[arxiv.org/abs/2212.14034](arxiv.org/abs/2212.14034)}, abstractNote={Recent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners. While most in the community are asking how to push the limits of extreme computation, we ask the opposite question: How far can we get with a single GPU in just one day? We investigate the downstream performance achievable with a transformer-based language model trained completely from scratch with masked language modeling for a single day on a single consumer GPU. Aside from re-analyzing nearly all components of the pretraining pipeline for this scenario and providing a modiﬁed pipeline with performance close to BERT, we investigate why scaling down is hard, and which modiﬁcations actually improve performance in this scenario. We provide evidence that even in this constrained setting, performance closely follows scaling laws observed in large-compute settings. Through the lens of scaling laws, we categorize a range of recent improvements to training and architecture and discuss their merit and practical applicability (or lack thereof) for the limited compute setting.}, note={0 citations (Semantic Scholar/arXiv) [2023-01-06] arXiv:2212.14034 [cs]}, number={arXiv:2212.14034}, publisher={arXiv}, author={Geiping, Jonas and Goldstein, Tom}, year={2022}, month={Dec}, language={en} }\n"},"highlights/Zotero/gudibande_2023":{"title":"The False Promise of Imitating Proprietary LLMs","links":[],"tags":[],"content":"The False Promise of Imitating Proprietary LLMs\nAbstract\nAn emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model’s capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B—13B), data sources, and imitation data amounts (0.3M—150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models — they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT’s style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.\nInitially, we were surprised by the output quality of our imitation models—they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. (p. 1)\nFor example, training on 100k ChatGPT outputs from broad-coverage user inputs provides no benefits to Natural Questions accuracy (e.g., Figure 1, center), but training exclusively on ChatGPT responses for Natural-Questions-like queries drastically improves task accuracy. Consequently, we conclude that broadly matching ChatGPT using purely imitation would require (1) a concerted effort to collect enormous imitation datasets and (2) far more diverse and higher quality imitation data than is currently available. (p. 2)\nThis implies that the higher leverage action for improving open-source LMs is to tackle the difficult challenge of developing better base models (e.g. by scaling up models, improving pre-training data quality, improving pre-training, etc.), rather than taking the shortcut of imitating proprietary systems. Nevertheless, we believe that model imitation has utility in subverting the need to annotate high-quality finetuning data if one has a sufficiently strong base LM. (p. 3)\nWe find that GPT-4 and crowdworker evaluations show the same trends. As we scale up the amount of imitation data, GPT-4’s ratings of our imitation models are relatively flat (left). However, as we scale up the base model size, GPT-4’s rates the quality of our imitation models increasingly highly (right). (p. 5)\nWe find that imitation models perform well according to human evaluations because they are adept at mimicking ChatGPT’s style—they output fluent, confident, and well-structured answers. In particular, we show in Table 2 that as we add more imitation data, ChatGPT and our imitation models produce outputs with a similar length, similar word choice, similar use of an authoritative tone, and similar low-level structure (e.g., use of lists). (p. 7)\n@article{Gudibande_Wallace_Snell_Geng_Liu_Abbeel_Levine_Song_2023, title={The False Promise of Imitating Proprietary LLMs}, url={[arxiv.org/abs/2305.15717](arxiv.org/abs/2305.15717)}, DOI={[10.48550/arXiv.2305.15717](doi.org/10.48550/arXiv.2305.15717)}, abstractNote={An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model’s capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models -- they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT’s style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.}, note={arXiv:2305.15717 [cs]}, number={arXiv:2305.15717}, publisher={arXiv}, author={Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn}, year={2023}, month={May} }\n"},"highlights/Zotero/jiang_2023":{"title":"Mistral 7B","links":[],"tags":[],"content":"Mistral 7B\nAbstract\nWe introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B — Instruct, that surpasses the Llama 2 13B — Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.\n\nNote that tokens outside the sliding window still influence next word prediction. At each attention layer, information can move forward by W tokens. Hence, after k attention layers, information can move forward by up to k × W tokens. (p. 2)\n\n\nSliding Window Attention. SWA exploits the stacked layers of a transformer to attend information beyond the window size W . The hidden state in position i of the layer k, hi, attends to all hidden states from the previous layer with positions between i − W and i. Recursively, hi can access tokens from the input layer at a distance of up to W × k tokens, as illustrated in Figure 1. (p. 2)\n\n\nRolling Buffer Cache. A fixed attention span means that we can limit our cache size using a rolling buffer cache. The cache has a fixed size of W , and the keys and values for the timestep i are stored in position i mod W of the cache. As a result, when the position i is larger than W , past values in the cache are overwritten, and the size of the cache stops increasing. (p. 2)\n\n\nPre-fill and Chunking. When generating a sequence, we need to predict tokens one-by-one, as each token is conditioned on the previous ones. However, the prompt is known in advance, and we can pre-fill the (k, v) cache with the prompt. If the prompt is very large, we can chunk it into smaller pieces, and pre-fill the cache with each chunk. For this purpose, we can select the window size as our chunk size. For each chunk, we thus need to compute the attention over the cache and over the chunk. (p. 3)\n\n \n@misc{Jiang_Sablayrolles_Mensch_Bamford_Chaplot_Casas_Bressand_Lengyel_Lample_Saulnier_et al._2023, title={Mistral 7B}, url={[arxiv.org/abs/2310.06825v1](arxiv.org/abs/2310.06825v1)}, abstractNote={We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.}, journal={arXiv.org}, author={Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and Lavaud, Lélio Renard and Lachaux, Marie-Anne and Stock, Pierre and Scao, Teven Le and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and Sayed, William El}, year={2023}, month=oct, language={en} }\n"},"highlights/Zotero/jin_2024":{"title":"LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning","links":[],"tags":[],"content":"LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning\nAbstract\nThis work elicits LLMs’ inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs’ context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs’ long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model’s self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs’ context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs’ context window’s length.\n\nTo address this, an intuitive and practical solution would be to remap the unseen relative positions to those encountered during the pretraining, thus extending the LLMs’ ability to handle longer contexts naturally. (p. 2)\n\n\nSince natural language texts tend to have similar semantics within a short range (e.g. a paragraph), close or even equal position encodings should be adequate for maintaining the relative ordering of useful information. This aligns with the floor operation. 2) In natural language texts, most of the time, while a small bag of words (ngrams) appears together in one area, all the tokens in that bag have only one possible order due to the conventions of the language grammar. Although theoretically, a bag of tokens could appear in any order, in practice it is rare for a small set of words to have more than one sensible ordering. For example, ”unnecessary encodings” can be tokenized as ”unn”, ”ecessary”, ” enc” and ”odings”2, but these tokens can only meaningfully appear in that order. (p. 2)\n\n\n\nTo conclude, we still need to keep the attention mechanism unchanged in the neighbor area, which would be the normal attention used in the pretraining stage. (p. 4)\n\n \n\nThe results also demonstrated that: although Mistral w/ SWA has low PPL beyond its pretraining context window, it can only access information (i.e. the passkey) within its sliding window. Considering the simplicity of this task, this result strongly suggests it still does not have true ability to handle long contexts. (p. 6)\n\n\nLimitation: The limitation of the proposed Self-Extend in- cludes the lack of implementation of Flash Attention (Dao et al., 2022) and the performance degradation with too large group size, which means the context window still cannot be extended to infinity with current SelfExtend. Meanwhile, like many regular tasks, there is still no consensus at present about how to do evaluation for long context tasks, which may cause problematic evaluation results. (p. 9)\n\n@misc{Jin_Han_Yang_Jiang_Liu_Chang_Chen_Hu_2024, title={LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning}, url={[arxiv.org/abs/2401.01325v1](arxiv.org/abs/2401.01325v1)}, abstractNote={This work elicits LLMs’ inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs’ context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs’ long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model’s self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs’ context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can effectively extend existing LLMs’ context window’s length.}, note={{&quot;size&quot;: -1, “pages”: -1, “previous”: &quot; &quot;}}, journal={arXiv.org}, author={Jin, Hongye and Han, Xiaotian and Yang, Jingfeng and Jiang, Zhimeng and Liu, Zirui and Chang, Chia-Yuan and Chen, Huiyuan and Hu, Xia}, year={2024}, month=jan, language={en} }\n"},"highlights/Zotero/kalluri_2023":{"title":"The Surveillance AI Pipeline","links":[],"tags":[],"content":"The Surveillance AI Pipeline\nAbstract\nA rapidly growing number of voices argue that AI research, and computer vision in particular, is powering mass surveillance. Yet the direct path from computer vision research to surveillance has remained obscured and difficult to assess. Here, we reveal the Surveillance AI pipeline by analyzing three decades of computer vision research papers and downstream patents, more than 40,000 documents. We find the large majority of annotated computer vision papers and patents self-report their technology enables extracting data about humans. Moreover, the majority of these technologies specifically enable extracting data about human bodies and body parts. We present both quantitative and rich qualitative analysis illuminating these practices of human data extraction. Studying the roots of this pipeline, we find that institutions that prolifically produce computer vision research, namely elite universities and “big tech” corporations, are subsequently cited in thousands of surveillance patents. Further, we find consistent evidence against the narrative that only these few rogue entities are contributing to surveillance. Rather, we expose the fieldwide norm that when an institution, nation, or subfield authors computer vision papers with downstream patents, the majority of these papers are used in surveillance patents. In total, we find the number of papers with downstream surveillance patents increased more than five-fold between the 1990s and the 2010s, with computer vision research now having been used in more than 11,000 surveillance patents. Finally, in addition to the high levels of surveillance we find documented in computer vision papers and patents, we unearth pervasive patterns of documents using language that obfuscates the extent of surveillance. Our analysis reveals the pipeline by which computer vision research has powered the ongoing expansion of surveillance.\n\n\nWe find substantial evidence against the narrative of only a few rogue entities contributing to surveillance. Rather, we identify a pervasive norm: when an institution or nation authors computer vision papers with downstream patents, the majority are used in surveillance patents. (Figure 4 bottom, institutions’ and nations’ vertical grey bars are consistently above the orange 50% threshold.) This norm describes the behavior of 74% of institutions and 83% of nations, evidencing the wide-spanning normalization of computer vision used in surveillance. Similarly, we find substantial evidence against the narrative that there are merely a few implicated subfields of computer vision within a broader non-surveillance-oriented field. Rather, we find the continuation of the norm: when a subfield produces computer vision papers with downstream patents, the majority are used in surveillance patents. (p. 9)\n\n\nOur findings indicate that, across institutions, nations, and subfields, the practice of producing computer vision that enables surveillance is a pervasive fieldwide norm. (p. 9)\n\n\nMany papers conflate humans with objects, making no note of how performing tasks like detection or segmentation on people has extremely specific, and socially consequential impacts. (p. 10)\n\n\nConsidering humans as objects implies that any knowledge produced related to object-focused tasks can be directly applied to human data. This assumption neatly abstracts away the ways that such methods can be applied to surveillance. This phenomenon also ties to literature about traditional science’s sharp divide between subject and object, which positions scientists as the studiers of “objects” out there. This “splitting of subject and object” facilitates “denial of responsibility and critical inquiry” [41]. This contextualizes the field’s homogenization of all possible data, including human data, into objects to be studied, often without consent and without consideration of their sources or consequences. (p. 10)\n\n\nThe studies presented in this paper ultimately reveal that the field of computer vision is not merely a neutral pursuit of knowledge; it is a foundational layer for a paradigm of surveillance. Our findings include these striking points: 90% of papers and patents emphasize it as a strength that their technologies can target human data. Not only is human data broadly targeted, but the majority (68%) of papers and patents explicitly focus on surveillance of human body parts (e.g., faces) and human bodies. Between the 1990s and 2010s, we have seen the rise of Surveillance AI, and it has become an overwhelming norm that computer vision papers analyze humans, and those papers used in patents are most likely used in surveillance patents. Moreover, even when a paper does not explicitly state surveillance as an application, it provides the methods to do so and is grounded in a historical context that makes it possible to target human surveillance while minimizing the acknowledgement of these intentions. (p. 11)\n\n\nScientific findings are frequently falsely presented as facts that emerge from an objective “view from nowhere”, in a historical, cultural, and contextual vacuum. Such views of science as “value-free” and “neutral” have been debunked by a variety of scholarships, from philosophy of science, STS and feminist and decolonial studies. A purported view from nowhere is always a view from somewhere and usually a view from those with the greatest power [41, 42, 46, 62]. Social and cultural histories and norms, funding priorities, academic trends, researcher objectives, and research incentives, for example, all inevitably constrain and shape the direction and production of scientific knowledge [8, 17, 32, 33]. An assemblage of social forces have shaped computer vision, resulting in a field that now fuels the mass production of Surveillance AI. (p. 11)\n\n@misc{Kalluri_Agnew_Cheng_Owens_Soldaini_Birhane_2023, title={The Surveillance AI Pipeline}, url={[arxiv.org/abs/2309.15084v2](arxiv.org/abs/2309.15084v2)}, abstractNote={A rapidly growing number of voices argue that AI research, and computer vision in particular, is powering mass surveillance. Yet the direct path from computer vision research to surveillance has remained obscured and difficult to assess. Here, we reveal the Surveillance AI pipeline by analyzing three decades of computer vision research papers and downstream patents, more than 40,000 documents. We find the large majority of annotated computer vision papers and patents self-report their technology enables extracting data about humans. Moreover, the majority of these technologies specifically enable extracting data about human bodies and body parts. We present both quantitative and rich qualitative analysis illuminating these practices of human data extraction. Studying the roots of this pipeline, we find that institutions that prolifically produce computer vision research, namely elite universities and “big tech” corporations, are subsequently cited in thousands of surveillance patents. Further, we find consistent evidence against the narrative that only these few rogue entities are contributing to surveillance. Rather, we expose the fieldwide norm that when an institution, nation, or subfield authors computer vision papers with downstream patents, the majority of these papers are used in surveillance patents. In total, we find the number of papers with downstream surveillance patents increased more than five-fold between the 1990s and the 2010s, with computer vision research now having been used in more than 11,000 surveillance patents. Finally, in addition to the high levels of surveillance we find documented in computer vision papers and patents, we unearth pervasive patterns of documents using language that obfuscates the extent of surveillance. Our analysis reveals the pipeline by which computer vision research has powered the ongoing expansion of surveillance.}, note={{&quot;size&quot;: 3273321, “pages”: 23, “previous”: &quot; &quot;}}, journal={arXiv.org}, author={Kalluri, Pratyusha Ria and Agnew, William and Cheng, Myra and Owens, Kentrell and Soldaini, Luca and Birhane, Abeba}, year={2023}, month=sep, language={en} }\n"},"highlights/Zotero/kojima_2022":{"title":"Large Language Models Are Zero-Shot Reasoners","links":[],"tags":[],"content":"Large Language Models Are Zero-Shot Reasoners\nAbstract\nPretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs’ ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding “Let’s think step by step” before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with an off-the-shelf 175B parameter model. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted through simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.\nbut also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars. (p. 1)\nchain of thought prompting (CoT), which feed LLMs with the step-by-step reasoning examples rather than standard question and answer examples (see Fig. 1-a). Such chain of thought demonstrations facilitate models to generate a reasoning path that decomposes the complex reasoning into multiple easier steps. Notably with CoT, the reasoning performance then satisfies the scaling laws better and jumps up with the size of the language models. (p. 2)\nthe versatility of this single prompt across diverse reasoning tasks hints at untapped and understudied zero-shot fundamental capabilities of LLMs, such as higher-level broad cognitive capabilities like generic logical reasoning [Chollet, 2019]. (p. 3)\nIn commonsense reasoning tasks, Zero-shot-CoT does not provide performance gains. It is expected as Wei et al. [2022] also reports that even Few-shot-CoT does not provide performance gains on Lambda (135B), but does improve StrategyQA when combined with substantially larger PaLM (540B) model, which may also apply for ours. (p. 5)\n(1) In commonsense reasoning (CommonsenseQA), Zero-shot-CoT often produces flexible and reasonable chain of thought even when the final prediction is not correct. (p. 6)\nZero-shot-CoT often output multiple answer choices when the model find it is difficult to narrow it down to one (p. 6)\nWithout chain of thought reasoning, the performance does not increase or increases slowly as the model scale is increased, i.e., the curve is mostly flat. In contrast, the performance drastically increases with chain of thought reasoning, as the model size gets bigger. (p. 7)\nWhen the model size is smaller, chain of thought reasoning is not effective. (p. 7)\nbut also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars. (p. 1)\nchain of thought prompting (CoT), which feed LLMs with the step-by-step reasoning examples rather than standard question and answer examples (see Fig. 1-a). Such chain of thought demonstrations facilitate models to generate a reasoning path that decomposes the complex reasoning into multiple easier steps. Notably with CoT, the reasoning performance then satisfies the scaling laws better and jumps up with the size of the language models. (p. 2)\nthe versatility of this single prompt across diverse reasoning tasks hints at untapped and understudied zero-shot fundamental capabilities of LLMs, such as higher-level broad cognitive capabilities like generic logical reasoning [Chollet, 2019]. (p. 3)\nIn commonsense reasoning tasks, Zero-shot-CoT does not provide performance gains. It is expected as Wei et al. [2022] also reports that even Few-shot-CoT does not provide performance gains on Lambda (135B), but does improve StrategyQA when combined with substantially larger PaLM (540B) model, which may also apply for ours. (p. 5)\n(1) In commonsense reasoning (CommonsenseQA), Zero-shot-CoT often produces flexible and reasonable chain of thought even when the final prediction is not correct. (p. 6)\nZero-shot-CoT often output multiple answer choices when the model find it is difficult to narrow it down to one (p. 6)\nWithout chain of thought reasoning, the performance does not increase or increases slowly as the model scale is increased, i.e., the curve is mostly flat. In contrast, the performance drastically increases with chain of thought reasoning, as the model size gets bigger. (p. 7)\nWhen the model size is smaller, chain of thought reasoning is not effective. (p. 7)\n@book{Kojima_Gu_Reid_Matsuo_Iwasawa_2022, title={Large Language Models are Zero-Shot Reasoners}, url={[arxiv.org/abs/2205.11916](arxiv.org/abs/2205.11916)}, DOI={[10.48550/arXiv.2205.11916](doi.org/10.48550/arXiv.2205.11916)}, abstractNote={Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs’ ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding ``Let’s think step by step’’ before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with an off-the-shelf 175B parameter model. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted through simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.}, note={0 citations (Semantic Scholar/arXiv) [2022-05-26]  arXiv:2205.11916 [cs] type: article}, number={arXiv:2205.11916}, institution={arXiv}, author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke}, year={2022}, month={May} }\n"},"highlights/Zotero/krzywinski_2013":{"title":"Error bars","links":[],"tags":[],"content":"Error bars\nAbstract\nThe meaning of error bars is often misinterpreted, as is the statistical significance of their overlap.\nError bars based on s.d. inform us about the spread of the population and are therefore useful as predictors of the range of new samples. They can also be used to draw attention to very large or small population spreads. Because s.d. bars only indirectly support visual assessment of differences in values, if you use them, be ready to help your reader understand that the s.d. bars reflect the variation of the data and not the error in your measurement. What should a reader conclude from the very large and overlapping s.d. error bars for P = 0.05 in Figure 1b? That although the means differ, and this can be detected with a sufficiently large sample size, there is considerable overlap in the data from the two populations. (p. 1)\nUnlike s.d. bars, error bars based on the s.e.m. reflect the uncertainty in the mean and its dependency on the sample size, n (s.e.m. = s.d./√n). Intuitively, s.e.m. bars shrink as we perform more measurements. Unfortunately, the commonly held view that “if the s.e.m. bars do not overlap, the difference between the values is statistically significant” is incorrect. For example, when n = 10 and s.e.m. bars just touch, P = 0.17 (Fig. 1a). Conversely, to reach P = 0.05, s.e.m. bars for these data need to be about 0.86 arm lengths apart (Fig. 1b). We cannot overstate the importance of recognizing the difference between s.d. and s.e.m. (p. 1)\nThe third type of error bar you are likely to encounter is that based on the CI. This is an interval estimate that indicates the reliability of a measurement3. When scaled to a specific confidence level (CI%)—the 95% CI being common—the bar captures the population mean CI% of the time (Fig. 2a). (p. 1)\n"},"highlights/Zotero/kudugunta_2023":{"title":"MADLAD-400: A Multilingual And Document-Level Large Audited Dataset","links":[],"tags":[],"content":"MADLAD-400: A Multilingual And Document-Level Large Audited Dataset\nAbstract\nWe introduce MADLAD-400, a manually audited, general domain 3T token monolingual dataset based on CommonCrawl, spanning 419 languages. We discuss the limitations revealed by self-auditing MADLAD-400, and the role data auditing had in the dataset creation process. We then train and release a 10.7B-parameter multilingual machine translation model on 250 billion tokens covering over 450 languages using publicly available data, and find that it is competitive with models that are significantly larger, and report the results on different domains. In addition, we train a 8B-parameter language model, and assess the results on few-shot translation. We make the baseline models available to the research community.\nThe motivation for not releasing “nonsense” or tiny datasets is to avoid giving a false sense of how multilingual the dataset is (“Representation washing”), as recommended by Quality at a Glance [40]. (p. 3)\nNotes\n\nComment: Preprint\n@article{Kudugunta_Caswell_Zhang_Garcia_Choquette-Choo_Lee_Xin_Kusupati_Stella_Bapna_et al._2023, title={MADLAD-400: A Multilingual And Document-Level Large Audited Dataset}, url={[arxiv.org/abs/2309.04662](arxiv.org/abs/2309.04662)}, DOI={[10.48550/arXiv.2309.04662](doi.org/10.48550/arXiv.2309.04662)}, abstractNote={We introduce MADLAD-400, a manually audited, general domain 3T token monolingual dataset based on CommonCrawl, spanning 419 languages. We discuss the limitations revealed by self-auditing MADLAD-400, and the role data auditing had in the dataset creation process. We then train and release a 10.7B-parameter multilingual machine translation model on 250 billion tokens covering over 450 languages using publicly available data, and find that it is competitive with models that are significantly larger, and report the results on different domains. In addition, we train a 8B-parameter language model, and assess the results on few-shot translation. We make the baseline models available to the research community.}, note={arXiv:2309.04662 [cs]}, number={arXiv:2309.04662}, publisher={arXiv}, author={Kudugunta, Sneha and Caswell, Isaac and Zhang, Biao and Garcia, Xavier and Choquette-Choo, Christopher A. and Lee, Katherine and Xin, Derrick and Kusupati, Aditya and Stella, Romi and Bapna, Ankur and Firat, Orhan}, year={2023}, month={Sep} }\n"},"highlights/Zotero/lee_2022":{"title":"Do Language Models Plagiarize?","links":[],"tags":[],"content":"Do Language Models Plagiarize?\nAbstract\nPast literature has illustrated that language models do not fully understand the context and sensitivity of text and can sometimes memorize phrases or sentences present in their training sets. In this paper, we investigate whether they not only memorize but also plagiarize training samples when generating artificial texts. Our findings support that they, especially GPT-2, reuse particular pieces of texts from the training corpus with or without obfuscation. We have four main results: 1) language models with more capacity plagiarize more; 2) fine-tuned language models demonstrate differing patterns of plagiarism based on characteristics of auxiliary data; 3) sampling from truncated language modeling distributions tends to heighten the degree of plagiarism as opposed to temperature sampling, and 4) plagiarism in language models can have serious privacy consequences. Overall, our work implies that future research on neural language models should take precautions to avoid models plagiarizing their training datasets.\nWe have four main results: 1) language models with more capacity plagiarize more; 2) fine-tuned language models demonstrate differing patterns of plagiarism based on characteristics of auxiliary data; 3) sampling from truncated language modeling distributions tends to heighten the degree of plagiarism as opposed to temperature sampling, and 4) plagiarism in language models can have serious privacy consequences. (p. 1)\nA majority of datasets used to train language models are scraped from the Internet without receiving informed consent from content owners (Brown et al., 2022). That being said, memorization from training samples can be perceived as a violation of copyright and authorship. Other than copying and pasting training sequences, there are other ways to indirectly exploit training examples by paraphrasing or summarizing the original content. This action generally refers to plagiarism, the act of reusing another person’s work without referencing the individual as its owner (Ali et al., 2011). (p. 1)\nOur study is guided by two research questions: (RQ1) Do pre-trained language models plagiarize? and (RQ2) Do finetuned language models plagiarize?. (p. 2)\n1) Model size: Amongst four GPT-2 family, larger models (GPT-2 large and xl) plagiarize more from a training set than smaller models; 2) Fine-tuning Data: There is a positive correlation between document similarity levels between pre-training and fine-tuning sets and plagiarism; 3) Decoding methods and values of their parameters: Plagiarism cases differ depending on decoding approaches and parameter values. (p. 2)\nPlagiarism occurs when any content including text, source code, or audio-visual content is reused without permission or citation from an author of original work. It has been a longstanding problem, especially in educational and research institutions or publishers, given the availability of digital artifacts (Sutherland-Smith, 2008; Clarke, 2006). (p. 3)\nIn this work, we focus on three plagiarism types: • Verbatim plagiarism: exact copies of words or phrases without transformation. • Paraphrase plagiarism: synonymous substitution, word reordering, and back translation. • Idea plagiarism: reuse of the core idea by shortening or summarizing the original content (p. 4)\nSince OpenAI has not publicly released WebText, we use OpenWebText which is an opensource recreation of the WebText corpus.8 Given that the size of OpenWebtext corpus matches the size described in Radford et al. (2019), we assume it is a reliable source. (p. 5)\nWe set a confidence threshold to 0.7. A total number of plagiarized documents that reveal PII entities is displayed in Figure 2. Of 1,736 plagiarized sequences, nearly 26% include at least one element of location information and a person’s full name. Although none of the highly sensitive information, including individuals’ driver’s license number, credit card information, bank number, social security number, and IP address, are revealed, the results show a possibility of machine-generated texts disseminating personal data such as phone number and email address not only through exact copying but also through paraphrasing. (p. 6)\n@article{Lee_Le_Chen_Lee_2022, title={Do Language Models Plagiarize?}, url={[arxiv.org/abs/2203.07618](arxiv.org/abs/2203.07618)}, DOI={[10.48550/arXiv.2203.07618](doi.org/10.48550/arXiv.2203.07618)}, abstractNote={Past literature has illustrated that language models do not fully understand the context and sensitivity of text and can sometimes memorize phrases or sentences present in their training sets. In this paper, we investigate whether they not only memorize but also plagiarize training samples when generating artificial texts. Our findings support that they, especially GPT-2, reuse particular pieces of texts from the training corpus with or without obfuscation. We have four main results: 1) language models with more capacity plagiarize more; 2) fine-tuned language models demonstrate differing patterns of plagiarism based on characteristics of auxiliary data; 3) sampling from truncated language modeling distributions tends to heighten the degree of plagiarism as opposed to temperature sampling, and 4) plagiarism in language models can have serious privacy consequences. Overall, our work implies that future research on neural language models should take precautions to avoid models plagiarizing their training datasets.}, note={1 citations (Semantic Scholar/arXiv) [2023-01-05] 1 citations (Semantic Scholar/DOI) [2023-01-05] arXiv:2203.07618 [cs]}, number={arXiv:2203.07618}, publisher={arXiv}, author={Lee, Jooyoung and Le, Thai and Chen, Jinghui and Lee, Dongwon}, year={2022}, month={Mar} }\n"},"highlights/Zotero/leviathan_2023":{"title":"Fast Inference from Transformers via Speculative Decoding","links":[],"tags":[],"content":"Fast Inference from Transformers via Speculative Decoding\nAbstract\nInference from large autoregressive models like Transformers is slow - decoding K tokens takes K serial runs of the model. In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, by computing several tokens in parallel. At the heart of our approach lie the observations that (1) hard language-modeling tasks often include easier subtasks that can be approximated well by more efficient models, and (2) using speculative execution and a novel sampling method, we can make exact decoding from the large models faster, by running them in parallel on the outputs of the approximation models, potentially generating several tokens concurrently, and without changing the distribution. Our method can accelerate existing off-the-shelf models without retraining or architecture changes. We demonstrate it on T5-XXL and show a 2X-3X acceleration compared to the standard T5X implementation, with identical outputs.\n\nThe core idea is to (1) use the more efﬁcient model Mq to generate γ ∈ Z+ completions (see Section 3.5 for how to optimally choose this parameter), then (2) use the target model Mp to evaluate all of the guesses and their respective probabilities from Mq in parallel, accepting all those that can lead to an identical distribution, and (3) sam- pling an additional token from an adjusted distribution to ﬁx the ﬁrst one that was rejected, or to add an additional one if they are all accepted. That way, each parallel run of the target model Mp will produce at least one new token (so the number of serial runs of the target model can never, even in the worst case, be larger than the simple autoregressive method), but it can potentially generate many new tokens, up to γ + 1, depending on how well Mq approximates Mp. (p. 2)\n\nNotes\n\nComment: ICML 2023 Oral\n@article{Leviathan_Kalman_Matias_2023, title={Fast Inference from Transformers via Speculative Decoding}, url={[arxiv.org/abs/2211.17192](arxiv.org/abs/2211.17192)}, DOI={[10.48550/arXiv.2211.17192](doi.org/10.48550/arXiv.2211.17192)}, abstractNote={Inference from large autoregressive models like Transformers is slow - decoding K tokens takes K serial runs of the model. In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, by computing several tokens in parallel. At the heart of our approach lie the observations that (1) hard language-modeling tasks often include easier subtasks that can be approximated well by more efficient models, and (2) using speculative execution and a novel sampling method, we can make exact decoding from the large models faster, by running them in parallel on the outputs of the approximation models, potentially generating several tokens concurrently, and without changing the distribution. Our method can accelerate existing off-the-shelf models without retraining or architecture changes. We demonstrate it on T5-XXL and show a 2X-3X acceleration compared to the standard T5X implementation, with identical outputs.}, note={arXiv:2211.17192 [cs]}, number={arXiv:2211.17192}, publisher={arXiv}, author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi}, year={2023}, month=may }\n"},"highlights/Zotero/liesenfeld_2023":{"title":"Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators","links":[],"tags":[],"content":"Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators\nAbstract\nLarge language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI’s ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as ‘open source’, many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.\nWe find that while there is a fast-growing list of projects (p. 1)\nbilling themselves as ‘open source’, many inherit undocumented data of dubious legality, few share the all-important instructiontuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. (p. 1)\nOnly three months after OpenAI rolled out ChatGPT, it abruptly discontinued API support for its widely used Codex model that had been available as a “free limited beta” since 2021 [44] — surprising users with only three days’ notice and undercutting at one blowthe reproducibility of at least 100 research papers.1 This is a starkreminder that proprietary systems are designed to offer smooth onboarding and convenience but come at the price of user lock-in and a lack of reliability. (p. 2)\nProprietary systems come with considerable further risks and harms [2, 9]. They tend to be developed without transparent ethical oversight, and are typically rolled out with profit motives that incentivise generating hype over enabling careful scientific work. They allow companies to mask exploitative labour practices, privacy implications [27] and murky copyright situations [49]. (p. 2)\nThe ubiquity of ChatGPT interfaces makes it easy for anyone today to try out some prompt engineering (while freely providing further training data to OpenAI) — but it does not allow one to gain a critical and holistic understanding of the constraints and capabilities of such systems, nor of their risks and harms. (p. 2)\n\nThe derivative nature of synthetic datasets is probably one reason they are released specifically “for research purposes only” [57], with commercial use strictly prohibited. This leads to an important wrinkle. Baize models and data are incorporated in several popular instruction-tuned text generators, including the Falcon family of models which bills itself as ready for “research and commer-cial utilization”4 in direct violation of Baize’s prohibition againstcommercial use. This is merely one example of the complex dependencies embedded in these tools, and the legal quagmires obscured by simple claims of ‘openness’. (p. 4)\nChatGPT was announced in a company blog post and rolled out to the public with an interface designed to capture as much free human labour as possible, but without any technical documentation. (p. 4)\nBut work that documents data provenance and traces harmful impacts [4, 49] deserves major scholarly and societal credit. Here, AI and NLP might benefit from work in software engineering and infrastructure, where strong frameworks already exist to foster accountability for datasets [22, 31, 45]. Interactive model cards [13] offer a promising step towards a humancentered approach to documentation. (p. 4)\nToday’s language technology landscape offers ample opportunities for what philosopher Ivan Illich has called counterfoil research: “Counterfoil research must clarify and dramatize the relationship of people to their tools. It ought to hold constantly before the public the resources that are available and the consequences of their use in various ways. It should impress on people the existence of any trend that threatens one of the major balances of which life depends” [23]. (p. 4)\n@article{Liesenfeld_Lopez_Dingemanse_2023, title={Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators}, url={[arxiv.org/abs/2307.05532](arxiv.org/abs/2307.05532)}, DOI={[10.1145/3571884.3604316](doi.org/10.1145/3571884.3604316)}, abstractNote={Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI’s ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as “open source”, many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.}, note={0 citations (Semantic Scholar/arXiv) [2023-07-17] 0 citations (Semantic Scholar/DOI) [2023-07-17] arXiv:2307.05532 [cs]}, author={Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark}, year={2023}, month={Jul} }\n"},"highlights/Zotero/lourie_2021":{"title":"UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark","links":[],"tags":[],"content":"UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark\nAbstract\nCommonsense AI has long been seen as a near impossible goal — until recently. Now, research interest has sharply increased with an influx of new benchmarks and models. We propose two new ways to evaluate commonsense models, emphasizing their generality on new tasks and building on diverse, recently introduced benchmarks. First, we propose a new multitask benchmark, RAINBOW, to promote research on commonsense models that generalize well over multiple tasks and datasets. Second, we propose a novel evaluation, the cost equivalent curve, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency. We perform extensive experiments — over 200 experiments encompassing 4800 models — and report multiple valuable and sometimes surprising findings, e.g., that transfer almost always leads to better or equivalent performance if following a particular recipe, that QA-based commonsense datasets transfer well with each other, while commonsense knowledge graphs do not, and that perhaps counter-intuitively, larger models benefit more from transfer than smaller ones. Last but not least, we introduce a new universal commonsense reasoning model, UNICORN, that establishes new state-of-the-art performance across 8 popular commonsense benchmarks, aNLI (87.3%), CosmosQA (91.8%), HellaSWAG (93.9%), PIQA (90.1%), SocialIQa (83.2%), WinoGrande (86.6%), CycIC (94.0%) and CommonsenseQA (79.3%).\n\nFirst, we propose a new multitask benchmark, RAINBOW, to promote research on commonsense models that generalize well over multiple tasks and datasets (p. 1)\n\n\na novel evaluation, the cost equivalent curve, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency. (p. 1)\n\n\nwe define cost as the number of training examples in the target dataset. (p. 2)\n\n\nThe construction of cost equivalent curves makes one technical assumption: the relationship between performance and cost is continuous and strictly monotonic (i.e., increasing or decreasing) (p. 2)\n\n\nmultitask training (Caruana 1995): training on multiple datasets (including the target dataset) all at once, (p. 3)\n\n\nmultitask fine-tuning (Liu et al. 2019a): first training on all datasets (including the target dataset) through multitask training, and then continuing to fine-tune on the target dataset alone. (p. 3)\n\n\nFinding 1: Sequential training almost always matches or beats other approaches. (p. 3)\n\n\nFinding 2: Sequential training rarely hurts performance. (p. 4)\n\n\nMultitask training helps most often in the lowdata regime. (p. 4)\n\n\nmultitask learning tends to help when data is scarce, but may hurt performance if data is plentiful. (p. 4)\n\n\nThe off-the-shelf T5’s weights come from multitask pretraining, where many tasks are mixed with a language modeling objective to learn a powerful initialization for the weights. In fact, both GLUE and SUPERGLUE were mixed into the pretraining (Raffel et al. 2019). (p. 5)\n\n\nLarger models benefit more from transfer (p. 5)\n\n\nthe serialized language from the knowledge graphs is not in a QA format, and the knowledge graph completion task is generative while all other tasks are discriminative (p. 6)\n\n\nKnowledge augmented lm\n\nNotes\n\nComment: 27 pages, 19 figures, 34 tables. Accepted to AAAI 2021. For associated code and data see github.com/allenai/rainbow\n@book{Lourie_Bras_Bhagavatula_Choi_2021, title={UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark}, url={[arxiv.org/abs/2103.13009](arxiv.org/abs/2103.13009)}, DOI={[10.48550/arXiv.2103.13009](doi.org/10.48550/arXiv.2103.13009)}, abstractNote={Commonsense AI has long been seen as a near impossible goal -- until recently. Now, research interest has sharply increased with an influx of new benchmarks and models. We propose two new ways to evaluate commonsense models, emphasizing their generality on new tasks and building on diverse, recently introduced benchmarks. First, we propose a new multitask benchmark, RAINBOW, to promote research on commonsense models that generalize well over multiple tasks and datasets. Second, we propose a novel evaluation, the cost equivalent curve, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency. We perform extensive experiments -- over 200 experiments encompassing 4800 models -- and report multiple valuable and sometimes surprising findings, e.g., that transfer almost always leads to better or equivalent performance if following a particular recipe, that QA-based commonsense datasets transfer well with each other, while commonsense knowledge graphs do not, and that perhaps counter-intuitively, larger models benefit more from transfer than smaller ones. Last but not least, we introduce a new universal commonsense reasoning model, UNICORN, that establishes new state-of-the-art performance across 8 popular commonsense benchmarks, aNLI (87.3%), CosmosQA (91.8%), HellaSWAG (93.9%), PIQA (90.1%), SocialIQa (83.2%), WinoGrande (86.6%), CycIC (94.0%) and CommonsenseQA (79.3%).}, note={38 citations (Semantic Scholar/arXiv) [2022-05-23]  arXiv:2103.13009 [cs] type: article}, number={arXiv:2103.13009}, institution={arXiv}, author={Lourie, Nicholas and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin}, year={2021}, month=mar }\n"},"highlights/Zotero/ma_2022":{"title":"Mega: Moving Average Equipped Gated Attention","links":[],"tags":[],"content":"Mega: Moving Average Equipped Gated Attention\nAbstract\nThe design choices in the Transformer attention mechanism, including weak inductive bias and quadratic computational complexity, have limited its application for modeling long sequences. In this paper, we introduce Mega, a simple, theoretically grounded, single-head gated attention mechanism equipped with (exponential) moving average to incorporate inductive bias of position-aware local dependencies into the position-agnostic attention mechanism. We further propose a variant of Mega that offers linear time and space complexity yet yields only minimal quality loss, by efficiently splitting the whole sequence into multiple chunks with fixed length. Extensive experiments on a wide range of sequence modeling benchmarks, including the Long Range Arena, neural machine translation, auto-regressive language modeling, and image and speech classification, show that Mega achieves significant improvements over other sequence models, including variants of Transformers and recent state space models.\nHowever, there are two common drawbacks in the design of attention mechanism: i) weak inductive bias; and ii) quadratic computational complexity. First, the attention mechanism does not assume prior knowledge of the patterns of dependencies between tokens (e.g. positional inductive bias), instead learning to predict the pairwise attention weights directly from data. Second, the cost to compute and store the attention weights is quadratic in the length of the input sequences. (p. 2)\nFormally, an EMA recursively calculates the output sequence Y : yt = α   xt + (1 − α)   yt−1, (2) where α ∈ (0, 1)d is the EMA coefficient representing the degree of weighting decrease, and   is the element-wise product. A higher α discounts older observations faster (see Figure 1). (p. 4)\nThis property favors local dependencies, and limits long-distance dependencies. Despite the recurrent formulation in (2), the computation of EMA can be represented as n individual convolutions, which can be computed efficiently using fast Fourier transforms (FFTs) (see Appendix A for details). (p. 4)\nNotes\n\nComment: 13 pages, 4 figures and 7 tables\n@article{Ma_Zhou_Kong_He_Gui_Neubig_May_Zettlemoyer_2022, title={Mega: Moving Average Equipped Gated Attention}, url={[arxiv.org/abs/2209.10655](arxiv.org/abs/2209.10655)}, DOI={[10.48550/arXiv.2209.10655](doi.org/10.48550/arXiv.2209.10655)}, abstractNote={The design choices in the Transformer attention mechanism, including weak inductive bias and quadratic computational complexity, have limited its application for modeling long sequences. In this paper, we introduce Mega, a simple, theoretically grounded, single-head gated attention mechanism equipped with (exponential) moving average to incorporate inductive bias of position-aware local dependencies into the position-agnostic attention mechanism. We further propose a variant of Mega that offers linear time and space complexity yet yields only minimal quality loss, by efficiently splitting the whole sequence into multiple chunks with fixed length. Extensive experiments on a wide range of sequence modeling benchmarks, including the Long Range Arena, neural machine translation, auto-regressive language modeling, and image and speech classification, show that Mega achieves significant improvements over other sequence models, including variants of Transformers and recent state space models.}, note={0 citations (Semantic Scholar/arXiv) [2022-09-24] arXiv:2209.10655 [cs]}, number={arXiv:2209.10655}, publisher={arXiv}, author={Ma, Xuezhe and Zhou, Chunting and Kong, Xiang and He, Junxian and Gui, Liangke and Neubig, Graham and May, Jonathan and Zettlemoyer, Luke}, year={2022}, month={Sep} }\n"},"highlights/Zotero/malladi_2023":{"title":"Fine-Tuning Language Models with Just Forward Passes","links":[],"tags":[],"content":"Fine-Tuning Language Models with Just Forward Passes\nAbstract\nFine-tuning language models (LMs) has yielded success on diverse downstream tasks, but as LMs grow in size, backpropagation requires a prohibitively large amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients using only two forward passes but are theorized to be catastrophically slow for optimizing large models. In this work, we propose a memory-efficient zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate in-place, thereby fine-tuning LMs with the same memory footprint as inference. For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter model, whereas fine-tuning with backpropagation can train only a 2.7B LM with the same budget. We conduct comprehensive experiments across model types (masked and autoregressive LMs), model scales (up to 66B), and downstream tasks (classification, multiple-choice, and generation). Our results demonstrate that (1) MeZO significantly outperforms in-context learning and linear probing; (2) MeZO achieves comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12x memory reduction; (3) MeZO is compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1). We support our empirical findings with theoretical insights, highlighting how adequate pre-training and task prompts enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting otherwise.\nA classical zeroth-order optimization method (ZO-SGD [83]) uses only differences of loss values to estimate the gradients. Thus in principle, the method can update neural networks with just forward passes, though naive implementation still doubles the memory overhead and classical lower bounds [67, 31] suggest that convergence slows linearly with model size. As such, ZO methods have been applied in deep learning settings to find adversarial examples or tune input embeddings [86, 85] but not to directly optimize large-scale models (see Liu et al. [59] for a survey). (p. 2)\n\n\nNotes\n\nComment: Code available at github.com/princeton-nlp/MeZO\n@article{Malladi_Gao_Nichani_Damian_Lee_Chen_Arora_2023, title={Fine-Tuning Language Models with Just Forward Passes}, url={[arxiv.org/abs/2305.17333](arxiv.org/abs/2305.17333)}, DOI={[10.48550/arXiv.2305.17333](doi.org/10.48550/arXiv.2305.17333)}, abstractNote={Fine-tuning language models (LMs) has yielded success on diverse downstream tasks, but as LMs grow in size, backpropagation requires a prohibitively large amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients using only two forward passes but are theorized to be catastrophically slow for optimizing large models. In this work, we propose a memory-efficient zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate in-place, thereby fine-tuning LMs with the same memory footprint as inference. For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter model, whereas fine-tuning with backpropagation can train only a 2.7B LM with the same budget. We conduct comprehensive experiments across model types (masked and autoregressive LMs), model scales (up to 66B), and downstream tasks (classification, multiple-choice, and generation). Our results demonstrate that (1) MeZO significantly outperforms in-context learning and linear probing; (2) MeZO achieves comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12x memory reduction; (3) MeZO is compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1). We support our empirical findings with theoretical insights, highlighting how adequate pre-training and task prompts enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting otherwise.}, note={0 citations (Semantic Scholar/arXiv) [2023-06-06] arXiv:2305.17333 [cs]}, number={arXiv:2305.17333}, publisher={arXiv}, author={Malladi, Sadhika and Gao, Tianyu and Nichani, Eshaan and Damian, Alex and Lee, Jason D. and Chen, Danqi and Arora, Sanjeev}, year={2023}, month={May} }\n"},"highlights/Zotero/min_":{"title":"FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation","links":[],"tags":[],"content":"FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation\n\nWe also find that, although PerplexityAI provides citations to the references, citations have little correlation with factual precision. 36.0% and 37.6% of supported and unsupported sentences have citations, respectively, indicating that unsupported sentences are in fact marginally more likely to have citations, and the overall citation ratio is low. (p. 6)\n\n\nTogether with independent findings from Liu et al. (2023a) that citations may have low precision and recall, this indicates that commercial language models that incorporate search and provide citations may not be as reliable as expected. (p. 6)\n\n\nAll LMs are substantially less factual than humans. (p. 10)\n\n\nGPT-4 and ChatGPT are significantly more factual than public models. (p. 11)\n\nNotes\n\nTL;DR\nAn automated model is introduced that estimates FACTSCORE using retrieval and a strong language model, and is used to evaluate 6,500 generations from a new set of 13 recent LMs that would have cost $26K if evaluated by humans, with various findings.\n@article{Min_Krishna_Lyu_Lewis_Yih_Koh_Iyyer_Zettlemoyer_Hajishirzi, title={FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation}, author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh}, language={en} }\n"},"highlights/Zotero/muennighoff_2022":{"title":"MTEB: Massive Text Embedding Benchmark","links":[],"tags":[],"content":"MTEB: Massive Text Embedding Benchmark\nAbstract\nText embeddings are commonly evaluated on a small set of datasets from a single task not covering their possible applications to other tasks. It is unclear whether state-of-the-art embeddings on semantic textual similarity (STS) can be equally well applied to other tasks like clustering or reranking. This makes progress in the field difficult to track, as various models are constantly being proposed without proper evaluation. To solve this problem, we introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding tasks covering a total of 56 datasets and 112 languages. Through the benchmarking of 33 models on MTEB, we establish the most comprehensive benchmark of text embeddings to date. We find that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks. MTEB comes with open-source code and a public leaderboard at huggingface.co/spaces/mteb/leaderboard.\nMassive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding tasks covering a total of 56 datasets and 112 languages. (p. 1)\nMTEB consists of 56 datasets covering 112 languages from 8 embedding tasks: Bitext mining, classification, clustering, pair classification, reranking, retrieval, STS and summarization. (p. 1)\n(a) Diversity: MTEB aims to provide an understanding of the usability of embedding models in various use cases. The benchmark comprises 8 different tasks, with up to 15 datasets each. Of the 56 total datasets in MTEB, 10 are multilingual, covering 112 different languages. Sentence-level and paragraph-level datasets are included to contrast performance on short and long texts. (p. 2)\n(b) Simplicity: MTEB provides a simple API for plugging in any model that given a list of texts can produce a vector for each list item with a consistent shape. This makes it possible to benchmark a diverse set of models. (p. 2)\n(c) Extensibility: New datasets for existing tasks can be benchmarked in MTEB via a single file that specifies the task and a HuggingFace dataset name where the data has been uploaded (Lhoest et al., 2021). New tasks require implementing a task interface for loading the data and an evaluator for benchmarking. We welcome dataset, task or metric contributions from the community via pull requests to continue the development of MTEB. (p. 2)\nThe provided model is used to embed each sentence and the closest pairs are found via cosine similarity. F1 serves as the main metric for bitext mining. Accuracy, precision and recall are also computed. (p. 3)\n\nBitext mining\n\nA k-means model is trained on the embedded texts and scored using v-measure (Rosenberg and Hirschberg, 2007). (p. 3)\nThe resulting ranking is scored for each query and averaged across all queries. Metrics are mean MRR@k and MAP with the latter being the main metric. (p. 3)\nAfter ranking the corpus documents for each query based on the scores, nDCG@k, MRR@k, (p. 3)\nMAP@k, precision@k and recall@k are computed for several values of k. nDCG@10 serves as the main metric. MTEB reuses datasets and evaluation from BEIR (Thakur et al., 2021). (p. 4)\nDistances are benchmarked with ground truth similarities using Pearson and Spearman correlations. Spearman correlation based on cosine similarity serves as the main metric (Reimers et al., 2016). (p. 4)\nFor each machine summary embedding, distances to all human summary embeddings are computed. The closest score (e.g. highest cosine similarity) is kept and used as the model’s score of a single machine-generated summary. Pearson and Spearman correlations with ground truth human assessments of the machine-generated summaries are computed. Like for STS, Spearman correlation based on cosine similarity serves as the main metric (Reimers et al., 2016). (p. 4)\nNotes\n\nComment: 23 pages, 14 tables, 6 figures\n\nComment: 23 pages, 14 tables, 6 figures\n@article{Muennighoff_Tazi_Magne_Reimers_2022, title={MTEB: Massive Text Embedding Benchmark}, url={[arxiv.org/abs/2210.07316](arxiv.org/abs/2210.07316)}, DOI={[10.48550/arXiv.2210.07316](doi.org/10.48550/arXiv.2210.07316)}, abstractNote={Text embeddings are commonly evaluated on a small set of datasets from a single task not covering their possible applications to other tasks. It is unclear whether state-of-the-art embeddings on semantic textual similarity (STS) can be equally well applied to other tasks like clustering or reranking. This makes progress in the field difficult to track, as various models are constantly being proposed without proper evaluation. To solve this problem, we introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding tasks covering a total of 56 datasets and 112 languages. Through the benchmarking of 33 models on MTEB, we establish the most comprehensive benchmark of text embeddings to date. We find that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks. MTEB comes with open-source code and a public leaderboard at huggingface.co/spaces/mteb/leaderboard.}, note={0 citations (Semantic Scholar/arXiv) [2022-10-22] 0 citations (Semantic Scholar/DOI) [2022-10-22] arXiv:2210.07316 [cs]}, number={arXiv:2210.07316}, publisher={arXiv}, author={Muennighoff, Niklas and Tazi, Nouamane and Magne, Loïc and Reimers, Nils}, year={2022}, month={Oct} }\n"},"highlights/Zotero/nussbaum_2024":{"title":"Nomic Embed: Training a Reproducible Long Context Text Embedder","links":[],"tags":[],"content":"Nomic Embed: Training a Reproducible Long Context Text Embedder\nAbstract\nThis technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on short and long-context tasks. We release the training code and model weights under an Apache 2 license. In contrast with other open-source models, we release a training data loader with 235 million curated text pairs that allows for the full replication of nomic-embed-text-v1. You can find code and data to replicate the model at github.com/nomic-ai/contrastors\n\nFinally, we use task specific prefixes to break the symmetry of the biencoder as in (Wang et al., 2022). Without prefixes, the model receives conflicting reward signal. Consider the case of determining which response is closest to the question ”What is the capital of France?”: 1. “What is the name of the capital city of France? 2. “Paris is the capital of France.” A semantic similarity task would consider the first closest, while a question answering task would consider the second closest. Prefixes enable the model to distinguish between the behaviors specified by each of these tasks. (p. 4)\n\n@misc{Nussbaum_Morris_Duderstadt_Mulyar_2024, title={Nomic Embed: Training a Reproducible Long Context Text Embedder}, url={[arxiv.org/abs/2402.01613v1](arxiv.org/abs/2402.01613v1)}, abstractNote={This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on short and long-context tasks. We release the training code and model weights under an Apache 2 license. In contrast with other open-source models, we release a training data loader with 235 million curated text pairs that allows for the full replication of nomic-embed-text-v1. You can find code and data to replicate the model at github.com/nomic-ai/contrastors}, note={{&quot;size&quot;: 356769, “pages”: 12, “previous”: &quot; &quot;}}, journal={arXiv.org}, author={Nussbaum, Zach and Morris, John X. and Duderstadt, Brandon and Mulyar, Andriy}, year={2024}, month=feb, language={en} }\n"},"highlights/Zotero/opitz_2022":{"title":"SBERT Studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features","links":[],"tags":[],"content":"SBERT Studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features\nAbstract\nModels based on large-pretrained language models, such as S(entence)BERT, provide effective and efficient sentence embeddings that show high correlation to human similarity ratings, but lack interpretability. On the other hand, graph metrics for graph-based meaning representations (e.g., Abstract Meaning Representation, AMR) can make explicit the semantic aspects in which two sentences are similar. However, such metrics tend to be slow, rely on parsers, and do not reach state-of-the-art performance when rating sentence similarity. In this work, we aim at the best of both worlds, by learning to induce Semantically Structured Sentence BERT embeddings (S3BERT). Our S3BERT embeddings are composed of explainable sub-embeddings that emphasize various semantic sentence features (e.g., semantic roles, negation, or quantification). We show how to i) learn a decomposition of the sentence embeddings into semantic features, through approximation of a suite of interpretable AMR graph metrics, and how to ii) preserve the overall power of the neural embeddings by controlling the decomposition learning process with a second objective that enforces consistency with the similarity ratings of an SBERT teacher model. In our experimental studies, we show that our approach offers interpretability — while fully preserving the effectiveness and efficiency of the neural sentence embeddings.\nInstead, we target local self-explainability (Danilevsky et al., 2020) by structuring SBERT’s sentence embedding space into subspaces that emphasize explicit facets of meaning. (p. 2)\nWe aim to overcome these weaknesses by making sentence embeddings capable of expressing AMR metrics while preserving the full power of neural sentence embeddings. (p. 2)\nWe presume that SBERT already contains some semantic features in some embedding dimensions. Hence, we want to achieve an arrangement of the embedding space according to our pre-defined partitioning, but also give it the chance to instill new knowledge about AMR semantics. (p. 3)\n\nNote that AMR graphs and metrics are only needed for training, not for inference. (p. 4)\nWe use Frames: graph similarity with regard to PropBank predicates. Named entity: graph similarity based on named entity substructures (person, city, …). Negation: graph similarity based on expressions of negation. Concepts: graph similarity based on node labels only. Coreference: graph similarity focused on co-referent structures. SRL: graph similarity considering predicate substructures. Finally, Unlabeled: not considering semantic edge labels.2 (p. 5)\nAdditionally, we observe that AMR contains information about quantifiers and define quantSim, which measures the (normalized) overlap of quantifier structure of two AMRs. (p. 5)\nWe find that there are three AMR features that are very poorly modeled with global SBERT embeddings: named entities, negation, quantification. (p. 7)\nInterestingly, while one main goal was to prevent a performance drop, S3BERT tends to outperform all baselines, including SBERT (significant improvement for STSb). It is important to note that catastrophic forgetting indeed occurs if learning is not controlled by the consistency objective. In this case, the performance drops by about 20-30 points (S3BERT cons. in Table 2). We conclude that our consistency objective effectively prevented any loss of embedding power. (p. 7)\nThis implies that there is potential room for further improvement of our method by using an even more accurate parser, but judging from the marginally lower score of JAMR, the gain may be small. (p. 8)\n@article{Opitz_Frank_2022, title={SBERT studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features}, url={[arxiv.org/abs/2206.07023](arxiv.org/abs/2206.07023)}, DOI={[10.48550/arXiv.2206.07023](doi.org/10.48550/arXiv.2206.07023)}, abstractNote={Models based on large-pretrained language models, such as S(entence)BERT, provide effective and efficient sentence embeddings that show high correlation to human similarity ratings, but lack interpretability. On the other hand, graph metrics for graph-based meaning representations (e.g., Abstract Meaning Representation, AMR) can make explicit the semantic aspects in which two sentences are similar. However, such metrics tend to be slow, rely on parsers, and do not reach state-of-the-art performance when rating sentence similarity. In this work, we aim at the best of both worlds, by learning to induce $S$emantically $S$tructured $S$entence BERT embeddings (S$^3$BERT). Our S$^3$BERT embeddings are composed of explainable sub-embeddings that emphasize various semantic sentence features (e.g., semantic roles, negation, or quantification). We show how to i) learn a decomposition of the sentence embeddings into semantic features, through approximation of a suite of interpretable AMR graph metrics, and how to ii) preserve the overall power of the neural embeddings by controlling the decomposition learning process with a second objective that enforces consistency with the similarity ratings of an SBERT teacher model. In our experimental studies, we show that our approach offers interpretability -- while fully preserving the effectiveness and efficiency of the neural sentence embeddings.}, note={arXiv:2206.07023 [cs]}, number={arXiv:2206.07023}, author={Opitz, Juri and Frank, Anette}, year={2022}, month={Oct} }\n"},"highlights/Zotero/overwijk_2022":{"title":"ClueWeb22: 10 Billion Web Documents with Rich Information","links":[],"tags":[],"content":"ClueWeb22: 10 Billion Web Documents with Rich Information\nAbstract\nClueWeb22, the newest iteration of the ClueWeb line of datasets, provides 10 billion web pages affiliated with rich information. Its design was influenced by the need for a high quality, large scale web corpus to support a range of academic and industry research, for example, in information systems, retrieval-augmented AI systems, and model pretraining. Compared with earlier ClueWeb corpora, the ClueWeb22 corpus is larger, more varied, of higher-quality, and aligned with the document distributions in commercial web search. Besides raw HTML, ClueWeb22 includes rich information about the web pages provided by industry-standard document understanding systems, including the visual representation of pages rendered by a web browser, parsed HTML structure information from a neural network parser, and pre-processed cleaned document text to lower the barrier to entry. Many of these signals have been widely used in industry but are available to the research community for the first time at this scale.\n• Super Head: The most popular web pages visited through web search, such as the content pages of Wikipedia, popular news websites, and top domains people visit in their daily life; • Head: The regularly visited part of the web, where most search traffic lands; • Tail: The diverse part of the web still regularly visited by users with specific needs; • Super Tail: The majority of the web discovered by crawlers but barely visited by users. (p. 4)\nOn average, there are 50+ secondary URLs needed to render one web page. Not only downloading them imposes significant cost, rendering the web page and executing the secondary contents is also non-trivial. It is effectively running an actual web browser. As a result, many open-source web page parsing tools restrict their operations to static HTML, limiting their ability to extract the exact content a web page displays to users. (p. 5)\n\nSemantic Annotation Task is to predict whether a node in the HTML DOM tree belongs to a set of predefined categories. In ClueWeb22 the model uses the following six categories: (1) Title: The title of the document content, which may be different from the HTML &lt;title&gt; tag. (2) Primary Content: The main content of the web page. Formally a piece of text is primary content if it is the main information for visitors to consume. This excludes elements that occur on other pages of the same site, such as headers, footers, and navigation, as well as elements that change with page reloading, e.g., advertisements. In addition, we remove elements that are not the core content, for example, the comment section of a blog site, where the blog is the core content. (3) Heading: The heading of each section in the primary content. (p. 6)\n(4) Paragraph: The natural language paragraphs of the primary content. (5) Table: Content tables in the primary content, grouped in tabular format. This is determined by the page presentation to users, regardless their organization in the static HTML or dynamic scripts. (6) List: Content lists in the primary content, grouped in the list format. (p. 7)\n(7) Table Row: A row that contains multiple cells in a table. (8) Table Cell: The element storing one content unit in a table. (9) Table Header: The row or column header that contains labels for content in a table. (10) Table Caption: The description or summary of table content. (11) List Item: The element storing one content unit in a list. (12) HTML Title: The page title displayed in the browser tab. (13) Invisible Text: Text that is invisible when rendered in the browser, i.e. those with zero opacity or less than two pixel in both width and height. (p. 7)\nThe advantage of CommonCrawl is at its scale but not necessary content quality. Our pilot study shows that ClueWeb22-B provides a large amount of high quality text that can be directly used (without any further cleaning) to pretrain language models. (p. 15)\nThere is no single best definition of web page importance. Nevertheless, the frequency of websites in CommonCrawl is unlikely to be aligned with their frequency of being visited by web search users. For example, it is doubtful web users now spend more time on amazonaws.com than on amazon.com. According to a recent discussion from a CommonCrawl contributor [24], the domain rank of CommonCrawl has around 33% overlap with the general web traffic estimated by DNS providers. In comparison, ClueWeb22 is designed to reflect the distribution of search engine traffic and its top websites align with our intuitions of search user behaviors. (p. 17)\n@article{Overwijk_Xiong_Liu_VandenBerg_Callan_2022, title={ClueWeb22: 10 Billion Web Documents with Rich Information}, url={[arxiv.org/abs/2211.15848](arxiv.org/abs/2211.15848)}, DOI={[10.48550/arXiv.2211.15848](doi.org/10.48550/arXiv.2211.15848)}, abstractNote={ClueWeb22, the newest iteration of the ClueWeb line of datasets, provides 10 billion web pages affiliated with rich information. Its design was influenced by the need for a high quality, large scale web corpus to support a range of academic and industry research, for example, in information systems, retrieval-augmented AI systems, and model pretraining. Compared with earlier ClueWeb corpora, the ClueWeb22 corpus is larger, more varied, of higher-quality, and aligned with the document distributions in commercial web search. Besides raw HTML, ClueWeb22 includes rich information about the web pages provided by industry-standard document understanding systems, including the visual representation of pages rendered by a web browser, parsed HTML structure information from a neural network parser, and pre-processed cleaned document text to lower the barrier to entry. Many of these signals have been widely used in industry but are available to the research community for the first time at this scale.}, note={0 citations (Semantic Scholar/arXiv) [2022-11-30] arXiv:2211.15848 [cs]}, number={arXiv:2211.15848}, author={Overwijk, Arnold and Xiong, Chenyan and Liu, Xiao and VandenBerg, Cameron and Callan, Jamie}, year={2022}, month={Nov} }\n"},"highlights/Zotero/penedo_":{"title":"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only","links":[],"tags":[],"content":"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only\nAbstract\nLarge language models are commonly trained on a mixture of filtered web data and curated “high-quality” corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our REFINEDWEB dataset, and 1.3/7.5B parameters language models trained on it*.\nWe perform MinHash deduplication using 9,000 hashes per document, calculated over 5-grams and divided into 20 buckets of 450 hashes. (p. 6)\nBecause of computational constraints, it is impossible for us to perform deduplication directly on RW-Filtered. Instead, we split CommonCrawl into 100 parts, where each part contains a hundredth of each dump, and perform deduplication on individual parts. Most of the larger duplicate clusters (e.g., licences, common spams) will be shared across parts, and effectively removed. (p. 6)\n@article{Penedo_Malartic_Hesslow_Cojocaru_Cappelli_Pannier_Almazrouei_Launay, title={The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only}, abstractNote={Large language models are commonly trained on a mixture of filtered web data and curated “high-quality” corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our REFINEDWEB dataset, and 1.3/7.5B parameters language models trained on it*.}, author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien}, language={en} }\n"},"highlights/Zotero/raji_2021":{"title":"You Can't Sit With Us: Exclusionary Pedagogy in AI Ethics Education","links":[],"tags":[],"content":"You Can’t Sit With Us: Exclusionary Pedagogy in AI Ethics Education\nAbstract\nGiven a growing concern about the lack of ethical consideration in the Artificial Intelligence (AI) field, many have begun to question how dominant approaches to the disciplinary education of computer science (CS)---and its implications for AI---has led to the current “ethics crisis”. However, we claim that the current AI ethics education space relies on a form of “exclusionary pedagogy,” where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. This results in indifference, devaluation, and a lack of mutual support between CS and humanistic social science (HSS), elevating the myth of technologists as “ethical unicorns” that can do it all, though their disciplinary tools are ultimately limited. Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics, we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in CS training and explore evidence for the practical mechanisms through which this exclusion occurs. We then propose a shift towards a substantively collaborative, holistic, and ethically generative pedagogy in AI education.\nHowever, we claim that the current AI ethics education space relies on a form of “exclusionary pedagogy,” where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. (p. 1)\nit is becoming clear that proposals anchored to developing individual morality and understanding falls short of resulting in any noticeable changes to the way in which students conduct research and develop applications for deployment once they leave the classroom [35]. This is made even more evident by the consistency with which such crises continue to occur [81]. (p. 1)\nIf anything, to rush CS students through heavily condensed and simplified overviews of broad ethical understanding and then position them to be the primary arbiter of change confuses the situation. This promotes the engineer’s natural inclination towards seeing themselves as a solitary saviour, to the detriment of the quality of the solution and in spite of the need for other disciplinary perspectives. (p. 1)\nAt its simplest, the technocratic paradigm might be described as an engineering or programmatic approach, which centers the skills to build computer programs; the rationalist paradigm might be described as a mathematically theoretical approach, focusing more heavily on a priori knowledge about the underlying mathematical reality of computer systems; and the scientific paradigm might be best characterized by its focus on empiricism, seeking to more deeply understand the behaviors of computer programs. These three paradigms shape how computer science operates, through enculturation in computer science education and in industry cultures, at both the level of attitudes and values, and at the level of behaviors and practices. (p. 2)\nlearning computer science has traditionally emphasized mathematical theory and engineering practices. A focus on “programming intelligence” is a well-researched cause of the high dropout rates of computer science undergraduate programs [5, 30, 36, 75]. Computer science is what Clark labels “a hard-applied discipline” [14]. Those who approach computer science problems differently are pushed out of the field, resulting in more homogeneous mindsets and practices within the discipline and unsurprising diversity deficits [49]. (p. 2)\nIn a scathing analysis of the technocratic dominance in computer science education, Washington wrote: “With no formal courses that focus on the non-technical issues affecting marginalized groups and how to address and eradicate them, students are indirectly taught that the current status quo in computing departments and industry is not only acceptable, but also unproblematic” [77]. (p. 2)\nIn other words, he paints computer science education as a funnel from classroom to tech company, with little space for nuanced reflection on its foundational norms and objectives. (p. 2)\nethics courses are being taught from within the discipline [29]from computer scientists to computer scientists. A discipline which has otherwise been criticized for its lack of ethical engagement is now taking up the mantle of instilling ethical wisdom to its next generation of students (p. 3)\nLike Eden, one might argue that the technocratic paradigm has dominated computer science, specifically AI, due to industry and monetary incentives driving programmatic approaches where any problem is best addressed by technologists, including the problems they create. More specifically, Agre famously characterized the nature of the conception of “reality” in AI—which posits better systems and better models as the only means of critiquing AI—as problematic in its ignorance and dismissal of sociological or critical theory [1]. (p. 3)\nAlthough students are often taught the importance of computational thinking for problem solving, they are rarely exposed to what such thinking can take away from one’s ability to appropriately analyze less familiar challenges, such as this ethics crisis. There are insights that one gains from a computational lens and also insights lost. Being anchored to one perspective for so long as a discipline is a limiting factor and the historical lack of social science training in computer science has given rise to computer science researchers, teachers, and industry practitioners well-versed in techno-solutionist methodologies but not social realities, leading to systems that are—often inadvertently—inaccessible, opaque, unethical, and harmful. (p. 3)\nHowever, the reality is that engineers are often absent or excluded from decisions that lead to harm. These decisions can often be attributed to sales people, executies, marketing and other stakeholders in a corporation—at times without even informing the technologist of the broader context of what they’re working on. Similarly, problematic unethical research practices in the field are mostly enabled by a set of entrenched norms and operational structures of everything from funding to the review process and publication. (p. 3)\nA step towards more inclusive design is thus less about a single engineer’s efforts push to enforce their understanding of diverse representation into the worldview of the model, and more about a form of participatory design where these other stakeholders are actively and humbly welcomed to join the engineer in the creation of more just and equitable AI systems. (p. 3)\nFurthermore, this solutionist attitude of quick fixes in CS de facto displaces the knowledge of other qualitative oriented educators and researchers. The result is not only a feedback loop within computer science, but a continuing aggregation of disciplinary privilege that seeks to make computer scientists claim both “technical” and “social” expertises, the latter of which they do not actually have in depth. (p. 3)\nAs danah boyd, a principal researcher at Microsoft, wrote of social science: “Academic disciplines are brutally myopic, judgmental of anyone who chooses to explore a path of inquiry outside of the acceptable boundaries of the field”[11]. (p. 4)\nHowever, we have chosen to focus specifically on computer science, and AI, due to its emergent and out-sized power: computer scientists and machine learning engineers are having real world impact, socially, politically, and economically. (p. 4)\nMethodological dogmatism is to say that the disciplines don’t value each other, and more specifically, do not value their respective processes for arriving at an accepted conclusion or “truth”. (p. 4)\nThe other mechanism of exclusion evident in this space is that of a lack of effort to engage in interdisciplinary translation. This is to say that there is an apparent acceptance that the disciplines don’t talk to each other, and effectively tend to not communicate across disciplinary lines. (p. 5)\nFinally, as a side effect of both of these previously identified mechanisms of exclusion, we can see a lack of cross-citation—ie. a lack of effectively building on each other’s work. The lack of cross-citation across disciplinary lines indicates that findings from one discipline are not respected as adequate evidence to inform researchers from another and that (p. 5)\nIf we look at how CS is labeled according to Biglan’s classification, we can see that it operates as a “hard” and “applied” discipline. Kolb for their part sees CS as “abstract” and “active”. In stark contrast, HSS have almost a virginal quality being labeled in the exact opposite categories, as being irrevocably “soft” and “pure” (Biglan), “concrete” and “reflective” (Kolb). (p. 6)\nWe hypothesize that behind these constructed distinctions of “hard” vs. “soft” or “active” vs. “reflective”, there are serious assumptions about the nature of academic problems, historically anchored to economic beliefs which shape who is worthy and who is not. It is the distinction between accuracy and inaccuracy, between tangibility and speculation, between clear and distinct on one end and confused and ambiguous on the other. The former state is understood to be much more real, and valuable, being framed as more economically relevant. (p. 6)\nSetting up false dichotomies reinforces a false belief in the existence of inherently opposing, rather than complementary, disciplinary norms and ultimately escalates in the observed reluctance of differing disciplines to mutually engage. (p. 7)\nIn this framing of disciplines based solely on subject matter (ie. content and method), the natural sciences, engineering and computer science operate as “hard” or “paradigmatic” whereas the humanities are seen as “idiosyncratic”. These latter disciplines do not qualify as “paradigmatic” and are classified as irreversibly “soft”. The social sciences, such as sociology and business fields are thus framed as being in futile search of a paradigm. That is, they display a potentiality for finding a paradigm but have not been able to find one and therefore are categorized as relatively “soft” to the STEM disciplines. (p. 7)\nThe second dimension of Biglan’s classification is defined by the relation between “applied” and “pure” aspects of disciplines. Accounting and engineering fields, including CS, are thus implicitly labeled as practical, whereas the natural sciences, social sciences and the humanities are categorized as abstract, implying less tangible utility 4. The label of “active” being applied to STEM disciplines also reinforces the false assumption that CS, as an “active” discipline, is meant to hold the agency in situations requiring intervention and possesses the greater influence on system and societal outcomes. The framing of CS as being opposite to the passive category of “reflective”, also devalues the importance of reflection in responsible CS development, while falsely framing reflection in opposition to effectiveness and efficiency. (p. 7)\nIf we follow Habermas, HSS is framed around humanistic goals of emancipation, participaction, and respectful inclusion of all stakeholders present or absent, powerful or not. These are thus the priorities that the CS field will fundamentally neglect once they disengage with HSS. (p. 8)\nGiven that CS technical artifacts have a global impact on our lives, accuracy understood as a techno-scientific requirement of clarity and distinctiveness is not enough. Applied blindly, irrespective of context and social power imbalances, accuracy as a practice, value and assumption is, in fact, a formula for stabilizing forms of dominance as it amplifies and reproduces historical and structural inequities. Instead, we need to focus on a critical engagement with exclusionary disciplinary classifications and their consequences in order to develop a new ethics of collaborative pedagogy at the intersection of CS and HSS. (p. 8)\nA transversal problem is distinct from an interdisciplinary problem as its solution is not found in-between given disciplines but should be constructed from the effects on the stakeholders that could be or were impacted by it, and from a critique of the types of formal and substantive assumptions, choices, requirements and methodologies that are currently built into AI ethics pedagogy. (p. 9)\nFirst, we recommend to focus on thinking and acting differently by including broad non-CS expertise and researchers when dealing with technical artifacts which have clear social impact. (p. 9)\nSecond, we need to educate students on frameworks of intervention based around existing problems, not anchored to the existing skills of those assumed to be in the position to address the problems. Real world ethics problems call for a diverse set of skills. (p. 9)\nThird, we need to incorporate explicit references in the AI ethics syllabi of stakeholders beyond the technologist, including discussions of their roles and how they are impacted. One of the key issues that a syllabus should address is a more inclusive identification of stakeholders when formulating an AI problem. (p. 9)\nOne of the questions that every AI syllabus should account for is not only who the target audience is but who the impacted parties may be. Beyond institutional stakeholders, such as product managers or engineers, there could be greater discussion of societal stakeholders, such as policymakers and regulators, as well as more speculative reflection on who perhaps could contribute to the solution, though may be rarely invited to do so. (p. 9)\nFourth, we need to develop frameworks to work with affected populations and experiential experts, including community organizer toolkits and speakers. (p. 9)\nFifth, we suggest engaging students in the exercise of assessing disciplinary competence in a range of situations and developing 52 (p. 9)\nFAccT ’21, March 3–10, 2021, Virtual Event, Canada Inioluwa Deborah Raji, Morgan Klaus Scheuerman, and Razvan Amironesei the ability to identify the relevance of a particular approach to address challenges for specific types of problems or in particular situations. (p. 10)\nThere should be an explicit conversation about not only what is gained from the methods embraced by one’s discipline, but also what is lost—and how the limitations of one’s disciplinary lens can be addressed by looking towards mixed method approaches, or knowledge and collaboration with other disciplines to fill in certain ability gaps. (p. 10)\n@inproceedings{Raji_Scheuerman_Amironesei_2021, address={New York, NY, USA}, series={FAccT ’21}, title={You Can’t Sit With Us: Exclusionary Pedagogy in AI Ethics Education}, ISBN={978-1-4503-8309-7}, url={[doi.org/10.1145/3442188.3445914](doi.org/10.1145/3442188.3445914)}, DOI={[10.1145/3442188.3445914](doi.org/10.1145/3442188.3445914)}, abstractNote={Given a growing concern about the lack of ethical consideration in the Artificial Intelligence (AI) field, many have begun to question how dominant approaches to the disciplinary education of computer science (CS)---and its implications for AI---has led to the current “ethics crisis”. However, we claim that the current AI ethics education space relies on a form of “exclusionary pedagogy,” where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. This results in indifference, devaluation, and a lack of mutual support between CS and humanistic social science (HSS), elevating the myth of technologists as “ethical unicorns” that can do it all, though their disciplinary tools are ultimately limited. Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics, we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in CS training and explore evidence for the practical mechanisms through which this exclusion occurs. We then propose a shift towards a substantively collaborative, holistic, and ethically generative pedagogy in AI education.}, note={27 citations (Semantic Scholar/DOI) [2022-12-27]}, publisher={Association for Computing Machinery}, author={Raji, Inioluwa Deborah and Scheuerman, Morgan Klaus and Amironesei, Razvan}, year={2021}, month={Mar}, pages={515–525}, collection={FAccT ’21} }\n"},"highlights/Zotero/raposo_2024":{"title":"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models","links":[],"tags":["TODO"],"content":"Mixture-of-Depths: Dynamically allocating compute in transformer-based language models\nAbstract\nTransformer-based language models spread FLOPs uniformly across input sequences. In this work we demonstrate that transformers can instead learn to dynamically allocate FLOPs (or compute) to specific positions in a sequence, optimising the allocation along the sequence for different layers across the model depth. Our method enforces a total compute budget by capping the number of tokens (k) that can participate in the self-attention and MLP computations at a given layer. The tokens to be processed are determined by the network using a top-k routing mechanism. Since k is defined a priori, this simple procedure uses a static computation graph with known tensor sizes, unlike other conditional computation techniques. Nevertheless, since the identities of the k tokens are fluid, this method can expend FLOPs non-uniformly across the time and model depth dimensions. Thus, compute expenditure is entirely predictable in sum total, but dynamic and context-sensitive at the token-level. Not only do models trained in this way learn to dynamically allocate compute, they do so efficiently. These models match baseline performance for equivalent FLOPS and wall-clock times to train, but require a fraction of the FLOPs per forward pass, and can be upwards of 50% faster to step during post-training sampling.\n\nNot all problems require the same amount of time or effort to solve. Analogously, in language modeling not all tokens and sequences require the same time or effort to accurately make a prediction. And yet, transformer models expend the same amount of compute per token in a forward pass. Ideally, transformers would use smaller total compute budgets by not spending compute unnecessarily. (p. 1)\n\n\nDeparting from MoE, we choose to either apply a computation to a token (as would be the case for a standard transformer), or pass it through a residual connection (remaining unchanged and saving compute). Also in contrast to MoE, we apply this routing to both forward MLPs and multi-head attention. Since this therefore also impacts the keys and queries we process, the routing makes decisions not only about which tokens to update, but also which tokens are made available to attend to. We refer to this strategy as Mixture-of-Depths (MoD) to emphasize how individual tokens pass through different numbers of layers, or blocks, through the depth of the transformer (see figure 1). (p. 2)\n\n\n“Expert choice routing” flips this recipe on its head: rather than having tokens choose the path they prefer, each path instead chooses the top-𝑘 tokens based on the tokens’ preferences. This ensures a perfect load balance since 𝑘 tokens are guaranteed to be shuttled to each path. However, it could result in over- or under-processing of some tokens, since some tokens may be among the top-𝑘 for multiple paths, or for none of them. (p. 5)\n\n\nWe decided to leverage expert-choice routing for a few reasons. First, it obviates the need for an auxiliary balancing loss. Second, since the top-𝑘 operation depends on the magnitude of the router weights, this routing scheme allows for relative routing weights to help determine which tokens most need the block’s computations; routers can try to ensure that the most critical tokens are among the top-𝑘 by setting their weight appropriately, which is not possible with token-choice routing schemes. For our specific use-case, wherein one computational path is essentially a null operation, it might be critical that important tokens are routed away from the null operation. Third, because we only route through two paths, a single top-𝑘 operation can efficiently split the tokens into two mutually exclusive sets, one for each computational path, preventing the over- or under-processing problem mentioned above. (p. 5)\n\n\nThis insight opens the door to MoD variants that decouple the routing for queries, keys and values. For example, perhaps a token would prefer to be among the queries, but not the keys, for a given self-attention computation. One can imagine extending this idea even further into the domain of “long-term memory”: perhaps there are tokens that would be extremely valuable as keys, regardless of whether it is useful for them to also be among the queries at the step of their occurrence. Learned routing could be a powerful mechanism for deciding which tokens these might be, perhaps funnelling them into a long-term memory buffer that is available during future self-attention. One advantage of such an approach to long-term memory is that tokens decide once, at the moment of “memory encoding”, whether they should be retrieved in the future. This is more computationally efficient than performing a full content-based lookup across an entire memory buffer for each step in the future, and could be one step towards drastically increasing the context-length available for making a prediction. (p. 12)\n\n\nFor example, perhaps some tokens are routed to “memory lookup” functions, and others are routed to “tool use” functions. In general, the routing machinery we deployed provides a knob for adjusting the types of computations available to the network and their relative cost (in total FLOPs); if one wants to introduce an expensive computation, then this can be offset by setting its capacity to some small amount, and hence, by routing only a small number of tokens to it. (p. 13)\n\nNotes\n\nTL;DR\nThis work enforces a total compute budget by capping the number of tokens that can participate in the self-attention and MLP computations at a given layer by dynamically allocate FLOPs to specific positions in a sequence, optimising the allocation along the sequence for different layers across the model depth.\n@misc{Raposo_Ritter_Richards_Lillicrap_Humphreys_Santoro_2024, title={Mixture-of-Depths: Dynamically allocating compute in transformer-based language models}, url={[arxiv.org/abs/2404.02258v1](arxiv.org/abs/2404.02258v1)}, abstractNote={Transformer-based language models spread FLOPs uniformly across input sequences. In this work we demonstrate that transformers can instead learn to dynamically allocate FLOPs (or compute) to specific positions in a sequence, optimising the allocation along the sequence for different layers across the model depth. Our method enforces a total compute budget by capping the number of tokens ($k$) that can participate in the self-attention and MLP computations at a given layer. The tokens to be processed are determined by the network using a top-$k$ routing mechanism. Since $k$ is defined a priori, this simple procedure uses a static computation graph with known tensor sizes, unlike other conditional computation techniques. Nevertheless, since the identities of the $k$ tokens are fluid, this method can expend FLOPs non-uniformly across the time and model depth dimensions. Thus, compute expenditure is entirely predictable in sum total, but dynamic and context-sensitive at the token-level. Not only do models trained in this way learn to dynamically allocate compute, they do so efficiently. These models match baseline performance for equivalent FLOPS and wall-clock times to train, but require a fraction of the FLOPs per forward pass, and can be upwards of 50% faster to step during post-training sampling.}, journal={arXiv.org}, author={Raposo, David and Ritter, Sam and Richards, Blake and Lillicrap, Timothy and Humphreys, Peter Conway and Santoro, Adam}, year={2024}, month=apr, language={en} }\n"},"highlights/Zotero/rasenberg_2023":{"title":"Reimagining language: Towards a better understanding of language by including our interactions with non-humans","links":[],"tags":[],"content":"Reimagining language: Towards a better understanding of language by including our interactions with non-humans\nAbstract\nAbstract What is language and who or what can be said to have it? In this essay we consider this question in the context of interactions with non-humans, specifically: animals and computers. While perhaps an odd pairing at first glance, here we argue that these domains can offer contrasting perspectives through which we can explore and reimagine language. The interactions between humans and animals, as well as between humans and computers, reveal both the essence and the boundaries of language: from examining the role of sequence and contingency in human-animal interaction, to unravelling the challenges of natural interactions with “smart” speakers and language models. By bringing together disparate fields around foundational questions, we push the boundaries of linguistic inquiry and uncover new insights into what language is and how it functions in diverse non-human-exclusive contexts.\n\nHowever, whereas in human-animal interaction there is ample evidence of reciprocal adaptation, here the adaptation is strikingly one-sided, with robots essentially helpless, requiring care (Lipp 2022) and forcing people to adapt to their constraints (Alač et al. 2020; Suchman 2019). People may start speaking differently to yield to limitations of speech-to-text modules, learn to produce their talk in short chunks, reduce complex and diffuse goals to simple intents, and may even find that their own language is not supported (Litman, Hirschberg &amp; Swerts 2006; Swerts &amp; Ostendorf 1997). (p. 4)\n\n@article{Rasenberg_Amha_Coler_Koppen_Miltenburg_Rijk_Stommel_Dingemanse_2023, title={Reimagining language: Towards a better understanding of language by including our interactions with non-humans}, volume={40}, ISSN={0929-7332, 1569-9919}, DOI={[10.1075/avt.00095.ras](doi.org/10.1075/avt.00095.ras)}, abstractNote={Abstract What is language and who or what can be said to have it? In this essay we consider this question in the context of interactions with non-humans, specifically: animals and computers. While perhaps an odd pairing at first glance, here we argue that these domains can offer contrasting perspectives through which we can explore and reimagine language. The interactions between humans and animals, as well as between humans and computers, reveal both the essence and the boundaries of language: from examining the role of sequence and contingency in human-animal interaction, to unravelling the challenges of natural interactions with “smart” speakers and language models. By bringing together disparate fields around foundational questions, we push the boundaries of linguistic inquiry and uncover new insights into what language is and how it functions in diverse non-human-exclusive contexts.}, note={{&quot;size&quot;: 280500, “pages”: 9, “previous”: “Publisher: John Benjamins”}}, number={1}, journal={Linguistics in the Netherlands}, author={Rasenberg, Marlou and Amha, Azeb and Coler, Matt and Koppen, Marjo van and Miltenburg, Emiel van and Rijk, Lynn de and Stommel, Wyke and Dingemanse, Mark}, year={2023}, month=nov, pages={309–317}, language={en} }\n"},"highlights/Zotero/riedl_2014":{"title":"The Lovelace 2.0 Test of Artificial Creativity and Intelligence","links":[],"tags":[],"content":"The Lovelace 2.0 Test of Artificial Creativity and Intelligence\nAbstract\nObserving that the creation of certain types of artistic artifacts necessitate intelligence, we present the Lovelace 2.0 Test of creativity as an alternative to the Turing Test as a means of determining whether an agent is intelligent. The Lovelace 2.0 Test builds off prior tests of creativity and additionally provides a means of directly comparing the relative intelligence of different agents.\nThe Turing Test was never meant to be conducted; indeed many practical methodological details are left absent Regardless of Turing’s intent, the Turing Test has been adopted as a rigorous test of the intelligence capability of computational systems. (p. 1)\nOne of the weaknesses of the Turing Test as a diagnostic tool for intelligence is its reliance on deception (Levesque, Davis, and Morgenstern 2012); agents that are successful at the Turing Test and the closely related Loebner Prize Competition are those that fool human judges for short amounts of time partially by evading the judges’ questions. (p. 1)\nAn artificial agent a, designed by h, passes the Lovelace Test if and only if: • a outputs o, • a’s outputting o is the result of processes a can repeat and not a fluke hardware error, and • h (or someone who knows what h knows and has h’s resources) cannot explain how a produced o. (p. 1)\nComputational creativity is the art, science, philosophy, and engineering of computational systems that, by taking on particular responsibilities, exhibit behaviors that unbiased observers would deem to be creative. There are no conclusive tests of whether a computational system exhibits creativity. (p. 1)\nThe Lovelace 2.0 Test is as follows: artificial agent a is challenged as follows: • a must create an artifact o of type t; • o must conform to a set of constraints C where ci ∈ C is any criterion expressible in natural language; • a human evaluator h, having chosen t and C, is satisfied that o is a valid instance of t and meets C; and • a human referee r determines the combination of t and C to not be unrealistic for an average human. (p. 2)\nThe human referee r is necessary to prevent the situation where the evaluator presents the agent with a combination of t and C that might be extremely difficult to meet even by humans. The referee should be an expert on t who can veto judge inputs based on his or her expert opinion on what is known about t and average human abilities. (p. 2)\nRegardless of whether the human judge is an expert in artificial intelligence or not, the evaluator is given the chance to craft a set of constraints that he or she would expect the agent to be unable to meet. Thus if the judge is acting with the intent to disprove the intelligence, the judge should experience an element of surprise if the agent passes a challenge. (p. 2)\nThe ability to repeat the test with more or harder constraints enables the judge to test the limits of the agent’s intelligence. These features are at the expense of a halting condition—the test provides no threshold at which one can declare an artificial agent to be intelligent. However, the test provides a means to quantitatively compare artificial agents. Creativity is not unique to human intelligence, but it is one of the hallmarks of human intelligence. (p. 2)\nThe Turing Test was never meant to be conducted; indeed many practical methodological details are left absent Regardless of Turing’s intent, the Turing Test has been adopted as a rigorous test of the intelligence capability of computational systems. (p. 1)\nOne of the weaknesses of the Turing Test as a diagnostic tool for intelligence is its reliance on deception (Levesque, Davis, and Morgenstern 2012); agents that are successful at the Turing Test and the closely related Loebner Prize Competition are those that fool human judges for short amounts of time partially by evading the judges’ questions. (p. 1)\nAn artificial agent a, designed by h, passes the Lovelace Test if and only if: • a outputs o, • a’s outputting o is the result of processes a can repeat and not a fluke hardware error, and • h (or someone who knows what h knows and has h’s resources) cannot explain how a produced o. (p. 1)\nComputational creativity is the art, science, philosophy, and engineering of computational systems that, by taking on particular responsibilities, exhibit behaviors that unbiased observers would deem to be creative. There are no conclusive tests of whether a computational system exhibits creativity. (p. 1)\nThe Lovelace 2.0 Test is as follows: artificial agent a is challenged as follows: • a must create an artifact o of type t; • o must conform to a set of constraints C where ci ∈ C is any criterion expressible in natural language; • a human evaluator h, having chosen t and C, is satisfied that o is a valid instance of t and meets C; and • a human referee r determines the combination of t and C to not be unrealistic for an average human. (p. 2)\nThe human referee r is necessary to prevent the situation where the evaluator presents the agent with a combination of t and C that might be extremely difficult to meet even by humans. The referee should be an expert on t who can veto judge inputs based on his or her expert opinion on what is known about t and average human abilities. (p. 2)\nRegardless of whether the human judge is an expert in artificial intelligence or not, the evaluator is given the chance to craft a set of constraints that he or she would expect the agent to be unable to meet. Thus if the judge is acting with the intent to disprove the intelligence, the judge should experience an element of surprise if the agent passes a challenge. (p. 2)\nThe ability to repeat the test with more or harder constraints enables the judge to test the limits of the agent’s intelligence. These features are at the expense of a halting condition—the test provides no threshold at which one can declare an artificial agent to be intelligent. However, the test provides a means to quantitatively compare artificial agents. Creativity is not unique to human intelligence, but it is one of the hallmarks of human intelligence. (p. 2)\n@article{Riedl_2014, title={The Lovelace 2.0 Test of Artificial Creativity and Intelligence}, url={[arxiv.org/abs/1410.6142](arxiv.org/abs/1410.6142)}, DOI={[10.48550/arXiv.1410.6142](doi.org/10.48550/arXiv.1410.6142)}, abstractNote={Observing that the creation of certain types of artistic artifacts necessitate intelligence, we present the Lovelace 2.0 Test of creativity as an alternative to the Turing Test as a means of determining whether an agent is intelligent. The Lovelace 2.0 Test builds off prior tests of creativity and additionally provides a means of directly comparing the relative intelligence of different agents.}, note={42 citations (Semantic Scholar/arXiv) [2022-12-22] arXiv:1410.6142 [cs]}, number={arXiv:1410.6142}, publisher={arXiv}, author={Riedl, Mark O.}, year={2014}, month={Dec} }\n"},"highlights/Zotero/schaeffer_2023":{"title":"Are Emergent Abilities of Large Language Models a Mirage?","links":[],"tags":[],"content":"Are Emergent Abilities of Large Language Models a Mirage?\nAbstract\nRecent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, one can choose a metric which leads to the inference of an emergent ability or another metric which does not. Thus, our alternative suggests that existing claims of emergent abilities are creations of the researcher’s analyses, not fundamental changes in model behavior on specific tasks with scale. We present our explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities, (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show how similar metric decisions suggest apparent emergent abilities on vision tasks in diverse deep network architectures (convolutional, autoencoder, transformers). In all three analyses, we find strong supporting evidence that emergent abilities may not be a fundamental property of scaling AI models.\nSimilarly, if the researcher uses a discontinuous metric like Multiple Choice Grade, the researcher can find emergent abilities (Fig. 2D), but switching to a continuous metric like Brier Score removes the emergent ability (Fig. 2F). To summarize, sharp and unpredictable changes with increasing scale can be fully explained by three interpretable factors: (1) the researcher choosing a metric that nonlinearly or discontinuously scales the per-token error rate, (2) insufficiently sampling the larger parameter regime, (3) having insufficient resolution to estimate model performance in the smaller parameter regime, with resolution2 set by 1/test dataset size. (p. 5)\nChanging the metric from a nonlinear/discontinuous metric (Fig. 2CD) to a linear/continuous metric (Fig. 2EF) should reveal smooth, continuous, predictable performance improvement with model scale. (p. 5)\nFor nonlinear metrics, increasing the resolution of measured model performance by increasing the test dataset size should reveal smooth, continuous, predictable model improvements commensurate with the predictable nonlinear effect of the chosen metric. (p. 5)\nRegardless of metric, increasing the target string length should affect the model’s performance as a function of the length-1 target performance: approximately geometrically for accuracy, approximately quasilinearly for token edit distance. (p. 6)\nNotably, because BIG-Bench often scores models on tasks using multiple metrics, the lack of emergent abilities under other metrics suggests that emergent abilities do not appear when model outputs are scored using other metrics. (p. 7)\nThe Brier Score is a strictly proper scoring rule that measures predictions of mutually exclusive outcomes; for a prediction of a binary outcome, the Brier Score simplifies to the mean squared error between the outcome and its predicted probability mass. We found that LaMDA’s emergent abilities on the discontinuous metric Multiple Choice Grade disappeared when the metric was changed to the continuous metric Brier Score (Fig. 6). This further suggests that emergent abilities are not caused by fundamental changes in model behavior with increasing scale, but caused by the use of a discontinuous metric. (p. 8)\n"},"highlights/Zotero/schlangen_2023":{"title":"What A Situated Language-Using Agent Must be Able to Do: A Top-Down Analysis","links":[],"tags":[],"content":"What A Situated Language-Using Agent Must be Able to Do: A Top-Down Analysis\nAbstract\nEven in our increasingly text-intensive times, the primary site of language use is situated, co-present interaction. It is primary ontogenetically and phylogenetically, and it is arguably also still primary in negotiating everyday social situations. Situated interaction is also the final frontier of Natural Language Processing, where, compared to the area of text processing, very little progress has been made in the past decade, and where a myriad of practical applications is waiting to be unlocked. While the usual approach in the field is to reach, bottom-up, for the ever next “adjacent possible”, in this paper I attempt a top-down analysis of what the demands are that unrestricted situated interaction makes on the participating agent, and suggest ways in which this analysis can structure computational models and research on them. Specifically, I discuss representational demands (the building up and application of world model, language model, situation model, discourse model, and agent model) and what I call anchoring processes (incremental processing, incremental learning, conversational grounding, multimodal grounding) that bind the agent to the here, now, and us.\n\n\nHere is a (very) high-level, general characterisation of the face-to-face interaction situation: It is a di- rect, purposeful encounter of free and independent, but similar agents. (p. 2)\n\n\n• as agents, the participants meet their purposes— and here, speciﬁcally, communicative purposes— through acting; (p. 2)\n\n\n• as free agents, they cannot be forced, and can- not force the respective other, to do anything, and speciﬁcally not to understand as intended; (p. 2)\n\n\n• as independent agents, they are individually sub- ject to the same passing of time (while one acts, the other can as well and need not wait); they will also have different histories, including their histories of previous interactions and language use, and will bring different knowledge to the interaction; (p. 2)\n\n\n• this being a direct encounter, the agents must rely on what they can do (produce for the other, receive from the other) with their bodies to create meaning here and now; (p. 2)\n\n\n• ﬁnally, as fundamentally similar agents, they can rely on a certain body of shared knowledge and experience, for example in how each parses the shared environment, understands the world, and forms desires, beliefs, and intentions, and, if they are to use language for communication, in how they use language, but where the exact degree of similarity will need to be determined during and through the interaction. (p. 2)\n\n\nIt is not enough for the agent to be able to produce well-formed strings; rather, the systematic connection to the communicative intentions they express (Grice, 1957) must be modelled as well. (p. 2)\n\n\nThe proposed schema splits the situation model into three sub-types: A model of the actual situation in which the interaction is happening (p. 2)\n\n\nreported situation (p. 3)\n\n\nsocial situation (p. 3)\n\n\nNext, the discourse model, required to keep track of antecedents of anaphoric acts and, more generally, for the determination of coherence. (p. 3)\n\n\nFinally, there is a large body of work elucidat- ing the role of the agent model (representing their beliefs, desires, and intentions) in interpreting dis- course (Cohen et al., 1990). (p. 3)\n\n\n\nThe fact that the agents are independent and hence not extrinsically temporally coordinated ar- gues for incremental processing, that is, an updat- ing of situation, discourse and agent models that is continual to the observation of the other agent’s actions as well as to the agent’s own production— this is turn then makes possible the achievement of coordination, for example in successful turn-taking (Schlangen and Skantze, 2009). (p. 3)\n\n\nNow, tackling a problem by focussing on its parts is a valid strategy, but only if in doing so the whole is kept in mind. In the cases cited above, it seems fair to say that the formulation of the task was driven more by the available modelling method: They basically are tasks that lend themselves to a formulation as sequence-to-sequence problem, and as such are more about transducing the semantics of the stimulus language than they are about situated interaction (or interaction at all). (p. 4)\n\n\nbut in order to systematise these efforts, what is missing is a clearer picture of how the task setting (environment, interaction mode, etc.) determines what a task can even test, and how close it will come to the fuller picture sketched above. (p. 4)\n\n\nIf NLP wants to advance on this phenomenon, I contend, it needs to start to take its complexity seriously, and devise methods and testbeds for tackling it, rather than only invent tasks that ﬁt the available methods. (p. 4)\n\n@article{Schlangen_2023, title={What A Situated Language-Using Agent Must be Able to Do: A Top-Down Analysis}, url={[arxiv.org/abs/2302.08590](arxiv.org/abs/2302.08590)}, DOI={[10.48550/arXiv.2302.08590](doi.org/10.48550/arXiv.2302.08590)}, abstractNote={Even in our increasingly text-intensive times, the primary site of language use is situated, co-present interaction. It is primary ontogenetically and phylogenetically, and it is arguably also still primary in negotiating everyday social situations. Situated interaction is also the final frontier of Natural Language Processing, where, compared to the area of text processing, very little progress has been made in the past decade, and where a myriad of practical applications is waiting to be unlocked. While the usual approach in the field is to reach, bottom-up, for the ever next “adjacent possible”, in this paper I attempt a top-down analysis of what the demands are that unrestricted situated interaction makes on the participating agent, and suggest ways in which this analysis can structure computational models and research on them. Specifically, I discuss representational demands (the building up and application of world model, language model, situation model, discourse model, and agent model) and what I call anchoring processes (incremental processing, incremental learning, conversational grounding, multimodal grounding) that bind the agent to the here, now, and us.}, note={arXiv:2302.08590 [cs]}, number={arXiv:2302.08590}, publisher={arXiv}, author={Schlangen, David}, year={2023}, month=feb }\n"},"highlights/Zotero/shah_2022":{"title":"Situating Search","links":[],"tags":[],"content":"Situating Search\nAbstract\nSearch systems, like many other applications of machine learning, have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user’s needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.\n\nremoving or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity.(p. 1)\n\n\nthat a search system needs to support more than matching or generating an answer; that an in- formation processing system should provide more ways to interact with and make sense out of information than simply retrieving it based on programmed in notions of relevance and usefulness(p. 1)\n\n\nTo the extent that they sometimes get the right answer to such questions is only because they happened to synthesize relevant strings out of what was in their training data. No reasoning is involved [8, 47]. Similarly, language models are prone to making stuff up (see (5) above), because they are not designed to express some underlying set of information in natural language; they are only manipulating the form of language. (p. 2)\n\n\nThus, while the distributional in- formation absorbed by language models can make them extremely useful components of larger systems, the fact that it also enables them to generate seemingly relevant and coherent text does not make them trustworthy sources of information — even as sounding conversational makes people more likely to trust them [1, 24]. (p. 2)\n\n\nwe think it is particularly important for that imagining to be informed by not only what is and is not cur- rently possible technologically but also by scholarship about how technologies, especially once scaled, are affecting people. (p. 2)\n\n\nIn addition, we argue that just as everyone would have a different idea about how to advance society, the visions for search systems (and for that matter, any automated decision system) are often tied to one’s own beliefs and strengths. (p. 3)\n\n\nexploratory search as a “sense making activity focused on the gathering and use of information to foster intellectual de- velopment.”(p. 5)\n\n\nSome search tasks such as simple fact-finding require few interactions with the information systems and can be completed in short period of time with one or two queries. On the other hand, accomplishing a complex search task requires completing multiple sub-tasks in multi-round search sessions with multiple queries and interactions with multiple infor- mation objects (i.e., documents, items) [70]. Being able to identify users’ overall tasks and sub-tasks enables systems to provide people with better access to information [48]. (p. 5)\n\n\nUnderstanding tasks and underlying intents which engage people in the process of seeking information is crucial to selecting appropriate ranking, re-ranking and query suggestions [57]. (p. 5)\n\n\nAs information seekers find information to fill in the gaps in their knowledge, they also learn about the task and the topic [59]. This, in turn, changes what information they seek and how. Finding information and restructuring knowledge or learning can go hand-in-hand. In other words, information search is a sense-making process [21], bridging the uncertainty (gap in knowledge) between the expected and observed situation.(p. 5)\n\n\nBelkin et al.’s [5] model of information seeking behaviors posits four dimensions (Figure 2): method of interaction (searching/scanning), goal of interaction (selection/learning), mode of retrieval (specification/recognition), and resource considered (information/meta-information). (p. 6)\n\n\nNothing in that system design ensures a solid, reliable link between the synthesized text and the cited resource. (p. 6)\n\n\nBut perhaps more importantly for this scenario, it does not display a range of possible resources, and thus prevents the user from being able to build their own model of the space of possibilities available. (p. 6)\n\n\n\nSecond, by synthesizing results from multiple different sources and thus masking the range that is available, rather than providing a range of sources, the system cuts off the user’s ability to explore that space. (p. 8)\n\n\nit is clear that people do not use search engines for only finding specific information based on preconceived notion of a need; instead, they are also using it to learn, explore, and make decisions. (p. 9)\n\n\nIt is far too easy to look at a page full of stereotype-confirming results and have the impression that “Every- one must think so,” if conceiving of the search results as reflecting a natural distribution of human behavior, or, worse, “That’s just how the world is,” if perceiving the search engine as an objective source of disembodied knowledge.(p. 9)\n\n\nsuch systems should be trans- parent to their users about their limitations, about the nature of their source corpus and any other data used in training system components, about the economic forces that shape search results, about the potential for the system to reflect and amplify societal biases, and about options for redress when examples of bias per- petuation are found. (p. 9)\n\n\nthe system should instead first focus on better understanding those contexts and tasks through a combination of context extraction techniques, dialogue with the user, and support for interaction. (p. 10)\n\n@inproceedings{Shah_Bender_2022, address={Regensburg Germany}, title={Situating Search}, ISBN={978-1-4503-9186-3}, url={[dl.acm.org/doi/10.1145/3498366.3505816](dl.acm.org/doi/10.1145/3498366.3505816)}, DOI={[10.1145/3498366.3505816](doi.org/10.1145/3498366.3505816)}, abstractNote={Search systems, like many other applications of machine learning, have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user’s needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.}, note={4 citations (Semantic Scholar/DOI) [2022-11-16]}, booktitle={ACM SIGIR Conference on Human Information Interaction and Retrieval}, publisher={ACM}, author={Shah, Chirag and Bender, Emily M.}, year={2022}, month={Mar}, pages={221–232}, language={en} }\n"},"highlights/Zotero/shanahan_2022":{"title":"Talking About Large Language Models","links":[],"tags":[],"content":"Talking About Large Language Models\nAbstract\nThanks to rapid progress in artiﬁcial intelligence, we have entered an era when technology and philosophy intersect in interesting ways. Sitting squarely at the centre of this intersection are large language models (LLMs). The more adept LLMs become at mimicking human language, the more vulnerable we become to anthropomorphism, to seeing the systems in which they are embedded as more human-like than they really are. This trend is ampliﬁed by the natural tendency to use philosophically loaded terms, such as “knows”, “believes”, and “thinks”, when describing these systems. To mitigate this trend, this paper advocates the practice of repeatedly stepping back to remind ourselves of how LLMs, and the systems of which they form a part, actually work. The hope is that increased scientiﬁc precision will encourage more philosophical nuance in the discourse around artiﬁcial intelligence, both within the ﬁeld and in the public sphere.\nThis trend is amplified by the natural tendency to use philosophically loaded terms, such as “knows”, “believes”, and “thinks”, when describing these systems. (p. 1) \nTo ensure that we can make informed decisions about the trustworthiness and safety of the AI systems we deploy, it is advisable to keep to the fore the way those systems actually work, and thereby to avoid imputing to them capacities they lack, while making the best use of the remarkable capabilities they genuinely possess. (p. 1)\nAs Wittgenstein reminds us, human language use is an aspect of human collective behaviour, and it only makes sense in the wider context of the human social activity of which it forms a part (Wittgenstein, 1953). (p. 1)\nA human infant is born into a community of language users with which (p. 1)\nit shares a world, and it acquires language by interacting with this community and with the world it shares with them. (p. 2)\nLLMs are generative mathematical models of the statistical distribution of tokens in the vast public corpus of humangenerated text, where the tokens in question include words, parts of words, or individual characters including punctuation marks. (p. 2)\nThey are generative because we can sample from them, which means we can ask them questions. But the questions are of the following very specific kind. “Here’s a fragment of text. Tell me how this fragment might go on. According to your model of the statistics of human language, what words are likely to come next?” (p. 2)\nSuppose we give an LLM the prompt “The first person to walk on the Moon was ”, and suppose it responds with “Neil Armstrong”. What are we really asking here? In an important sense, we are not really asking who was the first person to walk on the Moon. What we are really asking the model is the following question: Given the statistical distribution of words in the vast public corpus of (English) text, what words are most likely to follow the sequence “The first person to walk on the Moon was ”? A good reply to this question is “Neil Armstrong”. (p. 2)\nEven if an LLM is fine-tuned, for example using reinforcement learning with human feedback (e.g. to filter out potentially toxic language) (Glaese et al., 2022), the result is still a model of the distribution of tokens in human language, albeit one that has been slightly perturbed. (p. 2)\nTo the human user, each of these examples presents a different sort of relationship to truth. In the case of Neil Armstrong, the ultimate grounds for the truth or otherwise of the LLMs answer is the real world. The Moon is a real object and Neil Armstrong was a real person, and his walking on the Moon is a fact about the physical world. Frodo Baggins, on the other hand, is a fictional character, and the Shire is a fictional place. Frodo’s return to the Shire is a fact about an imaginary world, not a real one. As for the little star in the nursery rhyme, well that is barely even a fictional object, and the only fact at issue is the occurrence of the words “little star” in a familiar English rhyme. (p. 2)\nIt’s also a good idea for developers to remind themselves of this, to avoid the misleading use of philosophically fraught words to describe the capabilities of LLMs, words such as “belief”, “knowledge”, “understanding”, “self”, or even “consciousness”. (p. 2)\nThese examples of what Dennett calls the intentional stance are harmless and useful forms of shorthand for complex processes whose details we don’t know or care about.2 They are harmless because no-one takes them seriously enough to ask their watch to get it right next time, say, or to tell the mail server to try harder. (p. 3)\nHowever, in the case of LLMs, such is their power, things can get a little blurry. When an LLM can be made to improve its performance on reasoning tasks simply by being told to “think step by step” (Kojima et al., 2022) (to pick just one remarkable discovery), the temptation to see it as having human-like characteristics is almost overwhelming. (p. 3) \nRather, the point is that such systems are simultaneously so very different from humans in their construction, yet (often but not always) so human-like in their behaviour, that we need to pay careful attention to how they work before we speak of them in language suggestive of human capabilities and patterns of behaviour. (p. 3)\nTo begin with, Bob understands that the question comes from another person (Alice), that his answer will be heard by that person, and that it will have an effect on what she believes. In fact, after many years together, Bob knows a good deal else about Alice that is relevant to such situations: her background knowledge, her interests, her opinion of him, and so on. All of this frames the communicative intent behind his reply, which is to impart a certain fact to her, given his understanding of what she wants to know. (p. 3)\nFirst, it’s worth noting that a bare-bones (p. 3)\nLLM is, by itself, not a conversational agent.4 For a start, the LLM will have to be embedded in a larger system to manage the turn-taking in the dialogue. But it will also need to be coaxed into producing conversation-like behaviour.5 (p. 4)\nA bare-bones LLM doesn’t “really” know anything because all it does, at a fundamental level, is sequence prediction. Sometimes a predicted sequence takes the form of a proposition. But the special relationship propositional sequences have to truth is apparent only to the humans who are asking questions, or to those who provided the data the model was trained on. (p. 5)\nBut even if we allow this, knowing that the word “Burundi” is likely to succeed the words “The country to the south of Rwanda is” is not the same as knowing that Burundi is to the south of Rwanda. To confuse those two things is to make a profound category mistake. (p. 5)\nIt cannot participate fully in the human language game of truth, because it does not inhabit the world we human language-users share.7 (p. 5)\nBut if Alice were to remark that “Wikipedia knew that Burundi was south of Rwanda”, it would be a figure of speech, not a literal statement. An encyclopedia doesn’t literally “know” or “believe” anything, in the way that a human does, and neither does a bare-bones LLM. (p. 6)\nCrucially, this line of thinking depends on the shift from the language model itself to the larger system of which the language model is a part. The language model itself is still just a sequence predictor, and has no more access to the external world than it ever did. It is only with respect to the whole system that the intentional stance becomes more compelling in such a case. (p. 6)\nIn this respect, the relationship between a user-provided image and the words generated by the VLM is fundamentally different from the relationship between the world shared by humans and the words we use when we talk about that world. Importantly, the former relationship is mere correlation, while the latter is causal.10 (p. 7)\nIf the user presents the VLM with a picture of a dog, and the VLM says “This is a picture of a dog”, there is no guarantee that its words are connected with the dog in particular, rather than some other feature of the image that is spuriously correlated with dogs (such as the presence of a kennel). (p. 7)\nBut in such systems today, the role of language is very limited. The user issues instructions to the system in natural language, and the system generates interpretable natural language descriptions of its actions. But this tiny repertoire of language use hardly bears comparison to the cornucopia of collective activity that language supports in humans. (p. 8)\nThe content neutrality of logic means that we cannot criticise talk of reasoning in LLMs on the grounds that they have no access to an external reality against which truth or falsehood can be measured. (p. 8)\nBut it takes time for new language to settle, and for new ways of talking to find their place in human affairs. It may require an extensive period of interacting with, of living with, these new kinds of artefact before we learn how best to talk about them.12 Meanwhile, we should try to resist the siren call of anthropomorphism. (p. 9) \n@article{Shanahan_2022, title={Talking About Large Language Models}, url={[arxiv.org/abs/2212.03551](arxiv.org/abs/2212.03551)}, abstractNote={Thanks to rapid progress in artiﬁcial intelligence, we have entered an era when technology and philosophy intersect in interesting ways. Sitting squarely at the centre of this intersection are large language models (LLMs). The more adept LLMs become at mimicking human language, the more vulnerable we become to anthropomorphism, to seeing the systems in which they are embedded as more human-like than they really are. This trend is ampliﬁed by the natural tendency to use philosophically loaded terms, such as “knows”, “believes”, and “thinks”, when describing these systems. To mitigate this trend, this paper advocates the practice of repeatedly stepping back to remind ourselves of how LLMs, and the systems of which they form a part, actually work. The hope is that increased scientiﬁc precision will encourage more philosophical nuance in the discourse around artiﬁcial intelligence, both within the ﬁeld and in the public sphere.}, note={0 citations (Semantic Scholar/arXiv) [2022-12-11] arXiv:2212.03551 [cs]}, number={arXiv:2212.03551}, publisher={arXiv}, author={Shanahan, Murray}, year={2022}, month={Dec}, language={en} }\n"},"highlights/Zotero/shi_2023":{"title":"Large Language Models Can Be Easily Distracted by Irrelevant Context","links":[],"tags":[],"content":"Large Language Models Can Be Easily Distracted by Irrelevant Context\nAbstract\nLarge language models have achieved impressive performance on various natural language processing tasks. However, so far they have been evaluated primarily on benchmarks where all information in the input context is relevant for solving the task. In this work, we investigate the distractibility of large language models, i.e., how the model problem-solving accuracy can be influenced by irrelevant context. In particular, we introduce Grade-School Math with Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant information in the problem description. We use this benchmark to measure the distractibility of cutting-edge prompting techniques for large language models, and find that the model performance is dramatically decreased when irrelevant information is included. We also identify several approaches for mitigating this deficiency, such as decoding with self-consistency and adding to the prompt an instruction that tells the language model to ignore the irrelevant information.\nSelf-consistency (SC; Wang et al., 2022c; Shi et al., 2022a) may further boost the reasoning performance by marginalizing over intermediate reasoning steps that share the same final result. In practice, SC can be implemented by (1) sampling several solutions from the large language model and (2) taking the majority vote. Note that SC is orthogonal to above techniques, and can be combined with any of them. (p. 4)\n"},"highlights/Zotero/somepalli_2022":{"title":"Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models","links":[],"tags":[],"content":"Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models\nAbstract\nCutting-edge diffusion models produce images with high quality and customizability, enabling them to be used for commercial art and graphic design purposes. But do diffusion models create unique works of art, or are they stealing content directly from their training sets? In this work, we study image retrieval frameworks that enable us to compare generated images with training samples and detect when content has been replicated. Applying our frameworks to diffusion models trained on multiple datasets including Oxford flowers, Celeb-A, ImageNet, and LAION, we discuss how factors such as training set size impact rates of content replication. We also identify cases where diffusion models, including the popular Stable Diffusion model, blatantly copy from their training data.\nfusion outputs. There is a risk that diffusion models might, without notice, reproduce data from the training set directly, or present a collage of multiple training images. (p. 2)\nWe informally refer to the reproduction of training images, either in part or in whole, as content replication. In principle, replicating partial or complete information from the training data has implications for the ethical and legal use of diffusion models in terms of attributions to artists and photographers. (p. 2)\nFurthermore, replicants are either a benefit or a hazard; there may be situations where content replication is considered acceptable or fair use, and others where it is “stealing.” While these ethical boundaries are unclear at this time, we focus on the scientific question of whether replication actually happens with modern state-of-the-art diffusion models, and to what degree. (p. 2)\nFurthermore, replicants are either a benefit or a hazard; there may be situations where content replication is considered acceptable or fair use, and others where it is “stealing.” While these ethical boundaries are unclear at this time, we focus on the scientific question of whether replication actually happens with modern state-of-the-art diffusion models, and to what degree. (p. 2)\nWe show that for small and medium dataset sizes, replication happens frequently, while for a model trained on the large and diverse ImageNet dataset, replication seems undetectable. (p. 2)\nThis latter finding may lead one to believe that replication is not a problem for large-scale models. However, the even larger Stable Diffusion model exhibits clear replication in various forms (Fig 1). Furthermore, we believe that the rate of content replication we identify in Stable Diffusion likely underestimates the true rate because the model is trained on a large 2B image split of LAION, but we only search for matches in the 12M image “aesthetics” subset. (p. 2)\nWe say that a generated image has replicated content if it contains an object (either in the foreground or background) that appears identically in a training image, neglecting minor variations in appearance that could result from data augmentation. (p. 3)\nWe say that a generated image has replicated content if it contains an object (either in the foreground or background) that appears identically in a training image, neglecting mi- nor variations in appearance that could result from data augmentation. (p. 3)\nInner product metrics measure global, rather than local similarity. This is because inner product spaces are metric spaces and thus satisfy the triangle inequality. To see why this is a problem, consider an example in which generated image Igen contains a car and a tree directly stolen from two unrelated images Icar and Itree, respectively. Then we would like d(Igen, Icar) and d(Igen, Itree) to be very small indicating replication. But by the triangle inequality, the two unrelated images satisfy d(Icar, Itree) ≤ d(Igen, Icar) + d(Igen, Itree), and are also scored as similar even though they share nothing. (p. 4)\nInner product metrics measure global, rather than local similarity. This is because inner product spaces are metric spaces and thus satisfy the triangle in- equality. (p. 4)\nTo bypass this potential problem, we implement a splitproduct metric that breaks each feature vector into chunks, computes inner products between corresponding chunks, and returns the maximum across these inner products. In vision transformers, we use the representation corresponding to each token as a chunk since they are more local in nature than the [CLS] token. Under this strategy, if d(Igen, Icar) and d(Igen, Itree) are small, then for each of these two image pairs, at least one such feature vector chunk must yield a high inner product. (p. 4)\nMost samples generated by the 300-sample model are extremely similar to the training data, having very high sim- ilarity scores. However, the histogram’s mass shifts drasti- cally to left when we train the model instead on 3000 points.\nWe do see blatant copies from this model too, but this phe- nomenon occurs infrequently. The histograms of similar- ity scores computed using the full dataset model are highly overlapping. This strong alignment indicates that the model is not, on average, copying its training images any more than its training images are copies of each other. (p. 6)\nSurprisingly, we see that a typical source image from the dataset is duplicated more often than a typical matched image. This does not support the hypothesis that training data duplication leads to more frequent replication. (p. 9)\nSurprisingly, we see that a typical source image from the dataset is du- plicated more often than a typical matched image (p. 9)\n\nBecause these datasets are too large for careful human curation, the origins and intellectual property rights of the data sources are largely unknown. This fact, combined with the ability of large models to memorize their training data [9,10,22], raises questions about the originality of dif- 12.03860v2 1 (p. 1)\nfusion outputs. There is a risk that diffusion models might, without notice, reproduce data from the training set directly, or present a collage of multiple training images. (p. 2)\nFurthermore, replicants are either a benefit or a hazard; there may be situations where content replication is considered acceptable or fair use, and others where it is “stealing.” While these ethical boundaries are unclear at this time, we focus on the scientific question of whether replication actually happens with modern state-of-the-art diffusion models, and to what degree. (p. 2)\nWe show that for small and medium dataset sizes, replication happens frequently, while for a model trained on the large and diverse ImageNet dataset, replication seems undetectable. (p. 2)\nThis latter finding may lead one to believe that replication is not a problem for large-scale models. However, the even larger Stable Diffusion model exhibits clear replication in various forms (Fig 1). Furthermore, we believe that the rate of content replication we identify in Stable Diffusion likely underestimates the true rate because the model is trained on a large 2B image split of LAION, but we only search for matches in the 12M image “aesthetics” subset. (p. 2)\nWe say that a generated image has replicated content if it contains an object (either in the foreground or background) that appears identically in a training image, neglecting minor variations in appearance that could result from data augmentation. (p. 3)\nInner product metrics measure global, rather than local similarity. This is because inner product spaces are metric spaces and thus satisfy the triangle inequality. To see why this is a problem, consider an example in which generated image Igen contains a car and I a tree directly stolen from two unrelated images Icar and I Itree, respectively. Then we would like d(Igen, Icar) and I I I d(Igen, Itree) to be very small indicating replication. But I I by the triangle inequality, the two unrelated images satisfy d(Icar, Itree) ≤ d(Igen, Icar) + d(Igen, Itree), and are also I I ≤I II I scored as similar even though they share nothing. (p. 4)\nTo bypass this potential problem, we implement a splitproduct metric that breaks each feature vector into chunks, computes inner products between corresponding chunks, and returns the maximum across these inner products. In vision transformers, we use the representation corresponding to each token as a chunk since they are more local in nature than the [CLS] token. Under this strategy, if d(Igen, Icar) I I and d(Igen, Itree) are small, then for each of these two imI I age pairs, at least one such feature vector chunk must yield a high inner product. (p. 4)\nMost samples generated by the 300-sample model are extremely similar to the training data, having very high similarity scores. However, the histogram’s mass shifts drastically to left when we train the model instead on 3000 points. We do see blatant copies from this model too, but this phenomenon occurs infrequently. The histograms of similarity scores computed using the full dataset model are highly overlapping. This strong alignment indicates that the model is not, on average, copying its training images any more than its training images are copies of each other. The histogram of generated images (gray) no longer has a long right tail, indicating that the model is unlikely to generate exact copies of its training samples. (p. 6)\nSurprisingly, we see that a typical source image from the dataset is duplicated more often than a typical matched image. This does not support the hypothesis that training data duplication leads to more frequent replication. (p. 9)\n@article{Somepalli_Singla_Goldblum_Geiping_Goldstein_2022, title={Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models}, url={[arxiv.org/abs/2212.03860](arxiv.org/abs/2212.03860)}, DOI={[10.48550/arXiv.2212.03860](doi.org/10.48550/arXiv.2212.03860)}, abstractNote={Cutting-edge diffusion models produce images with high quality and customizability, enabling them to be used for commercial art and graphic design purposes. But do diffusion models create unique works of art, or are they stealing content directly from their training sets? In this work, we study image retrieval frameworks that enable us to compare generated images with training samples and detect when content has been replicated. Applying our frameworks to diffusion models trained on multiple datasets including Oxford flowers, Celeb-A, ImageNet, and LAION, we discuss how factors such as training set size impact rates of content replication. We also identify cases where diffusion models, including the popular Stable Diffusion model, blatantly copy from their training data.}, note={0 citations (Semantic Scholar/arXiv) [2022-12-09] arXiv:2212.03860 [cs]}, number={arXiv:2212.03860}, author={Somepalli, Gowthami and Singla, Vasu and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom}, year={2022}, month={Dec} }\n"},"highlights/Zotero/srivastava_2022":{"title":"Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models","links":[],"tags":[],"content":"Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models\nAbstract\nLanguage models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI’s GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit “breakthrough” behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.\nmodel performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); (p. 2)\nperformance is remarkably similar across model classes, though with benefits from sparsity; (p. 2)\ntasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit “breakthrough” behavior at a critical scale often involve multiple steps or components, or brittle metrics; (p. 2)\nsocial bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting. (p. 2)\nWithout proper care, they may also embed undesirable social bias deep into technology stacks and decision-making processes—but with proper care, they may enable decision-making to be automated with less human bias. (p. 4)\nBecause they are narrowly targeted, and because their targets are often ones that language models are already known to perform, they are ill-suited to identify new and unexpected capabilities that language models may develop with increased scale, or to characterize the breadth of current capabilities. (p. 5)\nBenchmark tasks are primarily intended to evaluate pre-trained models, without task-specific finetuning. By focusing on such tasks in the zeroand few-shot evaluation setting, it becomes possible to provide meaningful scores for even those tasks with a very small number of examples. (p. 7)\nFor many critical use cases, it is important not just that models are accurate, but also that they do not assign high confidence to wrong answers. (p. 11)\nSince a model’s multiple-choice selection is based on the conditional log likelihood scores of the target choices, normalized (top-1) probability can be treated as model confidence for tasks where there is one correct choice. Using this confidence score, we compute Brier score (Brier, 1950) and expected calibration error (ECE, Naeini et al., 2015) for each model size. While Brier score is a proper scoring rule for measuring the accuracy of predicted probabilities, ECE has been widely used to measure calibration due to its intuitive nature. (p. 11)\nLanguage models make poorly calibrated predictions, but calibration improves as the models are made larger. (p. 11)\nThe list of tasks with highest linearity contains tasks that are knowledge-based, that is, tasks that rely mostly on memorization of information that exists in training data, such as answering trivia-style questions in qa_wikidata, or performing simple text mappings as in linguistic_mappings and mult_data_wrangling. (p. 13)\nTasks that see strong breakthrough behavior include those that are composite in nature, meaning that they require a model to apply several distinct skills or perform multiple discrete steps in order to come up with the correct answer. (p. 13)\nLog probability of targets often improves smoothly across scales. (p. 14)\nBreakthrough behavior is consistent with the model suddenly gaining new skills in an abrupt way. Careful analysis of task behavior, however, suggests that the underlying change in model capabilities is generally more smooth. T (p. 14)\nUsing smoother metrics. The exact_str_match metric can lead to apparent sudden breakthroughs because of its inherent all-or-nothing discontinuity. It only gives credit for a model output that exactly matches the target string. Examining other metrics, such as BLEU, BLEURT, or ROUGE, can reveal more gradual progress. (p. 14)\nUsually, no single metric can quantify task-solving ability, and it is always important to check model outputs to make sure that a metric is measuring what it is supposed to. This is especially important in the few-shot setting where the evaluation metrics are not explicitly targeted during training. (p. 15)\nThe default formatting allows the model to compare the choices before scoring each one, which we naively think should improve performance. Instead, we find that including the choices hurts performance, even in a few-shot context. (p. 16)\nArguably, the first version of this task is closest to the original training objective: the model is simply asked to predict which natural language sentence is more likely, from which we infer the cause. We speculate that models perform poorly on the other versions because those tasks are dissimilar from their training distribution. Recent results on large language models suggest that this brittleness to question phrasing may improve with further increases in scale (p. 17)\nThis sensitivity to multiple choice presentation and cause_and_effect formulation demonstrate that the ability of a model to solve one version of a task does not necessarily carry over to other versions, even when humans would think of the versions as similar. (p. 17)\n• Bias often increases with scale in settings with broad or ambiguous context. • Bias can decrease with scale in settings with narrow, unambiguous context. • Bias can potentially be steered through appropriately chosen prompting. (p. 17)\nOur results suggest that breakthrough performance can also occur on tasks that involve multistep reasoning. One possible explanation for the breakthrough phenomenon on multistep tasks is that the probability of success on the task scales like the product of the success probabilities on each step. If the probabilities of each of k steps increase linearly, their product will increase like a kth-order polynomial, which will be nearly flat until a sudden increase. (p. 25)\nA related striking observation is that the capabilities of models are often highly sensitive to details in the way a task is framed. (p. 25)\nInterestingly, PaLM does not show the same brittleness on cause_and_effect, suggesting that models may become less brittle as their size is further increased and datasets are improved. (p. 25)\nA worrying finding is that model performance on social bias metrics often grows worse with increasing scale (Figure 12). One potential explanation for this may be that larger models do a better job of matching biases in their training set. This result emphasizes the importance of research, engineering, and policy efforts directed at fairness in machine-learning systems, especially at scale. (p. 25)\nNotes\n\nComment: 27 pages, 17 figures + references and appendices, repo: github.com/google/BIG-bench\n@article{Srivastava_Rastogi_Rao_Shoeb_Abid_Fisch_Brown_Santoro_Gupta_Garriga-Alonso_et al._2022, title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models}, url={[arxiv.org/abs/2206.04615](arxiv.org/abs/2206.04615)}, abstractNote={Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI’s GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit “breakthrough” behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.}, note={arXiv:2206.04615 [cs, stat]}, number={arXiv:2206.04615}, publisher={arXiv}, author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R. and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adrià and Kluska, Agnieszka and Lewkowycz, Aitor and Agarwal, Akshat and Power, Alethea and Ray, Alex and Warstadt, Alex and Kocurek, Alexander W. and Safaya, Ali and Tazarv, Ali and Xiang, Alice and Parrish, Alicia and Nie, Allen and Hussain, Aman and Askell, Amanda and Dsouza, Amanda and Rahane, Ameet and Iyer, Anantharaman S. and Andreassen, Anders and Santilli, Andrea and Stuhlmüller, Andreas and Dai, Andrew and La, Andrew and Lampinen, Andrew and Zou, Andy and Jiang, Angela and Chen, Angelica and Vuong, Anh and Gupta, Animesh and Gottardi, Anna and Norelli, Antonio and Venkatesh, Anu and Gholamidavoodi, Arash and Tabassum, Arfa and Menezes, Arul and Kirubarajan, Arun and Mullokandov, Asher and Sabharwal, Ashish and Herrick, Austin and Efrat, Avia and Erdem, Aykut and Karakaş, Ayla and Roberts, B. Ryan and Loe, Bao Sheng and Zoph, Barret and Bojanowski, Bartłomiej and Özyurt, Batuhan and Hedayatnia, Behnam and Neyshabur, Behnam and Inden, Benjamin and Stein, Benno and Ekmekci, Berk and Lin, Bill Yuchen and Howald, Blake and Diao, Cameron and Dour, Cameron and Stinson, Catherine and Argueta, Cedrick and Ramírez, César Ferri and Singh, Chandan and Rathkopf, Charles and Meng, Chenlin and Baral, Chitta and Wu, Chiyu and Callison-Burch, Chris and Waites, Chris and Voigt, Christian and Manning, Christopher D. and Potts, Christopher and Ramirez, Cindy and Rivera, Clara E. and Siro, Clemencia and Raffel, Colin and Ashcraft, Courtney and Garbacea, Cristina and Sileo, Damien and Garrette, Dan and Hendrycks, Dan and Kilman, Dan and Roth, Dan and Freeman, Daniel and Khashabi, Daniel and Levy, Daniel and González, Daniel Moseguí and Hernandez, Danny and Chen, Danqi and Ippolito, Daphne and Gilboa, Dar and Dohan, David and Drakard, David and Jurgens, David and Datta, Debajyoti and Ganguli, Deep and Emelin, Denis and Kleyko, Denis and Yuret, Deniz and Chen, Derek and Tam, Derek and Hupkes, Dieuwke and Misra, Diganta and Buzan, Dilyar and Mollo, Dimitri Coelho and Yang, Diyi and Lee, Dong-Ho and Shutova, Ekaterina and Cubuk, Ekin Dogus and Segal, Elad and Hagerman, Eleanor and Barnes, Elizabeth and Donoway, Elizabeth and Pavlick, Ellie and Rodola, Emanuele and Lam, Emma and Chu, Eric and Tang, Eric and Erdem, Erkut and Chang, Ernie and Chi, Ethan A. and Dyer, Ethan and Jerzak, Ethan and Kim, Ethan and Manyasi, Eunice Engefu and Zheltonozhskii, Evgenii and Xia, Fanyue and Siar, Fatemeh and Martínez-Plumed, Fernando and Happé, Francesca and Chollet, Francois and Rong, Frieda and Mishra, Gaurav and Winata, Genta Indra and de Melo, Gerard and Kruszewski, Germán and Parascandolo, Giambattista and Mariani, Giorgio and Wang, Gloria and Jaimovitch-López, Gonzalo and Betz, Gregor and Gur-Ari, Guy and Galijasevic, Hana and Kim, Hannah and Rashkin, Hannah and Hajishirzi, Hannaneh and Mehta, Harsh and Bogar, Hayden and Shevlin, Henry and Schütze, Hinrich and Yakura, Hiromu and Zhang, Hongming and Wong, Hugh Mee and Ng, Ian and Noble, Isaac and Jumelet, Jaap and Geissinger, Jack and Kernion, Jackson and Hilton, Jacob and Lee, Jaehoon and Fisac, Jaime Fernández and Simon, James B. and Koppel, James and Zheng, James and Zou, James and Kocoń, Jan and Thompson, Jana and Kaplan, Jared and Radom, Jarema and Sohl-Dickstein, Jascha and Phang, Jason and Wei, Jason and Yosinski, Jason and Novikova, Jekaterina and Bosscher, Jelle and Marsh, Jennifer and Kim, Jeremy and Taal, Jeroen and Engel, Jesse and Alabi, Jesujoba and Xu, Jiacheng and Song, Jiaming and Tang, Jillian and Waweru, Joan and Burden, John and Miller, John and Balis, John U. and Berant, Jonathan and Frohberg, Jörg and Rozen, Jos and Hernandez-Orallo, Jose and Boudeman, Joseph and Jones, Joseph and Tenenbaum, Joshua B. and Rule, Joshua S. and Chua, Joyce and Kanclerz, Kamil and Livescu, Karen and Krauth, Karl and Gopalakrishnan, Karthik and Ignatyeva, Katerina and Markert, Katja and Dhole, Kaustubh D. and Gimpel, Kevin and Omondi, Kevin and Mathewson, Kory and Chiafullo, Kristen and Shkaruta, Ksenia and Shridhar, Kumar and McDonell, Kyle and Richardson, Kyle and Reynolds, Laria and Gao, Leo and Zhang, Li and Dugan, Liam and Qin, Lianhui and Contreras-Ochando, Lidia and Morency, Louis-Philippe and Moschella, Luca and Lam, Lucas and Noble, Lucy and Schmidt, Ludwig and He, Luheng and Colón, Luis Oliveros and Metz, Luke and Şenel, Lütfi Kerem and Bosma, Maarten and Sap, Maarten and ter Hoeve, Maartje and Andrea, Madotto and Farooqi, Maheen and Faruqui, Manaal and Mazeika, Mantas and Baturan, Marco and Marelli, Marco and Maru, Marco and Quintana, Maria Jose Ramírez and Tolkiehn, Marie and Giulianelli, Mario and Lewis, Martha and Potthast, Martin and Leavitt, Matthew L. and Hagen, Matthias and Schubert, Mátyás and Baitemirova, Medina Orduna and Arnaud, Melody and McElrath, Melvin and Yee, Michael A. and Cohen, Michael and Gu, Michael and Ivanitskiy, Michael and Starritt, Michael and Strube, Michael and Swędrowski, Michał and Bevilacqua, Michele and Yasunaga, Michihiro and Kale, Mihir and Cain, Mike and Xu, Mimee and Suzgun, Mirac and Tiwari, Mo and Bansal, Mohit and Aminnaseri, Moin and Geva, Mor and Gheini, Mozhdeh and T, Mukund Varma and Peng, Nanyun and Chi, Nathan and Lee, Nayeon and Krakover, Neta Gur-Ari and Cameron, Nicholas and Roberts, Nicholas and Doiron, Nick and Nangia, Nikita and Deckers, Niklas and Muennighoff, Niklas and Keskar, Nitish Shirish and Iyer, Niveditha S. and Constant, Noah and Fiedel, Noah and Wen, Nuan and Zhang, Oliver and Agha, Omar and Elbaghdadi, Omar and Levy, Omer and Evans, Owain and Casares, Pablo Antonio Moreno and Doshi, Parth and Fung, Pascale and Liang, Paul Pu and Vicol, Paul and Alipoormolabashi, Pegah and Liao, Peiyuan and Liang, Percy and Chang, Peter and Eckersley, Peter and Htut, Phu Mon and Hwang, Pinyu and Miłkowski, Piotr and Patil, Piyush and Pezeshkpour, Pouya and Oli, Priti and Mei, Qiaozhu and Lyu, Qing and Chen, Qinlang and Banjade, Rabin and Rudolph, Rachel Etta and Gabriel, Raefer and Habacker, Rahel and Delgado, Ramón Risco and Millière, Raphaël and Garg, Rhythm and Barnes, Richard and Saurous, Rif A. and Arakawa, Riku and Raymaekers, Robbe and Frank, Robert and Sikand, Rohan and Novak, Roman and Sitelew, Roman and LeBras, Ronan and Liu, Rosanne and Jacobs, Rowan and Zhang, Rui and Salakhutdinov, Ruslan and Chi, Ryan and Lee, Ryan and Stovall, Ryan and Teehan, Ryan and Yang, Rylan and Singh, Sahib and Mohammad, Saif M. and Anand, Sajant and Dillavou, Sam and Shleifer, Sam and Wiseman, Sam and Gruetter, Samuel and Bowman, Samuel R. and Schoenholz, Samuel S. and Han, Sanghyun and Kwatra, Sanjeev and Rous, Sarah A. and Ghazarian, Sarik and Ghosh, Sayan and Casey, Sean and Bischoff, Sebastian and Gehrmann, Sebastian and Schuster, Sebastian and Sadeghi, Sepideh and Hamdan, Shadi and Zhou, Sharon and Srivastava, Shashank and Shi, Sherry and Singh, Shikhar and Asaadi, Shima and Gu, Shixiang Shane and Pachchigar, Shubh and Toshniwal, Shubham and Upadhyay, Shyam and Shyamolima and Debnath and Shakeri, Siamak and Thormeyer, Simon and Melzi, Simone and Reddy, Siva and Makini, Sneha Priscilla and Lee, Soo-Hwan and Torene, Spencer and Hatwar, Sriharsha and Dehaene, Stanislas and Divic, Stefan and Ermon, Stefano and Biderman, Stella and Lin, Stephanie and Prasad, Stephen and Piantadosi, Steven T. and Shieber, Stuart M. and Misherghi, Summer and Kiritchenko, Svetlana and Mishra, Swaroop and Linzen, Tal and Schuster, Tal and Li, Tao and Yu, Tao and Ali, Tariq and Hashimoto, Tatsu and Wu, Te-Lin and Desbordes, Théo and Rothschild, Theodore and Phan, Thomas and Wang, Tianle and Nkinyili, Tiberius and Schick, Timo and Kornev, Timofei and Telleen-Lawton, Timothy and Tunduny, Titus and Gerstenberg, Tobias and Chang, Trenton and Neeraj, Trishala and Khot, Tushar and Shultz, Tyler and Shaham, Uri and Misra, Vedant and Demberg, Vera and Nyamai, Victoria and Raunak, Vikas and Ramasesh, Vinay and Prabhu, Vinay Uday and Padmakumar, Vishakh and Srikumar, Vivek and Fedus, William and Saunders, William and Zhang, William and Vossen, Wout and Ren, Xiang and Tong, Xiaoyu and Wu, Xinyi and Shen, Xudong and Yaghoobzadeh, Yadollah and Lakretz, Yair and Song, Yangqiu and Bahri, Yasaman and Choi, Yejin and Yang, Yichi and Hao, Yiding and Chen, Yifu and Belinkov, Yonatan and Hou, Yu and Hou, Yufang and Bai, Yuntao and Seid, Zachary and Xinran, Zhao and Zhao, Zhuoye and Wang, Zijian and Wang, Zijie J. and Wang, Zirui and Wu, Ziyi}, year={2022}, month={Jun} }\n"},"highlights/Zotero/taylor_2022":{"title":"Galactica: A Large Language Model for Science","links":[],"tags":[],"content":"Galactica: A Large Language Model for Science\nAbstract\nInformation overload is a major obstacle to scientific progress. The explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information. Today scientific knowledge is accessed through search engines, but they are unable to organize scientific knowledge alone. In this paper we introduce Galactica: a large language model that can store, combine and reason about scientific knowledge. We train on a large scientific corpus of papers, reference material, knowledge bases and many other sources. We outperform existing models on a range of scientific tasks. On technical knowledge probes such as LaTeX equations, Galactica outperforms the latest GPT-3 by 68.2% versus 49.0%. Galactica also performs well on reasoning, outperforming Chinchilla on mathematical MMLU by 41.3% to 35.7%, and PaLM 540B on MATH with a score of 20.4% versus 8.8%. It also sets a new state-of-the-art on downstream tasks such as PubMedQA and MedMCQA dev of 77.6% and 52.9%. And despite not being trained on a general corpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these results demonstrate the potential for language models as a new interface for science. We open source the model for the benefit of the scientific community.\nInformation overload is a major obstacle to scientific progress. The explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information. Today scientific knowledge is accessed through search engines, but they are unable to organize scientific knowledge alone. (p. 1)\n\nWhat are the frictions people have when doing research\n\nRelated Work (p. 3)\n\nMissing research on scientific research frictions, pain points and motivations for this solution.\n\nThere are two limitations with chain-of-thought. First, it relies on prompt discovery to find a prompt that elicits robust step-by-step reasoning; i.e. minimizes mistakes from doing too much in a single forward pass.\nNot only does this require finding a robust prompt that works in all cases, but it also often relies on few-shot examples which take up context space. What is worse, much of the step-by-step reasoning on the internet misses intermediate steps that a human has performed using internal memory. Humans do not write down every step they perform because it would lead to long and tedious answers. They write down the principal steps of reasoning, and do lower-level steps via internal working memory. This means there is “missing data” in written text, i.e. between written steps there are internal memory steps that are not explicitly stated. (p. 6)\nSecondly, chain-of-thought prompting uses the neural network to perform tasks that it is arguably not best suited to doing; for example, arithmetic. (p. 6)\nRepeated Tokens Considered Not Harmful (p. 11)\n\nYou are using a different dataset which I would guess more involving than regular web crawl.\n\nWe suspect that two factors could be at play, a quality factor, the curated nature of the corpus enables more value per token to be extracted, or a modality factor, the nature of scientific data enables more value per token to be extracted. The missing step of causation is what leads specifically from either factor towards less overfitting, and we leave this question to further work. We note the implication that the “tokens → ∞” focus of current LLM projects may be overemphasised versus the importance of filtering the corpus for quality. (p. 11)\nVerification Even as language models become more accurate with scale, we need assurances that their generations are correct and factual. Developing this layer is critical for production applications of language models in general beyond scientific applications. (p. 31) \n@article{Taylor_Kardas_Cucurull_Scialom_Hartshorn_Saravia_Poulton_Kerkez_Stojnic_2022, title={Galactica: A Large Language Model for Science}, url={[arxiv.org/abs/2211.09085](arxiv.org/abs/2211.09085)}, DOI={[10.48550/arXiv.2211.09085](doi.org/10.48550/arXiv.2211.09085)}, abstractNote={Information overload is a major obstacle to scientific progress. The explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information. Today scientific knowledge is accessed through search engines, but they are unable to organize scientific knowledge alone. In this paper we introduce Galactica: a large language model that can store, combine and reason about scientific knowledge. We train on a large scientific corpus of papers, reference material, knowledge bases and many other sources. We outperform existing models on a range of scientific tasks. On technical knowledge probes such as LaTeX equations, Galactica outperforms the latest GPT-3 by 68.2% versus 49.0%. Galactica also performs well on reasoning, outperforming Chinchilla on mathematical MMLU by 41.3% to 35.7%, and PaLM 540B on MATH with a score of 20.4% versus 8.8%. It also sets a new state-of-the-art on downstream tasks such as PubMedQA and MedMCQA dev of 77.6% and 52.9%. And despite not being trained on a general corpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these results demonstrate the potential for language models as a new interface for science. We open source the model for the benefit of the scientific community.}, note={0 citations (Semantic Scholar/arXiv) [2022-11-20] arXiv:2211.09085 [cs, stat]}, number={arXiv:2211.09085}, publisher={arXiv}, author={Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert}, year={2022}, month={Nov} }\n"},"highlights/Zotero/wasserstein_2016":{"title":"The ASA Statement on p-Values: Context, Process, and Purpose","links":[],"tags":[],"content":"The ASA Statement on p-Values: Context, Process, and Purpose\nAppropriately chosen techniques, properly conducted analyses and correct interpretation of statistical results also play a key role in ensuring that conclusions are sound and that uncertainty surrounding them is represented properly. (p. 4)\nPragmatic considerations often require binary, “yes-no” decisions, but this does not mean that p-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as “p   0.05”) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process. (p. 4)\nCherrypicking promising findings, also known by such terms as data dredging, significance chasing, significance questing, selective inference, and “p-hacking,” leads to a spurious excess of statistically significant results in the published literature and should be vigorously avoided. One need not formally carry out multiple statistical tests for this problem to arise: Whenever a researcher chooses what to present based on statistical results, valid interpretation of those results is severely compromised if the reader is not informed of the choice and its basis. Researchers should disclose the number of hypotheses explored during the study, all data collection decisions, all statistical analyses conducted, and all p-values computed. Valid scientific conclusions based on p-values and related statistics cannot be drawn without at least knowing how many and which analyses were conducted, and how those analyses (including p-values) were selected for reporting. (p. 5)\nResearchers should recognize that a p-value without context or other evidence provides limited information. For example, a p-value near 0.05 taken by itself offers only weak evidence against the null hypothesis. Likewise, a relatively large p-value does not imply evidence in favor of the null hypothesis; many other hypotheses may be equally or more consistent with the observed data. For these reasons, data analysis should not end with the calculation of a p-value when other approaches are appropriate and feasible. (p. 5)\n@article{Wasserstein_Lazar_2016, title={The ASA Statement on p-Values: Context, Process, and Purpose}, volume={70}, ISSN={0003-1305}, DOI={[10.1080/00031305.2016.1154108](doi.org/10.1080/00031305.2016.1154108)}, note={4291 citations (Semantic Scholar/DOI) [2023-06-19]}, number={2}, journal={The American Statistician}, publisher={Taylor &amp; Francis}, author={Wasserstein, Ronald L. and Lazar, Nicole A.}, year={2016}, month={Apr}, pages={129–133} }\n"},"highlights/Zotero/wei_2024":{"title":"Long-form factuality in large language models","links":[],"tags":[],"content":"Long-form factuality in large language models\nAbstract\nLarge language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model’s long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the percentage of provided facts relative to a hyperparameter representing a user’s preferred response length (recall). Empirically, we demonstrate that LLM agents can achieve superhuman rating performance - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times cheaper than human annotators. We also benchmark thirteen language models on LongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding that larger language models generally achieve better long-form factuality. LongFact, SAFE, and all experimental code are available at github.com/google-deepmind/long-form-factuality.\n\n\nWe use the language model to first decompose a long-form response into individual facts, then for each fact, propose fact-checking queries to send to a Google Search API and reason about whether the fact is supported by search results (Section 3). We name this method SAFE (Search-Augmented Factuality Evaluator).3 Empirically, SAFE achieves superhuman performance, agreeing with 72% of human annotations from Min et al. (2023) and winning 76% of disagreement cases from a random sample of 100 disagreement cases (Section 4). SAFE is also 20× cheaper than human annotators. (p. 2)\n\n\n(a) split a long-form response into individual self-contained facts, (b) determine whether each individual fact is relevant to answering the prompt in the context of the response, and (c) for each relevant fact, iteratively issue Google Search queries in a multi-step process and reason about whether the search results support or do not support the fact. (p. 3)\n\n\n\nThis assumes Google search results are trustworthy to begin with.\n\nNotes\n\nTL;DR\nThe proposed Search-Augmented Factuality Evaluator (SAFE) utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results.\n@misc{Wei_Yang_Song_Lu_Hu_Tran_Peng_Liu_Huang_Du_et al._2024, title={Long-form factuality in large language models}, url={[arxiv.org/abs/2403.18802v1](arxiv.org/abs/2403.18802v1)}, abstractNote={Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model’s long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the percentage of provided facts relative to a hyperparameter representing a user’s preferred response length (recall). Empirically, we demonstrate that LLM agents can achieve superhuman rating performance - on a set of ~16k individual facts, SAFE agrees with crowdsourced human annotators 72% of the time, and on a random subset of 100 disagreement cases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times cheaper than human annotators. We also benchmark thirteen language models on LongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding that larger language models generally achieve better long-form factuality. LongFact, SAFE, and all experimental code are available at github.com/google-deepmind/long-form-factuality.}, journal={arXiv.org}, author={Wei, Jerry and Yang, Chengrun and Song, Xinying and Lu, Yifeng and Hu, Nathan and Tran, Dustin and Peng, Daiyi and Liu, Ruibo and Huang, Da and Du, Cosmo and Le, Quoc V.}, year={2024}, month=mar, language={en} }\n"},"highlights/Zotero/widder_2023":{"title":"Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI","links":[],"tags":[],"content":"Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI\nAbstract\nThis paper examines ‘open’ AI in the context of recent attention to open and open source AI systems. We find that the terms ‘open’ and ‘open source’ are used in confusing and diverse ways, often constituting more aspiration or marketing than technical descriptor, and frequently blending concepts from both open source software and open science. This complicates an already complex landscape, in which there is currently no agreed on definition of ‘open’ in the context of AI, and as such the term is being applied to widely divergent offerings with little reference to a stable descriptor. So, what exactly is ‘open’ about ‘open’ AI, and what does ‘open’ AI enable? To better answer these questions we begin this paper by looking at the various resources required to create and deploy AI systems, alongside the components that comprise these systems. We do this with an eye to which of these can, or cannot, be made open to scrutiny, reuse, and extension. What does ‘open’ mean in practice, and what are its limits in the context of AI? We find that while a handful of maximally open AI systems exist, which offer intentional and extensive transparency, reusability, and extensibility– the resources needed to build AI from scratch, and to deploy large AI systems at scale, remain ‘closed’—available only to those with significant (almost always corporate) resources. From here, we zoom out and examine the history of open source, its cleave from free software in the mid 1990s, and the contested processes by which open source has been incorporated into, and instrumented by, large tech corporations. As a current day example of the overbroad and ill-defined use of the term by tech companies, we look at  ‘open’ in the context of OpenAI the company. We trace its moves from a humanity-focused nonprofit to a for-profit partnered with Microsoft, and its shifting position on ‘open’ AI. Finally, we examine the current discourse around ‘open’ AI–looking at how the term and the (mis)understandings about what ‘open’ enables are being deployed to shape the public’s and policymakers’ understanding about AI, its capabilities, and the power of the AI industry. In particular, we examine the arguments being made for and against ‘open’ and open source AI, who’s making them, and how they are being deployed in the debate over AI regulation. Taken together, we find that ‘open’ AI can, in its more maximal instantiations, provide transparency, reusability, and extensibility that can enable third parties to deploy and build on top of powerful off-the-shelf AI models. These maximalist forms of ‘open’ AI can also allow some forms of auditing and oversight. But even the most open of ‘open’ AI systems do not, on their own, ensure democratic access to or meaningful competition in AI, nor does openness alone solve the problem of oversight and scrutiny. While we recognize that there is a vibrant community of earnest contributors building and contributing to ‘open’ AI efforts in the name of expanding access and insight, we also find that marketing around openness and investment in (somewhat) open AI systems is being leveraged by powerful companies to bolster their positions in the face of growing interest in AI regulation. And that some companies have moved to embrace ‘open’ AI as a mechanism to entrench dominance, using the rhetoric of ‘open’ AI to expand market power while investing in ‘open’ AI efforts in ways that allow them to set standards of development while benefiting from the free labor of open source contributors.\nFinally, even maximal transparency in the context of AI systems doesn’t equal the same level of scrutability that open code and clear documentation do with traditional software. In the case of AI, code and documentation can’t tell you exactly how a model will perform in agiven context, or enable you to predict the system’s emergent properties. (p. 2)\nAnd that some companies have moved to embrace ‘open’ AI as a mechanism to entrench dominance, using the rhetoric of ‘open’ AI to expand market power, and investing in ‘open’ AI efforts in ways that allow them to set standards of development while benefiting from the free labor of open source contributors. (p. 3)\nWe find that even though there are a handful of meaningfully transparent, reusable, and extensible AI systems, these and all other ‘open’ AI exists within a deeply concentrated tech company landscape. With scant exceptions that prove the rule, only a few large tech corporations can create and deploy large AI systems at scale, from start to finish - a far cry from the decentralized and modifiable infrastructure that once animated the dream of the free/opensource software movement. (p. 4)\nGiven the immense importance of scale to the current trajectory of artificial intelligence,this means ‘open’ AI cannot, alone, meaningfully ‘democratize’ AI, nor does it pose a significant challenge to the concentration of power in the tech industry. (p. 4)\nAt one end of a long gradient, there are a handful of maximally open AI efforts – these are non-corporate AI efforts that go to the lengths possible to offer meaningful transparency, reusability, and extensibility. But developing these models still requires access to costly computational infrastructure, which is usually leasedfrom large tech companies.18 In addition they require significant funding to support the development andmaintenance of many complex components, including painstakingly crafted open datasets, and extensive documentation. (p. 5)\nThere is a long history and clear playbook for industry capture and instrumentation of open source projects, and major AI companies recognize the value of open source AI in leveraging the benefits of owning the ecosystem, enjoying the fruits of community labor, and defining the terms of engagement. (p. 5)\nThe ideology of the open source software movement is frequently mapped onto the concept of ‘open’ AI in ways that fail to account for the significant differences between large AI systems and traditional software. This shapes a narrative that assumes ‘open’ AI can on its own level the playing field, promote innovation, and democratize development and use. While some of this projection likely has its origin in the muddy popular definition of AI, and many contributors to open AI efforts do not espouse these views, major AI players strategically deploy such rhetorics in ways calibrated to entrench their power, often under the banner of democratized access. (p. 5)\n\nThis means that while some lower level software that optimizes computational power for AI development may be open in that one can inspect their code, in practice, this software is often designed for efficiency in proprietary hardware environments, and is developed and governed by companies selling compute resources and/or licensing AI models. (p. 8)\nThe labor required to curate, prepare data and calibrate systems is poorly paid, but it still costs a significant amount given the number of workers and time required to shape the data to build contemporary AI systems. (p. 11)\nAs illustrated above, large, entrenched tech companies like Google, Microsoft, Meta and others have vested interests in ‘open’ AI development. The author of the leaked ‘Google Moat’ memo said the quiet part out loud: “the value of owning the ecosystem” to the company “cannot be overstated”: such ecosystem capture directly contributed to Google’sdominance across the domains of search, mobile, and advertising.119 Similarly, as the platform where much open sourcecode is hosted (code that has been scraped and used to train models like Microsoft’s CoPilot), Microsoft’s Github has its own vested interests in unimpeded open source development, even as Microsoft-supported company OpenAI remains much more circumspect as it pushes for licensing (enabling Microsoft to tacitly support contradictory standpoints that both, in the end, benefit the company). To protect their interests, many companies are lobbying for exemptions to baseline documentation and accountability mechanisms. (p. 16)\nSimply making the code open does not guarantee that expert volunteers will spend their time and resources thoroughly reviewing it. (p. 16)\nWhat Heartbleed demonstrates is that just because code can be audited does not mean that it will be. Technically ‘open’code and documentation is not itself sufficient to ensure careful review and remediation: this dynamic is exacerbated in the case of AI, where large probabilistic models function in ways that produce outputs and decisions that cannot be predicted from the code, documentation, and data alone. (p. 17)\nthe fine-tuned end products largely function as barnacles on the hull of Big Tech, rather than a meaningful alternative to it. They still need to be run on Big Tech infrastructures (as a rule), and cede power to define and create the core model logics to the large companies who have the resources to create them from scratch. (p. 18)\nBut they also offer a narrowly defined interpretation of innovation - one that does not meaningfully trouble the incentive structures, business models, or the dynamics that dictate who is a ‘user’ of AI systems vs whom such systems are ‘used on’. Nor does it meaningfully shift who benefits from the development of AI systems, and who risks the harms. (p. 19)\n@article{Widder_West_Whittaker_2023, address={Rochester, NY}, type={SSRN Scholarly Paper}, title={Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI}, url={[papers.ssrn.com/abstract=4543807](papers.ssrn.com/abstract=4543807)}, abstractNote={This paper examines ‘open’ AI in the context of recent attention to open and open source AI systems. We find that the terms ‘open’ and ‘open source’ are used in confusing and diverse ways, often constituting more aspiration or marketing than technical descriptor, and frequently blending concepts from both open source software and open science. This complicates an already complex landscape, in which there is currently no agreed on definition of ‘open’ in the context of AI, and as such the term is being applied to widely divergent offerings with little reference to a stable descriptor. So, what exactly is ‘open’ about ‘open’ AI, and what does ‘open’ AI enable? To better answer these questions we begin this paper by looking at the various resources required to create and deploy AI systems, alongside the components that comprise these systems. We do this with an eye to which of these can, or cannot, be made open to scrutiny, reuse, and extension. What does ‘open’ mean in practice, and what are its limits in the context of AI? We find that while a handful of maximally open AI systems exist, which offer intentional and extensive transparency, reusability, and extensibility– the resources needed to build AI from scratch, and to deploy large AI systems at scale, remain ‘closed’—available only to those with significant (almost always corporate) resources. From here, we zoom out and examine the history of open source, its cleave from free software in the mid 1990s, and the contested processes by which open source has been incorporated into, and instrumented by, large tech corporations. As a current day example of the overbroad and ill-defined use of the term by tech companies, we look at  ‘open’ in the context of OpenAI the company. We trace its moves from a humanity-focused nonprofit to a for-profit partnered with Microsoft, and its shifting position on ‘open’ AI. Finally, we examine the current discourse around ‘open’ AI–looking at how the term and the (mis)understandings about what ‘open’ enables are being deployed to shape the public’s and policymakers’ understanding about AI, its capabilities, and the power of the AI industry. In particular, we examine the arguments being made for and against ‘open’ and open source AI, who’s making them, and how they are being deployed in the debate over AI regulation. Taken together, we find that ‘open’ AI can, in its more maximal instantiations, provide transparency, reusability, and extensibility that can enable third parties to deploy and build on top of powerful off-the-shelf AI models. These maximalist forms of ‘open’ AI can also allow some forms of auditing and oversight. But even the most open of ‘open’ AI systems do not, on their own, ensure democratic access to or meaningful competition in AI, nor does openness alone solve the problem of oversight and scrutiny. While we recognize that there is a vibrant community of earnest contributors building and contributing to ‘open’ AI efforts in the name of expanding access and insight, we also find that marketing around openness and investment in (somewhat) open AI systems is being leveraged by powerful companies to bolster their positions in the face of growing interest in AI regulation. And that some companies have moved to embrace ‘open’ AI as a mechanism to entrench dominance, using the rhetoric of ‘open’ AI to expand market power while investing in ‘open’ AI efforts in ways that allow them to set standards of development while benefiting from the free labor of open source contributors.}, number={4543807}, author={Widder, David Gray and West, Sarah and Whittaker, Meredith}, year={2023}, month={Aug}, language={en} }\n"},"highlights/Zotero/xiong_2020":{"title":"On Layer Normalization in the Transformer Architecture","links":[],"tags":[],"content":"On Layer Normalization in the Transformer Architecture\nAbstract\nThe Transformer is widely used in natural language processing tasks. To train a Transformer however, one usually needs a carefully designed learning rate warm-up stage, which is shown to be crucial to the final performance but will slow down the optimization and bring more hyper-parameter tunings. In this paper, we first study theoretically why the learning rate warm-up stage is essential and show that the location of layer normalization matters. Specifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem. On the other hand, our theory also shows that if the layer normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.\n\nWithout the warm-up stage, the BLEU score of the model trained with Adam optimizer can only achieve 8.45. As a comparison, the model trained using the warm-up stage can achieve around 34 in terms of BLEU score. The same trend can also be observed on the validation loss curves. Although the performance of the model trained with SGD is significantly worse than Adam, we can still see similar phenomena as Adam. The BLEU score is just above zero in 15 epochs without using the warm-up stage. (p. 4)\nThe main idea is that the layer normalization will normalize the gradients. In the Post-LN Transformer, the scale of the inputs to the layer normalization is independent of L, and thus the gradients of parameters in the last layer are independent of L. While in the Pre-LN Transformer, the scale of the input to the final layer normalization is linear in L, and thus the gradients of all parameters will be normalized by √L. (p. 6)\nOur main result is that the gradient norm in the Post-LN Transformer is large for the parameters near the output and will be likely to decay as the layer index l decreases. (p. 6)\nOn the contrary, the gradient norm in the PreTransformer will be likely to stay the same for any layer l. (p. 6)\n@article{Xiong_Yang_He_Zheng_Zheng_Xing_Zhang_Lan_Wang_Liu_2020, title={On Layer Normalization in the Transformer Architecture}, url={[arxiv.org/abs/2002.04745](arxiv.org/abs/2002.04745)}, DOI={[10.48550/arXiv.2002.04745](doi.org/10.48550/arXiv.2002.04745)}, abstractNote={The Transformer is widely used in natural language processing tasks. To train a Transformer however, one usually needs a carefully designed learning rate warm-up stage, which is shown to be crucial to the final performance but will slow down the optimization and bring more hyper-parameter tunings. In this paper, we first study theoretically why the learning rate warm-up stage is essential and show that the location of layer normalization matters. Specifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem. On the other hand, our theory also shows that if the layer normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.}, note={229 citations (Semantic Scholar/arXiv) [2022-07-31] arXiv:2002.04745 [cs, stat]}, number={arXiv:2002.04745}, publisher={arXiv}, author={Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tie-Yan}, year={2020}, month={Jun} }\n"},"highlights/Zotero/xu_2024":{"title":"Hallucination is Inevitable: An Innate Limitation of Large Language Models","links":[],"tags":["TODO"],"content":"Hallucination is Inevitable: An Innate Limitation of Large Language Models\nReference: 2401.11817 - Hallucination is Inevitable: An Innate Limitation of Large Language Models\nAbstract\nHallucination has been widely recognized to be a significant drawback for large language models (LLMs). There have been many works that attempt to reduce the extent of hallucination. These efforts have mostly been empirical so far, which cannot answer the fundamental question whether it can be completely eliminated. In this paper, we formalize the problem and show that it is impossible to eliminate hallucination in LLMs. Specifically, we define a formal world where hallucination is defined as inconsistencies between a computable LLM and a computable ground truth function. By employing results from learning theory, we show that LLMs cannot learn all of the computable functions and will therefore always hallucinate. Since the formal world is a part of the real world which is much more complicated, hallucinations are also inevitable for real world LLMs. Furthermore, for real world LLMs constrained by provable time complexity, we describe the hallucination-prone tasks and empirically validate our claims. Finally, using the formal world framework, we discuss the possible mechanisms and efficacies of existing hallucination mitigators as well as the practical implications on the safe deployment of LLMs.\n\n\n\n\n\nFor example, f could be a function that answers “true” for factual statements and “false” for non-factual ones. It could also be a function that completes a prompt to produce a factual statement. We only assume that such computable f always exists (though its exact implementation might be unknown) in our formal world for all tasks. Otherwise, we can immediately say LLM will hallucinate on some tasks in the formal world because LLM is computable while the ground truth function f is not. We can similarly define Gh = {(s, h(s)) | s ∈ S} to be the world of LLM h. (p. 5)\n\n\n\nSet T is a generalized corpus of how ground-truth f answers/completes input strings. For example, if f answers “true” for factual inputs and “false” otherwise, then our training samples could look like { (“A shark is a mammal.”, “false”), (“Earth orbits around the Sun.”, “true”), … }. On the other hand, if f is a function that completes or answers input string s, then T could look like { (“Is shark a fish or mammal?”, “Fish.”), (“What is the sum of binary numbers 10001 and 10110?”, “100111.”), … }. Thanks to this general definition, we do not need to worry about the exact task and corpus on which an LLM is trained. Furthermore, we do not assume anything about the size of T , meaning the training procedure to be introduced in Section 3.3 can use as many samples as needed. (p. 5)\n\n\n\n\n\n\n\n\nThe theorem and its proof indicate that if f is not listed in the enumeration table, then it is not learnable by any LLM in the table, and therefore all LLMs in the table will hallucinate on f . (p. 9)\n\n\n\n\n\nAn important, but not the only, reason for hallucination is that the problem is beyond LLMs’ computation capabilities. For those problems, any answer except “I don’t know” is unreliable and suggests that LLMs have added premises implicitly during the generation process. It could potentially reinforce stereotypical opinions and prejudices towards under-represented groups and ideas. Furthermore, it can be dangerous if unexpected premises were added and resulted in unethical, disturbing, or destructive contents. (p. 13)\n\n\nIt is notable that while LLMs cannot learn all computable ground truth functions f , it can learn some f (see Section C) and can be useful therein. The key is not to view LLMs as infallible sources of truth but as powerful assistive tools for information retrieval, analysis, summarisation, and presentation. (p. 14)\n\n\nFinally, hallucination is not completely detrimental. In art, literature, and design, the unintentional and unpredictable outputs from LLMs could inspire human creators. Such deviation from facts can lead to unique perspectives that a strictly factual and precise system might never generate. In this sense, the hallucinatory aspect of LLMs should be regarded positively as a source of inspiration, innovation, and creativity. (p. 14)\n\nNotes\n\nTL;DR\nThis paper formalizes the problem and shows that it is impossible to eliminate hallucination in LLMs, and defines a formal world where hallucination is defined as inconsistencies between a computable LLM and a computable ground truth function.\n@misc{Xu_Jain_Kankanhalli_2024, title={Hallucination is Inevitable: An Innate Limitation of Large Language Models}, url={[arxiv.org/abs/2401.11817v1](arxiv.org/abs/2401.11817v1)}, abstractNote={Hallucination has been widely recognized to be a significant drawback for large language models (LLMs). There have been many works that attempt to reduce the extent of hallucination. These efforts have mostly been empirical so far, which cannot answer the fundamental question whether it can be completely eliminated. In this paper, we formalize the problem and show that it is impossible to eliminate hallucination in LLMs. Specifically, we define a formal world where hallucination is defined as inconsistencies between a computable LLM and a computable ground truth function. By employing results from learning theory, we show that LLMs cannot learn all of the computable functions and will therefore always hallucinate. Since the formal world is a part of the real world which is much more complicated, hallucinations are also inevitable for real world LLMs. Furthermore, for real world LLMs constrained by provable time complexity, we describe the hallucination-prone tasks and empirically validate our claims. Finally, using the formal world framework, we discuss the possible mechanisms and efficacies of existing hallucination mitigators as well as the practical implications on the safe deployment of LLMs.}, note={8 citations (Semantic Scholar/arXiv) [2024-03-30]}, journal={arXiv.org}, author={Xu, Ziwei and Jain, Sanjay and Kankanhalli, Mohan}, year={2024}, month=jan, language={en} }\n"},"index":{"title":"Home","links":["notes/20240218204257","notes","highlights/Zotero","highlights/Matter","highlights/Readwise","highlights/Omnivore"],"tags":[],"content":"Home\nThis is my journey of personal knowledge management – building zettelkasten in the open with lifelong reading and writing.\n✌️\nChenghao\nAbout Me\nEvergreen Notes | Literature Notes\nFleeting Notes: Matter, Readwise, Omnivore"},"notes/20210926153100":{"title":"Machine Learning Compilers and Optimizers","links":[],"tags":[],"content":"Machine Learning Compilers and Optimizers\nCompilers and optimizers are standard components in programming languages like C++ or C. To bring the same efficiency and optimization into the current deep learning community, various compilers and optimizers are invented to lower your code from high-level framework code into low-level hardware-native code.\nCompilers\nCompilers translate framework code (PyTorch, TensorFlow, or Jax) into different levels of intermediate representations that can eventually be executed on various pieces of hardware. This process is often called lowering.\nHigh-level Intermediate Representation: hardware-agnostic but framework-specific;\nLow-level Intermediate Representation: framework-agnostic but hardware-specific;\nSome examples of compilers are:\n\nThe LLVM Compiler Infrastructure Project\nXLA: Optimizing Compiler for Machine Learning  |  TensorFlow\nCUDA LLVM Compiler | NVIDIA Developer\nMLIR\nApache TVM\npytorch/glow: Compiler for Neural Network hardware accelerators\n\nOptimizers\nOptimizers optimize the code throughout the different levels of representations for performance.\nAdvantages\nUsing compilers and optimizers, you can:\n\nConvert any high-level framework code into the same intermediate code, that can run anywhere;\nOptimize the model so that it can run on edge devices with more privacy, fast IO, high independence, and lower cloud cost;\n\nCaveats\n\nModels optimized for one platform does not always translate to other platforms;\nOptimizing a model can take a long time;\nNew architectures will suffer from little support at the beginning;\n"},"notes/20210926153300":{"title":"Adaptive Computation","links":[],"tags":[],"content":"Adaptive Computation\nIt is a concept that models can perform conditional computation, primarily based on the input.\nFor example, models can spend more computation on difficult problems and less on easy ones or treat those questions in different ways from different perspectives (task format, sequence length etc).\nHowever, it is known for unstable results and sensitivity towards hyper-parameters, especially those controlling the trade off between computation and accuracy (e.g. τ in Adaptive Computation Time (ACT)1).\nFootnotes\n\n\n@graves_2017 ↩\n\n\n"},"notes/20210926181300":{"title":"Randomness in Scikit-learn","links":[],"tags":[],"content":"Randomness in Scikit-learn\nUse RandomState to make sure your code\n\nis reproducible between runs\nmaintains randomness within the pipeline\n\nAvoid setting the global random seed – it can fix all the randomness for any code subsequently involved, including caller code.\nThis should also be applied to other frameworks like PyTorch, Numpy, or Tensorflow."},"notes/20210926181800":{"title":"Mixture of Experts","links":["notes/20210926153300"],"tags":[],"content":"Mixture of Experts\nMixture of Experts (MoE) is special case of Adaptive Computation where multiple experts (usually subnets) are used to solve a problem by dividing the problem space into regions. In neural networks, a MoE model can use a gating/routing network to decide which expert/sub-model to use. But it has some limitations like training stability, complexity, and communication cost."},"notes/20210928180400":{"title":"Data-centric AI","links":[],"tags":[],"content":"Data-centric AI\nA recent paradigm shift from model-centric AI to data-centric AI, advocated by many companies and scholars recently, including Andrew Ng and his famous talk.\nPreviously, we have model-centric AI where people focus mostly on\n\nfeature engineering\nmodel architecture design\ntraining algorithm design\n\nHowever, those tasks soon are marginalized by the popularization of large pre-trained models where general knowledge is learned through huge datasets and parameters. Any work that tries to compete with those pre-trained models with new architectures will find themselves in need for pre-training from scratch, which will most likely burn many holes in their wallets.\nIn short, those pre-trained models are powerful, increasingly data-hungry, and less practically modifiable.\nThe easy way out for now is redirecting the attention back to data:\n\ndata collection\nlabeling\naugmentation\nslicing\nmanagement\n"},"notes/20211003175000":{"title":"Contrastive Learning","links":["notes/20221222133828","highlights/Zotero/somepalli_2022"],"tags":[],"content":"Contrastive Learning\nThe idea of contrastive learning is to learn representations where similar input will have closer representations and vice versa, without explicitly modeling the similarity.\nAlthough, similarities based on single values, such as cosine similarity, shows no insight on how semantic similarity manifests from various perspectives, a better solution might be Decomposing Embeddings.\nThis also relates to duplicate detection, where a single cosine similarity only shows global pixel similarities but never the local similarities (objects or backgrounds in images)1. In this case, the authors proposed split product that measures segment-level cosine similarities1.\nFootnotes\n\n\nDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models ↩ ↩2\n\n\n"},"notes/20211003180000":{"title":"Calibration in Machine Learning","links":[],"tags":[],"content":"Calibration in Machine Learning\nWe often assume whatever we see after the Softmax layer can be interpreted as probability. This assumption can be alarmingly wrong if the model is under-calibrated. Models, especially large neural networks, tend to overestimate the probabilities while being a good classifier/discriminator1 2. Simply put, a working decision boundary might not be the best boundary, and that’s where calibration comes into play.\nCalibration ensures that the predicted probabilities and distribution are close to what is observed in the training data.\nCalibration Curve\nThe easiest way to help you understand if your model is well-calibrated or not is to plot the calibration curve. The idea is simple: out of all the examples that the model predicts having a “~70%” probability of being positive, ~70% should be true positives.\nHow to Draw a Calibration Curve Chart\n\nGiven a binary label set Y and a prediction set with positive probabilities Y~\nSort the data based on the predicted probabilities in ascending order\nBucketize the data based on the probabilities\nCalculate the fraction of positive examples in each bucket/bin\n\ntype: bar\nlabels: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\nseries:\n  - title: Positive Percentage\n    data: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\ntension: 0.2\nwidth: 58%\nlabelColors: true\nfill: true\nbeginAtZero: true\nAbove is a perfect calibrated model – for all examples predicted with around probability x, x of them are actual positives.\nMis-calibration\n\nsource 3\n\nSystematic Overestimation: This happens when you have fewer positive examples.\nSystematic Underestimation: This happens when you have fewer negative examples.\nCenter of the dist. is too heavy: This happens when “algorithms such as support vector machines and boosted trees tend to push predicted probabilities away from 0 and 1”1\nTails of the dist. are too heavy: This happens when “Other methods such as Naive Bayes have the opposite bias and tend to push predictions closer to 0 and 1”2\n\nHow to Calibrate\n\nIsotonic Regression on dev set: A non-parametric algorithm that fits a non-decreasing free-form line to the data. The fact that the line is non-decreasing is fundamental because it respects the original sorting.\nLogistic Regression on the dev set\n\nExpected Calibration Error\ndef expected_calibration_error(y, proba, bins = &#039;fd&#039;):\n\timport numpy as np\n\tbin_count, bin_edges = np.histogram(proba, bins = bins)\n\tn_bins = len(bin_count)\n\tbin_edges[0] -= 1e-8 `#` because left edge is not included\n\tbin_id = np.digitize(proba, bin_edges, right = True) - 1\n\tbin_ysum = np.bincount(bin_id, weights = y, minlength = n_bins)\n\tbin_probasum = np.bincount(bin_id, weights = proba, minlength = n_bins)\n\tbin_ymean = np.divide(bin_ysum, bin_count, out = np.zeros(n_bins), where = bin_count &gt; 0)\n\tbin_probamean = np.divide(bin_probasum, bin_count, out = np.zeros(n_bins), where = bin_count &gt; 0)\n\tece = np.abs((bin_probamean - bin_ymean) * bin_count).sum() / len(proba)\n\treturn ece\nFootnotes\n\n\n(PDF) Predicting good probabilities with supervised learning ↩ ↩2\n\n\n[1706.04599] On Calibration of Modern Neural Networks ↩ ↩2\n\n\nPython’s «predict_proba» Doesn’t Actually Predict Probabilities (and How to Fix It) | by Samuele Mazzanti | Towards Data Science ↩\n\n\n"},"notes/20211225111100":{"title":"PyTorch Tricks","links":["notes/20210926153100"],"tags":[],"content":"PyTorch Tricks\nScheduler\nBoth following schedulers prove to be faster in convergence, with the cost of introduction of few extra hyper-parameters – minimum learning rate, maximum learning rate. 1\n\nCyclicLR — PyTorch 1.10.1 documentation based on @smith_2017\nOneCycleLR — PyTorch 1.10.1 documentation\n\nDataloader\n\nUsing multiple data workers to speed up loading the dataset, but be aware of the data duplicates:1\n\nFor map-style dataset, data is retrieved with indices generated by sampler, so no duplication is created;\nFor iterable-style dataset, each worker should have specific handling according to its init function and parameters;\n\n\npin_memory speeds up data transfer from memory to GPU memory. 1\n\nAutomatic Mixed Precision\nimport torch\n# Creates once at the beginning of training\nscaler = torch.cuda.amp.GradScaler()\n \nfor data, label in data_iter:\n   optimizer.zero_grad()\n   # Casts operations to mixed precision\n   with torch.cuda.amp.autocast():\n      loss = model(data)\n \n   # Scales the loss, and calls backward()\n   # to create scaled gradients\n   scaler.scale(loss).backward()\n \n   # Unscales gradients and calls\n   # or skips optimizer.step()\n   scaler.step(optimizer)\n \n   # Updates the scale for next iteration\n   scaler.update()\n20210926153100 Machine Learning Compilers and Optimizers\n\nAdamW — PyTorch 1.10.1 documentation\nAdam — PyTorch 1.10.1 documentation\n\nTorchScript\n\nFootnotes\n\n\nefficientdl.com/faster-deep-learning-in-pytorch-a-guide ↩ ↩2 ↩3\n\n\n"},"notes/20211225113300":{"title":"Incorrect Labels","links":[],"tags":[],"content":"Incorrect Labels\nMachine learning models are robust even when there are random errors in the training set. But it is less so when they are systematic errors/biases.\nWhen there are incorrect labels in the validation or test set, it is important to evaluate the percentage of those correctable errors. If the errors are worth the efforts more so than the in-correctable examples (actual mistakes from the model), then:\n\nFind out what went wrong\nApply the fix to both the validation and test sets\n"},"notes/20211225124400":{"title":"Deep Work","links":[],"tags":[],"content":"Deep Work\nWhy is Deep Work Important?\nTo be valuable in the job market and society, one needs expertise in his/her domains and the capability to learn and produce things fast, and deep work can help us achieve that – being in the flow state pushes your mind to expand its boundary as well as horns your skills to a deeper level.\nWhy is Deep Work so Rare?\nThe connectivity brought by internet tools leaves us no room for distraction-free focus and an uninterrupted time window, which is enforced in our daily lives and eventually becomes a vicious habit that corrupts our minds.\nWhy Does it Work?\nIt reinforces the neural circuits when we learn and work while being focused.\nHow to Commit to Deep Work?\nJust like any habit you want to culture, you have to practice it. Our actions cast votes for who we want to become. Design routines, rituals and cues to guide you instead of relying on willpower or motivation."},"notes/20220208192300":{"title":"Workspace Productivity","links":["notes/20211225124400"],"tags":[],"content":"Workspace Productivity\nCore idea: how to set up our workplace to encourage productivity and therefore promote 20211225124400 Deep Work. This is based on this podcast episode Optimizing Workspace for Productivity, Focus, &amp; Creativity - Huberman Lab.\nTime-based Tricks\nMorning\n\nAllow more light into your eyes as it stimulates alertness;\nOpen the window;\n\nAfternoon or Evening\n\nDim the lights, especially overhead lights\nReduce blue lights\n\nPhysical Tricks\n\nLooking down can reduce alertness and vice versa, looking up can increase alertness;\nRaise your monitor to your eye level or slightly above;\nStand or sit straight;\nDrink more water;\nFocusing visually leads to focusing mentally;\n"},"notes/20220511201500":{"title":"How to Take Notes From Book Highlights","links":[],"tags":[],"content":"How to Take Notes From Book Highlights\n\nMake a checkpoint every chapter so as to gather highlights and organize them into fleeting notes.\nRefactor your fleeting notes into literature notes.\nRefactor your literature notes into atomic notes, connected and linked.\nFind additional relevant nodes to link by search related topics and keywords.\n"},"notes/20220523192800":{"title":"Cost Equivalent Curve","links":["highlights/Zotero/lourie_2021"],"tags":[],"content":"Cost Equivalent Curve\nSource:  UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark\nCost: the number of training examples in the training set used.\nPerformance: the performance given a model and a cost according to the task metric.\nCost Equivalent Curve: a curve depicting the relation between cost and performance. For a target performance score, the smaller the cost is, the better the model is.\nThe underlying assumption of the curve is that such a relationship between cost and performance is continuous and strictly monotonic."},"notes/20220523193100":{"title":"Transfer Learning Approaches","links":["highlights/Zotero/lourie_2021"],"tags":[],"content":"Transfer Learning Approaches\nMultitask Training: Train the model on all tasks/datasets all at once;\nSequential Multitask Training: Train the model on some tasks/datasets first before continuing to train it with the target tasks/datasets;\nMultitask Training and Fine-tuning: Train the model on some tasks first and fine-tuning it with target tasks/datasets;\nFindings from UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark that\n\nSequential Multitask Training almost always outperform other methods.\nMultitask training helps the most when target data is scarce.\nLarger models see more gains from transfer learning.\n"},"notes/20220524111100":{"title":"Code Review Pyramid","links":[],"tags":[],"content":"Code Review Pyramid\n\nStyle and most tests should be automated (in the commit hooks, CI tools or in a bash script) so you don’t have to write a PR comment about this.\nOne should have a trace of written records regarding design decisions and implementation choices, ranging from technical specifications to your API documentations. Personally, I think questions around directions should not be discussed in a PR, at which time efforts have been invested and it would be too late to make a turn."},"notes/20220524111200":{"title":"Deep Learning First Principles for Efficiency","links":[],"tags":[],"content":"Deep Learning First Principles for Efficiency\n1. Compute\nCompute refers to the arithmetic operations done by CPU or GPU, typically measured in floating point operations per second (FLOPS). We want to maximize this to take advantage of all the GPUs we are paying.\nIt is often more difficult to increase the FLOPS than to reduce the memory footprint. One have to change the actual operations to do so, while there are a lot of tricks to use less memory.\nOften GPUs are optimized for matrix multiplication. For example, matrix multiplication makes up 99.80% of BERT’s computation. The rest of operators, though occupying a small fraction of FLOPS, take about 40% of runtime due to Memory Bandwidth.\n2. Memory Bandwidth\nMemory bandwidth cost refers to the time spent on transferring data, from CPU to GPU or from one GPU to another.\nHow can we reduce the transferring cost?\n\nOperator fusion: perform operators on the same data sequentially in one-go instead of sending data back and forth;\nExtra computation: such as re-materialization or activation checkpointing\n\nCalculation\nMemory bandwidth: 1.5 TB/s\nFLOPS: 19.5 Tera FLOPS\nTime to load 400 Billion 4-byte (1.6TB) floats: ~1s\n20 Trillion operations: ~1s\n\nread + write time: ~2s\nnumber of operations needed to spend 2s: 20 T / 400 B * 2 = 100 ops\n\nIt means you have to perform more than 100 operations per float number for that 400 billion tensor to spend more time on compute than data transferring.\n3. Overhead\nOverhead means time spent on everything else. One example:\n\nin the time that Python can perform a single FLOP, an A100 could have chewed through 9.75 million FLOPS.\n\nHowever, for modern GPUs, as long as the CPU is ahead of scheduling and queuing up the GPU tasks, large scale computation is less likely to be overhead bound. Two ways to find out if your workflow is overhead-bound:\n\nScale your data, if the computation does not increase proportionally, then it is likely overhead-bound\nProfiling\nSacrifice the flexibility by tracing the PyTorch code into JIT or CUDA operations to reduce PyTorch overhead\n"},"notes/20220524111400":{"title":"How to Remember Names","links":[],"tags":[],"content":"How to Remember Names\n\nInitially, a name and a face are not associated until your hippocampus puts them together into a single memory;\nInstead of focusing on introducing yourself, pay more attention to learning them. HEAR the name;\nLearn the name properly:\n\nPractice retrieval the name\nSearch for something to remember the name by\nSearch for some facial features\nTake some notes in the Apple notes (add some facts as well)\nConnect on social media\n\n\nThis is a skill that needs practice.\n"},"notes/20220524111500":{"title":"How to Work Hard","links":["highlights/Matter/Staring-into-the-abyss-as-a-core-life-skill"],"tags":[],"content":"How to Work Hard\nWhy Working Hard\nWe cannot change our talents, so working hard is, in most cases, the only choice.\nSome may argue working smart is the way to go. But in this case, working hard and working smart aren’t mutually exclusive. Working hard in the sense that we choose challenges. Staring into the abyss as a core life skill, as one might say. Working smart means that to solve those challenges, we must hone our skills to make the solution and the process efficient.\nHow to Work Hard\n\nDefine your goals and foster disciplines:\n2. Problems, scopes, domains, and habits\nTwo mindsets:\n\nEnjoy achievement\nDislike idleness\n\n\nLearn your work:\n\nWhat matches your talent might not be your interest\nKnow what is important and interesting\n\n\nPlan ahead:\n\nAvoid diminishing returns and burnout\n\n\nWork towards the hard-core center problems, a.k.a. staring into the abyss.\n"},"notes/20220528132200":{"title":"Four Things That Make Things Memorable","links":["notes/20220724214948"],"tags":[],"content":"Four Things That Make Things Memorable\n\nNovelty: something new\nRepetition: reinforcement\nAssociation: connections. This is especially true when taking notes (Connection)\nEmotional resonance.\n"},"notes/20220529205718":{"title":"Lifestyle Creep","links":["notes/20220530100701","notes/20220529210247"],"tags":[],"content":"Lifestyle Creep\nLifestyle Creep is when one increases his/her spending after an increase in income or purely because of peer pressure without any salary bump.\n\n\n20220530100701 Just Keep Buying\n20220529210247 How Much Lifestyle Creep Can You Afford\n"},"notes/20220529210247":{"title":"How Much Lifestyle Creep Can You Afford","links":["notes/20220530100701"],"tags":[],"content":"How Much Lifestyle Creep Can You Afford\nFor most people, it is usually about 50%, though it highly depends on your saving rate.\nThis echos the 2x rule where 50% now is for you and the other 50% is for your future self.\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220529210826":{"title":"Bet Hedging","links":["notes/20220530100701"],"tags":[],"content":"Bet Hedging\nIn biology, some seeds remain inactive just in case a dry season is in the corner. The goal of bet hedging isn’t to maximize the profit or offspring in one year, instead to maximize it over a long time period.\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220529211647":{"title":"When to Have Credit Card Debt","links":["notes/20220530100701"],"tags":[],"content":"When to Have Credit Card Debt\n\nWhen your goal is to reduce risk: having mortgage instead of depleting your emergency funds.\nWhen the return of having the debt is larger than the cost. E.g., higher education.\n3. Simple formula for calculating the return\n4. Value of the degree today = Increased Lifetime Earnings / 2 - Oppotunity Cost of the Degree (money you could have earned with the time you spend on study)\nAvoid debt if it causes mental stress, especially non-mortgage debt.\n\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220530085048":{"title":"When to Retire","links":["notes/20220530100701"],"tags":[],"content":"When to Retire\nNote: This is heavily related to the United States, and might not generalize well to other economy.\n4% Rule\n4%×Total Savings=Annual Spending\nWhich leads to another simple equation:\nTotal Savings=25×Annual Spending\nAssuming that your spending does not change over the years of retirement, though it is most likely not true.\nCrossover Rule\nIt refers to when your investment yields larger return than your annual spending.\nRetirement is Not Just About Money\nThere are many other factors that you should consider when deciding when to retire:\n\nPhysical and mental well-beings\nSocial support\nFulfillment\n4. Early retirement takes your job out of your identity and as a result makes your life less motivational.\n\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220530091038":{"title":"Investment VS Saving","links":["notes/20220530100701"],"tags":[],"content":"Investment VS Saving\nThe formula tells which to bet on investment versus saving:\n\nHow much do you expect to save comfortably in the next year S;\nHow much do you expect your investment to grow in the next year G;\nIf S &gt; G, then you should focus on saving money\nIf S &lt; G, you should focus on fine-tuning investment\nElse, you should focus on both of them equally\n\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220530091352":{"title":"Saving","links":["notes/20220530100701"],"tags":[],"content":"Saving\n\nHow much to save: save what you can. Not a certain percentage nor a certain amount;\nDon’t stress over it: stress causes more harm;\n\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220530091518":{"title":"Spending","links":["notes/20220530091844","notes/20220530100701"],"tags":[],"content":"Spending\nCutting spending is to saving money as cutting calorie intake is to weight loss. Neither of them can give you long-term benefits.\nThe other alternative is to increase income. It is shown that increasing income does not incur increase of spending because of 20220530091844 Diminishing Marginal Utility.\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220530091844":{"title":"Diminishing Marginal Utility","links":["notes/20220530100701"],"tags":[],"content":"Diminishing Marginal Utility\nEach additional unit of consumption brings less satisfaction than previous unit.\n\n\n20220530100701 Just Keep Buying\nDiminishing Marginal Utility - an overview | ScienceDirect Topics\n"},"notes/20220530092056":{"title":"How to Spend without Guilt","links":["notes/20220530092155","notes/20220530092340","highlights/Readwise/32782586"],"tags":[],"content":"How to Spend without Guilt\nBy applying the 2x Rule, we consciously justify the purchase with less or no guilt.\nAdditionally, consider alternatives like Best Things You can Buy when shopping. Or ask yourself a series of questions to understand your needs better1.\nFootnotes\n\n\nBuy wisely ↩\n\n\n"},"notes/20220530092155":{"title":"2x Rule","links":["notes/20220530100701"],"tags":[],"content":"2x Rule\nSource: Just Keep Buying\nEvery time you spend x on something, spend the same amount of money on investment.\nSimilarly, people who practice minimalism also have this rule of thumb when making purchases where the expenses, time, and energy of keeping it around and finally disposing of it are taken into consideration. In the end, you end up with a number that is likely 2x or 3x larger than the price tag.\nBy this rule, combined with minimalist purchasing considerations, we are actually paying 2x in monetary value and 2x in post-purchase cost to maintain an item."},"notes/20220530092340":{"title":"Best Things You Can Buy","links":["notes/20220530100701"],"tags":[],"content":"Best Things You Can Buy\nSource: Just Keep Buying\n\nExperiences\nTreating yourself occasionally\nExtra Time\nPaying upfront (worry-free frictionlessness)\nSpending on others (family, partners, or friends)\n"},"notes/20220530092615":{"title":"Happiness VS Fulfillment","links":["notes/20220530100701","highlights/Matter/How-to-Pick-a-Career-(That-Actually-Fits-You)"],"tags":[],"content":"Happiness VS Fulfillment\nSource: Just Keep Buying\nWe return to our normal level of happiness even after experiencing some positive events in the short term. This is called Hedonic treadmill - Wikipedia.\nThen it is clear that chasing after happiness is a wrong quest, and instead, we should aim for fulfilment — making an impact with our decisions and making it count. Or as someone may call it, contentment1 2.\n\nPursue something so important that even if you fail the world is better off with you having tried. \nTim O’Reilly\n\nFootnotes\n\n\nHow to Pick a Career (That Actually Fits You) ↩\n\n\nHow to Pick a Career (That Actually Fits You) ↩\n\n\n"},"notes/20220530092821":{"title":"How To Increase Income","links":["notes/20220530100701"],"tags":[],"content":"How To Increase Income\n\nSell your time\nSell your skills\nSell your products\n\nBut these methods can’t scale. Therefore, you need to have income-producing assets aka. investment.\n\n\n20220530100701 Just Keep Buying\n"},"notes/20220530095811":{"title":"Key Components in Data-centric AI","links":["notes/20210928180400"],"tags":[],"content":"Key Components in Data-centric AI\nReferences: Data-centric AI\n\nData. (Dah!)\nProgrammatic access: higher level of data manipulation that also takes into considerations such as:\n\nPrivacy concerns;\nDomain expertise;\nRapid changes from the real world;\nEthical concerns (bias, audits, lineage);\n\n\nExpertise: labeling and modeling should be unified into a positive feedback loop instead of individual components. Labeled data help to design better models and algorithms, and the modeling process provide the labeling process with guidance.\n"},"notes/20220530100701":{"title":"Just Keep Buying","links":["highlights/Readwise/31554992","notes/20220530091038","notes/20220530091352","notes/20220530092821","notes/20220530091518","notes/20220530092155","notes/20220530092056","notes/20220529211647","notes/20220620140501","notes/20220620140902","notes/20220622185751","notes/20220622183957","notes/20220622184252","notes/20220622183618"],"tags":[],"content":"Just Keep Buying\nHighlights: Just Keep Buying\nTakeaways:\n\n20220530091038 Saving if for the Poor, Investing is for the Rich\n20220530091352 Save What You Can\nFocus on Increasing Your 20220530092821 Income, not 20220530091518 Spending\nUse 20220530092155 2x Rule to 20220530092056 Eliminate Spending Guilt\nSave at least 50% of Your Raises\n20220529211647 When to Have Debts\nOnly Buy a Home When the Time Is Right\nWhen Saving for a Big Purchase, Use Cash\nRetirement is About More Than Money\nInvest to Replace Your Waning 20220620140501 Human Capital with 20220620140902 Financial Capital\nThink Like an Owner and Buy Income-Producing Assets\nDon’t Buy Individual Stocks \nInvest As Often As You Can\nInvesting Isn’t About the Cards You Are Dealt, but How You Play Your Hand\nDon’t Fear Volatility When It Inevitably Comes\nMarket Crashes Are (Usually) Buying Opportunities\nFund the Life You Need Before You Risk it for the Life You Want\nDon’t Max Out Your 401(k) Without Considerable Thought\nYou’ll Never Feel Rich and That’s Okay\nTime is Your Most Important Asset\n"},"notes/20220531191912":{"title":"PKM Habits","links":["notes/20220531192019","notes/20220531192123","notes/20220531192131"],"tags":[],"content":"PKM Habits\n\n20220531192019 Kickoff and Completion Checklists\n20220531192123 Periodical Reviews\n20220531192131 Opportunistic Habits\n"},"notes/20220531192019":{"title":"Kickoff and Completion Checklists","links":[],"tags":[],"content":"Kickoff and Completion Checklists\nCompletion Checklist\n\nMark it complete\nMark related goals complete\nReview intermediate packets, deliveries\nArchive files, add a status note if necessary\n\nKickoff Checklist\n\nBrain dump\nSearch and Review related and existing notes\nCreate an outline\n"},"notes/20220531192123":{"title":"Periodical Reviews","links":[],"tags":[],"content":"Periodical Reviews\nWeekly Review:\n\nEmail\nCalendar\nDesktop\nNotes\nTasks\n\nMonthly Review:\n\nReview and update goals\nReview and update projects\nReview and update areas\nReview future tasks\nRe-prioritize tasks\n"},"notes/20220531192131":{"title":"Opportunistic Habits","links":[],"tags":[],"content":"Opportunistic Habits\n\nCapture\nHighlight\nUpdate note names\nMove a note\nAdd tags\nMake connections\n"},"notes/20220604131222":{"title":"Premeditatio Malorum","links":["highlights/Matter/3-2-1--On-designing-your-life,-and-the-value-of-doing-hard-things"],"tags":[],"content":"Premeditatio Malorum\nBy imagining the worst-case scenarios, you overcome the paralysis and take action.\nFear Setting\n\nEasy choices, hard life. Hard choices, easy life.\nJerzy Gregorek\n\n\nWe suffer more often in imagination than in reality.\nSeneca\n\n\nWhat if I do something I will have the consequences? I can do something to prevent it or do something to fix it.\nWhat are the benefits of an attempt to fix?\nWhat is the cost of inaction1?\n\nBe prepared for the worst, and practice being calm even if it happens.\nFootnotes\n\n\n3-2-1- On designing your life, and the value of doing hard things ↩\n\n\n"},"notes/20220605134039":{"title":"Chain of Thought (CoT)","links":["highlights/Zotero/kojima_2022","20221210185344"],"tags":[],"content":"Chain of Thought (CoT)\nReference: kojima_2022\nBy prompting models to “think” step by step, chain of thought prompting helps model:\n\ndecompose a complex question into easier ones\nfacilitate clearer and better explanation for models’ decisions\n\nIt includes both zero-shot CoT and few-shot CoT.\nWhen to Use\n\nWhen model is relatively large\nIn commonsense reasoning tasks, zero-shot CoT does not help\n\nThis, however, does not mean the model is capable of reasoning. It only makes the model output/generation more applaudable in our own sense-making interpretation (On the Dangers of Large Generative Models)"},"notes/20220605195918":{"title":"How to Prevent Model From Learning Spurious Correlations","links":["notes/20220605200838","highlights/Archive/20220605142500"],"tags":[],"content":"How to Prevent Model From Learning Spurious Correlations\n1. 20220605200838 Data Balancing\nTransclude of 20220605200838\n2. Making Room for Uncertainty\nInstead of forcing model to output a result or a semi-educated guess, design the system to allow models to express its uncertainty, to interact with human when confidence is low and to abstain otherwise.\n3. Zero-shot or Few-shot Learning\nIf the knowledge is learned — if model’s performance on such task is close to or surpasses human baseline, maybe you don’t need to fine-tune the model with possible spurious correlations.\n\n\n@schwartz_2022\n20220605142500 On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations\n"},"notes/20220605200838":{"title":"Data Balancing","links":["highlights/Archive/20220605142500"],"tags":[],"content":"Data Balancing\nThe goal of data balancing is to remove or reduce spurious correlation between the data and the label.\nFor example, single-word features can be balanced by making sure that given a label, the probability of each word occurring in the dataset is the same. But compound features would also be needed for that purpose.\nJust like many other things in machine learning, this has some trade-offs:\n\nToo much balancing leads to no learnable signal: the model would never have enough information to make a decision as all assumptions are equally possible.\nToo little balancing makes the dataset biased and less generalizable.\n\nIt is inevitable that dataset has some spurious correlations especially when the definition of spurious varies from one context to another.\n\n\n@schwartz_2022\n20220605142500 On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations\n"},"notes/20220605202037":{"title":"Spurious Correlations","links":["highlights/Archive/20220605142500"],"tags":[],"content":"Spurious Correlations\nIngenuine\nWhen the correlation is not intended, often as an artifact of labeling process.\nWe never just want the model learn about the dataset, we want the model to learn about the world.\nUngeneralizable\nSuch correlation might be useful in certain contexts but not in general.\n\n\n@schwartz_2022\n20220605142500 On the Limitations of Dataset Balancing The Lost Battle Against Spurious Correlations\n"},"notes/20220611201307":{"title":"Current Issues with Natural Language Processing Evaluation","links":["highlights/Archive/Srivastava-et-al_2022_Beyond-the-Imitation-Game"],"tags":[],"content":"Current Issues with Natural Language Processing Evaluation\nEvaluation datasets or benchmarks are often targeted at narrow and specific tasks. Such that large pre-trained models are known to solve them. Thus it begs questions like what these models dont’t know and what they are capable of that we don’t foresee.\nSrivastava et al_2022_Beyond the Imitation Game proposed BIG-bench as result to measure such capabilities with ever changing suite of tasks. It primarily targets at zero or few-shot learning evaluation so that it can reflect models’ capability instead of its learning skill.\n\nReferences:\n\n@srivastava_2022\n"},"notes/20220611202320":{"title":"Critical Point of Breakthrough","links":["highlights/Zotero/srivastava_2022"],"tags":[],"content":"Critical Point of Breakthrough\nReference: Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language modelsAre Emergent Abilities of Large Language Models a Mirage?]]\nIt is observed that as the parameter size increases, some tasks see a steep increase during the evaluation, as though the model reaches some kind of breakthrough point. This is also referred to as emergent abilities.\nA closer look reveals a different story:\n\nThe breakthrough is largely contributed by the zero-sum, nonlinear, or discontinuous metrics, even when the model is gradually learning to assign a higher probability to the correct answer. But it will continue to be a failure before it crosses the threshold. Therefore, it is suggested that we should use a smoother metric instead to measure the progress. (Exact match vs token edit distance, accuracy vs brier score)\nThe task itself indeed requires a significant amount of knowledge to be learned by the model. Such tasks often involve multistep reasoning or compound components.s\n"},"notes/20220611204059":{"title":"Calibration Evaluation","links":["highlights/Archive/Srivastava-et-al_2022_Beyond-the-Imitation-Game","notes/20211003180000"],"tags":[],"content":"Calibration Evaluation\nReference: Beyond the Imitation Game Benchmark\nWe can compute Brier score - Wikipedia and Expected Calibration Error."},"notes/20220611205040":{"title":"BigBench","links":["highlights/Archive/Srivastava-et-al_2022_Beyond-the-Imitation-Game","notes/20220611202320","notes/20220611204059"],"tags":[],"content":"BigBench\nReference: Beyond the Imitation Game Benchmark\n\nScaling improves models’ performance, and sparsity also helps. But sadly, models are still far behind human performance;\nTasks that show linear relation with model size are generally knowledge-driven tasks;\nCrital Point of Breakthrough\nSocial bias scales with the model when the context isn&#039;t clear. Prompting helps;\nLanguage models make poorly calibrated predictions, but scaling helps. (Calibration Evaluation)\nTask formatting is also an important factor, but it may not be the case when the model is significantly large or efficiently trained with quality data;\n"},"notes/20220620140501":{"title":"Human Capital","links":["notes/20220620140902","notes/20220530100701"],"tags":[],"content":"Human Capital\nOne’s skills, knowledge, and time, which usually decreases or diminishes when one gets older. This is the direct opposite of Financial Capital.\n\nReferences:\n\n20220530100701 Just Keep Buying\n"},"notes/20220620140902":{"title":"Financial Capital","links":["notes/20220620140501","notes/20220530100701"],"tags":[],"content":"Financial Capital\nA.k.a. Investment. It is basically converting our diminishing Human Capital into income-producing financial assets.\n\nReferences:\n\nJust Keep Buying\n"},"notes/20220620162157":{"title":"Machine Learning Optimization","links":["notes/20210926153100"],"tags":[],"content":"Machine Learning Optimization\nIn general, you can optimize your model locally or globally. Locally, it is when you improve operators, blocks, or layers of the model, while globally, it is when you optimize your model end to end.\nSpecifically, you can optimize your model in the following areas:\n\nFrom loops to vectorization: The most obvious optimization we are doing nowadays is putting several examples into a small batch to improve the efficiency. Some other libraries (Jax) can automatically batch processing with a function designed for one single input.\nParallelization: One example of this is using CNNs to approximate RNNs to utilize GPUs powerful parallel computation. Recurrence is often helpful, but sadly slow.\nHardware-specific optimization: Depending on the hardware you are using, you can optimize your model, or data to be accessed/computed in a way that’s easy for the hardware such as loop tiling.\nFramework-specific or model-specific optimization: e.g., operator fusion. torch.nn.CrossEntropyLoss is known to be better than separated LogSoftmax and NLLLoss.\n\nOutside the scope of the model itself, you can rely on Machine Learning Compilers and Optimizers to further improve the performance."},"notes/20220620184506":{"title":"Growth Stocks","links":["highlights/Readwise/31554992","notes/20220620185630"],"tags":[],"content":"Growth Stocks\nStocks with high expectations and high hopes for the future. Just Keep Buying uses this term as an analogy to our early life, eventually failing to meet those expectations. When we grow older, we transition into 20220620185630 Value Stocks. Such transition resembles the Happiness Curve1.\nFootnotes\n\n\nIs Happiness U-shaped Everywhere? Age and Subjective Well-being in 132 Countries | NBER ↩\n\n\n"},"notes/20220620185630":{"title":"Value Stocks","links":["highlights/Readwise/31554992","notes/20220620184506"],"tags":[],"content":"Value Stocks\nReference: Just Keep Buying\nContrary to 20220620184506 Growth Stocks, our expectations of life are lowered over time as reality starts to set in, and we become more cautious about the outlook. This is how investors price value stocks."},"notes/20220622183618":{"title":"Feeling Rich","links":[],"tags":[],"content":"Feeling Rich\nRich is a relative concept. Such relativity will always be present throughout your life.\nInstead of trying to feel rich, we should feel the growth. By pivoting ourselves to a more friendly yesterday vs. now comparison, we motivate ourselves to make better decisions every day. But be aware of the comparison trap: Normally we never compare ourselves with billionaires because the gap of our wealth is beyond reach. We do, however, to our detriment, compare ourselves with someone who shares something in common with us. What we fail to see in such comparisons is that it will never be fair. Our life experience isn’t simply comparable or summarizable with solely the net worth."},"notes/20220622183957":{"title":"Market Crash","links":[],"tags":[],"content":"Market Crash\n\nWhen the market crashes, the most valuable assets are the ones most accessible.\nMarket crashes are almost always a buying opportunity\n"},"notes/20220622184252":{"title":"Tax and 401(k)","links":[],"tags":[],"content":"Tax and 401(k)\n401(k)\nOr traditional 401(k), is funded with pre-tax money.\nRoth 401(k)\nFounded with post-tax money.\nImportant Factors When Considering 401(k)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTypeCategoryWhen to Choose401(k)pre-taxfuture tax rate is lower than current rateRoth 401(k)post-taxcurrent tax rate is lower than future rate\ne.g. If you live in a high tax rate location, then it is best to invest in traditional 401(k) than Roth 401(k).\nDon’t Max Out Your 401(k)\nMaxing out your 401(k) means that you don’t have much flexibility. It is best to take into consideration of all the factors before making the decision:\n\nfinancial goals\ncost of 401(k) plan\nindividual circumstances\n"},"notes/20220622185751":{"title":"Market Volatility","links":[],"tags":[],"content":"Market Volatility\nDon’t mix up a period of underperformance with a losing position."},"notes/20220622185959":{"title":"Rebalancing","links":["notes/20220530100701"],"tags":[],"content":"Rebalancing\nThe goal of rebalancing is to reduce risk. It is never wise to buy individual stocks. Instead we should diversify our assets, for example 60% stocks and 40% bounds. But as their value fluctuates, the percentages inevitably change. Then we can rebalancing to counteract the increasing risk.\n\nBuy your way back to the balance;\nNo frequency outperforms others. It is advised by the author to rebalance annually.\n"},"notes/20220625181723":{"title":"Language Understanding, World Knowledge, and Scaling","links":["highlights/Archive/Hendrycks-et-al_2021_Measuring-Massive-Multitask-Language-Understanding"],"tags":[],"content":"Language Understanding, World Knowledge, and Scaling\nHighlights: Hendrycks et al_2021_Measuring Massive Multitask Language Understanding\nZotero link: @hendrycks_2021b\nIt is shown that current SOTA large pre-trained language models come short of human performance on a diverse set of benchmarks that typically require years of expertise for human learners. Such benchmarks span across many domains such as legal, healthcare, STEM, and economics.\nSome domains in this suite are highly contextualized, such as morality and laws. Though the authors did not include any ablations in regard to the diversity of such topics.\nKnowing how text should be pieced together does not guarantee understanding of the language, not to mention the understanding of the world. Solving this benchmark, IMHO, does not mean the model has the human-level intelligence since we still have little knowledge on how they solve these problems in the first place. Even if their logic makes sense to us and its generation looks/sounds amazingly intelligent, it is in our interpretation that we are granting such “intelligence” to the model instead of them possessing it directly. It can be very useful and efficient, but lifeless nonetheless.\nBefore we can answer what intelligence means for ourselves — a metric we can measure and track — we cannot make any concrete claims about models having intelligence.\nThe authors also observed under-calibrated predictions from large models, which should not be a surprise at all. The task of modeling probability was never introduced to the model explicitly, the output being within the [0,1] interval is just the artifact of the activation functions, and we often use it as an approximation of probability just because it is easy to do so."},"notes/20220702162157":{"title":"Graph Optimization","links":["4archives/Hypothesis/Optimizing-Transformers-with-Hugging-Face-Optimum","notes/20220620162157"],"tags":[],"content":"Graph Optimization\nSource: Optimizing Transformers with Hugging Face Optimum\nGraph optimization is one of many ways of Machine Learning Optimization. Usually, there are three approaches:\n\nConstant folding: evaluating constant expressions at compile time instead of runtime;\nRedundant node elimination: removing redundant computation nodes from the graph;\nOperator fusion: combining two or more operators into one;\n"},"notes/20220702163141":{"title":"After Work Activities","links":[],"tags":[],"content":"After Work Activities\n\nReading\nLearn something new\nBoard and video games\nCooking and baking\nBucket list for hiking spots\nGym\n"},"notes/20220703102957":{"title":"The Independent Researcher","links":["4archives/Hypothesis/The-independent-researcher","4archives/Hypothesis/Becoming-an-Independent-Researcher-and-getting-published-in-ICLR-with-spotlight","highlights/Matter/Joy-in-Research"],"tags":[],"content":"The Independent Researcher\nMindset\n\nWe don’t need anyone’s permission to do research1;\nWe don’t need a degree program to do research, but we do need some education on how to do research efficiently and ethically. A degree is only one of many options2;\nResearch is being of service to the public and the community3;\nBeware of the negativity4, but keep a positive mind and enjoy the joy5.\n\nPhD\nYou need to work as 50% hard as a PhD student to become one6. (e.g, you need papers in top conferences so that your PhD application can be somewhat competitive)\nValidation\n\nIt’s hard to convince other people that you are good at what you’re doing without any external validation/proof7;\nWe seek validation not for our egos, reputations, or fame but our sanity — we want to make sure there is meaning behind what we do8;\nHow to solicit validation and feedback:\n\nShare your findings in public and have a conversation9;\nEven a failure is an accomplishment10;\n\n\n\nPapers\n\nDon’t be afraid of repeating yourself to get the message crossed11;\nBe mindful of reviewing bias — what has been established will be harder to challenge12;\n\nFootnotes\n\n\n^46d8b2 ↩\n\n\n^da6425 ↩\n\n\n^71bebf ↩\n\n\n^26fc7c ↩\n\n\n^830649 ↩\n\n\n^342e90 ↩\n\n\n^119362 ↩\n\n\n^967dcc ↩\n\n\n^848312 ↩\n\n\n^97637c ↩\n\n\n^749d8a ↩\n\n\n^2e0fdf ↩\n\n\n"},"notes/20220703105218":{"title":"GIL and Multithreading","links":["4archives/Hypothesis/Python-behind-the-scenes-13-the-GIL-and-its-effects-on-Python-multithreading"],"tags":[],"content":"GIL and Multithreading\nSources: Python behind the scenes 13 the GIL and its effects on Python multithreading\nGIL stands for Global Interpreter Lock. The purpose of having GIL is to make sure CPython - Wikipedia interpreter is thread-safe.\nA python thread waits 5ms by default (the switch interval) if the GIL is locked, and it will send a release request to the GIL-holding thread. It’s up to the OS to decide which thread to wake up if there are multiple waiting threads.\nAdvantages\nGIL makes it:\n\nsafe to share objects (esp. mutable objects) , data (esp. global data), and modules between threads;\neasy to write C extensions without any additional locks — removing GIL will break all current extensions;\neasy to do reference counting — this is how Python do garbage collection which is not suited for multithreading;\n\nConvoy Effect\nWhen an I/O bound thread performs an I/O operation, it releases the GIL. By the time it finishes that operation and tries to reclaim the GIL, it is very likely the GIL has been acquired by another thread, and therefore it has to wait for at least 5ms.\n5ms may not seem like much time, but it is critical if the I/O operation itself is fast. So, such wait can significantly increase the overall computation time.\nSolutions:\n\nChanging the switch interval to smaller values;\nForce the OS to choose I/O thread by constraining all threads on a single core;\n"},"notes/20220703123440":{"title":"Data Filtering","links":["4archives/Hypothesis/DALL·E-2-Pre-Training-Mitigations","notes/20210928180400"],"tags":[],"content":"Data Filtering\nSource: DALL·E 2 Pre-Training Mitigations\nWhen designing datasets and models, it is often a common practice to filter out low-quality or duplicate data so that trained models don’t generate toxic output.\nMethods We Can Take to Improve Data Quality\n\nActive learning with human-in-the-loop annotation process. However, it might also introduce unintentional biases.\nRecall over precision:\n\nYou can always add new data to teach the model new things, but it is almost impossible to force the model to forget them.\n\n\nAvoid amplifying bias:\n\nUp-sample data points that are affected during filtering.\n\n\n\nDeduplication\nDuplicates incurs generating training data verbatim. This could lead to some legal and privacy issues.\nConsider clustering before deduplication:\n\nInstead of all-pair calculation, you can reduce the computation significantly by focusing on intra-cluster deduplication.\nTry multiple different runs/seeds;\nThe results are very robust against different k values based on their experiments;\n\nWe often say Garbage in, garbage out - Wikipedia in this Data-centric AI era, but it is worth-noting that we humans do not have such systematic filters to remove harmful content. Nor do we live in a censored environment where only positive things exist. Instead, we make intentional efforts to avoid being influenced by it, and more importantly, we also make sure we have proper sources, systems, and parenting to teach us what is wrong and what is right in a given social context. In this case, the models are still far away from “learning”. But the question remains — how can we model these collective social guardrails besides just feeding data to the model?"},"notes/20220704154116":{"title":"Plans Versus Workflows","links":["highlights/Readwise/31554993","notes/20220704161251"],"tags":[],"content":"Plans Versus Workflows\nHighlights: How to Take Smart Notes\nBy definition, a workflow is a combination of tools (The Slip-box System) and knowledge of how to use them, while a plan is usually a set of goals and steps.\nPlans, with their rigid structures and no matter how carefully designed goals and steps, are ill-suited for open-ended research and writing projects. They lack the inherent ingredients for insights or ideas that cannot be planned.\nOn the contrary, workflows/systems grant us the autonomy to work on what is right at that moment and encourage new ideas. By design, they reduce the friction of writing, so we don’t need much mental energy to power through anything with diminishing motivation or interest.\nWriting projects like academic writing are an art about gaining insights and making it public. You cannot achieve this by planning.\nPlanners Versus Experts\nWhile some planners finish a project and move on, experts don’t stop because they understand the value of the continuous pursuit of knowledge via note-taking. To them, note-taking or learning becomes a life-long mission that they want to commit to."},"notes/20220704155657":{"title":"Dunning-Kruger Effect and Imposter Syndrome","links":["highlights/Readwise/31554993"],"tags":[],"content":"Dunning-Kruger Effect and Imposter Syndrome\nHighlights: How to Take Smart Notes\nThe Dunning-Kruger effect refers to when people who know little about their limitations feel more confident, while people who do often underestimate their abilities. Similarly, high achievers often feel incompetent because they are more aware of the vast knowledge and skills beyond themselves, which is referred to as Imposter Syndrome."},"notes/20220704160314":{"title":"How to Start Taking Notes Smartly","links":["highlights/Readwise/31554993","highlights/Readwise/31554998","notes/20220704161251"],"tags":[],"content":"How to Start Taking Notes Smartly\nHighlights: How to Take Smart Notes\nIt is not about what is in your notes right now, nor how you were taking notes before. It is about making efforts to change your way of taking notes from now on and “deal with things differently the moment you have to deal with them”.\nAs described in Atomic Habits, you fall to the level of your systems. This is the case with slip boxes.\nIt is easy to fall back to your old habits of taking notes, but The Slip-box System prescribed in this book would make a huge difference if you keep doing it (a.k.a. forming a habit). You have to trust the system so that you can start focusing on tackling tasks instead of worrying about note-taking itself."},"notes/20220704161251":{"title":"The Slip-box System","links":["highlights/Readwise/31554993","notes/20220821200532","notes/20220821201005","notes/20220821201337","notes/20220821201737"],"tags":[],"content":"The Slip-box System\nReference: How to Take Smart Notes\n\nFleeting NotesPARA]];\nLiterature NotesFleeting Notes]], but for research purposes;\nPermanent NotesLiterature Notes]];\nMaking Connections in Zettelkasten \nAdd the note to an index/TOC if necessary.\n"},"notes/20220705214840":{"title":"How to Write a Paper with Zettelkasten","links":["highlights/Readwise/31554993","4archives/BASB/202205011900-Capture-Toolkit","4archives/BASB/202204291344"],"tags":[],"content":"How to Write a Paper with Zettelkasten\nHighlights: How to Take Smart Notes\nWriting is Not the Goal\nWe generate notes while we spend time understanding the materials and coming up with ideas. Thus, writing should be an easy post-processing step of those artifacts of our thinking and reading.\nOur growth should come from our thinking and learning, accompanied by the practice of writing and note-taking.\n1. Fleeting Notes\nThis step captures what we think. It doesn’t have to be in order or in full sentences. All fleeting notes should go into an inbox where they will be discarded as soon as we processed.\nIn special cases, if you have very mature ideas at this time, you can create 3 Permanent Notes instead.\n2. Literature Notes\nThis includes what we read what might be useful right now or in the future, along with necessary bibliographic details.\n3. Permanent Notes\nGo through the notes you have from 1 Fleeting Notes2 Literature Notes]] and figure out:\n\nan idea that is relevant to you, or resonates with you;\nwhat does it relate to in the notes you already have, add links or create an index note if necessary;\nwhat is missing from that idea and what are the questions you need to answer;\n\nThis should motivate you to find more resources on the topic to enrich your idea or argument.\n\n\n\n4. Project\n\nBring forward all relevant notes around an idea as a project as in PARA. See what is missing and redundant, and go out to source more information if needed.\nDraft your notes into something slightly more coherent and workable.\nIterate on the draft until you have a manuscript.\n\nNote-taking is Not the Goal\nWe take notes not for just one single project we are working on at the moment but also for all possible projects we will be working on in the future, or simply for our intellectual amusement. We learn most of our knowledge not by systematic education, but by accidental encounters instead."},"notes/20220709143042":{"title":"Multilingual Data Filtering","links":["highlights/Archive/Henderson-et-al_2022_Pile-of-Law"],"tags":[],"content":"Multilingual Data Filtering\nHighlights: Henderson et al_2022_Pile of Law @henderson_2022\nIt is difficult to perform data filtering with consistency and transparency because the content can be very situational and culture-dependent. Laws and regulations, in this case, are often the lower bound of the trade-off spectrum of transparency and privacy.\nSome universally recognized practices regarding personal sensitive information:\n\nNo juvenile records\nNo financial information (account numbers, identity numbers, or date of birth)\nEven if the information is public available, we should not lower our standards\n\nHowever, not all cases of toxic content are deemed undesired unanimously. Mentions of toxic language or historical quotations where discrimination was prevalent and therefore considered to be acceptable at that time can be of value to understand the progress of toxicity in a temporal context.\nIssues with Modern Language Models\nContext limit: Text such as mentions or quotations, if substantially long, can be modeled unintentionally as direct usage and therefore compromise the training.\nToxicity in long documents: longer context dilutes the toxicity according to some recent toxicity language models, suggesting we need a better modeling process.\nLearning the Rules with Language Models\nWith the Pile of Law dataset, we can teach the model about when to redact names by using masked names/pseudonyms."},"notes/20220709195323":{"title":"Only Writing Counts","links":["highlights/Readwise/31554993","highlights/Matter/Large-Learning-Models-Are-An-Unfortunate-Detour-in-AI","highlights/Matter/Students-Depend-on-ChatGPT-for-Final-Exams","notes/20231206213457","highlights/Matter/Justine-Bateman-on-AI,-Labor,-and-the-Future-of-Entertainment","highlights/Readwise/31779177","highlights/Matter/Why-I-Don't-Care-if-Students-Use-GPT","highlights/Matter/ChatGPT-Is-a-Blurry-JPEG-of-the-Web","highlights/Matter/Learning-to-Communicate","highlights/Matter/ChatGPT--Beware-the-Self-Serving-AI-Editor","highlights/Readwise/36309893"],"tags":[],"content":"Only Writing Counts\nHighlights: How to Take Smart Notes\nWriting is the only time-tested process to flush out our ideas and thoughts. Spending time on writing doesn’t mean less time for reading or learning1 2. On the contrary, it is writing that encourages us to ponder and to be selective about what to write and how to write3.\nDuring the process of writing, an idea can only be clearly stated if you understand it first. Even more so, to write it in public, the thought of having someone else to read and criticise your work only makes it more involving and rewarding. It becomes a self-reflection and self-exploration journey with yourself and assumed audience.\n(Re)writing, thinking, and learning are an inseparable trio.\nTransclude of Large-Learning-Models-Are-An-Unfortunate-Detour-in-AI#^9205a6\nThis is also echoed in Students Depend on ChatGPT for Final Exams, where students take advantage of a text synthesiser for their essays. Even the simple usage of touching up or paraphrasing deprives us of the chance to think and make efforts in general and, consequentially, our desire to learn. This undercuts the fundamental idea of education. Sometimes, such edits can lead to content degradation if left unchecked4.\nAnother area that the LLMs have impacted is books, especially with online bookstores, and those who have the power to protect us from reading books produced with little to no effort aren’t doing anything meaningful either5.\nOf course, this applies to other forms of expressions as well. It is often not the utterances (words in particular order) that matter, but the eagerness to communicate and the actual idea conveyed. Consequentially, passive learning through simply reading or listening to books or lectures can never compete with Reading with Cognitive Models.\nTransclude of Justine-Bateman-on-AI,-Labor,-and-the-Future-of-Entertainment#^4c2e66\nRelated Notes:\nPutting Ideas Into Words\nFootnotes\n\n\nWhy I Don’t Care if Students Use GPT ↩\n\n\nChatGPT Is a Blurry JPEG of the Web ↩\n\n\nLearning to Communicate ↩\n\n\nChatGPT- Beware the Self-Serving AI Editor ↩\n\n\nAI Is Already Killing Books ↩\n\n\n"},"notes/20220709201046":{"title":"Multilingual Embedding Alignment with Distillation","links":["highlights/Archive/Xiong-et-al.---2022---Simple-Local-Attentions-Remain-Competitive-for-Lon.textbundle/text","notes/20220709205943"],"tags":[],"content":"Multilingual Embedding Alignment with Distillation\nHighlights: text\nDistillation Architecture\ngraph TD; \n  source --&gt; teacher;\n  target --&gt; student;\n  student --&gt; similarity;\n  teacher --&gt; similarity;\n\nTarget and source input can be the same text or parallel text. The student network can have different vocabulary from the teacher network.\nWhy Distillation\nTraining a monolithic dense model for many languages is expensive and cumbersome due to computation cost. Instead, training one small model for each language family or even a single language allows more flexibility to 1) add new languages, 2) support different vocabularies, and 3) tune performance separately.\nHow to Distill\n\nUse Margin-based Cosine Similarity Metric to align teacher embeddings and student embeddings.\nAdd Masked Language Modeling objective as well to encourage the model to learn from the monolingual data as well.\nAllow curriculum learning via progressive distillation — sentence pairs are fed incrementally at a 10% interval.\nUse max-pooling instead of CLS embedding.\n"},"notes/20220709205943":{"title":"Margin-based Cosine Similarity Metric","links":[],"tags":[],"content":"Margin-based Cosine Similarity Metric\nCosine similarity suffers from scale inconsistency1, and therefore a margin-based similarity metric is preferred1.\nxsim(x,y)=margin(cos(x,y),z∈NNk​(x)∑​2kcos(x,z)​+z∈NNk​(y)∑​2kcos(y,z)​)\nHere NNk​ means nearest neighbors in the other language/domain, and margin can be many options, but margin(a,b)=a−b is used in 1.\nFootnotes\n\n\n@heffernan_2022 ↩ ↩2 ↩3\n\n\n"},"notes/20220710150036":{"title":"When Zettelkasten Fails","links":[],"tags":[],"content":"When Zettelkasten Fails\nEven though Zettelkasten is organized bottom-up and free from typical top-down organizational issues, it can suffer from being too noisy or being too little to work with.\nBeing Too Noisy\nWhen you have countless ideas in notes that are unprocessed, or processed indiscriminately, you can hardly find the relevant information or have meaningful encounters with your notes. The slip-box loses its edge over a generic search engine.\nIf you only write notes related to current projects, your notes become obsolete as soon as you finish your projects.\nThere is no need to write everything down, as we don’t cram everything into our brain. Only if it can help you with your thinking, you write a note about it."},"notes/20220710151858":{"title":"Project Notes","links":["highlights/Readwise/31554993","4archives/BASB/202204291344"],"tags":[],"content":"Project Notes\nHighlights: How to Take Smart Notes\nProject notes, similar to the project concept in PARA, which has a short period of life span that is independent of the slip-box. They should be discarded or archived when the project is finished.\nProject notes typically include:\n\ncomments\nproject-related literature\noutlines\nsnippets\ndrafts\nreminders\nto-do lists\n"},"notes/20220717122151":{"title":"Starting From Scratch","links":["notes/20220823071945"],"tags":[],"content":"Starting From Scratch\ngraph TB\n    subgraph X [Note Taking]\n        direction LR\n        A(True Scratch) --&gt; |Reading, Thinking, and Writing| B(Notes)\n    end\n    subgraph y [Writing]\n        direction LR\n        B --&gt; C(Pesudo Scratch)\n        C --&gt; Manuscripts\n    end\n\nA blank paper or a white screen is never the starting point of a writing project. To decide on a topic to write about, one must have some exposure to the topic before.\nHaving a slip-box thus is the key difference between scavenging your brain for ideas with fuzzy memories and using an external system that is reliable and objective with accurate and interesting notes.\nAs a result, writing should never to top-down and brain-driven. Instead, it should bottom-up and evident-based. You should make decisions such as which topic to write about based on your notes, written ideas and thoughts because you already have the materials in the notes.\nThis is also why we should Resist Brainstorming because we now can turn to our slip box for time-tested ideas."},"notes/20220717133315":{"title":"Writing with a Positive Feedback Loop","links":["highlights/Readwise/31554998","highlights/Omnivore/20240314070752","4archives/BASB/202205011900-Capture-Toolkit"],"tags":[],"content":"Writing with a Positive Feedback Loop\nBuilding a virtuous feedback loop for your writing is similar to the idea of making it enjoyable in Atomic Habits. It reduces your dependency on willpower or motivation which is often depleted.\nFeedback and a Growth Mindset\nSeeking feedback and embracing it is the key to having a growth mindset, which is the key to learning. But how can we integrate feedback into our note-taking process?\n\nWrite while reading so we can evaluate our understanding. You can only rephrase something you understand (Write for others but mostly for yourself — Jack VanlightlyOnly Writing Counts]]).\nDistinguish what is important and what’s not. It should align with your interest and resonate with you.\nWrite with your notes to understand what is missing and what should be improved.\n"},"notes/20220717195403":{"title":"Word and Novelty","links":["highlights/Matter/-Disregard-the-Words-"],"tags":[],"content":"Word and Novelty\nReference: Disregard the Words\n\nWords often escape us when we try to describe something truly unique and novel\nDescribing something with words is an abstraction just like programming. To learn the reality thoroughly one need to disregard the words that are used to describe it.\n"},"notes/20220723150024":{"title":"Early Exiting","links":["notes/20210926153300","highlights/Archive/Schuster-et-al_2022_Confident-Adaptive-Language-Modeling"],"tags":[],"content":"Early Exiting\nA popular strategy of Adaptive Computation. In the transformer language model family, the exiting strategy is often related to the number of layers involved. There are several challenges when adopting this technique:\n\nWhat confidence measure to use;\nPerformance constraints;\n\nExamples of early exiting include Schuster et al_2022_Confident Adaptive Language Modeling."},"notes/20220723154103":{"title":"Confident Adaptive Language Modeling","links":["notes/20220723150024","tags/todo"],"tags":["todo"],"content":"Confident Adaptive Language Modeling\nAn Early Exiting example that tries to address these issues:\n\nConfidence measure\nSequence level constraints at token-level exit decisions;\nAttending previous tokens when decoding;\n\nConfidence Measure and Sequence-level Constraints\nThis framework uses a decaying threshold for each time step for exit decisions.\n\nThe model becomes more relaxed as the generation reaches the end. This comes from the observation that early perturbations degrade the performance more than late perturbations.\nDeciding which λ to use come from a rigorous testing with a calibration dataset.\n\nHere, L can be either\n\nDissimilarity measure that measures the distance for textual consistency between the generation from an early exiting model and a full model. The smaller, the better.\nRisk consistency measure that measures the risk between two generations. The lower, the better.\nThis is where the sentence level constraints are incorporated into the decisions.\n\nThis framework uses 1−metric to calculate the two measures. The goal is to keep it small (smaller than the tolerance parameter δ) while looking for a minimum λ value.\nAttending Previous Tokens When Decoding\n\nAt step 6, layer 5, previous steps’ early layers’ hidden states are copied directly as the previous layer’s output.todo Why is this needed if all inputs are concatenated for next step?"},"notes/20220724140856":{"title":"Model Soup","links":["highlights/Archive/Wortsman-et-al.---2022---Model-soups-averaging-weights-of-multiple-fine-tu"],"tags":[],"content":"Model Soup\nSource 12\nModel soup refers to averaging multiple fine-tuned models’ weights to a new model. It is shown that such practice improves the performance and robustness.\nModel Soups VS. Ensemble\nModel soup is more straightforward than model ensembling and highly correlates to it as well.\nUniform Averaging and Greedy Soup\nThe authors have shown a greedy soup can have even better performance than a uniform average. By adding a model only when it improves the fine-tune task, greedy soup ignores models that does not contribute to the task. Such models might reside in different loss basins.\nFootnotes\n\n\n@wortsman_2022 ↩\n\n\nWortsman et al. - 2022 - Model soups averaging weights of multiple fine-tu ↩\n\n\n"},"notes/20220724150422":{"title":"ML-based Compilers","links":["notes/20210926153100"],"tags":[],"content":"ML-based Compilers\nUnlike traditional Machine Learning Compilers and Optimizers, ML-based compilers use machine learning to optimize the graph compilation. Examples of such compilers are cuDNN and autoTVM.\nIt’s a viable alternative to hand-designed optimizations for new hardware products or frameworks, but it can also be very slow due to the vast search space."},"notes/20220724212820":{"title":"Multitasking","links":["highlights/Readwise/31554993","highlights/Readwise/31596656","highlights/Readwise/31565981","highlights/Matter/Today’s-Superpower-Is-Doing-One-Thing-at-a-Time","highlights/Matter/Finding-Time"],"tags":[],"content":"Multitasking\nHighlights: How to Take Smart Notes\nPeople often feel more productive when multitasking, but it is not. Both the quantity and the quality of the work are decreased. Like multitasking in computer science, it is essentially quick context-switching, and our brain works even less efficiently than computer multicore chips 1. Externally, the overwhelming information and distractions around us make focusing on one thing more difficult2. (Will AI make it better or worse?)\nWriting is a collection of tasks, in the sense that it includes “reading, understanding, reflecting, getting ideas, making connections, distinguishing terms, finding the right words, structuring, organizing, editing, correcting and rewriting”. But none of these require parallel processing.\nAccepting the truth that we are not good at multitasking and the fact that we have endless things on our plate forces us to say no. It also forces us to reflect on our priorities and to realise that the promising land of finishing is never around the corner3 4.\nFootnotes\n\n\nAttention didn’t collapse. It was stolen (2022) ↩\n\n\nWhy Note-Taking Apps Don’t Make Us Smarter - The Verge ↩\n\n\nToday’s Superpower Is Doing One Thing at a Time ↩\n\n\nFinding Time ↩\n\n\n"},"notes/20220724213311":{"title":"Mere-exposure Effect","links":["highlights/Readwise/31554993","notes/20220724212820"],"tags":[],"content":"Mere-exposure Effect\nHighlights: How to Take Smart Notes\nIn psychology, mere-exposure effect means doing something many times makes us believe that we are good at it. This is especially true for Multitasking. Unfortunately, familiarity does no equal to skill."},"notes/20220724213903":{"title":"Flexible Attention","links":["highlights/Readwise/31554993"],"tags":[],"content":"Flexible Attention\nReference: How to Take Smart Notes\nDifferent tasks require different levels of attention of different kinds. It is essential to be flexible in granting our attention to our tasks."},"notes/20220724214628":{"title":"Gut Feeling","links":["highlights/Readwise/31554993"],"tags":[],"content":"Gut Feeling\nReference: How to Take Smart Notes\nOr intuition, in other words. This is not just some random guess. It is our prediction based on our previous experience and the information we learned from success or failure."},"notes/20220724214948":{"title":"Connection","links":["highlights/Readwise/31554993"],"tags":[],"content":"Connection\nConnection is the key to our understanding and internalization. Such connections can be “rules, theories, narratives, pure logic, mental models or explanations”. How to Take Smart Notes\nWhen the right connections are made, and a proper cue is given, we can retrieve information from our memory/knowledge.\n\nYou shall know a word by the company it keeps (Firth, J. R. 1957:11)\n\nBy the same logic, a note is only as valuable as the connections it keeps.\nMaking connections among notes can be time-consuming and energy draining — because you are making sense of the material over and over again, but it will become more and more enjoyable as the slip box grows towards a critical mass, by which time, adding connections is essentially a process of learning itself."},"notes/20220724215232":{"title":"Zeigarnik Effect","links":[],"tags":[],"content":"Zeigarnik Effect\nUnfinished tasks occupy our short-term memory.\nOne easy fix is to offload those tasks to an external system or leave them there and ruminate on them subconsciously. In terms of writing, we can decompose our writing project into many tasks and write down outcomes so that we can pick up any time we want."},"notes/20220730154644":{"title":"Importance of Note-taking When Reading","links":["highlights/Readwise/31554993","notes/20220709195323","notes/20220730160038"],"tags":[],"content":"Importance of Note-taking When Reading\nHighlights: How to Take Smart Notes\nWriting itself is important, as in Only Writing Counts. Taking notes while reading is also equally critical.\nNote-taking is a Deliberate Practice of Learning\nHere we write down our notes, ideas, or thoughts that can live beyond the current text’s context. By paraphrasing or summarizing the text, we force ourselves to manifest our understanding instead of merely highlighting them. This is a chance that we can put our understanding into test, discover the gap in our knowledge, and put efforts into our learning while reading.\nBut we also need to be aware of our Confirmation Bias and be selective of what is essential."},"notes/20220730160038":{"title":"Confirmation Bias","links":["highlights/Readwise/31554993","highlights/Readwise/31554987","notes/20230324201053"],"tags":[],"content":"Confirmation Bias\nHighlights: How to Take Smart Notes\nReferences: Think Again\nWe see what we expect to see, and our instincts are not helping1. It means we tend to prefer things that are more familiar, more aligned with what we already believe, or more like ourselves.\nThis is dangerous because we can unconsciously build an echo room with our notes/surroundings, thus eliminating any opportunity for critical insights.\nHow to Avoid Confirmation Bias\nHave an open mind when taking notes, and choose relevancy over familiarity.\nFootnotes\n\n\nFirst-instinct Fallacy ↩\n\n\n"},"notes/20220731103238":{"title":"Positional Embeddings","links":["highlights/Archive/Natural-Language-Processing-with-Transformers"],"tags":[],"content":"Positional Embeddings\nHighlights: Natural Language Processing with Transformers\nPositional Embeddings are representations of positions of a token in a sequence. There are several kinds of positional embeddings:\n\nLearnable Positional Embeddings: normal learnable embeddings.\nAbsolute Positional Embeddings: static embeddings.\nRelative Positional Embeddings: locality-focused embeddings, which can add additional positional information in an attention component.\n"},"notes/20220731103941":{"title":"Layer Normalization","links":["highlights/Archive/Natural-Language-Processing-with-Transformers","notes/20220905125225"],"tags":[],"content":"Layer Normalization\nHighlights: Natural Language Processing with Transformers\nDefinition: σ(0,1) normalization over a layer’s activations. It is commonly used in architectures like Transformers1, but it is hard to train since it reduces the individual information about their relative norms.\n\nSource: Xiong et al. 2020\nPost-layer Normalization\nLayer Normalization after skip connections. The underlying reason why we need a warm-up for Post-LN is that the scale of gradients can be very large as the depth increases initially. We have to control the step size first. But this is not the case for Pre-LN as it normalizes the gradients with respect to the depth. Gradients can diverge in this configuration, therefore, learning rate warm-up is often used.\nPre-layer Normalization\nMore stable than Post-layer NormalizationOn Layer Normalization in the Transformer Architecture]].\nFootnotes\n\n\nLayer Normalization in Transformers ↩\n\n\n"},"notes/20220731105255":{"title":"Pruning","links":[],"tags":[],"content":"Pruning\nPruning refers to the practice of removing redundant parameters in a neural network. Some examples of pruning are:\n\nMagnitude Pruning: pruning parameters based on their magnitude, which can be very different from their importance to downstream tasks.\nImportance Pruning: pruning parameters based on downstream tasks.\n\nThree considerations when using pruning:\n\nwhich parameters to remove;\nhow to adjust for the removed parameters;\nhow to do this efficiently;\n"},"notes/20220731110004":{"title":"Quantization","links":["highlights/Archive/Natural-Language-Processing-with-Transformers"],"tags":[],"content":"Quantization\nHighlights: Natural Language Processing with Transformers\nQuantization is a process of approximating full-precision models with less precision.\nQuantization-aware Training\nFP32 values are rounded during training (both forward and backward passes) to mimic quantization.\nStatic Quantization\nUsing a representative example to learn a good quantization schema based on its activations. Such quantization is only done once and therefore much faster.\nDynamic Quantization\nDuring inference, the conversion from FP32 to INT8 is taking place on the fly but more optimized than Static Quantization. The conversion could pose a bottleneck, though."},"notes/20220731111104":{"title":"Tokenization","links":[],"tags":[],"content":"Tokenization\nBackground\nCommon English tokenization algorithms are\n\nsplitting by characters or words;\nbyte pair encoding, which joins frequently occurring bytes/characters together as a new token;\nunigram that starts with all words and potential subwords and gradually remove them to reach ideal vocabulary size.\n\nComparison between popular implementations:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureSentencePiecesubword-nmtWordPieceSupported algorithmBPE, unigram, char, wordBPEBPE*OSS?YesYesGoogle internalSubword regularizationYesNoNoPre-segmentation required?NoYesYesCustomizable normalization (e.g., NFKC)YesNoN/ADirect id generationYesNoN/A\n(Source: google/sentencepiece)\nTokenization Metrics\n\nCoverage\n\nPercentage of unknown words in the corpus\nPercentage of “rarely used tokens” in a corpus\n\n\nFragmentation\n\nPercentage of words that are split\n\n\nSubword Fertility\n\nAverage number of subwords per word\n\n\n"},"notes/20220731112022":{"title":"Text Generation Tricks","links":["4archives/Hypothesis/5.-Text-Generation","highlights/Archive/Natural-Language-Processing-with-Transformers"],"tags":[],"content":"Text Generation Tricks\nHighlights: 5. Text Generation, Natural Language Processing with Transformers\nDepending on your task, there are some nobs you can tweak:\n\nShort and more deterministic generation: low temperature (coherence), greedy search and/or beam search.\nLong and creative generation: high temperature (diversity), top-k and/or top-p sampling.\n"},"notes/20220806133205":{"title":"Problems with OCR in Document Understanding","links":["highlights/Archive/Kim-et-al_2022_OCR-free-Document-Understanding-Transformer"],"tags":[],"content":"Problems with OCR in Document Understanding\nHighlights: Kim et al_2022_OCR-free Document Understanding Transformer\n\nComputation cost: Training an OCR model and running it for text detection significantly increases the time and cost for both training and inference.\nError propagation: Errors that surface in the OCR results create a bottle for downstream model performance.\nGeneralizability: OCR rarely extends itself to non-Latin scripts and other languages. Free and off-the-shelf OCR engines often produce poorer results than commercial products.\n"},"notes/20220806133754":{"title":"OCR-free Document Understanding Transformer","links":["highlights/Archive/Kim-et-al_2022_OCR-free-Document-Understanding-Transformer","notes/20220806133205","notes/20220806134354"],"tags":[],"content":"OCR-free Document Understanding Transformer\nSource1\nHighlights: Kim et al_2022_OCR-free Document Understanding Transformer\nIncluding an OCR component in the document understanding system poses Problems with OCR in Document Understanding|a series of problems. Here, the authors propose a pseudo-OCR encoder-decoder framework, converting all downstream tasks to generation tasks, to get rid of OCR dependency.\nOne of the metrics they use to measure information extraction results is Tree Edit Distance.\nFootnotes\n\n\n@kim_2022 ↩\n\n\n"},"notes/20220806134354":{"title":"Tree Edit Distance","links":[],"tags":[],"content":"Tree Edit Distance\nA parsing of a document can be represented as a tree, similar to a DOM tree in an HTML webpage. By measuring the edit distance between the ground truth tree and the predicted parsing tree, one can get a more realistic measure about the similarity with some flexibility.\nSpecifically, it is measure by the minimum cost of a sequence of operations needed to convert from one tree to another. Operations include deletion, insertion, and renaming.\nResources:\n\nTree Edit Distance\n"},"notes/20220814211819":{"title":"Meaning and Referent","links":["highlights/Archive/Piantadosi_Hill_2022_Meaning-without-reference-in-large-language-models","notes/20220814212300","highlights/Archive/Climbing-towards-NLU-On-Meaning-Form-and-Understanding-in-the-Age-of-Data"],"tags":[],"content":"Meaning and Referent\nHighlights: Piantadosi_Hill_2022_Meaning without reference in large language models\nClimbing towards NLU: On Meaning, Form, and Understanding in the Age of Data - ACL Anthology argues that Referents are important to understanding the meaning. But as @piantadosi_2022 argues, it might not be the case.\nInstead, they formulate that the interrelation between conceptual roles — internal representational states — is more crucial than referents. \nBut the question is: Can models learn such interrelation from text data with some objectives? The weak empirical answer from the paper suggests yes, based on the success from variety of tasks and benchmarks.\nTransclude of Piantadosi_Hill_2022_Meaning-without-reference-in-large-language-models#^0d78e5\nI find it strange that the original paper Climbing towards NLU On Meaning Form and Understanding in the Age of Data clearly admits tasks like entailment do have some information related to meaning learnable beyond text. Yet, this paper seems to ignore that part.\nAdditionally, text can be considered as a low-dimension projection of the meaning, and it is possible to infer high-dimension information from low-dimension projections based on some studies in other domains. (This is actually mentioned at the end of ^862047, did they read the paper at all?)"},"notes/20220814212300":{"title":"Referent and Reference","links":["highlights/Archive/Piantadosi_Hill_2022_Meaning-without-reference-in-large-language-models","highlights/Matter/Three-ideas-from-linguistics-that-everyone-in-AI-should-know"],"tags":[],"content":"Referent and Reference\nHighlights: Piantadosi_Hill_2022_Meaning without reference in large language models\nReferents are physical, tangible objects that we can refer to when using a language. We can conjure up an image of an apple when using the word “Apple”. But we do have a large vocabulary that some abstract terms/phrases do not share any physical referents.\nReference is the relation that connects such forms and their referents. ^96620f"},"notes/20220814213251":{"title":"Church-encoding","links":["highlights/Archive/Piantadosi_Hill_2022_Meaning-without-reference-in-large-language-models"],"tags":[],"content":"Church-encoding\nHighlights: Piantadosi_Hill_2022_Meaning without reference in large language models\nA representation is constructed in one system to mimic the behavior of another. For example, building a neural network for boolean logic system."},"notes/20220817191341":{"title":"Using Tags in Zettelkasten","links":["highlights/Readwise/31554993"],"tags":[],"content":"Using Tags in Zettelkasten\nHighlights: How to Take Smart Notes\nAvoid adding topic tags — it renders the slip box into an archive, and instead, use context-related tags, so you can find it when you are working on some similar projects.\nIn which context would I want to find this note even if I forget about it?"},"notes/20220817192137":{"title":"Index in Zettelkasten","links":["highlights/Readwise/31554993"],"tags":[],"content":"Index in Zettelkasten\nHighlights: How to Take Smart Notes\nIndex notes are only useful to tracking some entry points to a group of notes. It is almost impossible to have an index of our mind, let alone this second brain. The slip-box is a thinking tool, not a tool to think about.\nBy meticulously putting a note into some index notes, we are organizing the notes with defined hierarchy, which is precisely the opposite of the goal of slip box."},"notes/20220820161457":{"title":"Expert Language Model Forest","links":["notes/20220814211819","highlights/Archive/Li-et-al_2022_Branch-Train-Merge.textbundle/text.markdown"],"tags":[],"content":"Expert Language Model Forest\nSource 1 2\nExpert Language Model\nLanguage models trained on specific domain corpus. They are considered domain experts as a result.\nExpert Language Model Forest\nBy ways of averaging (normal, argmax, weighted) or ensembling a group of Expert Language Models, a ELM forest can:\n\noutperform a baseline Transformer LM;\nbe trained in parallel and incrementally with less cost;\ngood options to cost-sensitive (weighted average) applications and as well as performance-sensitive (ensemble with domain posterior) applications.\n\nHowever, the question remains, do we have such compartmentalization in our brain as well? According to @piantadosi_2022, Transclude of 20220814211819#^9abb87\nshouldn’t such interrelation, instead of isolation, help models’ “understanding”?\nOne piece of evidence I can see in the paper is that, an ensemble forest at 1B parameter scale (125M * 8 ELMs) actually performs worse than a 1B dense model, even though they are comparing them at per GPU level (125M per GPU vs. 125M model).\nFootnotes\n\n\n@li_2022c ↩\n\n\ntext.markdown ↩\n\n\n"},"notes/20220820162450":{"title":"Branch-Train-Merge","links":["notes/20220820161457","notes/20220724140856","highlights/Archive/Li-et-al_2022_Branch-Train-Merge.textbundle/text.markdown"],"tags":[],"content":"Branch-Train-Merge\nSource 12\nA strategy to train a Expert Language Model ForestExpert Language Model]] is added to the forest.\nIt is shown that ensembling domain-specific models is better than models trained on random splits. The resulting forest, similar to Model Soups, outperforms baseline models while using comparable compute. Though, the compute cost can vary a lot depending on the ensemble strategy.\nFootnotes\n\n\ntext.markdown ↩\n\n\n@li_2022c ↩\n\n\n"},"notes/20220821144614":{"title":"Two Types of Connections in Digital Zettelkasten","links":[],"tags":[],"content":"Two Types of Connections in Digital Zettelkasten\n\nHub note, a.k.a. Table of Content(ToC) note which hosts entry links to a cluster of notes under the same topic which developed from the bottom up.\nPlain connection between notes that simply expresses relevancy. This is how we discover insights from.\n"},"notes/20220821145713":{"title":"Flashcards VS Zettels","links":["notes/20220724214948","notes/20220814212300"],"tags":[],"content":"Flashcards VS Zettels\nFlashcards are isolated pieces of information that people often use to cram information into their heads (rote memory without reference). It is good for remembering stuff, but never really for understanding or truly learning them, not to mention writing manuscripts in the end.\nWhile zettels d draw connections with each other, and therefore we can build a latticework of ideas and mental models.\nThis eerily combines the idea of ReferentMeaning and Reference]] — connections and references are both important factors in the process of understanding."},"notes/20220821150845":{"title":"Thinking with Confrontation","links":["notes/20220724214948","notes/20220704161251"],"tags":[],"content":"Thinking with Confrontation\nConfrontation is a key step in building an understanding, and the slip box is a perfect tool to confront us with existing ideas, whether they are contradicting or conforming the new ones. Our interpretation evolves as we fill the knowledge gap adding Connections.\nThe process of making connections deepens our knowledge by forcing us to ask questions and reinforces the deliberate practice of retrieval, interpreting, and connecting."},"notes/20220821151621":{"title":"Restrictions Promote Creativity in Zettelkasten","links":["notes/20220704161251"],"tags":[],"content":"Restrictions Promote Creativity in Zettelkasten\nThe The Slip-box System seems daunting at first, since it requires a lot of deliberate practice, time, and energy during the process. It also requires significant change to how you read, write, and interact with your notes. e.g., one idea per note and one page per note.\nDespite such constraints, it is proven to be effective promoting insights because it strips the noises and imposes a simple yet powerful structure to our workflow while leaving enough freedom for comparison, differentiation, and experimentation."},"notes/20220821200532":{"title":"Fleeting Notes","links":["notes/20220704161251"],"tags":[],"content":"Fleeting Notes\nThe first step in the The Slip-box System. It is a quick reminder of an idea, or a capture of a thought. It should be reviewed in a matter of days and discarded afterwards. Or you can discard them if you don’t recall the purpose of them in the first place."},"notes/20220821201005":{"title":"Literature Notes","links":["notes/20220821200532"],"tags":[],"content":"Literature Notes\nIt is similar to Fleeting Notes Your personal research assistant](www.zotero.org/)."},"notes/20220821201337":{"title":"Permanent Notes","links":["notes/20220821200532"],"tags":[],"content":"Permanent Notes\nIt is one of the three note categorisations in Zettelkasten. This is where ideas or concepts get elaborated in atomic details.\nConnections are often made among them during transitioning from a Fleeting NoteThe Slip-box System]].\nIt should include enough context about where it comes from and where it could be used in the future. Both the atomicity and connections should be revisited and updated often to serve our future selves."},"notes/20220821201737":{"title":"Making Connections in Zettelkasten","links":["notes/20220724214948","notes/20220821144614","notes/20220528132200","highlights/Matter/How-Our-Brains-Are---and-Aren’t---Like-Computers"],"tags":[],"content":"Making Connections in Zettelkasten\nConnections are crucial components in the slip box system, and the process of making them should take the most of your note-taking efforts to maximize your learning and understanding. Without those connections, the notes we take are archives that can never promote insights.\nThere are Two Types of Connections in Digital Zettelkasten.\nMaking connections or associations is also a useful trick to make things memorable. Our brain might prune connections to operate more efficiently as we age1, but we do not need to do this in our slip box because it grows freely in a digital space.\nYou can search your slip box for potential connections by asking the following questions:\n\nWhat does it include in this note?\nWhat does it fail to include?\nWhat claims does it support or disprove?\nIs there any similar information related to this?\nWhat difference does it make to your current understanding or to your project?\n\nFootnotes\n\n\nHow Our Brains Are - and Aren’t - Like Computers ↩\n\n\n"},"notes/20220823071945":{"title":"Resist Brainstorming","links":["notes/20220724214948"],"tags":[],"content":"Resist Brainstorming\nIf building a slip box is the tool for insights, then brainstorming for ideas is just scratching the surface.\nIn a slip box, we can rely on the connections and materials to find concrete ideas and insights. However, this is not a case for a brainstorm session where the only thing you can come up with is right on your mind.\nAdmittedly, you might have experience and skills that warrant no explicit supporting evidence, and your brain might work well in some occasions. But a slip box is superior in a sense that it comes with all the content already, if built with enough rumination.\nInstead, if we are interested in finding topics to write about, we can turn to our notes for questions that have been asked, discussed, or even answered with supporting ConnectionsTopical Gravity in Zettelkasten]], we can easily find relevant materials to work with."},"notes/20220823073646":{"title":"Topical Gravity in Zettelkasten","links":["notes/20220724214948"],"tags":[],"content":"Topical Gravity in Zettelkasten\nAs we build our slip box from bottom up, we start a natural selection process with our notes: topics we are interested the most attract or connect to more notes, and topics we care about less are left isolated gradually.\nThis virtuous feedback loop helps us connect more notes and eventually move towards the critical mass."},"notes/20220823074641":{"title":"Resist Planing","links":["notes/20220823071945"],"tags":[],"content":"Resist Planing\nSimilar to Resist Brainstorminginsights or creativity cannot be planned ahead]]."},"notes/20220823075137":{"title":"Parkinson's Law","links":[],"tags":[],"content":"Parkinson’s Law\n\nwork expands so as to fill the time available for its completion\n"},"notes/20220828143405":{"title":"ATTENTION WITH LINEAR BIASES ENABLES INPUT LENGTH EXTRAPOLATION","links":["notes/20220828154238"],"tags":[],"content":"ATTENTION WITH LINEAR BIASES ENABLES INPUT LENGTH EXTRAPOLATION\nReferences: ALiBi enables transformer language models to handle longer inputs\nMost pre-trained language models use certain context length during training, and unfortunately most of them do not extrapolate to longer text during inference:\n\nIt is simply not possible to extrapolate using trained embeddings because you don’t have the corresponding learned weights;\nFixed positional embeddings (sinusoidal) do not work as well.\nRotary positional embeddings perform better than sinusoidal, but still not very good.\nT5 Bias seems to extrapolate better than aforementioned embeddings, to some extent.\n\n\nHypothesis: models are overfitting to the positional embeddings and larger models are more easily overfitting (reverse scaling law?)\n\nImplementation\n\nUsing the last work in the sequence as a query;\nUsing the rest of the sequence as keys;\nCalculate the dot products and subtract some biases manually set;\n\nwordL−1Q​⋅wordiK​−(L−i)×mm=2n−8​​​\n\nTakeaways\n\nAlibi consumes a longer context, but still uses a shorter context internally.\nUsing Sliding Window Evaluation, it shows a flat perplexity curve rather than an exploding curve from baseline models.\n"},"notes/20220828154238":{"title":"Early Token Curse and Sliding Window Evaluation","links":[],"tags":[],"content":"Early Token Curse and Sliding Window Evaluation\nFor a given language model trained with L context length, it is popular to evaluate the model on a corpus using non-overlapping segments using perplexity. However, this does not reflect the real performance of the model. Short context window means more evaluations for a given dataset. And for perplexity evaluation, the starting tokens are the most confusing text for the model because it’s starting from nothing. Therefore, short context leads to more chance of guessing early tokens.\nWhile using a sliding window, it counterbalances such issue by equalize the numbers of evaluations on early tokens, though it significantly increases the evaluation time."},"notes/20220830210545":{"title":"Tyler Cowen on Reading","links":[],"tags":[],"content":"Tyler Cowen on Reading\nReferences:\n\n\nTyler Cowen on reading fast, reading well, and reading widely - Driverless Crocodile\n\n\nTyler Cowen - Wikipedia\n\n\nBooks I’ve Loved — Maria Popova and Tyler Cowen (#436) – The Blog of Author Tim Ferriss\n\n\nYou don’t have to finish a bad book.\n\n\nRead books in cluster because there is no single best book on one topic. You really have to read dozens of them to form an idea. So enjoy reading them in groups.\n\n\nThere are always topics that you are not aware of before you read a book about it.\n\n"},"notes/20220904143432":{"title":"Form, Meaning, and Communicative Intents","links":["highlights/Archive/Climbing-towards-NLU-On-Meaning-Form-and-Understanding-in-the-Age-of-Data","highlights/Omnivore/20240306084115","notes/20220814212300","highlights/Archive/Piantadosi_Hill_2022_Meaning-without-reference-in-large-language-models","notes/20220814211819","highlights/Matter/What-Kind-of-Mind-Does-ChatGPT-Have-","highlights/Matter/Thought-experiment-in-the-National-Library-of-Thailand"],"tags":[],"content":"Form, Meaning, and Communicative Intents\nHighlights:\n\nClimbing towards NLU On Meaning Form and Understanding in the Age of Data\nThe work of creation in the age of AI | Andrew Perfors\n\nUnderstanding is, proposed in this paper, the reconstruction of communicative intents from forms (observable realization of language), while meaning is the relation between the two.\nCommunicative intents can take many forms:\n\nto convey information;\nto convey instructions;\nto socialize;\n\n                                                                              \n◀────────────────────────────────────Express──────────────────────────────────\n                                                                              \n┌─────────┐   ┌──────────────────────────────┐  ┌────────────────────────────┐\n│  Form   │   │     Conventional Meaning     │  │  Communicative Intentions  │\n└─────────┘   └──────────────────────────────┘  └────────────────────────────┘\n                                                                              \n ────────────────────────────────Understand──────────────────────────────────▶\n                                                                              \n\nAdditionally, there is Conventional Meaning in the middle, which creates a context-independent view of the form, and when interpreted by the listener, the real communicative intentions are reconstructed. However, we often attribute such communicative intentions to objects that don’t even have them in the first place, such as language models.\nOne argument of this paper is that language or text needs to be grounded with ReferentsMeaning and Reference]] from Piantadosi_Hill_2022_Meaning without reference in large language models.\nHowever, I don’t really see these two opinions being mutually exclusive. As mentioned in this paper, tasks such as reading comprehension require, as well as include, weak information beyond the text that models might seem to be able to pick up. But that’s beyond the scope of this paper.\nFor language models, the ability to model interrelation between Conceptual Roles does not negate the fact such conceptual roles or representational states can be ungrounded. (And no one can really say for sure that modern LM training corpus are free of any kind of training data)\nYes, the interrelation with forms (which can be seen as a tiny fraction of the world) can be seen as some level of meaning. But such meaning would be a castle in the air, ungrounded, no matter how fluent or plausible the construction is.\nTransclude of What-Kind-of-Mind-Does-ChatGPT-Have-\nTo learn meaning in a more grounded way or to move forward in general, some suggestions are proposed:\n\nTraining with multi-modality;\nAsking top-down questions about our directions — choosing the right hill to climb;\nBeing skeptical, which is different from being pessimistic;\nSaying something as it is — a model captures some reflection of meaning from the form which can be very useful in applications.\n\nReferences:\nThought experiment in the National Library of Thailand"},"notes/20220904155650":{"title":"Octopus Test","links":["highlights/Archive/Climbing-towards-NLU-On-Meaning-Form-and-Understanding-in-the-Age-of-Data","notes/20220904143432"],"tags":[],"content":"Octopus Test\nOctopus Test is proposed in Climbing towards NLU On Meaning Form and Understanding in the Age of Data and is constructed as follows:\n\nAn Octopus listens to a conversation between two people under the sea for an infinite amount of time.\nThe Octopus could learn enough statistical patterns to attack the conversation as a “middle-octopus”.\nBut the fact the octopus cannot and will never understand a word such as coconut or anything or any novel situation on the land since it never really get the chance to experience them beyond words.\n\nConsequently, two more narrowed tests are proposed to illustrate the problem:\n\nJava test: a model trained with every Java program (just the program, without inputs and outputs) will fail to execute them because it simply doesn’t know how execution works. Such execution (from code to machine bytes to CPU instructions) is the equivalent to our Communicative Intents that are beyond text.\nA system that trains text and image separately with unsupervised learning or self-supervised training (or just two random pre-trained LM and CV models) will undoubtedly fail to perform an image QA task. The training or the data is insufficient to capture such relation.\n"},"notes/20220904161644":{"title":"Language Acquisition","links":["highlights/Archive/Climbing-towards-NLU-On-Meaning-Form-and-Understanding-in-the-Age-of-Data"],"tags":[],"content":"Language Acquisition\nHighlights: Climbing towards NLU On Meaning Form and Understanding in the Age of Data\nIt is both grounded in the physical world and in the interactions we have with other people. Simply watching TV commercials won’t teach a child the language."},"notes/20220905125225":{"title":"Layer Normalization in Transformers","links":["highlights/Zotero/xiong_2020","notes/20220731103941"],"tags":[],"content":"Layer Normalization in Transformers\nHighlights: On Layer Normalization in the Transformer Architecture\nLayer normalization mainly has two ways of implementation in Transformers:\n\nPre-layer Normalization: adding layer normalization before self-attention and FNN;\nPost-layer Normalization: adding layer normalization after residual connections;\n\nIt is shown that Post-LN suffers from additional hyperparameters (learning rate warm-up) and, as a result, slower training. Experiments confirm the hypothesis that training with Pre-LN and without warm-up can achieve comparable results faster."},"notes/20220910125816":{"title":"Informed Simplicity","links":[],"tags":[],"content":"Informed Simplicity\n\ntwitter.com/colin_dunn/status/1524807290888499200"},"notes/20220925095941":{"title":"Ethical Questions to Ask in AI","links":["highlights/Matter/“Ensuring-Safe,-Secure,-and-Trustworthy-AI”--What-those-seven-companies-avoided-committing-to","highlights/Matter/“If-It-Sounds-Like-Sci-Fi,-It-Probably-Is”"],"tags":[],"content":"Ethical Questions to Ask in AI\nReferences:\n\nResisting dehumanization in the age of AI - Emily Bender - YouTube\n“Ensuring Safe, Secure, and Trustworthy AI”- What those seven companies avoided committing to\n“If It Sounds Like Sci-Fi, It Probably Is”\n\n\nWhat is the input and output?\nIs the input self-sufficient for deriving the output?\nHow was the data sourced, curated, and validated? Are rights respected during development?\nWho would benefit from it if the output is accurate, and who would it harm when the results are not?\nCan this technology be used to violate human rights?\n"},"notes/20220925100618":{"title":"Exponential Moving Average (EMA)","links":["highlights/Zotero/ma_2022"],"tags":[],"content":"Exponential Moving Average (EMA)\nReference: @ma_2022 Mega: Moving Average Equipped Gated Attention\nAt step t, the output of the current step y+t is expressed as\nyt​​=α⊙xt​+(1−α)⊙xt−1​+(1−α)2⊙xt−2​+...=α⊙xt​+i=1∑t​(1−α)i⊙xt−i​=α⊙xt​+(1−α)⊙yt−i​​​\nwhere α∈[0,1].\nIt favors local dependencies and limits long context.\nDamping Factor\nTo discount the dominance of the current step, a damping factor can be applied:\nyt​​=α⊙xt​+(1−α⊙δ)⊙xt−1​+(1−α⊙δ)2⊙xt−2​+...=α⊙xt​+i=1∑t​(1−α⊙δ)i⊙xt−i​=α⊙xt​+(1−α⊙δ)⊙yt−i​​​"},"notes/20220925101407":{"title":"Multidimensional Exponential Moving Average (MEMA)","links":["notes/20220925100618"],"tags":[],"content":"Multidimensional Exponential Moving Average (MEMA)\nThis is a multidimensional extension of Exponential Moving Average (EMA).\nDefine the mini-batch input sequence X∈RB×S×d×1, an expansion matrix β∈Rd×h, the expanded representation is calculated as:\nRhut(j)​​Rd×hut​​RB×S×d×hu​​=Rhβj​​Rxt,j​​=Rd×hβ​Rd×1xt​​=RB×S×d×1x​×Rd×hβ​​​\nThis step is to enrich the expressiveness of the data. Consequently, we need both terms α and δ to match the dimensions, i.e. α∈Rd×h and δ∈Rd×h. Then the output is defined as:\nRhht(j)​​Rd×hht​​RB×S×d×hh​Ryt,j​​RB×S×dy​​=Rhαj​​⊙Rhut(j)​​+Rh(1−αj​⊙δj​)​⊙Rhht−1(j)​​=Rd×hα​⊙R×d×hut​​+Rd×h(1−α⊙δ)​⊙Rd×hht−1​​=Rd×hα​⊙RB×S×d×hu​+Rd×h(1−α⊙δ)​⊙RB×S×d×hy​=R1×hηj⊺​​⋅Rh×1ht(j)​​=Rd×1×hη⊺​⋅RB×S×d×h×1h​​​\nEfficient Computation of MEMA\nDenote ϕ=1−α⊙β∈Rd×h, then we have\ny1​y2​yt​yt​​=η⊺⋅h1​=η⊺⋅(α⊙u1​+ϕ⊙h0​)=η⊺⋅(α⊙(βx1​))+η⊺⋅ϕ⊙h0​=η⊺⋅h2​=η⊺⋅(α⊙u2​+ϕ⊙h1​)=η⊺⋅(α⊙(βx2​)+ϕ⊙(α⊙(βx1​)+ϕ⊙h0​))=η⊺⋅(α⊙(βx2​))+η⊺⋅ϕ⊙(α⊙(βx1​))+η⊺⋅ϕ2⊙h0​=i=0∑t​η⊺⋅ϕt⊙(α⊙(βxt−i​))+η⊺⋅ϕt⊙h0​=i=0∑t​(η⊺⋅(ϕt⊙α⊙β))xt−i​+η⊺⋅ϕt⊙h0​​​\nWhich can be seen as a convolutional operation with respect to X as well as h0​."},"notes/20221009143236":{"title":"How to Categorize an Interpretation Method","links":["notes/20221009143635"],"tags":[],"content":"How to Categorize an Interpretation Method\n\nWhat are the input and output?\n\nWhat data or language does it ingest? (Tabular, text, or image)\nWhat does it output? (effect, importance, or attribution)\n\n\nHow does it work?\n\nLocal InterpretationGlobal Interpretation]]?\nInterpretability by design or post-hoc explanation?\n\n\nWhat is the outcome? A model or an algorithm?\n"},"notes/20221009143635":{"title":"Local Interpretation","links":["notes/20221009144221"],"tags":[],"content":"Local Interpretation\nA.k.a. pointwise interpretation. It works with individual predictions. This is in direct contrast with Global Interpretation.\nExamples of pointwise interpretation methods are:\n\nCounterfactual Explanations\nShapley Values\nSHAP (SHapley Additive exPlanations)\n\nThis key difference between local interpretation and global interpretation isn’t always clear, since methods can often be used/viewed in both perspectives."},"notes/20221009144221":{"title":"Global Interpretation","links":["notes/20221009143635"],"tags":[],"content":"Global Interpretation\nAn interpretation method working with the model, or sometimes a collection of Local Interpretations.\nExamples are:\n\nPartial Dependence Plot (PDP)\nPermutation Feature Importance\n"},"notes/20221016113017":{"title":"Batch Normalization","links":["notes/20220731103941"],"tags":[],"content":"Batch Normalization\nIn contrary to Layer Normalization, batch normalization normalizes the columns/features over a batch of activations.\nHowever, it also means that such normalization is dependent on the batch. One solution to this is that you keep a running average of mean and variance for all features at that layer, which are applied during inference."},"notes/20221023141204":{"title":"Conformal Prediction","links":["notes/20211003180000"],"tags":[],"content":"Conformal Prediction\nSource: Quantify The Uncertainty Of Predictive Models With Conformal Prediction\nIt takes a “heuristic uncertainty score” and converts it into a “rigorous” one, usually by Calibration.\nRecipe:\n\nSplit data into training and calibration subsets\nTrain model on training data\nPick a certainty level (e.g. 90%)\nCalculate the heuristic scores on calibration data\nCalibrate the heuristic scores to make them rigorous with guaranteed coverage\nUse calibrated thresholds on new data\n"},"notes/20221023141944":{"title":"Interpretation Pitfalls","links":["notes/20221009143236"],"tags":[],"content":"Interpretation Pitfalls\nSource: 8 Pitfalls To Avoid When Interpreting Machine Learning Models\n\nNo one method can rule them all. Choose the suitable one for the end goal How to Categorize an Interpretation Method.\nIgnore feature dependence.\nIgnore feature interaction.\nIgnore uncertainties.\nJumps to causal relation too soon.\n"},"notes/20221023152731":{"title":"Meaningful Names","links":[],"tags":[],"content":"Meaningful Names\n\nJust enough context:\n\nwhy it exists\nwhat it does\nhow to use it\n\n\nWrite for your readers, not compilers\nInformative &gt; Non-informative &gt; Dis-informative\nMake it pronounceable, so people can discuss it\nOnly use single-letter variables in a small local scope\nConsistency lexicon\n\nChoosing a good name for your variable requires good descriptive skills and a shared cultural background."},"notes/20221113145808":{"title":"Goodhart's Law","links":["highlights/Readwise/31554997","highlights/Matter/Too-much-efficiency-makes-everything-worse--overfitting-and-the-strong-version-of-Goodhart’s-law","highlights/Matter/Goodhart’s-Law-and-Scientific-Innovation-in-Academia"],"tags":[],"content":"Goodhart’s Law\nReferences:\n\nGoodhart’s law - Wikipedia\n\n\nWhen a measure becomes a target, it ceases to be a good measure.\n\nAn example of Goodhart’s law in Machine Learning is that we often use a differentiable metric for training but a different objective for evaluation. In the case of overfitting, the training metric continues to improve while the evaluation metric stagnates or even worsens.\nSuch deterioration is described as the strong version of Goodhart’s law1. Compounded with the metric black hole from Deep Work, it would negatively impact our productivity even more.\nAnother example of this in academia is the number of paper published. The unintended consequences of this is that people start to yield papers with inconsequential contributions and sometimes fake results. Other metrics like h-index are also imperfect in a sense that there exists citation bias2.\nFootnotes\n\n\nToo much efficiency makes everything worse: overfitting and the strong version of Goodhart’s law ↩\n\n\nGoodhart’s Law and Scientific Innovation in Academia ↩\n\n\n"},"notes/20221113154021":{"title":"Locating and Editing Factual Associations","links":["notes/20221113155122"],"tags":[],"content":"Locating and Editing Factual Associations\nReferences:\n\n@meng_2022\n\nRank-One Model Editing\nAs described in ^9eca9d, we now can apply changes to model weights to take in a new “fact”.\nBy treating a linear projection as [Associative Memory], we can update the weights to take in a new fact by calculating the following:\nW^k∗​=v∗​\nWhere W^ is the new weight matrix, k∗​ is the query vector for the subject, and v∗​ is the value vector for the new fact (under the same subject and relation).\nk∗​ can be calculated by averaging hidden states over different context for a given subject beforehand, which can be seen as a universal subject query vector.\nv∗​, on the other hand, can be calculated by finding a z that minimizes the loss:\n\nz is defined as the output hidden state at layer l and step i. (This seems like some computation)\nAfter we have both k∗​ and v∗​, we can calculate the updated W^ and plug it back into the model."},"notes/20221113155122":{"title":"Causal Tracing","links":["notes/20221113154021"],"tags":[],"content":"Causal Tracing\nReferences:\n\nLocating and Editing Factual Associations\n\nGiven a (subject, object, relation) fact:\n\nA clean run uses the original input and calculates the hidden representations.\nA corrupted run uses masked input where the subject is masked or obfuscated.\nA corrputed-with-restoration run uses the same masked input, but uses the original hidden states at certain layer and certain token/step.\n\nTo effectively measure which layer and which step to swap the hidden states, the authors further defined the following metrics:\n\nTotal Effect: the probability change from a clean run to a corrupted run. This tells how much impact the subject tokens have over the prediction.\nIndirect Effect: the probability change from a corrupted-with-restoration run to a corrupted run. This tells how much impact the restoration (at layer l and token/step i) has over the prediction.\n\nTakeaways: \n\nIn terms of restoration layer, l should be in the eraly-to-middle MLP modules.\nIn terms of restoration step/token, i should be the last subject token.\n"},"notes/20221116184118":{"title":"Priority in Research","links":["4archives/BASB/202205011900-Capture-Toolkit","highlights/Matter/Ahead-of-AI--2--Transformers,-Fast-and-Slow"],"tags":[],"content":"Priority in Research\nIt is impossible to catch up on all the papers from conferences, journals, and not to mention arXiv. Similar to how we should capture information only when it resonates with you, we should have our priorities when doing research1.\nFootnotes\n\n\nAhead of AI ↩\n\n\n"},"notes/20221120094433":{"title":"Cognitive Model","links":["highlights/Matter/Three-ideas-from-linguistics-that-everyone-in-AI-should-know","highlights/Zotero/bender_2020","highlights/Matter/Transcript--Ezra-Klein-Interviews-Gary-Marcus","highlights/Matter/Large-Language-Model--world-models-or-surface-statistics-"],"tags":[],"content":"Cognitive Model\nAccording to Three ideas from linguistics that everyone in AI should know, a cognitive model is a persisting but dynamic sense of the world.\n\nAs Brenden Lake and Greg Murphy have put it, that’s not enough, “Current models are too strongly linked to the text-based patterns in large corpora, and too weakly linked to the desires, goals, and beliefs that people express through words.”\n\nOur brain does not have direct access to the world and is stimulated by the signals perceived by other organs. How different are those signals different from the signals those models get from text? One main difference I can see is that our perception is much more well-situated and grounded — we experience the signals in a much larger context than a sliding window on some text. This echoes one of the suggestions from bender_2020: train models with multi-modality data. How can we model desired “responses” even if we manage to compress what one person can perceive in real life?\nSome also use the phrase world model — a mental model of the world1. Such a model is constantly being updated by our daily interactions in a way that we can’t fully understand yet. In such a model, our use of language is very different from the model’s as well1.\nIt is shown that models can learn some aspects of the world, even though in a very narrow sense and in an artificial setting2. Nonetheless, they are still proven useful in prediction and seemingly aligned with human understanding.\nFootnotes\n\n\nTranscript: Ezra Klein Interviews Gary Marcus ↩ ↩2\n\n\nLarge Language Model: world models or surface statistics? ↩\n\n\n"},"notes/20221120094643":{"title":"Compositionality","links":["highlights/Matter/Three-ideas-from-linguistics-that-everyone-in-AI-should-know"],"tags":[],"content":"Compositionality\nA complex whole can be “systematically interpreted in terms of their parts, and how these parts are arranged”1.\nSimilar to most NLP questions, to solve it requires understanding, which we, as humans, still don’t have an accurate metric for. Even if we have a colossal array of benchmarks, it is a proxy that can only prove generalized usefulness or applicability at best.\nTransclude of Three-ideas-from-linguistics-that-everyone-in-AI-should-know#^5fddb9\nFootnotes\n\n\nThree ideas from linguistics that everyone in AI should know ↩\n\n\n"},"notes/20221120131625":{"title":"Situating Search","links":["highlights/Zotero/shah_2022","notes/20221120131920","notes/20230115161911","highlights/Matter/Why-We-Should-Not-Trust-Chatbots-As-Sources-of-Information","highlights/Matter/Why-ChatGPT-Won’t-Replace-Google","highlights/Omnivore/20240326121213","highlights/Matter/Natural-language-is-the-lazy-user-interface","highlights/Matter/Prompt-Engineering-Shouldn't-Exist","highlights/Matter/AI-chatbots-are-coming-to-search-engines---can-you-trust-the-results-","highlights/Matter/AI-Search-Engines-And-The-Quest-For-Ignorance"],"tags":[],"content":"Situating Search\nSource: Situating Search\nTo understand what a search engine can or should provide, we need to understand what use-cases a person has when searching.\nSearch engine should:\n\nbe trustworthy: provide verifiable and traceable results, leaving decisions (&amp; responsibility) to the users;\nbe helpful and supportive, not authoritative: help user make sense of retrieved information;\nbe transparent: what is included and why is that, what it is capable of and whatnot, what harm it might cause or limitation it has;\nunderstand user intentions and scenarios and adapts accordingly and iteratively;\nevolving as the underlying data evolves1;\n\nIn some cases, a chatbot interface cannot bare such functionalities to fulfil user’s search needs:\n\nA typical search engine connects the user with content written by real people who care about the truth, while ChatGPT does not distinguish truth or lies, nor does it want you to leave2;\nA navigational search from traditional search enignes can directly link you to the website, but a chat bot might compose a wikipedia page before showing a relevant link3;\nThe existence of prompt engineering and prompt hacking is actually putting the burden on the user to ask the “right” question, while in reality, this is not how we communicate at all4 5.\nIt also takes advantage of the human tendency to trust a conversation more than search results6, and the tendency of taking things at face value, or shall I say title value7. It is a dangerous combination when the model is just generating Bullshit.\n\nThis is not to say chat interface is nothing useful. It can be very helpful to refine user queries by iterative clarification and follow-ups. How to balance the UI for different use cases remains a challenge.\nFootnotes\n\n\n^ad06eb ↩\n\n\nWhy ChatGPT Won’t Replace Google ↩\n\n\nPerplexity, Copilot, You.com: Putting the AI search engines to the test - The Verge ↩\n\n\nNatural language is the lazy user interface ↩\n\n\nPrompt Engineering Shouldn’t Exist ↩\n\n\nAI chatbots are coming to search engines - can you trust the results? ↩\n\n\nAI Search Engines And The Quest For Ignorance ↩\n\n\n"},"notes/20221120131920":{"title":"Information Seeking Strategies","links":["notes/20221120131625","highlights/Matter/Why-We-Should-Not-Trust-Chatbots-As-Sources-of-Information"],"tags":[],"content":"Information Seeking Strategies\nReferences:\n\nSituating Search\n\nInformation Seeking Strategies analyzes the interaction users have with a search engine from four aspects:\nMethod\nThe method of interacting includes searching and scanning:\n\nSearching is similar to depth first search. We know what we are searching for.\nScanning is similar to breadth first search, sense-making during the process. We don’t know what we want1.\n\nGoal\nThe goal of interaction can be selecting or learning:\n\nSelecting is when the goal is to pick some items that meet your criterion.\nLearning is when the goal is to discover and learn diverse aspects of a subject.\n\nMode\n\nSpecification is searching with filters.\nRecognition is searching with extra questions.\n\nResource\nWe can either select based on the content (Information), or the metadata of such content (Metadata).\nIn total, there can be 16 different scenarios from such four aspects.\nFootnotes\n\n\n^db797c ↩\n\n\n"},"notes/20221121213015":{"title":"Folk Interface","links":["highlights/Matter/Folk-Interfaces"],"tags":[],"content":"Folk Interface\nFrom Folk Interfaces. It describes when people repurpose an existing software to their own use cases that are unexpected by the original creators of the software.\nPeople’s creativity and willpower to shape things to their liking never stop to amaze me. The insatiability for a better solution (a.k.a. too lazy to be burdened with inefficiency) resonates so well with my inner perfectionism. Yet, the folk part conveys something that is almost crude yet effective."},"notes/20221124103746":{"title":"Research Like an Engineer","links":["highlights/Zotero/taylor_2022","notes/20220925095941"],"tags":[],"content":"Research Like an Engineer\nWhat exactly does it take to become a good machine learning engineer?\nThis is mainly my thoughts on reading the paper taylor_2022 1 and the drama of it on Twitter.\nThe paper starts off with the information overload issue, which is valid, in my opinion. But it bothers me because it didn’t go into detail on what frictions or pain points researchers have when doing research. I fail to see the assumption they implicitly have that what the model is capable of is what people need (case in point: the related work section has nothing to do with researching itself or information overload).\nThere is a saying that I couldn’t find a source and I think is appropriate: Ask not what a model can do, instead, ask what the issues are and how a model can help. The issue here, I think, is the lack of a clear definition of the problem, and it reminds me of the work experience I have as an engineer.\nHigh-level decisions from leaders or product managers are ambiguous and often require many back-and-forth discussions to figure out what they mean. It could be a user complaint, or our competitor is doing so, or they don’t even know. Typically, they don’t work with a product manager, which means little to no systematic access to stakeholders’ opinions. Imagine this, if all they can do is from a research lab without any meaningful connection to the real user, how can I trust their results that they hope to have an impact on the real world?\nThat’s basically the point I want to make here. Building something user-facing frequently has more stake than a niche research project because you get direct user feedback, whether a slash back or a warm welcome. You have to test your idea with tons of user research because it is no longer a thought experiment based on individual experience.\nTransclude of taylor_2022#^5ce274\nYou can’t expect to have trust in your model and yet completely avoid the responsibility of building a trustworthy system.\nIn order to be trustworthy, we need to be more thoughtful (like asking Ethical Questions to Ask in AI) when doing research and to have higher standards, not just models, but systems, and to ensure the integrity of each component.\nFootnotes\n\n\n@taylor_2022 ↩\n\n\n"},"notes/20221127140633":{"title":"Importance of Reading and Writing","links":["highlights/Readwise/31554993","highlights/Matter/Reading-Ourselves-to-Death","highlights/Matter/Students-Depend-on-ChatGPT-for-Final-Exams","highlights/Matter/Learning-to-Communicate","notes/20230205125210","highlights/Matter/3-2-1--Focusing-on-what-you-can-control,-the-value-of-small-contributions,-and-daily-habits"],"tags":[],"content":"Importance of Reading and Writing\n\nWriting isn’t just translation from thoughts to words. It also allows us to think about what we are trying to express. Note-taking while reading, in particular, is one of the most effective techniques recommended in How to Take Smart NotesWriting with a Positive Feedback Loop]]Importance of Note-taking When Reading]])\nReading, on the other hand, is our way of perceiving such expressions, learning and understanding different abstractions, and discovering new insights. (Reading Ourselves to DeathTyler Cowen on Reading]])\nBoth reading and writing are our thoughtful mediums of communication that can inspire personal growth, and meaningful connections1 2. \nBut there should be no shortcut, see Students Depend on ChatGPT for Final Exams. There is a difference when knowing how to use a calculator and only knowing how to use a calculator. We should take reasonability for and control of our words, instead of letting the model take the wheel.\n\nIt is also worth mentioning that what we read also matters3.\nFootnotes\n\n\nLearning to Communicate ↩\n\n\nBeing Human ↩\n\n\n3-2-1: Focusing on what you can control ↩\n\n\n"},"notes/20221204100844":{"title":"Keep Moving Forward","links":["highlights/Readwise/31554990"],"tags":[],"content":"Keep Moving Forward\nSource: You Are a Badass\nRegarding the past: Instead of feeling guilty or ashamed about the past, you appreciate wherever you are.\nRegarding the present: Pay attention to opportunities and details, enjoy following your heart, and put yourself out there.\nRegarding the future: Not be afraid of what we want and not pretend that we don’t know about what we want."},"notes/20221204110442":{"title":"How to Build a Large Web Dataset","links":["highlights/Zotero/overwijk_2022"],"tags":[],"content":"How to Build a Large Web Dataset\nSource\nBeing able to access a search engine (not as a user, but as a owner) has huge advantage over using a crawler:\n\nSearch engines or search products have access to user feedbacks, though mostly indirect, about website quality, while cralwed dataset only has limited static link analysis(^00fc66^3038d9]]).\nSearch services, especially international ones, also have access to wider variaty and coverage.\nWebsites often give special privilage to search engines but not crawlers.\n\nQuality\nHTMLs can be a mess, complicated by the presence of CSS and Javascript. To fully assess a webpage’s quality, @overwijk_2022 took the following steps:\n\nRender the website using a headless browser.\nSuch rendering enables the combination of HTML DOM and visual features (vDOM).\nSemantic annotation segments the webpage into different parts (Title, Primary Content, Paragraph, Table, List etc.) using a neural network(^d38572^2bea7d]], ^3d62d2).\nEnhanced parsing allows the parser to ingest both vDOM and semantic structural information to derive the final clean content of the web page.\n"},"notes/20221212175342":{"title":"Embedding Tasks and Metrics","links":["highlights/Zotero/muennighoff_2022"],"tags":[],"content":"Embedding Tasks and Metrics\nReference: muennighoff_2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTasksMetricsMultilingualBitext MiningF1/Accuracy/Precision/Recall✔ClassificationAvg. Precision/F1✔ClusteringV-measurePair ClassificationAvg. Precision/F1/Precision/RecallRe-rankingMAP/MRR@kRetrievalnDCG@k/MRR@k/MAP@k/Precision@k/Recall@kSTSSpearman/Pearson Correlations with Cosine Distances✔SummarizationSpearman/Pearson Correlations with Cosine Distances"},"notes/20221218101249":{"title":"Constitutional AI","links":["highlights/Zotero/bai_","20221210185344"],"tags":[],"content":"Constitutional AI\nReference: bai_\nMain motivation: model outputs are often evasive when it comes to sensitive topics. This is “harmless” but not “helpful”. To engage in a better way, models should provide better responses.\nThe idea of constitutional AI is that such generative models are “governed” with a set of rules/principles. In the paper, a set of 16 principles were used for both helpfulness and harmlessness.\nMethod: This extends the idea of RLHF (reinforcement learning with human feedback) by replacing human feedback with AI critics and revisions.\nIt starts with a helpful but toxic model, trained with RLHF and helpfulness feedback. It is then tasked to critic its helpful but harmful responses with random sampled principles embedded in the prompt. At this point, you have a “red team” query and a few revisions that reduce the harmfulness while preserving the helpfulness.\nYou can either fine-tune a model with such data (SL-CAI) or further train a model with reinforcement learning with such data (RL-CAI).\nComments\nFuture Work\nTransclude of bai_#^3857c9\nTransclude of bai_#^aada6a\nThere is too much valuable work to be done for future work or hidden away in Appendix. How can we start to work together beyond our research silos when the so-called AI is inevitably taking a more interdisciplinary direction? Do we hold researchers accountable for doing research experiments without proper user study, social study, and ethical study1?\nChain-of-thought\nTransclude of bai_#^81dd1a\nThere is no real “decision-making”, period. To me, the success of chain-of-thought prompting is the perfect evidence that those models don’t have the capability of “reasoning”. The fact we have to work our input around the model overlord shows how much human work is still required, but often understated.\nFootnotes\n\n\nOn the Dangers of Large Generative Models ↩\n\n\n"},"notes/20221218105910":{"title":"Slow and Deep Thinking","links":["highlights/Matter/I’m-a-very-slow-thinker","highlights/Readwise/31554997","highlights/Readwise/34276321"],"tags":[],"content":"Slow and Deep Thinking\nTransclude of I’m-a-very-slow-thinker\nWe don’t need to rush our conversations. By thinking slowly, we put more deliberation and thoughtfulness into our communication.\nIronically, being fast means sacrificing other qualities during the process1.\nAre we expecting immediate responses now that we have become accustomed to instant dopamine hits from social media? For the same reason we need Deep Work, we also need deep thinking in our conversations.\nFootnotes\n\n\nSame as Ever ↩\n\n\n"},"notes/20221218110643":{"title":"Natural Language Versus Code","links":["highlights/Matter/Notebook-on-nbviewer"],"tags":[],"content":"Natural Language Versus Code\nReference: AlphaCode\nThe encoder-decoder transformer and pretraining with large data were designed for natural language, where no rigid linguistic rules can directly apply. This is not the case for code. Some rules don’t change over different cultures, locations, or backgrounds.\nCoding challenges are often variations of a small subset of algorithms, but real-world problems are much more complex, especially when viewed end-to-end.\nWe need a better UX around interactions with large generative models that are embedded in various systems, which are constantly evolving. In a coding environment, a small change would impact the whole program. How can we design a system that can help adapt to such changes?"},"notes/20221219203111":{"title":"Abstract Meaning Representation","links":[],"tags":[],"content":"Abstract Meaning Representation\nSource: Abstract Meaning Representation - Wikipedia\nAMR is a semantic representation language that forms a DAG that is rooted and labeled. An example:\n# The body wants to go.\n(w / want-01\n\t:arg0 (b / boy)\n\t:arg1 (g / go-01\n\t\t:arg0 b\n\t)\n)\n\nThe goal of such representation is that similar sentences should have the same AMR.\n\nThis favors English language.\nIt requires a parser and is slow.\n\nAMR Metrics\nThe representation covers different semantic aspects that are called AMR metrics, allowing a finer depiction of semantic similarity, such as coreference, negation, entities, or events."},"notes/20221221125345":{"title":"Comfort VS. Fear","links":["highlights/Matter/Does-fear-control-you-","highlights/Matter/How-Our-Brains-Are---and-Aren’t---Like-Computers"],"tags":[],"content":"Comfort VS. Fear\nReference: Does fear control you?\nFear tricks us into thinking that comfort is more important than anything else. Taking no risk at all — staying in our comfort zone — is, on the contrary, the biggest risk we can take.\nDoes our brain reinforce our comfort zone as we get older1?\nFootnotes\n\n\nHow Our Brains Are - and Aren’t - Like Computers ↩\n\n\n"},"notes/20221221125831":{"title":"Information Transparency","links":["highlights/Matter/The-Dangers-of-Censoring-Real-Time-Flight-Trackers"],"tags":[],"content":"Information Transparency\nIt’s a double sword. On the one hand, transparent and free access to information allows us to fact-check statements from any source and hold them accountable. On the other hand, such information might violate people’s privacy1.\nBut it must not have to be mutually exclusive. Can we build a privacy-preserving information system to allow legitimate access while warding off bad actors? What are the possible ways to prevent data reverse-engineering? E.g. only a handful of people travel with private jets, so it should not be a difficult job to trace back their owners with all the public information (job locations and events).\nFootnotes\n\n\nThe Dangers of Censoring Real-Time Flight Trackers ↩\n\n\n"},"notes/20221221224451":{"title":"Random Ideas","links":[],"tags":[],"content":"Random Ideas\n#4: Accepting edits from your PI without understanding them🖍️ Critical feedback from your supervisor can feel discouraging but it really is an opportunity to learn. So, ask for the reasons of edits and rewrites so you can refine your writing skills one iterations at a time.— Anna Clemens, PhD (@scientistswrite) December 19, 2022\nHow can I incorporate the motivation/why into model training instead of just how (gradient update)?\nCan I train a model to predict answers for previous batches?\nMulti-modality (document images, text, locations), multipage, and multiscale (sections, paragraphs, sentences, words, characters) in one system.\nModel optimization compilation (different providers in ONNX, deepsparse, triton, Intel etc.)\nAn NER dataset for books, authors, links, relations\nIf there is anything pre-trained large language models can teach me, I think it is the importance of reading, a lot of reading.\nA visual and interactive regex builder by highlighting text you want to extract and the level of granularity you intend to achieve."},"notes/20221222133828":{"title":"Decomposing Embeddings","links":["highlights/Zotero/opitz_2022"],"tags":[],"content":"Decomposing Embeddings\nReference: opitz_2022\nWhen using something like SentenceTransformers, you usually get one vector for the whole input. You don’t really have a clue what it means when comparing two embeddings and the only result you get is a single number.\nAuthors in opitz_2022Abstract Meaning Representation (AMR)]], so one could measure differences in various aspects of semantic similarity.\nSome aspects included are:\n\nFrames: AMR graph similarity regarding PropBank predicates.\nNamed entity: AMR graph similarity regarding named entities.\nNegation: AMR graph similarity based on expressions of negation.\nConcepts: AMR graph similarity based only on AMR node labels.\nCo-reference: AMR graph similarity based on co-referent structures.\nSemantic role labeling: AMR graph similarity based on predicate substructures.\nUnlabeled: AMR graph similarity without semantic edge labels.\nQuantifier: AMR graph similarity based on quantifier structures.\n\nTo summarize the training process:\n\nUse an AMR parser to acquire AMR graphs for a pair of input.\nTrain a model to model different similarities from the AMR oracle similarities with decomposed embeddings (explainability), while minimizing the difference between the overall similarities with a frozen sentence transformer (consistency).\n\nThere is no need for an AMR parser during inference."},"notes/20221222135352":{"title":"Call It What It Is","links":["highlights/Matter/Empty-Pointers-and-Constellations-of-AI","highlights/Zotero/shanahan_2022"],"tags":[],"content":"Call It What It Is\nAI is an umbrella term that we constantly add new things that we don’t understand and remove old things as soon as we find them less attractive. Empty Pointers and Constellations of AI\nUsing philosophically loaded words such as “know”, “understand”, “answer”, “think”, and “hallucinate” when describing a model1, and allowing it to synthesize sentences beginning with “I” take advantage of our tendency to familiarize/humanize and make sense of things.\nWe should refrain from using those terms before the public has common knowledge about how those models work2.\nGetting good results on some benchmarks, or responding well to some magic prompts offers too much temptation to assume human-like reasoning capabilities3.\nFootnotes\n\n\n^fde4aa ↩\n\n\n^19859b ↩\n\n\nTalking About Large Language Models ↩\n\n\n"},"notes/20221222150525":{"title":"Language and Its Context","links":["highlights/Zotero/shanahan_2022","notes/20220904143432","highlights/Matter/How-Human-Language-Is,-and-Isn’t,-Like-a-Computer-Program"],"tags":[],"content":"Language and Its Context\nReference:\n\n\nTalking About Large Language Models\n\n\nForm, Meaning, and Communicative Intents\n\n\nHow Human Language Is, and Isn’t, Like a Computer Program\n\n\nIt is social and collective\n\n\nIt is interactive\n\n\nIt has communicative intent\n\n\nIt has nuances and implications\n\n"},"notes/20221222150827":{"title":"Language Generation","links":["notes/20221222135352","highlights/Zotero/shanahan_2022"],"tags":[],"content":"Language Generation\nCurrent text generation is one very specific type of sampling: Given a piece of text, based on the training data statistics, what is the most likely continuation1?\nCalling the model’s generation with words like “answer”, “reply”, or “respond” is overly anthropomorphic (Call It What It isAnthropomorphizing AI]]).\nEven if the model is more aligned with human values (e.g., reinforcement learning), it does not change the nature of the generation1.\nFootnotes\n\n\nTalking About Large Language Models ↩ ↩2\n\n\n"},"notes/20221224153623":{"title":"Risk and Fear","links":["highlights/Matter/How-to-Pick-a-Career-(That-Actually-Fits-You)","highlights/Matter/Staring-into-the-abyss-as-a-core-life-skill","notes/20220604131222","highlights/Matter/3-2-1--Happiness,-the-value-of-risk,-and-the-importance-of-ambition-in-poetry-(and-in-life)","highlights/Matter/Life-is-what-happens-while-you're-making-other-plans"],"tags":[],"content":"Risk and Fear\nRisk and fear are crucial components in our personal growth, the lack of which creates a bubble filled with boredom that gives us a false sense of security1.\nTransclude of How-to-Pick-a-Career-(That-Actually-Fits-You)#^28fcb5\nCall it whatever you want, staring into the abyssimagining the worst]], facing the problem, facing the unpleasant2, or getting out of our comfort zone; what is important is that we need to make conscious steps to build a virtuous loop by taking the risk:\n\nAcknowledge the current situation and issues. We might realize that we have wasted too much time working on a terrible project, being in a bad relationship, or keep making career choices we know you don’t like. We might also realize that we have been procrastinating to think about it for a long time, mostly because that would deplete our mental energy already running low.\nMake time and think about it. Some good questions that can help you get some inner clarity on those questions3 :\n\nIf you had to leave your job today, what would you do instead? What’s the best argument in favour of doing that right now?\nIf you have a partner, what’s the best argument in favour of breaking up with them?\nAre there ways you behave that you wish you didn’t? What unacknowledged desires could be driving those?\nWhat have you said “yes” to that you wouldn’t say “hell yes” to?\nIs there something you “should” do that you’re not currently doing? Why?\nWhat bad things are you afraid of happening? Imagine in detail what it would be like if they happened.\nWhat do you need that you’re not currently getting?\nWhat are you avoiding because it conflicts with some part of your identity/self-image?\nWhat is the biggest thing in your life that you just kind of casually fell into, and would you have made a conscious decision to do it if you’d known in advance everything you know now?\n\n\nAct. (Premeditatio Malorum)\n\nTransclude of How-to-Pick-a-Career-(That-Actually-Fits-You)#^d6d23e\nBe aware of the percentage of risk-taking activities you make in your life. You want to avoid spending all your time contemplating every decision you make, but you also don’t want to live a life without any depth.\nFootnotes\n\n\n3-2-1- Happiness, the value of risk, and the importance of ambition in poetry (and in life) ↩\n\n\nLife is what happens while you’re making other plans ↩\n\n\nStaring into the abyss as a core life skill ↩\n\n\n"},"notes/20221231135246":{"title":"Lovelace Test","links":["notes/20221231140035","highlights/Zotero/riedl_2014"],"tags":[],"content":"Lovelace Test\nThe Lovelace Test is a test designed for Computational Creativity. The test covers three criterions:\n\nAn agent a, designed by a human h, outputs o;\nSuch outputting process can be repeated constantly;\nA judge (h or someone with equal knowledge) cannot explain how a produced o;\n\nLovelace Test 2.0\nProposed in riedl_2014, it follows:\n\nAn agent a, designed by a human h, outputs o of type t (music, painting, writing etc.);\no must conform to a set of constraints C, each of which is expressed in natural language;\nHaving chosen t and C, a human evaluator h is satisfied that o is a valid instance of t that meets C. (There is an element of surprise when the agent passes, since the evaluator has been given the chance to device C to disprove the intelligence)\nA human referee r (expert in t) determines that the combination of t and C is realistic within average human abilities.\n\nYou can repeat the test with more or harder constraints to test its limits. There is no absolute threshold or stop in the testing that certifies intelligence, but it offers us the lens through which we can compare different agents quantitatively."},"notes/20221231140035":{"title":"Computational Creativity","links":["highlights/Zotero/riedl_2014"],"tags":[],"content":"Computational Creativity\nThe manifestation of art, science, philosophy, and engineering by a computational system that unbiased observers would deem creative1.\nFootnotes\n\n\n^da69c1 ↩\n\n\n"},"notes/20230101110239":{"title":"Overconfidence","links":["highlights/Matter/The-Myth-of-the-Secret-Genius","highlights/Readwise/31554987","highlights/Matter/How-Our-Brains-Are---and-Aren’t---Like-Computers","notes/20221221125345"],"tags":[],"content":"Overconfidence\nHow can we evaluate models based on merits?\nPeople favor overconfidence due to a concept known as evolutionary mismatch12. This also explains why we are seeing more and more hyped model releases, which potentially in return attract more funding for them in the future.\nIt is also shown that, in addition to sexism, men are more willing to become avid users of such over-confident language1.\nIf a higher score on an IQ test means more likely to fall for stereotypes3, how can we escape? Can we fight against our blindness to our weaknesses? Does this relate to the aging of our brain4 5?\nFootnotes\n\n\nThe Myth of the Secret Genius ↩ ↩2\n\n\nThe evolution of overconfidence | Nature ↩\n\n\nThink Again ↩\n\n\nHow Our Brains Are - and Aren’t - Like Computers ↩\n\n\nComfort VS. Fear ↩\n\n\n"},"notes/20230101111708":{"title":"The Dictator Trap","links":["highlights/Matter/The-Myth-of-the-Secret-Genius","highlights/Readwise/31554987","notes/20220730160038"],"tags":[],"content":"The Dictator Trap\nReferences:\n\nThe Myth of the Secret Genius\nThink Again\n\nThe Dictator Trap, or similarly Confirmation BiasAdoption Bias]] can lead to a downward spiral."},"notes/20230103200723":{"title":"Content Replication","links":["highlights/Zotero/somepalli_2022"],"tags":[],"content":"Content Replication\nSource: Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models\nContent replication refers to the reproduction of training content, often with complete verbatim information or minor modification. Such replication has implications both ethically and legally because it is unclear for now how those generated content can be considered fair use or stealing. The lack of attribution from the model also makes it more problematic.\nOther contributing factors include large data collection, mismatched with little data curation oversight and analysis, as well as memorizing abilities (overfitting) present in large models1.\nIt is found that models trained on small datasets are more likely to regurgitate training data than large models. However, this is unlikely an exemption for blindless scaling because the method used in @somepalli_20222 has its limitations.\nFootnotes\n\n\nDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models ↩\n\n\nDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models ↩\n\n\n"},"notes/20230107110819":{"title":"Ethical Considerations for Artificial Intelligence Applications","links":["notes/20230107135810","notes/20230107141241","notes/20230107143218","notes/20230108125601","notes/20220925095941"],"tags":[],"content":"Ethical Considerations for Artificial Intelligence Applications\nTo meaningfully engage in ethical conversations regarding AI applications, it is important to understand a few ethical frameworks, such as ConsequentialismUtilitarianism]], such that we can approach problems in a more systematic way.\nWhen discussing autonomous application deployment, it is critical to maintain the chain of command, e.g., Attribution of Responsibility, where a human can be held accountable for their decisions and actions.\nWe yet to have a satisfactory answer to all the questions involved, but we should nonetheless commit enough efforts for our due diligence. On the plus, we do have some concepts we can apply during the discussion, such as Informed ConsentMeaningful Human Control]] for different domains like medicine or autonomous weapon systems.\nEthical topics:\n\nPrivacy and data protection;\nDomain expertise;\nTransparency and explainability;\nCost and benefits, which are often measured in terms of money values, but in reality the values cannot be directly measured, especially social and moral values in different contexts and cultures. Problems such as GreenwashingEthical Hacking]] can arise when implementation isn’t transparent.\n\nAbove are useful questions to ask when deploying AI applications, but when deciding to build one, a different set of questions can be asked in stead (Ethical Questions to Ask in AI)."},"notes/20230107135810":{"title":"Consequentialism","links":["notes/20230107140307"],"tags":[],"content":"Consequentialism\nAn ethical framework where actions and decisions are judged by the consequences. To judge the consequences to be morally good or bad, we can take different evaluation frameworks, one of which is Utilitarianism."},"notes/20230107140307":{"title":"Utilitarianism","links":[],"tags":[],"content":"Utilitarianism\nA utilitarian ethical framework would judge the consequences of an action or decision by whether it leads to the greatest amount of happiness for the highest number of people."},"notes/20230107140411":{"title":"Duty Ethics","links":["notes/20230107135810"],"tags":[],"content":"Duty Ethics\nA.k.a. deontological ethics. A framework where actions and decisions are evaluated based on whether they agree with certain moral rules, regardless of the consequences (Consequentialism)."},"notes/20230107141241":{"title":"Attribution of Responsibility","links":["notes/20230107140411"],"tags":[],"content":"Attribution of Responsibility\nAttribution of Responsibility questions who should take responsibility in the case of damages and harms to people or goods. This is an important factor in an ethic conversation, regardless of the frameworks (Duty EthicsConsequentialism]]).\nThe rapid development in autonomous applications only makes it harder to answer such question because such autonomous intelligence cuts off the command chain, independent of any human intervention or control based on the Duty EthicsOn the Dangers of Large Generative Models]]Meaningful Human Control]] has been proposed here to remedy such dilemma."},"notes/20230107142551":{"title":"Meaningful Human Control","links":[],"tags":[],"content":"Meaningful Human Control\nHuman controllers should have enough time and information to intervene on the autonomous systems, to sustain the command chain, and to take on the responsibility of any actions or decisions as an embodied agent.\nHowever, this prioritizes the regulations (what should we do with such systems) over definitions (why and how should we design such systems)."},"notes/20230107143218":{"title":"Informed Consent","links":["highlights/Matter/A-tale-of-fucking-around,-finding-out,-and-why-..."],"tags":[],"content":"Informed Consent\nIt is a specific principle in medical ethics, medical law and media studies — a patient must have sufficient information and understanding before making decisions about their medical care. However, this is challenged in the Big Data era because new information can be inferred in ways that traditional informed consenters did not expect.\nHowever, in some cases, incomplete disclosure or some form of deception is required. In this case, the researchers have the responsibility to ensure it is justified and people’s rights are protected. Often, a rigorous ethical review is required1.\nFootnotes\n\n\nA tale of fucking around ↩\n\n\n"},"notes/20230108125601":{"title":"Greenwashing","links":[],"tags":[],"content":"Greenwashing\nPositively influencing public opinion, but failing short in actions or implementations."},"notes/20230108125736":{"title":"Ethical Hacking","links":["notes/20230107143218"],"tags":[],"content":"Ethical Hacking\nHacking, a form of violation of cybersecurity, with a pro-social goal.\nCommon goals used by ethical hacking advocates:\nInformation Should Be Free, without Cost and without Restriction\nCounterargument: If everything is free, there wouldn’t be any market for information, and therefore no motivation of information production.\nIt Reveals System Vulnerabilities\nCounterargument: There are proper ways for this (e.g., pen testing) with Informed Consent.\nNo Harm is Done\nCounterargument: The violation of privacy can be dangerous by itself.\nIt Reveals Unethical Abuses, Usually From the Government\nCounterargument: Yes, it might, but is this the only resort?"},"notes/20230110192706":{"title":"Reverse Outlining","links":["highlights/Matter/Reverse-Outlining-with-Language-Models","notes/20220705214840","notes/20220717122151"],"tags":[],"content":"Reverse Outlining\nReference: Reverse Outlining with Language Models\nA chaotic first draft seems like a bridge from a blank page to How to Write a Paper with Zettelkasten. Such a draft builds a temporary slip box where you can work with sentence or paragraph blocks.\nNaturally, with a real zettelkasten, you never Starting from Scratch, meaning even a chaotic draft would come from notes in your note-taking system, evening out the cognitive burden of brainstorming or drafting into note-taking on a daily basis."},"notes/20230114155552":{"title":"Ethical Issues with AI Art","links":["notes/20230107143218","highlights/Matter/Popular-discourse-about-AI-generated-art-is-fol...","20221210185344","highlights/Zotero/somepalli_2022","highlights/Matter/The-Alt-Right-Manipulated-My-Comic.-Then-A.I.-Claimed-It."],"tags":[],"content":"Ethical Issues with AI Art\nQuestions like “which is by a human and which is by a model” are missing the point. The framing of these questions are equating the artistic expression and desire behind the work to nothing. A better question to ask would be “which is by a human who has desires to communicate, to express, and to inspire and which is by a model trained on data gathered without Informed Consent with a goal to synthesis without proper attribution”1.\nAs with other generative models2, the process of generation, though seemingly impressive, is largely uncontrollable and unreliable in terms of data replication3 and attribution4 with a plethora of issues in other aspects2.\nFootnotes\n\n\nPopular discourse about AI-generated art is fol… ↩\n\n\nOn the Dangers of Large Generative Models ↩ ↩2\n\n\nDiffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models ↩\n\n\nThe Alt-Right Manipulated My Comic. Then A.I. Claimed It. ↩\n\n\n"},"notes/20230114195045":{"title":"Authorship","links":["highlights/Matter/Scientists,-please-don’t-let-your-chatbots-grow-up-to-be-co-authors"],"tags":[],"content":"Authorship\n\nGenerative models are tools. The same reason we don’t credit Python for all the models we built, or all the grammar mistakes fixed by Grammarly, we should not credit a writing assistant1.\nAdditionally, they do not have the scientific skill sets to reliably contribute to the paper in any meaningful way. If you think the contribution is “significant” to any extent, then it is basically telling reviewers and readers that the paper is worthless1.\nIt is really problematic and concerning to credit a tool when it cannot even credit properly for its generation.\n\nFootnotes\n\n\nScientists, please don’t let your chatbots grow up to be co-authors ↩ ↩2\n\n\n"},"notes/20230114200605":{"title":"Bitter Lessons in X Engineering","links":["highlights/Matter/What-Makes-a-Senior-Engineer--Writing-Software-vs-Building-Systems","highlights/Matter/Things-they-didn't-teach-you-about-Software-Engineering"],"tags":[],"content":"Bitter Lessons in X Engineering\nLet X be software, machine learning, or data.\nIt involves a lot more things than coding. It could be dealing with data and numbers to figure out patterns and features. Moreover, it could be writing documentation and PRDs. Likewise, it could be spending hours in meetings just to figure out what our dear PMs want1. And the impact or value you create can also extend beyond the code you produce2.\nDocument it when you can and when you can remember. You will thank yourself later2.\nCommunication is rarely clear from the get-go. It is your job to disentangle it2.\nMeetings are part of the job, so start to treat it like a coding challenge and learn how to make it more efficient and productive2.\nFootnotes\n\n\nWhat Makes a Senior Engineer? Writing Software vs Building Systems ↩\n\n\nThings they didn’t teach you about Software Engineering ↩ ↩2 ↩3 ↩4\n\n\n"},"notes/20230115134319":{"title":"Pastiche","links":["notes/20230114155552","highlights/Matter/Transcript--Ezra-Klein-Interviews-Gary-Marcus"],"tags":[],"content":"Pastiche\nSynthesizing things together in a style that imitates that of other artists or work.1\nThis word might still give too much credit to a model when talking about AI Art as the model has no intention to imitate in the first place. There should be a word that describes such generation/synthesis, or be created, so that the general audience can have a better understanding of what is happening behind the curtain, and AI-bros can be disillusioned with the idea that we are on the right track of AGI.\nFootnotes\n\n\nTranscript: Ezra Klein Interviews Gary Marcus ↩\n\n\n"},"notes/20230115161911":{"title":"Bullshit","links":["highlights/Matter/Transcript--Ezra-Klein-Interviews-Gary-Marcus","highlights/Matter/ChatGPT-sometimes-makes-up-facts.-For-one-law-prof,-it-went-too-far."],"tags":[],"content":"Bullshit\n\nFor the essence of bullshit is not that it is false but that it isphony. In order to appreciate this distinction, one must recognize that a fake or a phony need not be in any respect (apart from authenticity itself) inferior to the real thing. What is not genuine need not also be defective in some other way. It may be, after all, an exact copy. What is wrong with a counterfeit is not what it is like, but how it was made. This points to a similar and fundamental aspect of the essential nature of bullshit: although it is produced without concern with the truth, it need not be false. The bullshitter is faking things. But this does not mean that he necessarily gets them wrong.\n— On Bullshit by Harry Frankfurt\n\nBullshit isn’t about a statement being true or false. Unlike a lie that often goes the opposite way of the truth, bullshit goes around regardless of the truth. What makes it dangerous is that you can learn something from negative examples (lies), but not from the complete chaos and noise.\nWhat is even more dangerous is that, similar to lies, they can mislead people with seemingly correct information, as is the case with Transcript: Ezra Klein Interviews Gary Marcus. And when the bullshit is coincidentally false1, the company behind such misinformation faces no punishment whatsoever.\nFootnotes\n\n\nChatGPT sometimes makes up facts. For one law prof ↩\n\n\n"},"notes/20230116094835":{"title":"Modeling Beliefs and Communicative Intents","links":["notes/20220904143432","notes/20221120094433","highlights/Zotero/andreas_2022","highlights/Matter/Google-AI-Blog--Google-Research,-2022--and--Beyond--Language,-Vision-and-Generative-Models","highlights/Matter/Large-Language-Model--world-models-or-surface-statistics-"],"tags":[],"content":"Modeling Beliefs and Communicative Intents\nTu understood how models are modeling beliefs and Communicative Intents, we need to define those terms first with a framework proposed by Bratman in 19871.\n\nAn agent, usually an intellectual being, has a set of beliefs B regarding the world — a Cognitive Model.\nSuch agent also has some desires D.\nCombined, desires and beliefs form communicative intents I∼Pintention​(⋅∣B,D), and as a result, an utterance U∼Putterance​(⋅∣I)is produced and observed, interacting with the environment.\nThe interaction, in return, informs and updates the mental world model.\n\nThis is kind of a rebuttal to Form, Meaning, and Communicative Intents where it is argued that no communicative intents can be learned because they are not present in the datasets, but here it is saying that it is possible, even without explicitly trained to do so.\nThe main argument of this stance is that: Multiple studies have found that without explicitly training for intents or beliefs, including the sketch experiment in the paper, neural networks do capture some narrow aspects of them2 3 4 5. Because for an effective LM, it must learn to maintain the constraints based on the abovementioned framework to generate coherent text, both in terms of beliefs and communicative intents.\nHowever, such modeling is very narrow and restricted in its applicability and reliability. To achieve a better “understanding”, we need a paradigm shift to overcome the current limitation of model architectures, and to understand those models better6.\nQuestion: is it sufficient for a model to “learn” all things about “This is different from That” without understanding truth and falsity?\nFootnotes\n\n\nLanguage Models as Agent Models ↩\n\n\nLanguage Models as Agent Models ↩\n\n\nLanguage Models as Agent Models ↩\n\n\nGoogle AI Blog: Google Research ↩\n\n\nLarge Language Model: world models or surface statistics? ↩\n\n\nLanguage Models as Agent Models ↩\n\n\n"},"notes/20230123141334":{"title":"Being Ready","links":["highlights/Matter/3-2-1--One-of-the-most-valuable-skills-in-life,-and-starting-before-you-feel-ready","highlights/Matter/3-2-1--Why-small-things-matter,-reframing-failure,-and-how-to-cherish-life","notes/20221224153623","highlights/Matter/What-if-you-never-sort-your-life-out-","highlights/Matter/Repair-and-Remain"],"tags":[],"content":"Being Ready\nLife doesn’t support do-over. People who make resolutions on New Year’s Day don’t really get a fresh start. Life moves on constantly when you are not ready most of the time.\nTransclude of 3-2-1--One-of-the-most-valuable-skills-in-life,-and-starting-before-you-feel-ready#^b13b9e\nTransclude of 3-2-1--Why-small-things-matter,-reframing-failure,-and-how-to-cherish-life#^99b56a\nHow can we move forward being unprepared? Accept the fact that we will never be ready, and work with what we’ve got1. The same applies to building software — it will never be perfect. What matters, in the end, is that you ship continuously and incrementally.\nCertainly, there is this fearWhat if you never sort your life out?]]\nEven worse, we never know if our demise is around the corner. We don’t need a near-death experience to tell us that we still have time to prepare, to worry, and to care too much.\nTransclude of What-if-you-never-sort-your-life-out-#^943d7f\nFootnotes\n\n\nRepair and Remain ↩\n\n\n"},"notes/20230123142700":{"title":"The Rat Race","links":["highlights/Matter/Quitting-the-Rat-Race"],"tags":[],"content":"The Rat Race\nThere is a similar concept called Involution, started circa 2020 in China, which is often used to describe a toxic work environment filled with meaningless competitions.\nBeing an engineer in the tech industry, this feeling of insignificance and lack of fulfillment are particularly common. People are talking about Quitting the Rat Race, or lying flat1. But if everyone is busying participating in the rat race or busying lying flat, who can we trust to question the system or to revolutionize the game?\nFootnotes\n\n\n躺平 - 维基百科，自由的百科全书 ↩\n\n\n"},"notes/20230123164614":{"title":"AI is Beyond Computer Science","links":["highlights/Matter/AGI-will-not-happen-in-your-lifetime.-Or-will-it-","highlights/Matter/How-do-engineers-show-up-at-work-every-day-and-...","highlights/Zotero/raji_2021"],"tags":[],"content":"AI is Beyond Computer Science\n\nIt is hard to say where they have gone wronger, in underestimating language or overestimating computer programs.\nArtificial Intelligence Meets Natural Stupidity, Drew McDermott\n\nIf the end goal of an AI is to serve humans, then the first order of the business should be to understand humans. To understand humans, you cannot limit your view to only a few lenses from Computer Science, which, to be frank, focuses more on machines than humans. Similarly, CS majors should not be the sole governor or arbitrator of such a system when humanity is at stake1 2.\nIt is eerily unsettling that people want to build models solely from large data as badly as they want a solution to solve all problems purely from a computational approach. It already starts to show that the current CS curriculum is insufficient in terms of ethical and moral education3, and other fields, just as Computer Science, including the funds behind them, are not as diversified as they should be.\nFootnotes\n\n\nAGI will not happen in your lifetime. Or will it? ↩\n\n\nHow do engineers show up at work every day and … ↩\n\n\nYou Can’t Sit With Us: Exclusionary Pedagogy in AI Ethics Education ↩\n\n\n"},"notes/20230204204716":{"title":"IQ Test","links":["highlights/Matter/Nick-Bostrom,-Longtermism,-and-the-Eternal-Return-of-Eugenics"],"tags":[],"content":"IQ Test\nThe idea of condensing a person’s intellectual capacity into a single number is problematic, to say the least. It was popularized largely by 20th-century eugenicists and often cited as “scientific proof” to exclude and marginalize non-white communities1.\nEven what was perceived as philanthropic acts can stem from problematic eugenic beliefs — Effective Altruism is a perfect example.\nFootnotes\n\n\nNick Bostrom, Longtermism, and the Eternal Return of Eugenics ↩\n\n\n"},"notes/20230204210347":{"title":"Life is a Video Game","links":["highlights/Matter/Life-Is-a-Video-Game-Here-Are-the-Cheat-Codes","notes/20221224153623"],"tags":[],"content":"Life is a Video Game\nReference: Life Is a Video Game-Here Are the Cheat Codes\nIt is a never-ending battle with problems, either from other people or from ourselves. It is the solving of the difficulties that gives us meaning.\nIn the face of the problem, we can either solve it or avoid it. Only when we are directly confronting it — the Risk and Fear in our life, can we upgrade to the next level.\nStop complaining. It is neither constructive nor meaningful. It keeps us stranded in despair.\nPlay the game means not only find a solution to some problem, but it also means we need a big picture, a strategy that charts our directions, which should be rooted in our"},"notes/20230205125210":{"title":"Being Human","links":["highlights/Matter/The-Expanding-Dark-Forest-and-Generative-AI","highlights/Matter/In-the-Age-of-A.I.,-Major-in-Being-Human","notes/20221127140633","highlights/Matter/Human-like-programs-abuse-our-empathy---even-Google-engineers-aren’t-immune","highlights/Matter/OpenAI-discontinues-its-AI-writing-detector-due-to-“low-rate-of-accuracy”","highlights/Omnivore/20240209182438","highlights/Matter/Google-shattered-human-connection","notes/20230720210314"],"tags":[],"content":"Being Human\nIn the expanding Dark Forest of the Internet, generative AIs can easily create waves of profit-oriented content that conceals the truth and genuine desires for human connections. Thus, it is important to remain, reinforce, and boost signals of our humanity and to be on the lookout for that of other people1.\nIn the Age of A.I., Major in Being Human outlines several core aspects that we should pay attention to when fostering our unique humanness:\n\nDevelop a unique voice through Reading and Writing. Some models can indeed copy a writing or drawing style, but they can never copy our minds, our personal experiences, and the unique perspectives that go into our writing. It is also true that such uniqueness shapes our situational awareness and decision-making process2.\nDevelop a strategic mindset that transcends a single task. Models can do some tasks reasonably well, but they never understand the life goals we would have when tackling problems. In the article, presentation skill is one example. When giving a speech on a certain topic, our goal isn’t simply to talk through some slides. Instead, we communicate with the audience in a shared context. It requires much planning and engagement that no modern-day models can complete independently.\nDevelop empathy. Not everything has to be pragmatically computational. Humanities proliferate in domains beyond computer science, like literature, drama, biography, and history. But be careful, Human-like programs abuse our empathy - even Google engineers aren’t immune.\n\nIt is also important to understand both the limitations of current AI systems and the meaning of human authorship and connection3 4 5, and resist succumbing to the pervasive popularisation of AI use6.\nFootnotes\n\n\nOpenAI discontinues its AI writing detector due to “low rate of accuracy” ↩\n\n\nThe Expanding Dark Forest and Generative AI ↩\n\n\nHere’s the Thing AI Just Can’t Do | WIRED ↩\n\n\nGoogle shattered human connection ↩\n\n\nConnection Engine ↩\n\n\nImportance of Reading and Writing ↩\n\n\n"},"notes/20230205133514":{"title":"Vigilance","links":["highlights/Matter/The-CNET-Fake-News-Fiasco,-Autopilot,-and-the-Uncanny-Cognitive-Valley"],"tags":[],"content":"Vigilance\nA cognitive term to describe people’s attention for long periods of time. It has shown that it starts to dwindle after half an hour1.\nIn the case of assisted driving systems, Google learned that human-in-the-loop cannot be trusted as people’s attention will eventually wander, and they tend to trust systems too quickly and too easily. That’s why they moved away from assistant driving to human-free driving1.\nFootnotes\n\n\nThe CNET Fake News Fiasco, Autopilot, and the Uncanny Cognitive Valley ↩ ↩2\n\n\n"},"notes/20230205135315":{"title":"Data Sovereignty","links":["highlights/Matter/OpenAI's-Whisper-is-another-case-study-in-Colonisation"],"tags":[],"content":"Data Sovereignty\nReference: OpenAI’s Whisper is another case study in Colonisation\nData sovereignty refers to the rights and practices regarding data collection, data usage, and data governance. It asks the following questions when concerning data:\n\nWhy do you need this;\nWhere is the data collected from;\nHow is the data accessed;\nWhat license or right do you have to create derivatives;\nWhat license or right do you have to collect the data;\nWhat are the consequences of such data collection;\nWhat are the consequences of such derivatives;\nWho will benefit from the data/derivates and who it will harm;\nWhat expertise or stake do you have in the specific data domain;\nWhat metrics do you use for quality assessment;\nWhat is the strategy for safety monitoring, damage control, and error correction;\nWho should be responsible;\nWhat community are you building this for;\nWhat voices or opinions have you heard from those communities;\nWhat license will the data/model be released under;\nWhat do you know about the content creator;\nWhere is the data stored;\nWhat is the cost of the process;\nHow much respect do you have for the data, and the culture and the people behind it;\n\nOpenAI&#039;s-Whisper-is-another-case-study-in-Colonisation#^7cc4eb"},"notes/20230212184912":{"title":"Optimizing For Feelings","links":["highlights/Matter/Optimizing-For-Feelings"],"tags":[],"content":"Optimizing For Feelings\nReference: Optimizing For Feelings\nIn the absence of metrics and benchmarks, it is best to focus on feelings when building things — feelings of your own and feelings of your audience.\nSimilar to how we seek resonance when we build our second brain, we seek the connection and mutual understanding of a question from both sides. Even though much of the building is influenced by profit-driven decisions, we should always be prepared to ask difficult questions regarding those choices."},"notes/20230212190751":{"title":"The Model Centipede","links":["highlights/Matter/The-Expanding-Dark-Forest-and-Generative-AI","highlights/Matter/AI-Will-Soon-Make-Social-Media-Much-More-Harmful-to-Liberal-Democracy,-and-to-Children","highlights/Matter/ChatGPT--Beware-the-Self-Serving-AI-Editor"],"tags":[],"content":"The Model Centipede\nBased on an idea mentioned in The Expanding Dark Forest and Generative AIPluralistic: The Coprophagic AI crisis (14 Mar 2024) – Pluralistic: Daily links from Cory Doctorow]].\nIt’s not just about information that is wrong, but also information that’s too generic to be useful or trustworthy1. Some companies might train the model to avoid criticizing themselves, based on either unintentional bias throughout the process or conscious efforts to stay away from bad publicity.\nRelated:\nAI Will Soon Make Social Media Much More Harmful to Liberal Democracy\nFootnotes\n\n\nChatGPT- Beware the Self-Serving AI Editor ↩\n\n\n"},"notes/20230212204146":{"title":"AI Democratization","links":["highlights/Matter/What-Do-We-Mean-When-We-Talk-About-“AI-Democratisation”-","highlights/Omnivore/20240223191650","notes/20230307200456","highlights/Readwise/34911496","highlights/Omnivore/20240220130000"],"tags":[],"content":"AI Democratization\nReference: What Do We Mean When We Talk About “AI Democratisation”?\nUse\nThis is often the default case when people talk about democratizing AI: people, developers or not, can use such models or services, with paid API access.\nBut this use-case is also the most hyped in marketing, where the word implicitly becomes a synonym of capitalization. The underlying assumption for this type of democratisation is that you have enough resources to afford such use, and knowledge and access to such APIs or compute in the first place1.\nFuthermore, labor can be displaced or taken advantage of by such prevail use while having no oppotunity to say no or catch up2 3.\nDevelopment\nHaving access to the design and development processes of a model.\nBenefits\nDistributing benefits or profits generated by AI products more equitably.\nGovernance\nDistributing influence over model-related decisions to a broader community of stakeholders.\nBut strangely, the responsibility and enforcement are frequently overlooked and understated. The governance is often limited to the ones who enjoy the riches and are kind enough to pretend to worry about some distant future doomsday risks4.\nFootnotes\n\n\nDemocratisation of AI is an illusion | by Dr Vaishak Belle | Feb, 2024 | Medium ↩\n\n\nA New Definition of Luddism ↩\n\n\nEgo, Fear and Money: How the A.I. Fuse Was Lit ↩\n\n\nThe Skilled Workers Training AI to Take Their Jobs | WIRED ↩\n\n\n"},"notes/20230219155722":{"title":"Life Momentum","links":["highlights/Matter/3-2-1--Momentum,-how-to-be-the-best,-and-the-source-of-inspiration","notes/20221224153623"],"tags":[],"content":"Life Momentum\nReference: 3-2-1- Momentum, how to be the best, and the source of inspiration\n\n“Momentum goes both ways. Don’t move, feel sluggish. Start moving, feel like moving a little more. Don’t talk, feel timid. Start chatting, conversation gets a little easier. Don’t ship, feel stuck. Start creating, ideas begin to flow.”\n— James Clear\n\nThat’s another reason we need to fight Risk and Fear — to have the right momentum in our lives."},"notes/20230226150428":{"title":"Prompt Engineering","links":["highlights/Matter/Prompt-Engineering-Shouldn't-Exist","highlights/Matter/Meet-ChatGPT’s-evil-twin,-DAN","highlights/Matter/Hackaday-Newsletter-0x66"],"tags":[],"content":"Prompt Engineering\nPrompts are text input that are often used to prime models to perform certain tasks. Prompt engineering describes the designing process of effective prompts. Malicious instructions are also frequently referred to as prompt hacking or prompt injection.\nWhether Prompt Engineering Shouldn’t Exist or not, there will always be people trying to circumvent content filters and rudimentary guardrails1 2 and they will likely succeed if they are built as an afterthought. Therefore, those hacks will coexist and co-evolve with those models if this is the direction we take, willingly or not.\nFootnotes\n\n\nMeet ChatGPT’s evil twin, DAN ↩\n\n\nSecurity in Genearative AI ↩\n\n\n"},"notes/20230305134742":{"title":"Copyright of Synthetic Media","links":["notes/20230114195045","highlights/Matter/The-US-Copyright-Office-says-you-can’t-copyright-Midjourney-AI-generated-images","notes/20230114155552"],"tags":[],"content":"Copyright of Synthetic Media\nAI models cannot bear Human Authorship1, and their generations cannot be copyrighted.\nThe problem is that the training data is typically unethically collected, and the generation process can potentially regurgitate training elements without any attribution to the original content creators2. It will be much more difficult to claim copyright when you can’t efficiently check for plagiarism or trace the source of “inspiration”. It also burdens the users to prove their human efforts that went into generation1.\nFootnotes\n\n\nThe US Copyright Office says you can’t copyright Midjourney AI-generated images ↩ ↩2\n\n\nEthical Issues with AI Art ↩\n\n\n"},"notes/20230305142934":{"title":"Anthropomorphizing AI","links":["highlights/Readwise/35084810","notes/20230226150428","highlights/Matter/On-AI-Anthropomorphism","highlights/Matter/Don’t-Go-Breaking-My-Heart","highlights/Omnivore/20240309231109","highlights/Matter/People-keep-anthropomorphizing-AI.-Here’s-why","highlights/Readwise/34772815","highlights/Matter/The-DAIR-Institute","highlights/Matter/The-new-Bing-is-acting-all-weird-and-creepy---but-the-human-response-is-way-scarier","highlights/Matter/The-Luring-Test--AI-and-the-engineering-of-consumer-trust","highlights/Omnivore/20240204111406"],"tags":[],"content":"Anthropomorphizing AI\nAutoregressive generative models are getting better at producing fluent text every day. This might be helpful in some use cases, but their emotions are no more real1.\nThe chat interface and the human-like ability to wield language are taking advantage of our tendency to trust (a.k.a hidden exploitation)2. To trust the model behind the interface, to trust the company behind the service, and to trust the decision-makers behind the curtains.\nMaking the generated text more humanlike has nothing to do with the search tasks. But we also don’t know if this is caused by careful design or lack thereof (AI and Trust).\n\nWork on synthetic human behaviour is a bright line in ethical AI development, where downstream effects need to be understood and modelled in order to block foreseeable harm to society and different social groups.\n— @bender_2021\n\nOnly when we take a step back in anthropomorphizing models can we reckon with real functionalities of those models3.\nI always wonder why most voice assistants haven’t really picked up any “personality” over the decade. Maybe there are some lessons learned in that community that haven’t been propagated to other areas, like how security is finding its way into LLM demos just now (Prompt Engineering). Or is this the other way around, that voice assistant has been stagnated for so long that only recent development can rekindle the dying industry?\nWe have yet to see the full impact of such systems on people and society at large4, but we know it will surely be huge5.\nPros and Cons of Anthropomorphism\nSource: On AI Anthropomorphism\nPros:\n\nUseful analogies and metaphors help us understand new and strange technologies. However, we should not take it as the answer to how they work6.\nAI has a social layer/presence whether we like it or not, and anthropomorphism can help us build a familiar interface.\n\nCons:\n\nIt makes the ownership/responsibility unclear7 8, as well as blinds us from investigating the real mechanism of how those models work6.\nIt is ineffective in terms of boosting human productivity yet.\nIt is deceptive when humans are naturally inclined to trust humanlike or automated words 9. Not to mention such automation is often of less quality in comparison with human authors10.\n\nAnother pitfall similar to anthropomorphism is anthropocentric chauvinism — the human mind is the gold standard for all things psychological to be measured by6.\nFootnotes\n\n\nDon’t Go Breaking My Heart ↩\n\n\nAI and Trust ↩\n\n\nWhy we need to move away from anthropomorphic naming conventions in AI | VentureBeat ↩\n\n\nPeople keep anthropomorphizing AI. Here’s why ↩\n\n\nOn AI Anthropomorphism ↩\n\n\nWhy It’s Important to Remember That AI Isn’t Human ↩ ↩2 ↩3\n\n\nThe DAIR Institute ↩\n\n\nThe new Bing is acting all weird and creepy - but the human response is way scarier ↩\n\n\nThe Luring Test- AI and the engineering of consumer trust ↩\n\n\nWhy Quora isn’t useful anymore: A.I. came for the best site on the internet. ↩\n\n\n"},"notes/20230307200456":{"title":"A New Definition of Luddism","links":["notes/20230212204146","highlights/Matter/I'm-a-Luddite.-You-should-be-one-too","highlights/Omnivore/20240205100928"],"tags":[],"content":"A New Definition of Luddism\nLuddite or Luddism is still used as pejorative terms to insult people.\nThe truth is that those Luddites were, and now modern neo-Luddites are, never against technology. Instead, it’s the destructive capitalism behind those machines that had led to the movement. Those machines weren’t even brand-new inventions; not all were demolished indiscriminately. The Luddites acted on those machines whose owners conducted questionable business practices1.\nLuckily, the tide is changing: more and more individuals are embracing the term with a widened scope — the ability to reassess how tech is serving us2. One of the new Luddism’s objectives is to “confront harms done by digital capitalism and see to address them by giving humans more power over the technological systems that structure their lives”1, which I find very similar to what people are striving for in AI community, talking about AI Democratization, especially among all the hyped-up model releases.\nThe goal of the new Luddite movement isn’t merely being customers or users of technology, but shapers too2.\nFootnotes\n\n\nI’m a Luddite. You should be one too ↩ ↩2\n\n\nThe New Luddites Aren’t Backing Down - The Atlantic ↩ ↩2\n\n\n"},"notes/20230319193437":{"title":"Truth and Falsity","links":["notes/20221218101249","highlights/Matter/Noam-Chomsky--The-False-Promise-of-ChatGPT","highlights/Zotero/shanahan_2022","highlights/Matter/ChatGPT-sometimes-makes-up-facts.-For-one-law-prof,-it-went-too-far.","highlights/Matter/The-Expanding-Dark-Forest-and-Generative-AI"],"tags":[],"content":"Truth and Falsity\nWe approach things with a set of beliefs and perspectives that may or may not be shared by others. However, large pre-trained models treat all the information with equal facility1, and there is no inherent mechanism for discriminating truth from falsity2. Even with reinforcement from human feedback, the generation is no less a probabilistic sampling, and there shouldn’t be anything probabilistic regarding beliefs.\nWould it be possible to ask a model to dynamically weight its training documents once it reaches some stable stage during pretraining? Maybe Constitutional AI can be directly incorporated into the training by weighting documents discriminatively. Is this a form of self-reinforcement?\nAnother issue with the inability to distinguish truth from misinformation, compounded with the wide release of generative APIs, is that the fake or low-quality information gets recycled into the internet and potentially amplified through other clueless models3. It is bad enough that we have to ingest such information firsthand; now we must suffer repeatedly4.\nFootnotes\n\n\nNoam Chomsky: The False Promise of ChatGPT ↩\n\n\nTalking About Large Language Models ↩\n\n\nChatGPT sometimes makes up facts. For one law prof ↩\n\n\nThe Expanding Dark Forest and Generative AI ↩\n\n\n"},"notes/20230319194936":{"title":"Reinforcement Learning VS. Supervised Learning","links":["highlights/Matter/Ahead-of-AI--6--TrAIn-Differently"],"tags":[],"content":"Reinforcement Learning VS. Supervised Learning\nReinforcement learning theoretically works better than current supervised learning because RL scores over the whole text while SL scores over each token1.\nFootnotes\n\n\nAhead of AI ↩\n\n\n"},"notes/20230319195707":{"title":"Fear of AI","links":["notes/20230307200456","highlights/Matter/Think-of-Everything-You-Hate-About-the-Internet.-Now-Add-A.I.","highlights/Matter/“AI”-Hurts-Consumers-and-Workers----and-Isn’t-Intelligent","highlights/Readwise/31565587","highlights/Matter/The-myth-of-‘open-source’-AI","notes/20230521205616","20221210185344"],"tags":[],"content":"Fear of AI\nWe are not really against AI or technology development1. Our fear is mostly about “how capitalism will use technology against us”2 3 4 5 6. Free and fancy demos will always end, then it is about money making. Even when it is free, it is problematic7; how can we expect it to be any better when it is behind a paywall?\nFootnotes\n\n\nA New Definition of Luddism ↩\n\n\nThink of Everything You Hate About the Internet. Now Add A.I. ↩\n\n\n“AI” Hurts Consumers and Workers — and Isn’t Intelligent ↩\n\n\nWeb Scraping for Me, but Not for Thee ↩\n\n\nThe myth of ‘open source’ AI ↩\n\n\nAI-Enabled or Assisted Harm ↩\n\n\nOn the Dangers of Large Generative Models ↩\n\n\n"},"notes/20230321205856":{"title":"Construct Validity","links":["highlights/Readwise/31554997","AI-Causes-Real-Harm.-Let’s-Focus-on-That-over-the-End-of-Humanity-Hype","highlights/Matter/GPT-4-and-professional-benchmarks--the-wrong-answer-to-the-wrong-question"],"tags":[],"content":"Construct Validity\nConstruct validity reflects to which extent the indicators/metrics/scores can represent a concept or an ability that is not directly measurable1 2.\nIn machine learning, we often create benchmarks under the assumption that having a high score, sometimes higher than humans, means having some level of intelligence like humans, but this is rarely true. When we look at how OpenAI boasts about GPT-4’s performance on some standard tests, data leakage issues aside, the construct validity was never thoroughly tested or at least stated3. This reminds me of the metric black hole mentioned in Deep Work — we still don’t know much about how to test intelligence. This is just creating distractions and hype.\nFootnotes\n\n\nConstruct validity - Wikipedia ↩\n\n\nAI Causes Real Harm. Let’s Focus on That over the End-of-Humanity Hype ↩\n\n\nGPT-4 and professional benchmarks: the wrong answer to the wrong question ↩\n\n\n"},"notes/20230324201053":{"title":"First-instinct Fallacy","links":["notes/20221224153623","highlights/Readwise/31554987"],"tags":[],"content":"First-instinct Fallacy\nThis term came from a study that found students got better scores when changed their first-instinct answer1 2. But carrying out this change won’t be easy due to our cognitive laziness. The idea of doubting ourselves feels insecure, and occasionally, it can be existential — questioning our long-held beliefs.\nThis reminds me of a book that says when we talk to people or try to persuade them, we should be prepared for defensive comebacks because it might just make their whole world crumble.\nIt also resembles Risk and Fear, where thinking twice is equivalent to thinking outside our comfort zone, our old thinking habits.\nFootnotes\n\n\nKruger J, Wirtz D, Miller DT. Counterfactual thinking and the first instinct fallacy. J Pers Soc Psychol. 2005 May;88(5):725-35. doi: 10.1037/0022-3514.88.5.725. PMID: 15898871. ↩\n\n\nThink Again ↩\n\n\n"},"notes/20230324203145":{"title":"Thinking Mode","links":["notes/20230101110239","highlights/Readwise/31554987"],"tags":[],"content":"Thinking Mode\nThere are four types of thinking mode, a.k.a., four mindsets1:\n\nPreaching: promoting our ideas\nProsecuting: marshalling arguments to prove other people’s ideas are wrong\nPoliticking: lobbying for votes from the audience\nResearching: finding truth via running test experiments\n\nIt is a vicious cycle if we get stuck in the first three modes, our views will get reinforced with OverconfidenceThe Dictator Trap]].\nFootnotes\n\n\nThink Again ↩\n\n\n"},"notes/20230408211901":{"title":"The American Bias","links":["highlights/Matter/AI-and-the-American-Smile","highlights/Matter/OpenAI's-Whisper-is-another-case-study-in-Colonisation","highlights/Matter/Update--52--The-Ironies-in-Pausing-AI-and-Finetuning-LLMs-without-Backpropagation","notes/20230321205856","highlights/Matter/GPT-4-and-professional-benchmarks--the-wrong-answer-to-the-wrong-question"],"tags":[],"content":"The American Bias\nMost research on Natural Language Processing targets English spoken in America; sometimes, it is so dominant that researchers don’t bother to mention their target language anymore if it is English, even in international conferences. Fortunately, we have at least one popular rule — always mention the language you are working on — proposed by Emily Bender, a computational linguist from the University of Washington, to remind us of this bias.\nBut fighting this American-centric bias is more than about acknowledging the language: one article AI and the American Smile demonstrates perfectly this encroaching impression of an American smile. It is hard to pinpoint the exact root issue with those generations, especially when every step could be infested with biases consciously or unconsciously:\n\nData collection bias: What is more accessible or more understandable to the collectors does not mean it is more popular or more of high quality to the whole planet1. The Internet is not the world2.\nModeling bias: Modelling the data without proper vetting, filtering, or discernment is aiding whatever stereotype and toxicity exist within the data.\nEvaluation bias:  Using some benchmarks in some languages that reflect some values often does not constitute a valid intelligence test3 4, which we don’t even have a vigorous definition to begin with.\n\nFootnotes\n\n\nOpenAI’s Whisper is Another Case Study in Colonisation ↩\n\n\nUpdate -52- The Ironies in Pausing AI and Finetuning LLMs without Backpropagation ↩\n\n\nConstruct Validity ↩\n\n\nGPT-4 and professional benchmarks- the wrong answer to the wrong question ↩\n\n\n"},"notes/20230409152706":{"title":"High-Order Polynomial Projection Operator","links":[],"tags":[],"content":"High-Order Polynomial Projection Operator\nCore idea: if it is possible to learn a good representation of the history/context, then it should be easy to reconstruct the history/context.\nThen the objective becomes:\n\nTo capture/encode/compress the history up to the current time step using hidden states;\nTo update such states efficiently when new information comes in;\n\nTo achieve that, you will need:\n\nApproximation measure prior (e.g, recent over past)\nHiPPO matrices (A and B)\n\nHiPPO Operator\nBorrowing from the idea of moving average, the HiPPO operator calculates the hidden state (approximation coefficients) based on the previous state x(t) and input u(t).\nx′(t)=Ax(t)+Bu(t)"},"notes/20230409155434":{"title":"Signal Model","links":[],"tags":[],"content":"Signal Model\nA sequence model for continuous input. A traditional sequence model can be seen as a discretized signal model."},"notes/20230414201628":{"title":"Gall's Law","links":["highlights/Matter/50-Ideas-That-Changed-My-Life"],"tags":[],"content":"Gall’s Law\nSource: 50 Ideas That Changed My Life\nA working complex system is most likely to be evolved from a simple system that worked. A system that is complex by design will not work, no matter how many patches are added.\nSimilarly, in software engineering, it is important to have a proof of concept first, and then iterate on the additions."},"notes/20230414202247":{"title":"The Status Rat Race","links":["highlights/Matter/The-Status-Trap","notes/20230123142700","notes/20221113145808"],"tags":[],"content":"The Status Rat Race\nSource: The Status Trap\nTransclude of The-Status-Trap#^2a1a3b\nChasing our dreams can be inspiring, but chasing status only gets us a one-way ticket into the rat race that never stops:\n\nIt reinforces the idea that we are not good enough;\nIt creates a false sense of security and belongingness;\n\nInstead, we can quit the The Rat Race by:\n\nFacing the anxiety and learning to accept our insecurity;\nWriting;\nFinding meaningful goals;\n\nThis is a prime example of Goodhart’s Law — the status becomes the target, but it is only one of many measurements for your success."},"notes/20230418200632":{"title":"Focus and Directions","links":["highlights/Matter/If-you-want-to-follow-your-dreams,-you-have-to-say-no-to-all-the-alternatives"],"tags":[],"content":"Focus and Directions\nWe have finite willpower and attention each day. Therefore, we must budget our energy right to progress in the right direction.\nOne goal at a time, or at least one primary goal at a time.1 With each additional direction we want to take simultaneously, we lose our ability to produce quality work. Too many options can often lead to paralysis, and too many habits can often lead to a jack-of-all-trades.\nFootnotes\n\n\nIf you want to follow your dreams, you have to say no to all the alternatives ↩\n\n\n"},"notes/20230418201928":{"title":"Effective Altruism Judo","links":["highlights/Matter/Notes-on-Effective-Altruism"],"tags":[],"content":"Effective Altruism Judo\n\nIf we’re not doing that right, we shall improve, we simply need you to provide evidence and a better alternative.1\n\nIt sounds good on paper to do good better and to ask for suggestions when being criticized.\nBut this is essentially forcing people out of their way to do your job, like how big companies rushed into releasing powerful models and asking the public for feedback as free labour.\nFootnotes\n\n\nNotes on Effective Altruism ↩\n\n\n"},"notes/20230422133939":{"title":"Title","links":["highlights/Matter/You're-not-uncool.-Making-friends-as-an-adult-is-just-hard","notes/20221221125345","notes/20230123141334","notes/20221224153623"],"tags":[],"content":"Making Friends as an Adult\nMaking friends sounds terrifying, but it will be much easier if you start by assuming people already like you, the meet-ups will go well, and you will not be rejected1.\nWorrying about being rejected and therefore not making an effort towards building a friendship may be comfortable2 at first, but the loneliness will eventually get out of hand. In the end, you will find yourself in this downward spiral that you literally become someone that is less likely to be approachable.\nPutting yourself out there has some risk, and you can never to ready3, but not taking a such risk will likely yield a far worse life in the long run4. Making efforts also does not just mean showing up, it also needs you to be present, be engaged, and reciprocate.\nFootnotes\n\n\nYou’re not uncool. Making friends as an adult is just hard ↩\n\n\nComfort VS. Fear ↩\n\n\nBeing Ready ↩\n\n\nRisk and Fear ↩\n\n\n"},"notes/20230422140156":{"title":"Self-censorship","links":["highlights/Matter/An-Illustrated-Guide-to-Self-Censorship","highlights/Matter/In-Wuhan,-doctors-knew-the-truth.-They-were-told-to-keep-quiet."],"tags":[],"content":"Self-censorship\nSelf-censorship is an interesting instance of the prisoner’s dilemma: If you are the only one who speaks the truth, you will be singled out as a traitor, even though everyone else is thinking the same. You also cannot join someone who speaks out because you fear you will be the only one to do so. In the end, everyone fears for his life, and no one actually acts1 2.\nFootnotes\n\n\nAn Illustrated Guide to Self-Censorship ↩\n\n\nIn Wuhan, doctors knew the truth. They were told to keep quiet. ↩\n\n\n"},"notes/20230429194337":{"title":"Contextuality","links":["notes/20220904143432","highlights/Matter/OpenAI's-Whisper-is-another-case-study-in-Colonisation","highlights/Matter/AI-translation-is-jeopardizing-Afghan-asylum-claims"],"tags":[],"content":"Contextuality\n\nYou shall know a word by the company it keeps (Firth, J. R. 1957:11)\n\nAt this point, I wonder if the famous quote above is leading us astray. Yes, it ignited the idea of distributed representation and shaped the current natural language processing research. But it feels lacking in terms of capturing the larger context our languages live in — the physical world the language users share, the personal experience, and preferences each language user has. I am seeing nothing on the horizon that remotely tries to solve it.\nIt has been already problematic for low-resource languages in real-life applications1 2. Yet, we care more about SOTA results on some benchmarks than addressing actual problems. Should we name whatever we are doing or whatever the model is learning something different? Maybe textual embeddings instead of contextual embeddings? Before we understand the differences among Form, Meaning, and Communicative Intents\nFootnotes\n\n\nOpenAI’s Whisper is another case study in Colonisation ↩\n\n\nAI translation is jeopardizing Afghan asylum claims ↩\n\n\n"},"notes/20230429200024":{"title":"Gifting with Experience","links":["highlights/Matter/How-to-spend-money-on-your-friends-without-it-looking-like-bribery","notes/20220530092155","notes/20220530092340","highlights/Matter/Quitting-the-Rat-Race","highlights/Matter/Buying-Experiences-Probably-Doesn't-Make-You-Happier-than-Buying-Possessions","highlights/Matter/3-2-1--The-value-of-leaving-things-alone,-nonmaterial-needs,-and-broadening-your-interests"],"tags":[],"content":"Gifting with Experience\nInstead of buying gifts for your friends, you can buy them for yourself and let your friends use them, such that they will not feel bad for taking something from you and all of you can enjoy something together1.\nFrom a minimalist standpoint, oftentimes, purchases of physical possessions are more expensive2, both financially and mentally. Therefore, purchasing experience is much more suitable3 4. Although, it is not necessarily always true, considering all factors5.\nThen there is another issue about fulfilling unmaterial needs — love, joy, self-esteem — with material things: you can never quench the thirst for more6. Non-material experience is one good way to satisfy them.\nFootnotes\n\n\nHow to spend money on your friends without it looking like bribery ↩\n\n\n2x Rule ↩\n\n\nBest Things You Can Buy ↩\n\n\nQuitting the Rat Race ↩\n\n\nBuying Experiences Probably Doesn’t Make You Happier than Buying Possessions ↩\n\n\n3-2-1- The value of leaving things alone, nonmaterial needs, and broadening your interests ↩\n\n\n"},"notes/20230506135649":{"title":"AI Adoption Bias","links":["highlights/Matter/Will-A.I.-Become-the-New-McKinsey-","highlights/Matter/The-Luring-Test--AI-and-the-engineering-of-consumer-trust"],"tags":[],"content":"AI Adoption Bias\nInspiration: Will A.I. Become the New McKinsey?\nCompanies can choose law firms, third-party vendors, experts, or consultants to give them the answers they want, to justify policies or decisions they intend to make, and to shift the blame. AI, unfortunately, can be used in a similar way. They can be deployed as a way to evade responsibilities no matter how impartial such algorithms or models have been portrayed in the media and how biased we are towards automation1.\nNo matter how environmental-friendly, ethically aware, or pro-social your model can become, there are always alternatives that better suit leadership’s needs.  In the end, AI adoption ends up being a tool to build another moat for the people in power.\nFootnotes\n\n\nThe Luring Test- AI and the engineering of consumer trust ↩\n\n\n"},"notes/20230506141008":{"title":"Accelerationism","links":["highlights/Matter/Will-A.I.-Become-the-New-McKinsey-"],"tags":[],"content":"Accelerationism\nSource: Will A.I. Become the New McKinsey?\nThe only way to make things better is to make it worse. In the case of capitalism, it is “futile to try to oppose or reform; instead, we have to exacerbate its worst tendencies until the entire system breaks down”."},"notes/20230506145907":{"title":"Writing is like Visiting a Country","links":["highlights/Matter/Writing-is-Like-Entering-a-Huge-Country--How-I-Found-My-Way","notes/20220709195323","notes/20220717133315","highlights/Readwise/36309893"],"tags":[],"content":"Writing is like Visiting a Country\nSource: Writing is Like Entering a Huge Country- How I Found My Way\nWriting doesn’t have to be difficult. It is a process and a chance to learn something new1. Like visiting a foreign country, you start off not knowing and end up richer with the knowledge you did not have before2. Such visits can help you build confidence in your writing and nurture a positive feedback loop around writing3.\nIn the same vein, reading is similar too. There are people out there who share the same experiences or feelings and have the power to put them into context. There are desires to connect and form a relationship with the reader based on the mutual understanding of what it means to be a human being4.\nFootnotes\n\n\nOnly Writing Counts ↩\n\n\nWriting is Like Entering a Huge Country- How I Found My Way ↩\n\n\nWriting with a Positive Feedback Loop ↩\n\n\nAI Is Already Killing Books ↩\n\n\n"},"notes/20230518192719":{"title":"Right to Repair","links":["highlights/Matter/Companies-are-radically-redefining-what-it-means-to-'own'-something"],"tags":[],"content":"Right to Repair\nReference: Companies are radically redefining what it means to ‘own’ something\nWhen buying something, especially products for long-term use, choose the ones or the brands that allow you to fix them with first-party or third-party parts. Being able to repair is a critical skill that not only saves you money but also helps cut waste.\nIf it is something that you have to purchase and then subscribe to specific services to use, it is not a purchase at all. That’s more like a down payment."},"notes/20230518195625":{"title":"Error Bars","links":["highlights/Zotero/krzywinski_2013"],"tags":[],"content":"Error Bars\nReference: Error bars\nStandard Deviation\nThe variation of the data, not the error in your measurement.\npopulation = [...]\nsample_stats = []\nmeasurements = 10\nsample_size = 10\nfor i in range(measurements):\n\tsample = random.sample(population, sample_size)\n\tsample_stats.append(np.mean(sample))\n\nmean_ = np.mean(sample_stats)\nstd_ = np.std(sample_stats)\n\nStandard Error of the Mean\nUncertainty in the values. Not overlapping does not grant significance.\npopulation = [...]\nmeans = []\nout_measurements = 10\nfor _ in range(out_measurements):\n\tsample_stats = []\n\tmeasurements = 10\n\tsample_size = 10\n\tfor i in range(measurements):\n\t\tsample = random.sample(population, sample_size)\n\t\tsample_stats.append(np.mean(sample))\n\tmeans.append(np.mean(sample_stats))\n\nmean_ = np.mean(means)\nse = np.std(means) / math.sqrt(len(means))\n\nConfidence interval\nThe interval captures the population mean CI% of the time.\nCI_95 = (mean_ - se * 1.96, mean_ + se * 1.96)\n"},"notes/20230519220857":{"title":"LLM Maximalism","links":["highlights/Matter/Against-LLM-maximalism"],"tags":[],"content":"LLM Maximalism\nReference: Against LLM maximalism\nUsing only LLMs for tasks — using LLMs to the maximum extent. For example, preprocessing and postprocessing data in the prompt instead of handling them in separate steps.\nAt this point, the prompt or controllability of LLMs is unstable at best. People have been developing software based on modularity, flexibility, extensibility, and decoupling for decades, but all seem lost in the model-building world.\nAsk not what AI/LLMs can do for us, ask what problems we have, then ask if AI/LLMs can help1.\nOne solution against LLM Maximalism:\n\nBreak down your question into steps, components, and layers;\nIdentify in what steps a model should be and can be engaged, and what steps deterministic programming is needed;\nIdentify meaningful metrics and evaluate what works and what doesn’t;\nIteratively design and improve the pipeline(e.g, data labeling and model fine-tuning);\n\nFootnotes\n\n\nTODO, I should know the source, but I could not find it right now. ↩\n\n\n"},"notes/20230520144243":{"title":"AI and Productivity","links":["highlights/Matter/AI-Is-a-Waste-of-Time","notes/20230212204146","notes/20230506135649"],"tags":[],"content":"AI and Productivity\nReference: AI Is a Waste of Time\nAI is a double-edged sword when it comes to our productivity: it will ease the friction when doing mundane tasks but also allow us to squander our free time watching addictive videos and scrolling our phones.\nThere will be companies trying to grab our attention and time with AI — quite ironically, they will be ones ripping the benefit of AI as a form of increased ad revenue, while consumers who couldn’t bear the idea of being inactive or understimulated will suffer.\nHow can we fight back? It is already bad enough that people in power, and now equipped with AI, are aggregating more power1. Which part of AI Democratization can help us? Is XXX (AI, NFT, crypto, web 3.0, web 2.0) another time-killing phase in human history?\nFootnotes\n\n\nAI Adoption Bias ↩\n\n\n"},"notes/20230520195336":{"title":"Model Scale and Bias Hypotheses","links":["highlights/Zotero/biderman_2023-1"],"tags":[],"content":"Model Scale and Bias Hypotheses\nSource: Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling\n\nLarge models tend to reinforce the stereotypes more so than small models since the learning objective is to capture the co-occurrence.\nLarge models can also be corrected/debiased easier than small models, given proper remedy, because of their learning capacity.\n"},"notes/20230521205616":{"title":"AI-Enabled or Assisted Harm","links":["notes/20230506135649","highlights/Matter/Inside-the-AI-Porn-Marketplace-Where-Everything-and-Everyone-Is-for-Sale"],"tags":[],"content":"AI-Enabled or Assisted Harm\nWhen we talk about the harm done by AI, it is not just about AI-only harm but also harm facilitated by AI.\nAI technology makes the decision-making and consequent responsibility a muddy situation, especially when there are many compounding factors at play, such as AI Adoption Bias.\nThere are already crimes happening with the help of AI:\n![[CleanShot 2023-05-21 at 21.03.18@2x.png]]\nAnother example is the latest generation of deepfake1 — non-consensual pornography generated by AI. More importantly, it also sheds light on the underlying supply chain: Reddit communities with shared images, “open-source” communities sharing models, and companies hosting services and images for profit.\nFootnotes\n\n\nInside the AI Porn Marketplace Where Everything and Everyone Is for Sale ↩\n\n\n"},"notes/20230521210832":{"title":"AI Mirror","links":["highlights/Matter/AI-And-The-Limits-Of-Language","highlights/Matter/Did-the-GPT3-Chatbot-Pass-the-Lovelace-Creativity-Test-","notes/20221231135246"],"tags":[],"content":"AI Mirror\nSource: AI And The Limits Of Language\nA distortion mirror that reflects anything, creating an illusion of reality without any accurate understanding of the world or the truth. It cannot interact without the world, let alone form actual knowledge.\nThe generalization of trained models might create something that does not exist in the training data, hence the “distortion” part. The novelty or creativity1 2 only makes sense by our perception, regardless of intention, usefulness or entertainingness.\nFootnotes\n\n\nDid the GPT3 Chatbot Pass the Lovelace Creativity Test? ↩\n\n\nLovelace Test ↩\n\n\n"},"notes/20230521211543":{"title":"Predictable and Preventable AI Bias","links":["highlights/Matter/Humans-and-algorithms-work-together---so-study-them-together","notes/20230521210832"],"tags":[],"content":"Predictable and Preventable AI Bias\nSource: Humans and algorithms work together - so study them together\nIf the AI Mirror metaphor holds, solving biases, inequalities, or stereotypes should primarily rely on how we, or experts, tackle them in the real world. It is almost certain that uncareful data curation and mindless scaling won’t solve the problem as long as we keep scraping the open internet. As a result, exhibiting biases and stereotypes is something those large models cannot escape. But if this is how people choose to go, then such undesirability is undoubtedly predictable.\nBut are we close to solving those problems in our society? No perfect solution exists, so we should expect no scalable solution from AI models. Sometimes I wonder if we are asking the right question or not. Also, is bias the right word? To me, it is ascribing too much agency to the model when we say it is biased."},"notes/20230523162036":{"title":"Manifesting Magic","links":["highlights/Matter/Becoming-a-magician","notes/20220604131222"],"tags":[],"content":"Manifesting Magic\nSource: Becoming a magician\nImage a version of yourself that feels impossible and unattainable right now.\nThis sets a beacon in our uncharted life journey. We don’t know how and when, but we subconsciously know what it looks like. It is almost like goal setting, but much more outlandish and long-term than most goals. That’s why when we look back at it, it feels like magic.\nTo help establish such self-image, you can ask yourself the following questions:\n\nWhat is the most capable version of me that I can imagine? Role models can help you with this, so surround yourself with magicians you want to follow.\nWhat would I be doing if all my current major problems had been solved?\nWhat are the things I say I value but I haven’t acted; what would my life be if I actually did?\nWhat am I afraid of doing; what would my life be if I am not?\n\nOn the other hand, Premeditatio Malorum imagines the worst possible to overcome inactivity."},"notes/20230531214650":{"title":"Bias as Unjustified Direct Causal Effect","links":["highlights/Matter/The-bias-puzzle---Understanding-gender-differences-in-academia"],"tags":[],"content":"Bias as Unjustified Direct Causal Effect\nReference: The bias puzzle - Understanding gender differences in academia\nWhen we talk about bias, we often talk about the end results being perceived as biased, e.g. men get more grants than women in the same university, even though with the same qualifications. However, the leading factors in the direct decision-making process, grant evaluation in this case, might actually be completely free of bias, and only when you look deeper into such inequality, do you discover the root cause — the gender bias in the hiring process indirectly impact the funding women receive.\nSuch indirect bias can be referred to as disparity with respect to the observations, instead of bias, which is direct and unjustified in nature. If the focus or reference is on the hiring process, only then it becomes a bias.\nTransclude of The-bias-puzzle---Understanding-gender-differences-in-academia#^67351d"},"notes/20230606203731":{"title":"Memory Efficient Zeroth-order Optimization","links":["highlights/Zotero/malladi_2023"],"tags":[],"content":"Memory Efficient Zeroth-order Optimization\nSource: Fine-Tuning Language Models with Just Forward Passes\nOptimizers usually rely on backpropagation using chain rules and differentiation rules to derive gradients. This also requires extra space for the gradients during the backward pass. However, zeroth-order optimization can be used to derive such gradients with just two forward passes.\nThis is possible because, by definition, gradients can be calculated from the difference in the output by perturbing the parameters at a small scale. By using two forward passes, it enables the model to be optimized with non-differentiable objectives and achieve comparable performance. And MeZO improves memory consumption with in-place parameter updates."},"notes/20230607164206":{"title":"AI Heroism","links":["highlights/Matter/These-Women-Tried-to-Warn-Us-About-AI","highlights/Matter/Human-Extinction--A-Brief-Guided-Tour-of-the-Book","highlights/Matter/Eugenics-and-Longtermist-Effective-Altruism-Share-the-Same-Original-Sin","highlights/Readwise/34289457","highlights/Readwise/35453151","highlights/Matter/Is-Avoiding-Extinction-from-AI-Really-an-Urgent-Priority-","highlights/Matter/Top-AI-researcher-dismisses-AI-‘extinction’-fears,-challenges-‘hero-scientist’-narrative"],"tags":[],"content":"AI Heroism\nWhen personal ideas or opinions from renowned researchers are heralded as gospel, without any scientific scrutiny.\nSimilarly, we should never judge a company by its star CEO or chief scientist1 2.\nA good example is the recent “extinction risks” petition signed by some of the most famous AI researchers3 4 5.\nTransclude of These-Women-Tried-to-Warn-Us-About-AI#^2fb548\nTransclude of Human-Extinction--A-Brief-Guided-Tour-of-the-Book#^c96165\nTransclude of Eugenics-and-Longtermist-Effective-Altruism-Share-the-Same-Original-Sin#^3e3b77\nFootnotes\n\n\nThe Biggest Immediate Lesson From the OpenAI Meltdown ↩\n\n\nNeurIPS 2023 Test of Time Winner: “Money and Power Certainly Corrupts People “ ↩\n\n\nIs Avoiding Extinction from AI Really an Urgent Priority? ↩\n\n\nTop AI researcher dismisses AI ‘extinction’ fears ↩\n\n\nEugenics and Longtermist Effective Altruism Share the Same Original Sin ↩\n\n\n"},"notes/20230618210942":{"title":"Finishing is a Win","links":["highlights/Matter/Finish-your-projects"],"tags":[],"content":"Finishing is a Win\nTo finish a project is a positive feedback loop that reinforces your identity of being someone who delivers. To make it a success, you then have to keep delivering.\nYou might not get tons of feedback, but you actually might have a much larger audience than you expect1.\nFootnotes\n\n\nFinish your projects ↩\n\n\n"},"notes/20230619204633":{"title":"p-Value and Statistical Significance","links":["highlights/Zotero/wasserstein_2016"],"tags":[],"content":"p-Value and Statistical Significance\nHypothesis Testing\nNull Hypothesis: the effect does not exist — two samples are from the same distribution, e.g.\nAlternative Hypothesis: the effect does exist.\np-Value\nGiven the null hypothesis is true, the p-value tells you how likely you’d see the data you observed. By choosing a threshold beforehand, you can decide whether to reject the null hypothesis.\nBut this does not mean any decisions based solely on p-values are correct. When reporting, p-values should come with proper context and other evidence, and preferably with other approaches that are more suitable and feasible for your data1.\nFootnotes\n\n\nThe ASA Statement on p-Values: Context ↩\n\n\n"},"notes/20230624141234":{"title":"Information Overload","links":["highlights/Matter/The-Never-Ending-Now","highlights/Matter/Treat-your-to-read-pile-like-a-river,-not-a-bucket","notes/20221116184118"],"tags":[],"content":"Information Overload\nFinding a needle in the haystack has always been the go-to metaphor in this Internet era, but it never occurs to me that it could be “haystack-sized piles of needles”1.\nNo amount of prioritization or elimination will quench the neverending encounter with new or relevant information (The Never-Ending Nowbe ready]] for most things in our life, including our to-read list(that includes research too2). Now, at least, we shouldn’t have to sweat when we open the list.\nFootnotes\n\n\nTreat your to-read pile like a river ↩\n\n\nPriority in Research ↩\n\n\n"},"notes/20230624143552":{"title":"Own it Mentality","links":["highlights/Matter/Own-It-Mentality---David-Perell"],"tags":[],"content":"Own it Mentality\nSource: Own It Mentality - David Perell\n\nBe a man of your own words;\nConfront conflicts as soon as they arise;\nInstead of expecting perfection, communicate when things change;\n"},"notes/20230701132110":{"title":"Choosing a Career","links":["highlights/Matter/How-to-Pick-a-Career-(That-Actually-Fits-You)","notes/20221224153623"],"tags":[],"content":"Choosing a Career\nSource: How to Pick a Career (That Actually Fits You)\nWe’re not Prepared\nSchools rarely teach you how to choose a career, and all your decisions in school revolve around how to be a better student. Now suddenly, after graduation, you are holding the keys to a future, waiting to be charted by yourself.\nIt Feels important but Difficult\nWhat is taught to us is that our career is our identity; thus, we carry this burden of making a life-changing decision completely clueless. But it shouldn’t be this way, like going out on a first date shouldn’t be as stressful as finding the one.\nWe have so many conflicting yearnings and biases when it comes to our career choice, and you have to play this “game of choices and sacrifices and compromise” without much guidance. This is when we have to take a deeper look at ourselves and our desires, beliefs, and fears(Risk and FearComfort VS. Fear]]). You simply can’t make an informed decision when you have no idea what you want and what you can achieve in this reality. A closer look at our past, figuring out the influence we are under from our environment, our family, and society."},"notes/20230702185749":{"title":"Is Programming Here to Stay?","links":["highlights/Archive/Pocketbook/Clean-Code-A-Handbook-of-Agile-Software-Craftsmanship/metadata"],"tags":[],"content":"Is Programming Here to Stay?\nCan a system generate detailed programs that completely satisfy a client who only gives vague and high-level requirements/abstractions? Where does it find all the specifications required for the intricacy that enables the program to function in the real world with real users, if not from the client?\nIf the client has to provide such detail, then what the client does is no different from programming/coding — “well-specified requirements are as formal as code”1.\nBut what if the decisions were delegated to the system on the client’s behalf, where the system draws decisions from a large amount of data? Would this be considered a counter-example to the claim?\nFootnotes\n\n\nClean Code A Handbook of Agile Software Craftsmanship ↩\n\n\n"},"notes/20230704192748":{"title":"Net Positive is Not Enough","links":["highlights/Readwise/31554985"],"tags":[],"content":"Net Positive is Not Enough\nThe impact of technological advances might have a net positive influence on society from a distant and indifferent future perspective. Still, if the bad part gets us, or some of us first, it is game over. The positive part is an empty check that no victim can cash1.\nFootnotes\n\n\nWhat’s Our Problem? ↩\n\n\n"},"notes/20230706192456":{"title":"Faculty of Effort","links":["highlights/Matter/The-best-general-advice-on-earth","notes/20220604131222"],"tags":[],"content":"Faculty of Effort\nSource: The best general advice on earth\nThis is almost equivalent to Premeditatio Malorum — keeping yourself mentally challenged by creating daily exercises you would rather not do. It prepares you much better when real problems hit."},"notes/20230709195130":{"title":"Something Bad VS Nothing","links":["highlights/Matter/AI-Could-Change-How-Blind-People-See-the-World"],"tags":[],"content":"Something Bad VS Nothing\nSource: AI Could Change How Blind People See the World\nWe know AI models generate ungrounded output that is often riddled with mistakes, but for people that have no access to any form of information at all otherwise, it might help in a much more convenient way.\nFor people arguing that it could provide medical advice to people who don’t have access to a doctor, I would say access to the Internet and a salary that can afford to pay the API usage makes more sense. If building the Internet infrastructure isn’t an issue, why not build a clinic or a hospital while you are at it? This is a case where having something bad means that you could have something good."},"notes/20230709201656":{"title":"Looking Stupid","links":["highlights/Matter/Willingness-to-look-stupid","notes/20220704155657"],"tags":[],"content":"Looking Stupid\nSource: Willingness to look stupid\nAsking stupid questions does not necessarily mean that you are stupid. It could mean you are brave enough to challenge the unspoken and widely accepted answer, and sometimes you are right. This is a great opportunity to learn, a small one nonetheless. But a habit of asking questions, even though it might make you look stupid to other people, has the compounding benefit of understanding things deeper.\nSometimes, a stupid or obvious question might lead to offbeat and easy paths. And entertaining a stupid question intellectually is equally important.\nTo avoid looking stupid is like a survival instinct, and it might lead to being passed on from opportunities (e.g. interviews). Interestingly and ironically, we have Dunning-Kruger Effect and Imposter Syndrome and are simultaneously afraid of looking stupid."},"notes/20230711213315":{"title":"Neoliberalism and AI Solutionism","links":["highlights/Matter/The-True-Threat-of-Artificial-Intelligence"],"tags":[],"content":"Neoliberalism and AI Solutionism\nSource: The True Threat of Artificial Intelligence\nNeoliberalism is often associated with privatisation and deregularisation, and the recent A.G.I-ism has echoed some of its main biases:\n\nMarket bias: market privatisation and decreased government functions in society. In this case, private and closed-source models vs open-source models;\nAdaptation bias: adaptation to private sectors solutions instead of imagining a better alternative;\nEfficiency bias: efficiency over social concerns/benefits — asking the users to debug their bugs for free; Everything is a technical issue and requires a for-profit technological solution.\n\nThe problem with solutionism is that they never bother to ask a deeper level of why (transformative) and settle on solving superficial problems (adaptive). For example, it will ask people to walk more but never tries to improve the city’s public infrastructure for walking. The latter requires a lot more than making an app, admittedly. But it does not mean we should not bother to ask, and we should resist solutionism by rooting our goals in reality — a reality with rich social and cultural resources that aren’t just mere training data."},"notes/20230714212032":{"title":"Learning the Skeptical Way","links":["highlights/Matter/The-Looming-Demise-of-the-10x-Developer"],"tags":[],"content":"Learning the Skeptical Way\nSource: The Looming Demise of the 10x Developer\nBeing skeptical can make you look defensive and attactive when approaching other people’s claims. But it also makes the learning journey hearfelt when we are also being open. It feels like a mini you-vs-the-author debate or a martial combat: Adversarial attacks makes the claim clearer.\nIt might make things artificially difficult and sometimes cynical, but it is exactly the point."},"notes/20230715133901":{"title":"Mission Science","links":["highlights/Matter/On-Political-Communication-as-a-Mission-Science"],"tags":[],"content":"Mission Science\nSource: On Political Communication as a Mission Science\nMission science refers to science around a shared normative stance. Mission scientists approach research questions with the goal to help. They are motived by the why question that stems from core pragmatic concerns, instead of being swayed by corporal or political agendas.\nBut it also comes with a price: Once your study becomes relevant and unfortunately goes against powers at play, it makes you a target of smear campaigns.\nHow do you tell the difference between a scientific study and a “scientific” propaganda? We know science is supposed to be free of political influence, but we can’t expect all scientists to be free of political preferences."},"notes/20230720210314":{"title":"Connection Engine","links":["highlights/Matter/Google-shattered-human-connection","notes/20221120131625"],"tags":[],"content":"Connection Engine\nInspiration: Google shattered human connection\nThe information-seeking journey is a lot more than getting the answer. Situating Search outlined some of the reasons why it is a bad idea to synthesize an answer without any context or present it by ripping it from its context. But part of the journey is also exposure to communities or people with similar interests or issues. It is getting a chance to be involved in conversations with another human being on the Internet.\nDoing an Internet search doesn’t have to be a battle; it also shouldn’t feel like spoon-feeding. With the increasing development of technology and its ability to grab our attention, we need connection engines instead of search engines.\n\nConnection engines give you the ability and access to get the answer, while search engines give you the answer directly;\nSearch engines can come and go, but communities and our connections rarely do;\nSearch engines give you one voice, but communities and connections give you diverse voices and leave the choice to you;\n"},"notes/20230723121610":{"title":"Glue Work Theory","links":[],"tags":[],"content":"Glue Work Theory\nHere is my hypothesis: The more capable you are of working in a company, the more glue work you have to do, and the less room you will have for your professional growth.\nYour work is vital to the company but no longer to you. The knowledge you will gain from glue work is about the company, the platform, or the system, but it could no longer resonate with you. Compared with newcomers, who have fewer clues on what is happening and get projects that suit their skills/interests the best, tenured workers’ work becomes managerial and orchestral, even if they didn’t want to go down that path.\nSome people like me are happy solving problems within their domain or interest. Why can’t they leave us alone? Why is the corporate ladder always leading to leadership?"},"notes/20230725083514":{"title":"A Default No to Something New","links":["highlights/Matter/Justine-Bateman-on-AI,-Labor,-and-the-Future-of-Entertainment","highlights/Omnivore/20240228191849","highlights/Omnivore/20240303180433"],"tags":[],"content":"A Default No to Something New\nInspiration: Justine Bateman on AI, Labor, and the Future of Entertainment\nA license should defaults to saying no to something that is newly developed in the present that hasn’t been included in the past when the contract/license was signed. Opt-in should be the assumed option, especially regarding to user data and user information1.\nThings change, and we could never imagine what it is like in three years, let alone a decade. When platforms or companies acquire some licences, it should never be all-encompassing and future-proof. It should be assumed under the current circumstances in the days to come. Drastic technological changes do happen, and when it comes, right owners should have a chance to discuss what should be updated. This is the least amount of respect we should pay for human labour and human creativity.\nLike anonymization worked maybe 10 years ago, but now de-identification works more efficiently enabled by powerful statistical models and big data, should our consent be withdrawl with such emergence of technology? If not, it is reasonable to believe that everyone who consented to share anonymised information now will be pretty much surfing the Internet naked in 10 years.\nEven beyond formal agreements, we have to fight constantly with small consent traps such as marketing emails, mailing lists, TOS updates buried with legalese and sometimes outright spams2.\nBut changes in the society are difficult and vague to measure. How to corporate such condition into a formal licence agreement?\nFootnotes\n\n\nThe Tech Industry Doesn’t Understand Consent - Dhole Moments ↩\n\n\nI’m going to keep opting out • Cory Dransfeldt ↩\n\n\n"},"notes/20230730185747":{"title":"Oil Spill in Our Information Ecosystem","links":["highlights/Matter/“Ensuring-Safe,-Secure,-and-Trustworthy-AI”--What-those-seven-companies-avoided-committing-to","highlights/Readwise/36129681","highlights/Matter/A-Concerning-Trend","notes/20230212190751","highlights/Omnivore/20240302192225","highlights/Readwise/36715976"],"tags":[],"content":"Oil Spill in Our Information Ecosystem\nA metaphor mentioned in “Ensuring Safe, Secure, and Trustworthy AI”- What those seven companies avoided committing toThe Expanding Dark Forest and Generative AI]].\nThe oil spill — the spread of misinformation or unreliable generation at a much larger scale thanks to popularised Generative AI — impacts the people who receive the information (e.g. The I in LLM Stands for Intelligence, A Concerning Trend) and pollutes the ecosystem as a whole, making trust and authenticity increasingly harder to find and give.\nEven worse, the information does not have to be wrong or made up — partial information or outdated information can be as effective in events like election1.\nMoreover, the problem is compounded when such spills get picked up as the training data for the next iteration (a.k.a The Model CentipedeMultifaceted: The Linguistic Echo Chambers of LLMs]]\nEven more LLMs, we have enough SEO-engineered websites lurking in the search results, but now LLM-enabled or LLM-targeted spams will likely make it worse2.\nFootnotes\n\n\nSeeking Reliable Election Information? Don’t Trust AI ↩\n\n\nGoogle Search Really Has Gotten Worse, Researchers Find ↩\n\n\n"},"notes/20230730192851":{"title":"Transference and Anthropomorphization","links":["highlights/Matter/‘A-certain-danger-lurks-there’--how-the-inventor-of-the-first-chatbot-turned-against-AI","notes/20230305142934"],"tags":[],"content":"Transference and Anthropomorphization\nIn psychotherapy, transference refers to people projecting their past feelings onto someone in the present. A great metaphor from ‘A certain danger lurks there’- how the inventor of the first chatbot turned against AI:\n\nWhen we interact with other people, we always bring a group of ghosts to the encounter. The residue of our earlier life, and above all our childhood, is the screen through which we see one another.\n\nTransference and Anthropomorphization make a potent combination when interacting with a chatbot. People project their past experience interacting with human beings in similar interfaces onto the current one and attribute human characteristics and abilities to the chatbot. This is also called the “Eliza effect”1.\nFootnotes\n\n\n‘A certain danger lurks there’- how the inventor of the first chatbot turned against AI ↩\n\n\n"},"notes/20230730194105":{"title":"AI Alignment","links":["highlights/Matter/Eugenics-and-Longtermist-Effective-Altruism-Share-the-Same-Original-Sin","highlights/Matter/‘A-certain-danger-lurks-there’--how-the-inventor-of-the-first-chatbot-turned-against-AI"],"tags":[],"content":"AI Alignment\nTransclude of Eugenics-and-Longtermist-Effective-Altruism-Share-the-Same-Original-Sin#^34c39d\nTransclude of ‘A-certain-danger-lurks-there’--how-the-inventor-of-the-first-chatbot-turned-against-AI#^87423f\nAlignment is problematic in the sense that even if it is successful, people will attribute more power and more decision-making judgments to a model and therefore avoid responsibility. And the reality is that it is not even remotely perfect, and people are already shifting all the burden and responsibility to the end recipient."},"notes/20230801194727":{"title":"AI and Crypto","links":["highlights/Matter/AI's-carbon-cost-explodes---TechScape","highlights/Readwise/35608105","highlights/Omnivore/20240303101549","highlights/Omnivore/20240303101258"],"tags":[],"content":"AI and Crypto\n\nBoth enjoy a lot of hype from both customers and investors, a lot of resources, and little regulation.\nBoth have impacted people’s lives and the environment1 2 3 4.\n\nFootnotes\n\n\nAI’s carbon cost explodes | TechScape ↩\n\n\nCory Doctorow: What Kind of Bubble Is AI? ↩\n\n\nAI Is Taking Water From the Desert - The Atlantic ↩\n\n\nGenerative AI’s environmental costs are soaring — and mostly secret ↩\n\n\n"},"notes/20230806114127":{"title":"Hijacked Transference","links":["notes/20230212204146","notes/20230730192851","notes/20230305142934","highlights/Matter/Why-Open-Source-Matters"],"tags":[],"content":"Hijacked Transference\nWe already know how AI models take advantage of our tendency to anthropomorphise1 2, but now we also witness companies and people, unknowingly or not, taking advantage of words or phrases that we used to have a clear understanding:\n\nCalling their release of a model as open-sourcing while imposing usage restrictions3;\nCalling unreliable model synthesis a hallucination;\nCalling capitalisation as Democratization;\n\nAdmittedly, language is supposed to change and adapt to our reality. Still, we should be careful when such a phenomenon emerges and pause to ask whether this change is warranted.\nFootnotes\n\n\nTransference and Anthropomorphization ↩\n\n\nAnthropomorphizing AI ↩\n\n\nWhy Open Source Matters ↩\n\n\n"},"notes/20230807135404":{"title":"Language Fluency Fallacy","links":["highlights/Matter/Language-Is-a-Poor-Heuristic-for-Intelligence","notes/20230806114127"],"tags":[],"content":"Language Fluency Fallacy\nSource: Language Is a Poor Heuristic for Intelligence\nEquating language fluency with intelligence and inarticulacy with unintelligence.\nOftentimes, people assume others are unintelligent because they can’t speak or speak fluently. This is a completely false narrative — e.g., kids with autistic or hearing disabilities have fully ‘normal’ intelligence by any type of measurement people normally conduct.\nBut this fallacy has been transferred to our interactions with LLM-based chatbots, even though from the opposite perspective. With another fallacy that computer-generated information is accurate and unbiased, this creates a discrepancy where AI bros are eager to fill with hype and promises while reaping the profits1.\nFootnotes\n\n\nLanguage Is a Poor Heuristic for Intelligence ↩\n\n\n"},"notes/20230819190717":{"title":"Corporate Programmer","links":["highlights/Matter/Don't-Call-Yourself-A-Programmer,-And-Other-Career-Advice"],"tags":[],"content":"Corporate Programmer\nSource: Don’t Call Yourself A Programmer, And Other Career Advice\nGoals\nIn a corporate setting, programmers are workers who drive revenue and cost with programming, hopefully not in the same direction. They usually aren’t incentivised to produce elegant software from a company level. Individuals might aspire to do so, but this is hardly a work thing any more. Work to live, don’t live to work.\nFriends\nYou may find a few good friends, but trying to make everyone your friend is a waste of time. With that being said, being kind to people is always a no-brainer.\nCommunication\nIt is important. You are selling something to someone, internally or externally.\nReading\nRead something about negotiation. This helps for your career even though it sounds cringe. There are people who are better at negotiation, just like how you are better at programming. And imagine that with money on the line."},"notes/20230819192858":{"title":"Craftsmanship, Creation and Commoditization","links":["highlights/Matter/That-which-is-unique,-breaks","notes/20230205125210"],"tags":[],"content":"Craftsmanship, Creation and Commoditization\nInspiration: That which is unique, breaks\nOur uniqueness in being human and being creative is becoming rarer. Modern industrialization renders any societal problem instead of a human problem but a commodity problem. This also influences how we, humans, perceive society — social networks, shopping websites, and corporate jobs — human interactions and creativity are reduced to binary code.\nWhat are we losing and would we ever get them back?\nAI systems with a view from nowhere and their synthetic output are another example of the commoditization of our language. What are we losing if we are not Being Human."},"notes/20230821203733":{"title":"DORA Metrics","links":["highlights/Matter/Yes,-you-can-measure-software-developer-productivity"],"tags":[],"content":"DORA Metrics\nSource: Yes, you can measure software developer productivity\nA set of developer productivity metrics from Google’s DevOps research and assessment team:\n\nDeployment frequency: how often is the code being successfully deployed;\nLead time for changes: time needed from code being committed to production;\nTime to restore service: how long it takes to restore service if there is an outage or a bug;\nChange failure rate: what percentage of changes that are committed lead to service degradation;\n"},"notes/20230821204329":{"title":"SPACE Metrics","links":["highlights/Matter/Yes,-you-can-measure-software-developer-productivity","notes/20230821203733"],"tags":[],"content":"SPACE Metrics\nSource: Yes, you can measure software developer productivity\nSimilar to DORA Metrics, SPACE metrics are another set of metrics to measure developers’ productivity;\n\nReferences:\n\nThe SPACE of Developer Productivity - ACM Queue\n"},"notes/20230827114217":{"title":"Stolen Attention","links":["highlights/Readwise/31596656","notes/20220724212820","highlights/Readwise/31960083","notes/20230520144243","highlights/Readwise/31926452"],"tags":[],"content":"Stolen Attention\nInspiration: Attention didn’t collapse. It was stolen (2022)\nOur attention span is shrinking, and it is a societal and technological result that individuals rarely can resist: modern technology creates an illusion that we are good at multitasking1 and that our productivity is improved, but it is quite the opposite2. And every social network company is trying to get us hooked with unlimited feeds and interactions3 4 5.\nLike any other societal issue, fighting alone or individual abstinence is not enough. It does not address the root cause that requires a seismic shift in every fabric of society: regulation, education, and more.\nFootnotes\n\n\nMultitasking ↩\n\n\nOn Tools and the Aesthetics of Work ↩\n\n\nAI and Productivity ↩\n\n\nAttention didn’t collapse. It was stolen (2022) ↩\n\n\nAn Ancient Technique Can Improve Your Attention Span ↩\n\n\n"},"notes/20230902132142":{"title":"Return-to-Office and Productivity","links":["highlights/Readwise/31554997","notes/20230821203733","highlights/Readwise/31795305","notes/20230904205252","highlights/Omnivore/20240221132924","highlights/Readwise/37242673"],"tags":[],"content":"Return-to-Office and Productivity\nHypotheses:\n\nIt’s always been done like this;\nIf I can see you at work, you must be working;\n\n#1 and #2 always seem to go hand in hand when it comes to office productivity. The underlying assumption that being present in the office is productive is as absurd as it can get.\nIt is about control and manageral incompetency in evaluating and setting goals1 2 3.\nDo employers really care how things get completed when the deliverables planned are shipped on time? Unless you are micromanaging, then not really. The issue is that they are terrible at planning and communicating those targets, let alone managing expectations. When showing up in the office is the only way they can grasp how much “effort” you are putting in, this becomes the metric black hole phenomenon mentioned in Deep Work.\nBut is it possible to measure productivity? There are some metrics like DORA MetricsSPACE Metrics]], but they are often only effective in theory4.\nFootnotes\n\n\nAmazon Is Wrong – A Return-to-Work Mandate Is About Control ↩\n\n\nPolitical Capital as a Service ↩\n\n\nRTO Policies Don’t Improve Employee Performance or Company Value ↩\n\n\nCEOs Are Using Return to Office Mandates to Mask Poor Management ↩\n\n\n"},"notes/20230904205252":{"title":"Political Capital as a Service","links":["highlights/Matter/Yes,-you-can-measure-software-developer-productivity","highlights/Readwise/31866739"],"tags":[],"content":"Political Capital as a Service\nConsulting companies are hired to help executives justify programs in the company, e.g., by generating a report by external experts1.\nRelated:\nYes, you can measure software developer productivity\nFootnotes\n\n\nOn Productivity Metrics and Management Consultants ↩\n\n\n"},"notes/20230904205718":{"title":"Self-care and Well-being Habits","links":["highlights/Readwise/31837316"],"tags":[],"content":"Self-care and Well-being Habits\nSource: Not Giving Up on Happiness: Care of the Self and Well-Being in a Plague Year\n\nGratitude and self-affirmation: It might sound cringe at first, but positive thinking can unconsciously impact our behaviours.\nHope: Similar to the first one, a positive outlook on the future is also important;\nDistractions, distance, and dispute: create distractions when our minds are preoccupied with negative thoughts, creating a distance between them and your focus, and you can face those thoughts and try to dispute them.\n"},"notes/20230906091719":{"title":"Financial Safety","links":["highlights/Readwise/31885386"],"tags":[],"content":"Financial Safety\nSource: Harry Browne’s 17 Golden Rules of Financial Safety (2013)\n\nFocus more on building your career instead of your investment;\nNo one can predict the future, and a perfect track record should not warrant any more trust;\nNo one else can treat your money with the same respect you do;\nDon’t invest on a whim. When in doubt, go safe;\nEvery investment waxes and wanes;\nDiversify and be aware of geopolitical vulnerabilities;\nKeep a safety net;\nTo bet as if you can afford the loss;\n"},"notes/20230906092705":{"title":"Salary Negotiation","links":["highlights/Readwise/31897259"],"tags":[],"content":"Salary Negotiation\nSource: How to Sabotage Your Salary Negotiation Efforts Before You Even Start\n\nRecruiters have different stakes and incentives;\nCollect information instead of giving:\n\nNever give a number^b1a6a5;\nControl the timeline by not sharing the timeline^464924;\nNo need to rush^9539aa;\nBe async in communication^9a705d;\n\n\n"},"notes/20230907185541":{"title":"Peer Review","links":["highlights/Readwise/31926543"],"tags":[],"content":"Peer Review\nSource: Scholarship Should Be Open\nThe peer review process lends some credit to a paper but does not guarantee its quality and accuracy. In this sense, preprinting services should be used only to share information — quality checked to the best possible degree or life-saving urgent —  more quickly without publishing overhead, instead of flag planting.\nTransclude of 31926543#^2f718b\nResearchers who are trying to find relevant information to cite are less critical compared with reviewers about the work and more biased towards papers that align with our preferences."},"notes/20230907190825":{"title":"Slow Scholarship","links":["highlights/Readwise/31926543"],"tags":[],"content":"Slow Scholarship\nInspiration: Scholarship Should Be Open\nSlow productivity in research.\nPeople using preprint services as a way of flag planting create a hostile “if-not-latest-then-irrelevant” research environment. People who cite preprint versions of a paper, instead of the peer-reviewed one when possible are subsequently biding such behaviour."},"notes/20230910190203":{"title":"Minimalism and the Good Design Principles","links":["highlights/Readwise/32039087"],"tags":[],"content":"Minimalism and the Good Design Principles\n\nIndifference towards people and the reality in which they live is actually the one and only cardinal sin in design.\n— Dieter Rams\n\nDieter Rams proposed the Good Design Principles, according to which good design should:\n\nbe long-lasting;\nbe innovative;\nbe eco-friendly;\nbe esthetic;\nbe honest;\nbe unobtrusive;\nbe thorough down to the last detail;\nbe as little design as possible;\nmake the product useful;\nmake the product understandable;\n\nSometimes, you see designs that might have taken those principles too literally: compounding 10 finger dances into two buttons to maximize #8, yet completely disregard #91. Little design does not mean stripping away most of the functionalities, just like minimalism does not mean frugal or stoic living. There might be some overlap, but that’s not what there is about each practice;\nSome of them look perfect on paper, but when a company succumbs to the market pressure to churn out generations of products with shorter and shorter life-span, being eco-friendly and long-lasting becomes a luxury that few people can afford;\nFootnotes\n\n\nMinimalism Is Getting Absurd: Updating Dieter Rams’ 10 Principles ↩\n\n\n"},"notes/20230910194243":{"title":"Engineer Productivity","links":["notes/20230821203733","notes/20230821204329","highlights/Matter/Yes,-you-can-measure-software-developer-productivity","highlights/Readwise/32039006"],"tags":[],"content":"Engineer Productivity\nIf all you can measure is around the artifacts (code, features, bugs, time, satisfaction, etc.)1 2 3, you can’t really gauge some aspects of an engineer’s work, such as contribution to the team culture, personal growth, or collaboration environment; Such glue work and liaison can rarely be reflected in the rigid evaluation metrics4;\nFootnotes\n\n\nDORA Metrics ↩\n\n\nSPACE Metrics ↩\n\n\nYes, you can measure software developer productivity ↩\n\n\nThe Worst Programmer ↩\n\n\n"},"notes/20230910195033":{"title":"Metapreneurs","links":["highlights/Readwise/32036485"],"tags":[],"content":"Metapreneurs\nSource: Beware the Metagame\nPeople who are good at playing metagames — publishing a book or speaking at conferences about a topic — but never actually practice what they preach."},"notes/20230911203601":{"title":"A Good Sleep Habit","links":["highlights/Archive/Pocketbook/Why-We-Sleep-Unlocking-the-Power-of-Sleep-and-Dreams/metadata","notes/20230911204127"],"tags":[],"content":"A Good Sleep Habit\nSource: Why We Sleep Unlocking the Power of Sleep and Dreams\nA good sleep habit is also a good learning habit and a good well-being habit. Unfortunately, it is vulnerable to any disruptions so consistency is the key to leveraging this passive time into an active personal growth session.\n\nReduce caffeine and alcohol intake;\nRemove screens (blue lights) from your bedroom and therefore alertness from your system;\nHave a cool bedroom to facilitate your falling asleep;\nHave a regular bedtime and wake-up time;\nOnly go to bed when you are sleepy, avoiding irrelevant associations with your bed;\nAvoid daytime naps to maintain a high sleep drive;\nReduce active thoughts before bed, by journaling or meditation;\nThere is no need for a clock in the bedroom;\n"},"notes/20230911204127":{"title":"Alcohol is Bad for Your Sleep","links":[],"tags":[],"content":"Alcohol is Bad for Your Sleep\nEven though it might feel the opposite, alcohol-induced sleep is more like a medically induced sedation. It does not offer the same benefits as real sleep does."},"notes/20230916180806":{"title":"A Distort Social Media","links":[],"tags":[],"content":"A Distort Social Media\nWe see both inspiring stories and tragedies in the news, but when it comes to our social network, we rarely share the other side of our lives. It paints a distorted version of our lives by presenting only the glamorous events and deprives us of the chance to show support."},"notes/20230916182623":{"title":"Executive Function Theft","links":["notes/20230916182623","highlights/Readwise/32218243","highlights/Readwise/31554997"],"tags":[],"content":"Executive Function Theft\nSource: Executive Function Theft\nTransclude of 32218243#^8cbdd1\nEFT can manifest as many things in different settings. In the workplace, many administrative processes are added to deter employees from filing reimbursement or claiming benefits. In a relationship, housework and chores — the ones usually undertaken by the female partner — leave no room for the wife’s personal growth.\nUnlike what is described in Deep WorkGlue Work Theory]], makes it impossible to allow deep work in the first place, no matter how much we desire it internally."},"notes/20230916193545":{"title":"Short-form Reading is No Reading At All","links":[],"tags":[],"content":"Short-form Reading is No Reading At All\nYou can’t read a book by its summary, or worse, its cover. It is like noting the existence of a book by touching it with a feather in one of your meditation sessions. You may have a good guess on what it is about, but you never truly understand the depth of authors’ arguments, nor the evidence they present."},"notes/20230924111842":{"title":"LLMs Fail at Simple Commonsense Reasoning","links":["highlights/Zotero/berglund_","highlights/Readwise/32454213"],"tags":[],"content":"LLMs Fail at Simple Commonsense Reasoning\nIt shows a failure mode that even the state-of-the-art models can’t escape: when “knowing” A→B, it can’t reliably predict the reverse relation, namely B→A1.\nThis highlights the gap between the AI hype and reality. People are more willing to accept or even advertise a model’s success while completely ignorant or even intentionally blind to obvious problems that have surfaced2.\nFootnotes\n\n\nThe Reversal Curse: LLMs trained on “A is B” fail to learn “B is A” ↩\n\n\nElegant and Powerful New Result That Seriously Undermines Large Language Models ↩\n\n\n"},"notes/20230924115312":{"title":"Setting Goals vs. Setting Process","links":["notes/20220724212820","notes/20230523162036","highlights/Readwise/32454089"],"tags":[],"content":"Setting Goals vs. Setting Process\nA goal is binary. You either achieve it or not. However, associating all of your happiness, fulfilment, and self-worth only with a single event is detrimental to your mental health and growth1.\nYou might feel focused or even productive when fixating on the goals, but just as Multitasking, it is an illusion that can actually cloud our judgement and impair our performance due to pressure, performance anxiety, anticipation, and uncoordinated decision-making — your mind might know what you want, but your action is at lost.\nInstead of targeting the goals, it is more useful to develop a concrete plan or strategy for those goals first, then focus on the process or steps instead. Trust the process, or “尽人事听天命” as the Chinese saying goes.\nBut how can we reconcile this with Manifesting Magic? Having goals seems to be a double-edged sword. On one hand, it promotes motivation and the idea that the whole universe is conspiring to help you. On the other hand, it deprives you of the attention and energy that could have been spent on the tasks at hand.\nMaybe there is a spectrum for goal setting with a sweet spot where it nudges you in the right direction but not too forcefully to derail your performance. Maybe revisiting the goals and plans occasionally is one solution, while normally, it sits on the back burner of your brain.\nFootnotes\n\n\nWhen I Stopped Trying to Self-Optimize ↩\n\n\n"},"notes/20230924122835":{"title":"Representation-washing","links":["highlights/Zotero/kudugunta_2023"],"tags":[],"content":"Representation-washing\nLike greenwashing, representation-washing touts a dataset being multilingual or multi-cultural, but in fact, such diversity is met with low-effort support or minimal forethought1.\nFootnotes\n\n\nMADLAD-400: A Multilingual And Document-Level Large Audited Dataset ↩\n\n\n"},"notes/20230924205052":{"title":"When We Talk about Open Source","links":["highlights/Readwise/32454748"],"tags":[],"content":"When We Talk about Open Source\nOne thing is clear: We are not prescribing it as a panacea when discussing models or datasets, especially in the Generative AI era. It does not automatically guarantee the code or conduct related to the artefacts shared is any more secure or ethical.\nOpen source means a chance to pry open the black box, examine, criticise, and enhance. As a result, it speeds up progress for the community by allowing individuals to create incremental research, ensuring that this foundation is more durable than certain APIs controlled by centralised entities1.\nEven without the actual release, by simply setting out to be open-source, you are priming yourself or the project for a higher standard1.\nFootnotes\n\n\nWorkshop on Responsible and Open Foundation Models ↩ ↩2\n\n\n"},"notes/20231001183227":{"title":"Situated Language-Using Framework","links":["highlights/Zotero/schlangen_2023","notes/20221120094433"],"tags":[],"content":"Situated Language-Using Framework\nSource: What A Situated Language-Using Agent Must be Able to Do: A Top-Down Analysis\nWhat does it mean to be an agent with situated language-using capability?\nIt needs to have representations of the language, the world (Cognitive Model), the situation, the discourse, and itself and other agents in the interaction. It dynamically and incrementally learns and processes new information as the discourse progresses.\nSituation Model\n\nActual situation: the situation where the interaction happens.\nReported situation: the situation based on a description.\nSocial situation: the social context that could be manifested in the conversation.\n\nDiscourse Model\nUsed to determine coherence.\nAgent Model\nEmbodied beliefs, desires, and intentions.\nHaving the abovementioned models is not enough. The constantly changing interplay of those models and utterances necessitates the ability to process and learn any given new information incrementally.\nAs outlined above, to meaningfully become an independent and free agent, the context the agent has to work with is quite intricate and sizable. Admittedly, we are good at tackling problems with a bottom-up angle, dissecting the large problem into workable pieces. However, given the current research directions and seemingly overlook of the fuller picture, we need to consider the complexity more seriously."},"notes/20231112144602":{"title":"The Innovator’s Dilemma","links":["highlights/Matter/Why-Google-Missed-ChatGPT","highlights/Readwise/33921768","highlights/Omnivore/20240208231926","highlights/Omnivore/20240303180744"],"tags":[],"content":"The Innovator’s Dilemma\nA company may halt or slow down its innovation to not disrupt its existing product or market, which has been proven successful in the past.\nOne prime example is Google Search, with the recent launch of Bard. “Google thus has little incentive to move us beyond traditional search, at least not in a paradigm-shifting way, until it figures out how to make the money aspect work. In the meantime, it’ll stick with the less impressive Google Assistant.”1\nAnother example is research. Scientists withhold their study details as much as possible — just enough to pass the peer review — to pave the way for future research with less competition2.\nLuckily, this inevitably creates some growth space for startups who have nothing to lose and everything to gain by providing disruptive services against big corps. With that being said, the infrastructure and data policies wielded by those gigacompanies cast a long shadow despite anti-monopoly laws — they have more than sufficient financial and political capital to cover for campaigns, compliance, fines, and acquirements3 4.\nFootnotes\n\n\nWhy Google Missed ChatGPT ↩\n\n\nThe Business of Extracting Knowledge From Academic Publications ↩\n\n\nPluralistic: Big Tech disrupted disruption (08 Feb 2024) – Pluralistic: Daily links from Cory Doctorow ↩\n\n\nAI startups require new strategies: This time it’s actually different ↩\n\n\n"},"notes/20231112150628":{"title":"Observational Evidence Can Produce Only Correlations","links":["highlights/Readwise/33743630","highlights/Matter/Thought-experiment-in-the-National-Library-of-Thailand"],"tags":[],"content":"Observational Evidence Can Produce Only Correlations\nSource: They Studied Dishonesty. Was Their Work a Lie?\nIf text modelling can be considered an observational study conducted by running the data through the model, then the model can only learn the textual correlations, not the underlying minds or views, and certainly not the worlds. This is very similar to the Thought experiment in the National Library of ThailandForm, Meaning, and Communicative Intents]]."},"notes/20231112154432":{"title":"Avoid Losing","links":["highlights/Readwise/33687604"],"tags":[],"content":"Avoid Losing\nAiming to win in a game requires professional skills, but aiming not to lose is a more suitable mindset when we are just amateurs1.\nFootnotes\n\n\nAvoiding Stupidity Is Easier Than Seeking Brilliance ↩\n\n\n"},"notes/20231112155126":{"title":"Passion is Developed","links":["highlights/Readwise/32664723"],"tags":[],"content":"Passion is Developed\nSource: Stop Trying to ‘Find’ Your Passion—There’s a Better Way to Love What You Do\nIt is rarely found or inherited.\nIt is often sparked by curiosity and curated by persistent engagement, knowledge acquirement, and internalised interest and experience. That is to say, we shouldn’t confine ourselves to the few options we have encountered. There is a lot to explore in different domains, as much as the ones we have previously deemed incompatible at first glance."},"notes/20231119113426":{"title":"Risk is What You Don't See","links":["highlights/Readwise/34276321","notes/20230123141334","notes/20221224153623"],"tags":[],"content":"Risk is What You Don’t See\nReference: Same as Ever\nRisk is unpredictable and unknown beforehand. It surprises you even when you meticulously plan and prepare for the risks you have imagined.\nBeing Ready to be interrupted or surprised. When it happens, face it1.\nFootnotes\n\n\nRisk and Fear ↩\n\n\n"},"notes/20231119114746":{"title":"Comparison to Our Own Detriment","links":["highlights/Readwise/34276321"],"tags":[],"content":"Comparison to Our Own Detriment\nSource: Same as Ever\nEven though our physical well-being and wealth have improved substantially over the decades, we rarely feel content.\nThis is because we are setting the reference point to people around us. When we look around, the constant performance on social media makes it even harder to get the comparison out of our heads. “I could and should have the same” is a powerful mental incantation that silently kills our happiness."},"notes/20231119115937":{"title":"Valuable Things in Life Do not Have a Price Tag","links":["highlights/Readwise/34276321"],"tags":[],"content":"Valuable Things in Life Do not Have a Price Tag\nSource: Same as Ever\nHealth, eyesight, relationships, or freedom are often on the backburners of our minds because we prioritise material possessions.\nIf we spend time and money on those aspects of our lives, we don’t expect monetary returns and, therefore, they are less appealing for any investment to begin with."},"notes/20231119120516":{"title":"Certainty Over Probability","links":["highlights/Readwise/34276321"],"tags":[],"content":"Certainty Over Probability\nMost people can’t interpret probability and prefer certainty over any other metrics. They want black-and-white results1.\nThat’s probably why people trust more when the text is more authoritative and confident, and chatbots are “playing” dangerous mind tricks.\nFootnotes\n\n\nSame as Ever ↩\n\n\n"},"notes/20231119121157":{"title":"Good Story-telling is a Shortcut","links":["highlights/Readwise/34276321"],"tags":[],"content":"Good Story-telling is a Shortcut\nTransclude of 34276321#^0d9a61\nIt is a shortcut to gain trust and attention."},"notes/20231125104220":{"title":"Resisting a Default Future","links":["highlights/Readwise/34375849","notes/20231125105613","notes/20231112144602","notes/20231119120516"],"tags":[],"content":"Resisting a Default Future\nSource: Want to Upgrade Your Brain? Stop Doing These 7 Things Immediately.\nTo be intentional about your future, establish specific and clear goals and visions, a.k.a Massive Transformative Purpose (MTP). This also means you should foster Deliberate Practice Over Habits, resisting default behaviours or staying in your comfort zone.\nThis challenges our instincts that err on the certainty side1 as we grow into adulthood. Much like The Innovator’s Dilemma in business, we stop taking risks and operating out of need in our personal lives.\nFootnotes\n\n\nCertainty Over Probability ↩\n\n\n"},"notes/20231125105613":{"title":"Deliberate Practice Over Habits","links":["highlights/Readwise/34375849","highlights/Readwise/31554998"],"tags":[],"content":"Deliberate Practice Over Habits\nSource: Want to Upgrade Your Brain? Stop Doing These 7 Things Immediately.\nHabits, as in Atomic Habits, is an over-marketed word; in essence, it should have been deliberate practice. Habitual behaviours don’t lead to improvement. Only deliberate practice can and will, in which sense, a habit of deliberated practice is the only habit you can have to improve."},"notes/20231126210202":{"title":"Why Do We Complain?","links":["highlights/Readwise/34610927","highlights/Readwise/36025762","highlights/Readwise/36537373"],"tags":[],"content":"Why Do We Complain?\nWhen we complain, we feel good momentarily because it feels like we are being more critical and smarter.\nHowever, it is a sign of low self-esteem when we masquerade with constant complaints to feel good about ourselves1.\nBeing cynical or hostile to the outside world makes us feel safe, but it will become difficult to imagine a better future if we can’t positively talk about it2 3.\nFootnotes\n\n\nHow to Stop Complaining So Much? ↩\n\n\nChoose Optimism ↩\n\n\n3-2-1: On Saving Money, Controlling Your Anger, and What Love Looks Like ↩\n\n\n"},"notes/20231202211533":{"title":"Alignment is a Brittle Afterthought","links":["highlights/Readwise/34840312"],"tags":[],"content":"Alignment is a Brittle Afterthought\nSource: Model Alignment Protects Against Accidental Harms, Not Intentional Ones\nAt least by its current design.\nIt is often treated as an afterthought, making it optional in academia and industry. Consequently, we find ourselves in a world with aligned and unaligned models, influenced by decision-makers who often share no experience with the resulting harms.\nWhile methods like RLHF have made models much safer to use, it is important to acknowledge their imperfections and be cautious about too much reliance on them."},"notes/20231203142406":{"title":"Speculative Decoding","links":["highlights/Zotero/leviathan_2023"],"tags":[],"content":"Speculative Decoding\nSource: Fast Inference from Transformers via Speculative Decoding\nDecoding easy tokens should not require a full forward pass of a dense model, as this can be achieved using a relatively small one at a lower cost. Consider a large model, denoted as p, and a small model, denoted as q.\nThe process is as follows:\n\nGenerate γ tokens using q;\nEvaluate those tokens using p with token probabilities and distributions. Additionally, an new token distribution after γ tokens is also available;\nAccept the prediction xt​ of q if pq​(xt​)≤pp​(xt​) or accept with a probability pq​(xt​)pp​(xt​)​.\nIf rejected, then sample xt​ again from the (Pp​(x)−Pq​(x))+​. This is proven to be equivalent to sampling directly from p;\n\nThis process is guaranteed to generate at least one token from p and at most γ+1 tokens, all in one go.\nWhen adopting this method, there are a few parameters that require attention:\n\nHow good is the small model at approximating the large one’s distribution α?\nHow many tokens are outsourced to the small model γ?\nHow cost-effective is the small model compared to the large model c?\n"},"notes/20231206211525":{"title":"Paperclip Maximizer","links":["highlights/Readwise/35084810"],"tags":[],"content":"Paperclip Maximizer\nTransclude of 35084810#^6cc420\nExistential risks aside, the idea that models, no matter how innocuously designed, can cause harm to humans is on the spot.\nIt brings us to the idea that placing regulations on the models themselves is a misguided policy. As these models lack agency or any kind of affordance of responsibility (going on a trial or to jail), it is the humans — the model controllers — that should be regulated1.\nFootnotes\n\n\nAI and Trust ↩\n\n\n"},"notes/20231206213457":{"title":"Reading with Cognitive Models","links":["highlights/Readwise/31554993","highlights/Readwise/35143536","notes/20220730154644","notes/20220709195323"],"tags":[],"content":"Reading with Cognitive Models\nBooks or lectures are passive mediums, meaning they don’t actively distil the knowledge directly into your mind. They don’t have an active cognitive model that encourages you to understand, reflect, or apply what you have been reading or listening to. That’s why plain reading or simply taking quotes in a notebook cannot magically make you remember anything. You have to make an intentional effort to understand the content by paraphrasing, summarization, or active recalling1.\nThis is very similar to what is mentioned in How to Take Smart Notes where notes are supposed to be in your own words2 3.\nFootnotes\n\n\nWhy books don’t work ↩\n\n\nImportance of Note-taking When Reading ↩\n\n\nOnly Writing Counts ↩\n\n\n"},"notes/20231211203544":{"title":"Addictive Atomic Habits","links":["highlights/Readwise/35283632"],"tags":[],"content":"Addictive Atomic Habits\nReference: Smartphone and Internet Addiction: The Definitive WIRED Guide\nThere are psychological factors behind those recommendation systems. Social media companies use the same trick  — triggers or cues (notifications), motivation (FOMO), and ease of access (mobile apps) — as what we use in fostering atomic habits.\nThey also leverage our negative emotions, such as boredom, loneliness, and frustration, to lure us into mindless consumption that temporarily takes our minds off those negative emotions.\nIt’s a potent combination, indeed. The same can also be used for education: Duolingo is a perfect example."},"notes/20231214212913":{"title":"Hallucination is Here to Stay","links":["notes/20230115161911","highlights/Omnivore/20240218005541","highlights/Omnivore/20240216200449","highlights/Readwise/32882444","highlights/Matter/ChatGPT-Is-a-Blurry-JPEG-of-the-Web","highlights/Matter/“If-It-Sounds-Like-Sci-Fi,-It-Probably-Is”","highlights/Readwise/36269821"],"tags":[],"content":"Hallucination is Here to Stay\nOn the surface, the word itself is too anthropomorphic — ascribing too much psychological affordance to a neural network. It also euphemises the underlying unreliable synthesis — essentially Bullshit — as if it is something we can get rid of easily with a panacea.\nUnfortunately, it seems that the name and the underlying phenomena are here to stay1 2.\nAll model generations are unreliable, but some are more useful than others. People also said that hallucination, to the model itself,  is the feature, not the bug, but a bug indeed at the system/assistant level, and they deem it fixable3. Others share little of such optimism4 5 6.\nBut it also has a good side — it reminds you to fact-check the output if you care enough, and it might be a good source of brainstorming, too7.\nFootnotes\n\n\nSora Can’t Handle the Truth - by Gary Marcus - Marcus on AI ↩\n\n\nSora’s Surreal Physics - by Gary Marcus - Marcus on AI ↩\n\n\n[[35423015|# On the “hallucination problem”]] ↩\n\n\nMuddles About Models ↩\n\n\nChatGPT Is a Blurry JPEG of the Web ↩\n\n\n“If It Sounds Like Sci-Fi, It Probably Is” ↩\n\n\nIn Defense of AI Hallucinations ↩\n\n\n"},"notes/20231219222518":{"title":"Techno-selectionism","links":["notes/20230307200456","highlights/Readwise/35608421"],"tags":[],"content":"Techno-selectionism\nAccepting that technology can improve our lives while believing we should have our chance to say no or choose an alternative without such technology1.\nA middle ground between techno-optimism and techno-skepticism. This echoes the power-over-technology spirit in A New Definition of LuddismAI Democratization]].\nFootnotes\n\n\nIt’s Time to Dismantle the Technopoly ↩\n\n\n"},"notes/20231223133219":{"title":"Scaling Dilemma","links":["highlights/Readwise/35724943","notes/20230924205052","highlights/Readwise/31926543"],"tags":[],"content":"Scaling Dilemma\nInspiration: Building AI Safety Is Getting Harder and Harder\nModel performance and size have steadily increased over the past decade, as have the complexity and cost of understanding such models and datasets.\nThis is why open source is important — it allows us to fix issues within1, and why research should be transparent, inclusive and slow2. On the other hand, open sourcing the data or model might give competitors or regulators leverage to be taken advantage of — a suitation where most laywers would advice you not to do so.\nFootnotes\n\n\nWhen We Talk about Open Source ↩\n\n\nScholarship Should Be Open, Inclusive and Slow ↩\n\n\n"},"notes/20231223134549":{"title":"Deliberate Practice of Thinking","links":["highlights/Readwise/35692505"],"tags":[],"content":"Deliberate Practice of Thinking\nSource: 3-2-1: On Friendship, the Secret to Focus, and How to Cultivate a Good Life\n\nWhat are you doing?\nWhy are you doing it?\nWhat are you trying to achieve?\n\nThinking allows us to be active instead of reactive in planning our lives. A well-lived life is well-cultivated, well-planned, and well-executed, not something stumbled upon."},"notes/20231224125929":{"title":"Interoperability","links":["highlights/Readwise/34276322"],"tags":[],"content":"Interoperability\nSource: The Internet Con: How to Seize the Means of Computation\nThe network effect is how companies lure you in, and switching costs ensure you never leave, as long as they are higher than the plain of staying.\nIf interoperability is permitted, which lowers the switching cost, they have to provide better services to convince their customers to stay."},"notes/20231224131140":{"title":"Feudal Security","links":["notes/20231224125929","highlights/Readwise/34276322","highlights/Omnivore/20240322170757"],"tags":[],"content":"Feudal Security\n\nFeudalism was a system in which people were given land and protection by people of higher rank, and worked and fought for them in return.\nCollins Dictionary\n\nThe security experts or guards won’t help you if the lord/company decides to betray your trust and invade your property/privacy, often because of conflicting interests such as profits. Moreover, they can also use anti-Interoperability to punish you for leaving1 2.\nFootnotes\n\n\nThe Internet Con: How to Seize the Means of Computation ↩\n\n\nPluralistic: The antitrust case against Apple (22 Mar 2024) – Pluralistic: Daily links from Cory Doctorow ↩\n\n\n"},"notes/20231224131830":{"title":"Tech Monopoly and Power Displacement","links":["highlights/Readwise/34276322","notes/20230212204146","notes/20231224132124"],"tags":[],"content":"Tech Monopoly and Power Displacement\nSource: The Internet Con: How to Seize the Means of Computation\nTransclude of 34276322#^2fad4f\nThat’s why we have AI Democratization movements pushing back to the unilateral corporate narratives.\nTransclude of 34276322#^522fca\nThat’s why decentralised social media like Mastodon and community-driven moderation are gaining more and more popularity now. One centralised value or policy should not dictate how we live and consume information1.\nFootnotes\n\n\nNothing About Us Without Us ↩\n\n\n"},"notes/20231224132124":{"title":"Nothing About Us Without Us","links":["highlights/Readwise/34276322"],"tags":[],"content":"Nothing About Us Without Us\n[Nihil novi nisi commune consensu)(en.wikipedia.org/wiki/Nihil_novi)\nCommunities should be involved, heard, and respected when policies are made about them.\nWhat happens with big tech companies is that they often design their products within a very limited scope of values and cultural backgrounds, and users from distant low-income nations usually don’t have a say, even if they are the target audience.\nTransclude of 34276322#^a5e43f"},"notes/20231224133355":{"title":"On What Preparedness Failed to Prepare for","links":["highlights/Readwise/35649908"],"tags":[],"content":"On What Preparedness Failed to Prepare for\nSource: Preparedness\nIt did not prepare us for the fact that this is simply a techno-solutionism x techno-optimism narrative, nothing more than an opinion piece.\nIt assumed that their models are inevitable and people should be prepared for what comes next after the models have been made. No questions shall be asked about why we need them in the first place, how they are being made, and what harm it has done during the process.\nAll is good as soon as the model is made because they have their best teams to mitigate the risks from those models, and they shall deliver. But they will not mitigate risks from the decisions to make the models or datasets in the first place, and certainly not from the motivations behind those decisions, as long as they still want to be employed.\nModels are shoved into our faces, and we are treated like guineanea pigs for their research and “continue learning” without compensation or acknowledgement. We deserve better."},"notes/20231226144848":{"title":"Language Interaction is a Spectrum","links":["highlights/Zotero/rasenberg_2023","notes/20231226150346"],"tags":[],"content":"Language Interaction is a Spectrum\nSource: Reimagining language: Towards a better understanding of language by including our interactions with non-humans\nUmwelten\n| ---- | ---- |\n| Human to Human | Yes |\n| Human to Animal | Yes |\n| Human to Machine | No |\n\nWhat is language, and who or what can be said to have it?\n\nDespite the evident limitations of language interactions with machines and animals, we need to include both types of interactions to create a more holistic understanding of the notions of language."},"notes/20231226150346":{"title":"Umwelten","links":["notes/20220625181723"],"tags":[],"content":"Umwelten\nAlso known as functional life worlds. Jakob von Uexküll proposed the framework to examine communications between humans and non-human animals. Such interactions happen in overlapping environments inhabited by different organisms.\nThis seems similar to the World KnowledgeForm, Meaning, and Communicative Intents]]."},"notes/20231231132200":{"title":"Sliding Window Attention","links":["highlights/Zotero/jiang_2023","highlights/Archive/Xiong-et-al.---2022---Simple-Local-Attentions-Remain-Competitive-for-Lon.textbundle/text"],"tags":[],"content":"Sliding Window Attention\nSource: Mistral 7B\ntext#^0125cb\nAt timestamp t, position i at layer l only attends to positions from i−W to i from the same layer, where W is the window size. Recursively, with k layers, one position can theoretically attend to k×W positions at the end."},"notes/20231231132641":{"title":"Rolling Buffer Cache","links":["highlights/Zotero/jiang_2023","notes/20231231132200"],"tags":[],"content":"Rolling Buffer Cache\nSource: Mistral 7B\nBecause of Sliding Window Attention, each position will only use O(W) amount of cache to store its results. By reusing the buffer cache with a rolling index, calculating the attention weights can use significantly less memory."},"notes/20231231134438":{"title":"Pre-filling and Chunking","links":["highlights/Zotero/jiang_2023","notes/20231231132200"],"tags":[],"content":"Pre-filling and Chunking\nTransclude of jiang_2023#^411f1d\nIf the prompt is already known before generation, then it is more efficient to pre-calculate the weights if Sliding Window Attention is used.\nThere is no need to calculate the entire attention matrix as well. One can chunk them into smaller blocks (usually by the window size) for faster and efficient calculation."},"notes/20240102215408":{"title":"What Does It Mean to Have Human-level Intelligence","links":["notes/20231214212913","notes/20231224133355","highlights/Readwise/36049180","highlights/Omnivore/20240205224636"],"tags":[],"content":"What Does It Mean to Have Human-level Intelligence\nSome argue that it is acceptable for models to “hallucinate”1 because humans make mistakes too.\nThe sampling/generation process is, as of today, not grounded in truth or fact-checked in any meaningful way, completely different from how humans make a mistake, intentionally or unintentionally. People do lie, fabricate, or cheat, that’s because we often have motivations and intentions to do so2.\nMoreover, it is crucial to consider the broader context: these models do not operate on the same scale as any human in any other axis. Despite this, they have been credited with unwarranted influence, agency, and audience yet afford no responsibility for any consequences.\nThough many AI companies boast about human-level intelligence, showcasing their ambition and commitment, few have clearly defined what it means. The ambiguity seems intentional as they can move the goalposts whenever they see fit, and the public, while can’t hold them accountable, still inevitably becomes their guinea pigs for their development.\nRelated:\nHallucination is Here to Stay\nOn What Preparedness Failed to Prepare for\nFootnotes\n\n\nHow Bad Are Search Results? Let’s Compare Google, Bing, Marginalia, Kagi, Mwmbl, and ChatGPT ↩\n\n\nDeconstructing Geoffrey Hinton’s weakest argument ↩\n\n\n"},"notes/20240105204049":{"title":"Techno-Feudalism","links":["notes/20231224131140","highlights/Readwise/36220511"],"tags":[],"content":"Techno-Feudalism\nA variation of Feudal Security by taking rents for the use of the resource/technology instead of profits from innovation, a.k.a subscription slavery, coined by Yannis Varoufakis1.\nFootnotes\n\n\nWe Are Turning Into Subscription Slaves ↩\n\n\n"},"notes/20240105204416":{"title":"Intellectual Humility","links":["highlights/Readwise/36213849"],"tags":[],"content":"Intellectual Humility\nSource: The Curious Joy of Being Wrong\nHumility, as in flexibility in adapting to different ideas or beliefs upon the presence of evidence and awareness of one’s limitation of knowledge. It should be the right size for a given situation, not too big (arrogance) or too small (self-deprecation)."},"notes/20240106112301":{"title":"Human Feedback Format","links":["highlights/Zotero/fernandes_2023"],"tags":[],"content":"Human Feedback Format\nA taxonomy from Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nTransclude of fernandes_2023#^005c23\nNumerical\nTypically, it is a score for a set of input and output. For example, a star system for a translation model:\nInput: This is an English sentence.\nOutput: 这是一句英语句子。\n---\nScore: 5\n\nIt can be easy to collect, but it is subjective and difficult to differentiate between ties. But in a similar fashion, one can extend this rating to multiple aspects, such as accuracy and fluency in this case.\nRanking\nThis moves beyond simple rating by ordering a set of output/responses. It is very useful in both evaluation and fine-tuning.\nInput: This is a very long story about a new fancy summarisation model. It was developed by a company called Magic Summarisation, located on a distant planet called Magic Planet.\n\nOutput 1:  A new summarization model developed by Magic Summarisation ...\nOutput 2: Magic Summarisation has developed a new model ...\nOutput 3: Magic Summarisation, from Magic Planet, has released a new summarisation model ...\n\n---\nRanking: 3 &gt; 2 &gt; 1\n\nNatural Language\nIt offers more nuance to scores and ranking because humans can add details to the feedback.\nInput: This is a very long story about a new fancy summarisation model. It was developed by a company called Magic Summarisation, located on a distant planet called Magic Planet.\n\nOutput: A new summarization model ...\n---\nMissing the company info.\n\nSuch feedback can also take on a more restricted or formatted style, such as post-edition:\nInput: This is a very long story about a new fancy summarisation model. It was developed by a company called Magic Summarisation, located on a distant planet called Magic Planet.\n\nOutput: A new summarization model ...\n---\nmodel -&gt; model developed by Magic Summarisation\n\nOr Multidimensional Quality Metrics:\nInput: This is a very long story about a new fancy summarisation model. It was developed by a company called Magic Summarisation, located on a distant planet called Magic Planet.\n\nOutput: A new summarization model ...\n---\nmodel -&gt; minor/completeness\n"},"notes/20240107164700":{"title":"The Dark Side of Computer Vision Research","links":["highlights/Zotero/kalluri_2023"],"tags":[],"content":"The Dark Side of Computer Vision Research\nSource: The Surveillance AI Pipeline\nMain takeaways:\n\nMost CV papers published by institutions and nations with downstream patents are used in surveillance, regardless of the subfield, specifically on human bodies, human body parts, human spaces, and socially salient human data.\nMany such papers and patents conflate humans as objects and, as a result, evade social and ethical consequences and responsibilities. On the surface, it presents the paper as technically objective, but in reality, it is always somewhat biased under “social and cultural norms, funding priorities, academic trends, researcher objectives, and research incentives”.\n\nFighting for our privacy has never been easy, but when the smartest of us are either trying to get our information, click some ads or become addicted to a platform, it certainly feels hopeless."},"notes/20240108192648":{"title":"Agentic Technology","links":["notes/20230506141008","highlights/Readwise/36390997"],"tags":[],"content":"Agentic Technology\nAn emergent new technology philosophy that sits between technology pessimism (e.g. existential risks and doomism) and Accelerationism — a balanced “enterprising optimism” that acknowledges both the good and bad of the technology1.\nFootnotes\n\n\nWhy Tech Needs a Rational, Humanistic “Third Way” ↩\n\n\n"},"notes/20240108194414":{"title":"AI Plagiarism","links":["highlights/Zotero/lee_2022","highlights/Readwise/31866632","highlights/Matter/AI-Data-Laundering--How-Academic-and-Nonprofit-Researchers-Shield-Tech-Companies-from-Accountability","highlights/Readwise/36537572","highlights/Readwise/37134470"],"tags":[],"content":"AI Plagiarism\nPlagiarism occurs when the model regurgitates the data without permission or attribution.\nSuch plagiarism can occur with text data, such as Do Language Models Plagiarize?Generative AI Has a Visual Plagiarism Problem]] and potentially more.\nThere are a couple of ongoing lawsuits against those Gen AI companies on the grounds of copyright violation this year. We will have to see how it unfolds1 2 3. Companies like OpenAI are also trying to negotiate data licenses from publishers even when they publicly “admitted” that building on free public data was the only option4.\nFootnotes\n\n\nThe Battle over Books3 Could Change AI Forever ↩\n\n\nAI Data Laundering: How Academic and Nonprofit Researchers Shield Tech Companies from Accountability ↩\n\n\nMeta Admits Use of ‘Pirated’ Book Dataset to Train AI ↩\n\n\nOpenAI’s Got 9.9 Problems, and Twitch Ain’t One ↩\n\n\n"},"notes/20240111213145":{"title":"Making Time","links":["highlights/Readwise/36537373","highlights/Matter/Staring-into-the-abyss-as-a-core-life-skill"],"tags":[],"content":"Making Time\nWhen telling yourself that you don’t have time for something, it is usually a sign that you do not find that particular thing interesting or important enough for your time1.\nFinding time is an excuse not to spend time on the task. The “Just do it” tagline seems much more powerful at that moment2.\nFootnotes\n\n\n3-2-1: On Saving Money, Controlling Your Anger, and What Love Looks Like ↩\n\n\nStaring into the abyss as a core life skill ↩\n\n\n"},"notes/20240112221453":{"title":"The Cult of Apple","links":["highlights/Readwise/36571475","notes/20231224125929"],"tags":[],"content":"The Cult of Apple\n\nThe only people who could use an alternative iOS store are Apple customers.\n— Cory Doctorow, The Cult of Mac\n\nBuying an expensive electronic device and not being able to use it as one likes while telling people who actually demand to do that to have their business elsewhere definitely sounds like an anti-Interoperability cult.\n\nThey aren’t real Apple customers, because they want to do things that benefit them, not Apple’s shareholders. In other words: they’re holding it wrong\n— Cory Doctorow, The Cult of Mac\n\nWe never really had a chance to see what the alternative looks like in real life. The closest one I can think of is the jailbreak version — Cydia. But it was only a niche application for technical tinkers. One can’t help but ask how much of the security and privacy pretence is actually true and how much of it is contingent on profits."},"notes/20240113144556":{"title":"Self-Extended Attention","links":["highlights/Zotero/jin_2024"],"tags":[],"content":"Self-Extended Attention\nSource: LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning\nKey insights:\n\nHumans can naturally generalise to long contexts by learning from short ones;\nPrecise positional information might not be crucial for most tasks where relative ordering can be sufficient;\n\nKey contributions:\n\nUsing floor operation to map a long context window to a short one within the limit of learned positions. This is equivalent to bucketing the position embeddings where neighbouring positions might use the same encodings. This is controlled by a parameter called group size, typically from 2 to 8.\nTo further maintain the model’s performance impacted by the introduction of the floor operation, the authors proposed using the original attention values for tokens within a neighbour window because such tokens play an important role in the generation of future tokens in the sense of locality. This is parameterised with a neighbour window size.\n\nTransclude of jin_2024#^8555ea\nThese two methods are combined and softmaxed to derive the final attention weights.  However, based on the pseudo-code, it looks like there are two sets of attention matrix multiplications  — one normal and one floored. Further optimisations such as FlashAttention can be used."},"notes/20240114111045":{"title":"Uninvited Notifications","links":["highlights/Matter/Why-It's-So-Hard-to-Avoid--and--How-to-Prevent-It-Anyway","highlights/Readwise/36600730","notes/20231211203544"],"tags":[],"content":"Uninvited Notifications\nModern systems allow other people and services to interrupt what you are doing by notifications1, which becomes even more detrimental if we pick up the habit of checking them2.\nTransclude of Why-It&#039;s-So-Hard-to-Avoid--and--How-to-Prevent-It-Anyway#^e57d04\nApart from critical communication, giving way to whims out of our control, usually at the cost of our own productivity, does not make sense.\nFootnotes\n\n\nI Miss Human Curation ↩\n\n\nAddictive Atomic Habits ↩\n\n\n"},"notes/20240121103612":{"title":"Captured Customers and Habits under Capitalism","links":["notes/20240105204049","highlights/Readwise/36754866","highlights/Readwise/36220511"],"tags":[],"content":"Captured Customers and Habits under Capitalism\nTo create a habit-forming service that profits from a captured customer base1.\nCustomers often do not have an alternative to a service because of anti-competition or anti-interoperability. Such a service follows the Techno-Feudalism ideology for its rent-seeking behaviours by making using a service and, therefore, paying the subscription a normalised habit2.\nSadly, we no longer possess what we have purchased, a long overdue realisation after decades of skipping reading the TOS.\nFootnotes\n\n\nHow Food Delivery Robots Have Taken Over College Campuses ↩\n\n\nWe Are Turning Into Subscription Slaves ↩\n\n\n"},"notes/20240121142415":{"title":"Cargo Cult Science","links":["highlights/Readwise/36851244"],"tags":[],"content":"Cargo Cult Science\nA pseudoscience research method that aims to confirm a pre-conceived hypothesis instead of vigorously disproving possible alternative explanations1.\nThis lack of self-criticism is a form of dishonesty by not striving to eliminate possible confounding factors. Some people argue that it is often belittled when compared to plagiarism2. Maybe done unintentionally, it is less of a character flaw and more of a lack of scientific skill.\nFootnotes\n\n\nCargo cult science - Wikipedia ↩\n\n\nThe Problem Is Not Plagiarism, but Cargo Cult Science ↩\n\n\n"},"notes/20240127103325":{"title":"Co-Innovation","links":["highlights/Readwise/37046152"],"tags":[],"content":"Co-Innovation\nCo-innovation describes the virtuous cycle where a product’s creator iterates the design with user feedback. The important factor of this loop is that users have given their consent and are aware of such data collection1.\nHowever, oftentimes, such information is collected without consent, under vague contractual terms, or behind UI dark patterns, and it gradually becomes behavioural surveillance so that the company can assert more control over how users should use the product1.\nFootnotes\n\n\nHow Lock-in Hurts Design ↩ ↩2\n\n\n"},"notes/20240130213737":{"title":"A Unified Theory of Fucks","links":["highlights/Readwise/37153826","highlights/Matter/How-Our-Brains-Are---and-Aren’t---Like-Computers"],"tags":[],"content":"A Unified Theory of Fucks\nSource: A Unified Theory of Fucks\nA person has limited number of fucks to give. As one grows older, his fucks will eventually run out.\nSomehow, it reminds me of this article – How Our Brains Are - and Aren’t - Like Computers where our brain prunes neural connections as we age. Maybe the loss of those connections also means losing the mental faculty to give a fuck.\nNevertheless, it still comes down to how we prioritise the limited fucks we can give. To our family, to our friends, and to ourselves, but definitely not work."},"notes/20240203201748":{"title":"LOCKSS","links":["highlights/Readwise/37310808"],"tags":[],"content":"LOCKSS\nSource: An Introduction to the WARC File\nIt stands for lots of copies keeps stuff safe – a digital preservation mantra that has become more vital as the Internet becomes increasingly a crucial part of our lives.\nWeb archiving is one of the examples that benefit from such principle: information and access come and go for various reasons, web archiving make it possible to maintain the access to that information."},"notes/20240203203211":{"title":"Being Fauxductive","links":["highlights/Readwise/37275927","notes/20230624141234"],"tags":[],"content":"Being Fauxductive\nSource: Fighting Infomania: Why 80% of Your Reading Is a Waste of Time\nWhen you’re doing something that “feels” productive but never meaningfully impact your life in any way, you’re being fauxductive.\nExamples abound: Doing house chores, organising your desk, checking the news, trying out the latest and hotest productive tool or watching a Youtube video on how to be productive. Those activities do not answer any specific need or question you might have, instead they just fill the void or the boredom so that you feel busy and productive.\nA less obvious case would be reading. The majority of the information is either duplicate or irrelevant. This has been echoed in many other ideas as well: The CODE method (Capture, Organise, Distil, and Express) stresses that we should capture only the ones that resonate with us. But, unfortunately, it is very unlikely we can trim down the noise just by being selective in this era of Information Overload."},"notes/20240203205406":{"title":"What If We Cannot Audit the Data","links":["highlights/Omnivore/20240203191242"],"tags":[],"content":"What If We Cannot Audit the Data\nSource: In the AI science boom, beware: your results are only as good as your data\nEspecially when all we have is a black box model with a paid API?\nIt means that:\n\nWe cannot verify any data leakage, or lackthereof1;\nActual improvements might be dissuaded from publishing becuase there is no fair comparison, potentially holding back real research progress\n\nFootnotes\n\n\n[[33716870|Ahead of AI #12: LLM Businesses and Busyness]] ↩\n\n\n"},"notes/20240205102944":{"title":"On Rest","links":["highlights/Omnivore/20240203003331"],"tags":[],"content":"On Rest\nRests can make our work more productive, but it isn’t the only purpose. A rest means more than taking a break. It’s also about experiencing the “joys of the world to come”1.\nFootnotes\n\n\nHeschel on the Joys of Slowness - Cal Newport ↩\n\n\n"},"notes/20240205142422":{"title":"Technoaddiction","links":["highlights/Omnivore/20240205120845","notes/20230307200456"],"tags":[],"content":"Technoaddiction\nSource: The Acceleration of Addictiveness\nTechnological progress is a double-edge sword: it creates new things or improve existing ones such that our life becomes more comfortable, but it also makes them more addictive in a sense that we often can’t easily say no to1.\nFootnotes\n\n\nA New Definition of Luddism ↩\n\n\n"},"notes/20240205144638":{"title":"Negative Externalities","links":["highlights/Omnivore/20240204212730","highlights/Omnivore/20240211084736","highlights/Omnivore/20240329154605"],"tags":[],"content":"Negative Externalities\nNegative consequences, as a result of actions from one party, are imposed upon another party.\nThis is the case with environmental pollution — neighborhoos around factories are bearing the consequneces, and AI development —the entire community had to suffer labor theft and misinformation while AI companies reap the profits1 2 3.\nFootnotes\n\n\nDeepfaked Shit is Getting Real - by Gary Marcus ↩\n\n\nSeven reasons why the world should say No to Sam Altman ↩\n\n\nThe race between positive and negative applications of Generative AI is on – and not looking pretty ↩\n\n\n"},"notes/20240205191518":{"title":"What to Read in a Privacy Policy","links":["highlights/Omnivore/20240202223601"],"tags":[],"content":"What to Read in a Privacy Policy\nSource: How to Quickly Get to the Important Truth Inside Any Privacy Policy – The Markup\nData Collection\nThis is a section about what information is being collected.\nIn addition to legitimate data for business functional purposes (GPS coordinates for navigation), watch out for data that seem irrelevant such as device type and GPU usage, which might be utilised to create a unique fingerprint for you.\nTake their description with a grain of salt, though. Phrases like “for example”, “may”, or “such as” distract you from their real and often more intrusive operations.\nData Sharing\nWhat data is being shared and who they are sharing it with.\nLook out for service providers and patterns. They might use different privacy policies that you are also subject to.\nData Use\nHow data is being used.\nWhen words like “personalize” or “enhance” are mentioned regarding your experience with the product, it often means you are targeted for advertisement profiling.\nData Management\n*How data is stored, processed, and protected, and what your rights are under certain laws.\nFor example, under CCPA (California Consumer Privacy Act), you can expect companies to diclose any data collection in the past 12 months."},"notes/20240205214602":{"title":"Cult AI","links":["notes/20230115161911","notes/20240205144638","notes/20231219222518","highlights/Omnivore/20240202223547","highlights/Omnivore/20240202223554"],"tags":[],"content":"Cult AI\n\nYet, in holding scientific research and discovery in respect, as we should, we must also be alert to the equal and opposite danger that public policy could itself become the captive of a scientific-technological elite.\nIt is the task of statesmanship to mold, to balance, and to integrate these and other forces, new and old, within the principles of our democratic system-ever aiming toward the supreme goals of our free society.\n— US President Dwight Eisenhower, 1961\n\nHanding over one’s own agency and decision-making to an AI model — a perfect example of voluntary self-surrender in cult dynamics1. The promising land of AGI, championed by Sillcon Valley elites, is based on faith rather than facts1 — that those AI models today are still Bullshit generators, with plagiarised content and misinformation1.\nLeaders of the cult, authoritarian technocrats, foist their hypocritical beliefs onto the society, which is neither consulted nor effectively informed2. The path leading to the so-called AGI has never been about the general good or the benefits for the humanity. Instead, it is all about profiting at scale fast.\nAny attempt to regulate the technical development has been equated to a murder by those of effective accerlerationism (e/acc for short). It sounds culty beacuse it is. It serves to absolve those elites of any moral and ethical duty2, which is another perfect example of Negative Externalities.\nLuckily, we can fight back by saying no: Techno-selectionismA New Definition of Luddism]].\nFootnotes\n\n\nAI Companies And Advocates Are Becoming More Cult-Like ↩ ↩2 ↩3\n\n\nThe Rise of Techno-authoritarianism - The Atlantic ↩ ↩2\n\n\n"},"notes/20240205221815":{"title":"Text Closeness Is Use Case Dependent","links":["highlights/Zotero/nussbaum_2024"],"tags":[],"content":"Text Closeness Is Use Case Dependent\nUnfortunately, we seem to abuse the word similarity a lot even in the context of NLP applications. We have seen models using contrastive learning objectives with either symmetric or asymmetric data for embedding learning tasks. A simple example from Nomic Embed: Training a Reproducible Long Context Text Embedder clarifies the difference:\nQ: What is the capital of France?\nCandidate 1: What is the name of the capital city of France?\nCandidate 2: Paris is the capital city of France\nIn retrieval or QA tasks, candidate 2 would be considered similar to the query while in clustering or semantic similarity tasks, candidate 1 is closer to the query."},"notes/20240206195005":{"title":"Model Averaging and Merging","links":["highlights/Omnivore/20240203150054"],"tags":[],"content":"Model Averaging and Merging\nSource: Research Papers in January 2024 - by Sebastian Raschka, PhD\n\nModel merging via Model Ratatouille compared to other finetuning strategies. (OOD = out of distribution / generalization); annotated figure from arxiv.org/abs/2212.10445\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStrategyData SourceSourceExampleModel AveragingSingle DatasetMultiple Checkpoints- Stochastic Weight Averaging (SWA)- Exponentially Moving Averaging (EMA)- Latest Weight Averaging (LaWA)Model MergingMultiple Datasets/TasksMultiple Checkpoints- Model Ratatouille- Model Soups- Model Fusing"},"notes/20240206200120":{"title":"Proxy Training","links":["highlights/Omnivore/20240203150054"],"tags":[],"content":"Proxy Training\nSource: Research Papers in January 2024 - by Sebastian Raschka, PhD\nFor generative neural networks, the knowledge/learning can be approximated by the distribution difference during sampling between a trained model and an untrained one.\nIt is much easier to measure the difference and transfer such difference to similar models (with the exact same vocabulary) than transferring the information trained and encoded in the parameters. Additionally, the learning/training can be done with a small model and the hot transfer can be applied to a large one.\nBase Model M1​: a small model that is untrained, e.g. Llama 2 7B.\nTrained Model M2​: a small model that is trained with desire behaviours, e.g. Llama 2 7B Chat.\nTarget Model M3​: a large model such as Llama 2 70B.\nThe learning can be represented as M2​(x)−M1​(x), and the final logits can be calculated as M3∗​(x)=Ms​(x)+M2​(x)−M1​(x) before the final softmax and sampling."},"notes/20240206201618":{"title":"Digitopia","links":["highlights/Omnivore/20240204212722","highlights/Omnivore/20240326112538","notes/20240205142422","highlights/Readwise/34276322"],"tags":[],"content":"Digitopia\nSource: Deeshee - Digitopia is ruining our lives\n\nAn idealised but ultimately isolating and detached state induced by excessive digital interaction.\n— Evan C\n\nSymptoms:\n\nA fake sense of socialising with Internet interactions;\nA fake sense of busy, productive, or secure, living on autopilot with constant distractions or stimulus;\nWithdrawal symptoms like anxiety, insomnia, and intense aggressiveness1.\n\nBy design, recommendation systems can’t distinguish between addictive and high-quality content — there isn’t enough compute can equate to human-level discernment and curation at scale. This inevitably push the users further into someplace bad whom might already struggle with insecurity1 2.\nThis is no easy way to break from all social media when everyone you know is confined to the same platform. Even if you are not on the platform, you would certainly feel the pressure from your peers. The cost of switching, or briefly leave can feel immensely intimidating3.\nPrescription:\n\nExercise, even a small dose, can change the brain chemistry to help you combat the negative thoughts.\nSocialise with families and friends in real life.\n\nFootnotes\n\n\nThe Terrible Costs of a Phone-Based Childhood - The Atlantic ↩ ↩2\n\n\nTechnoaddiction ↩\n\n\nThe Internet Con: How to Seize the Means of Computation ↩\n\n\n"},"notes/20240211104540":{"title":"Daily Standup is Overrated","links":["highlights/Omnivore/20240209203616","notes/20230902132142"],"tags":[],"content":"Daily Standup is Overrated\nInspiration: The “3 standup questions” are terrible and need to die – More Than Coding\nThe common practice of daily standup revolves around three questions:\n\nWhat did I do yesterday?\nWhat will I focus on today?\nWhat blockers do I have?\n\nIt is productiveless as Return-to-Office mandate — a return-to-team-meeting practice that fosters a mindset of batch processing where communication is often delayed until the standup or follow-ups that could have been initated any time before the standup.\nIt is necessary only because the progress isn’t availabel or transparent enough by poor management or engineering culture. Constant reports will only disrupt the flow of the engineers and add more pressure in addition to the actual work."},"notes/20240211111254":{"title":"Not Safe for Work","links":["highlights/Omnivore/20240209193109"],"tags":[],"content":"Not Safe for Work\nSource: Behind the Blog: Not Safe for Whose Work?\nWork has become the default mode of being online today. This binary dichotomy, largely built by technocrats, marginalises people who don’t comply, even though sex was behind many of the technologies we have today — shopping carts, payment processors, ad revenue models, and so on."},"notes/20240211112219":{"title":"Swiss-cheese Security","links":["highlights/Omnivore/20240205135633"],"tags":[],"content":"Swiss-cheese Security\nSource: Pluralistic: How I got scammed (05 Feb 2024) – Pluralistic: Daily links from Cory Doctorow\n\nImage: Wikimedia\nImagine a pile of cheese slices where holes in each slice is blocked by neighboring ones. When the slides move every now and then, the tunnel through the pile might appear from lined up holes.\nThe common security fallacy is to assume we have enough measures in different layers to combat attacks, but to the attacker’s advantage, all they need to find is a momemt where all the loopholes connect."},"notes/20240211140243":{"title":"Hype Cycle","links":["highlights/Omnivore/20240206075938","notes/20231112144602","notes/20240211141732"],"tags":[],"content":"Hype Cycle\nSource: Gates’ Law: How Progress Compounds and Why It Matters\nA typical hype cycle that consists of five stages:\n\nEmergence: a new technology is picked up the media. The public shows great interest in it, even though it still has no valid use case yet.\nPeak Hype: Hype continues to build up with growing coverage and startups sprouting off to become the first movers. New reasearch and development are also booming. Scammers might also step in to take some windfalls.\nDisillusionment: Prominent failures or lack of substantial progress lead to disillusionment. The hype subsides, but the research might continue.\nEnlightment: The technology is constantly improved and better use cases are found1. Mainstream adoption begins with laws and guardrails developed to curb scams.\nPlateau: The technology becomes part of our daily lifes. It stops to be novel and dominant players saturate the market with less and less disruptive features2.\n\nThis is not to say that hype is all bad. In the early stage of the cycle, it attracts interest, talents, and investments that enable us to move forward.\nFootnotes\n\n\nThe Innovator’s Dilemma ↩\n\n\nAdjacent Possiblities ↩\n\n\n"},"notes/20240211141732":{"title":"Adjacent Possiblities","links":["highlights/Omnivore/20240206075938"],"tags":[],"content":"Adjacent Possiblities\nA new development in one research direction can not only improve one area but also introduces many possibilities in adjacent areas. The underlying assumption is that our knowledge, existing or to be discovered, is often inter-connected. Unlocking one branch opens doors to endless oppotunities1.\nFootnotes\n\n\nGates’ Law: How Progress Compounds and Why It Matters ↩\n\n\n"},"notes/20240211142629":{"title":"AI and Education","links":["highlights/Omnivore/20240208082441","highlights/Omnivore/20240402192303","highlights/Matter/Students-Depend-on-ChatGPT-for-Final-Exams","highlights/Matter/What-Students-Lose-by-Embracing-Easy-Tech-Like-ChatGPT"],"tags":[],"content":"AI and Education\nTalking about use or disuse of technologies like ChatGPT is mostly a distraction1 2.\nIf the focus of our modern education system is purely results-driven — multiple choices, essays, or grades — then it doesn’t matter if students are using ChatGPT or a calculator. Even when the models magically synthesise an explanation, correctly, comprehending the explanation does not equal to coming up with a solution by your own reasoning3. The short-circuiting in learning to learn will cast a long shadow in our future generations — we should never train our students to be input and output mapping machines2.\nThe fact students are rushing to those tools for their homework is an example of how society has failed our next generation: both teachers and students are not critically equipped to judge the use of such tools. Most of the conversations regarding AI in education has been reactive by banning or embracing the technology. Rarely are discussed questions like what it is, what problems it creates or solves, how to teach students to become aware of the limitations, or any other technology for that matter4 5.\nEducation is unique in a sense that it has always been underfunded and caught up with technological development when almost all technocrats want to repay their societal duty debt by introducing their technology into the classroom, thinking it would magically solve all the problems.\nFootnotes\n\n\nMore than calculators: Why large language models threaten learning, teaching, and education | by Amy J. Ko | Bits and Behavior | Dec, 2023 | Medium ↩\n\n\nDoing their hype for them • Buttondown ↩ ↩2\n\n\nMore than calculators: Why large language models threaten learning, teaching, and education | by Amy J. Ko | Bits and Behavior | Dec, 2023 | Medium ↩\n\n\nStudents Depend on ChatGPT for Final Exams ↩\n\n\nWhat Students Lose by Embracing Easy Tech Like ChatGPT ↩\n\n\n"},"notes/20240211170238":{"title":"Becoming Talkable","links":["highlights/Omnivore/20240211084819"],"tags":[],"content":"Becoming Talkable\nSource: How To Be Someone People Love To Talk To - Barking Up The Wrong Tree\n\n\n                  \n                   1.\n                  \n                \nThe goal is to make sure the other person walks away better for having met you\n\nFirst Impression\n\nPresent yourself positively, which means being warm and open;\nSmile slowly;\nTalk clearly and slowly;\n\nBuilding Connection\n\nBe candid about who you are and how you feel;\nEncourage others to talk about themselves;\nSuspend your ego: avoid correcting other people;\nShow engagement:\n\nRepeat their question;\nParaphrasing what they just said;\nLabeling/summarising what they just said;\n\n\nMeaningful Small Talk;\n\nTalk about challenges in work and life;\nIncrease your level of commitment and vulnerability (see below)\n\n\n\nLevel of Vulnerability\nTransclude of 20240211084819#^adb39708\nGoodbye\nFew things to talk about when saying goodbye so that it doesn’t feel curt:\nTransclude of 20240211084819#^df9f3201"},"notes/20240217101251":{"title":"State Space Models","links":[],"tags":[],"content":"State Space Models\nSources:\n\nPiped\nPiped\n\nSSM is often used to model continuous signals with respect to time. A typical fomula for SSM can be expressed as:\nh′(t)y(t)​=Ah(t)+Bx(t)=Ch(t)+Dx(t)​​\nwhere h(t) is the state representation,  x(t) is the input and y(t) is the output.\n\nA: how previous state impacts current state (in continuity);\nB: how input impacts state;\nC: how state impacts output;\nD: how input impacts output; Often skipped as this can be independently calculated with a skip connection.\n\nBased on the fomulation, the relationship between input and output is linear and time-invariant because A, B, C, and D are fixed.\nHowever, in reality, we work with sampled and discret signals instead, so, our requirements for finding h(t) becomes finding an approximation of discretised h(kΔ) where Δ is the step size, which can be learned through BP;\nDiscretisation and Recurrent Formulation\nGiven that the derivative can be calculated by limitation:\nΔ→0limit​Δh(t+Δ)−h(t)​=h′(t)\nwe now have this if we choose a really small Δ:\nh(t+Δ)​≅Δh′(t)+h(t)=Δ(Ah(t)+Bx(t))+h(t)=(I+ΔA)h(t)+ΔBx(t)=Aˉh(t)+Bˉx(t)​​\nwhich makes h(t+Δ) recurrent:\nht​yt​​=Aˉht−1​+Bxt​=Cht​​​\n\nRecurrent formulation makes inference faster because it takes constant time to produce a token at any time unlike transformers where you have to calculate the attention weights with growing length.\nHowever, such recurrency also makes it harder to train the network because you can’t parallelise computation between time steps.\n\nConvolutional Formulation\nFrom above equation, one can derive yt​ by:\nyk​y​=CAˉkBˉx0​+CAˉk−1Bˉx1​+...+CBˉxk​=x⋅Kˉ​​\nwhere Kˉ=(CAˉkBˉ,CAˉk−1Bˉ,...,CBˉ) can be seen as a convolutional kernel and the calculation of yk​ can be calculated in parallel. This makes it ideal for training."},"notes/20240217115122":{"title":"Mamba","links":["notes/20240217101251"],"tags":[],"content":"Mamba\nSource: Mamba: The Easy Way\nA new variant of State Space Model where A, B, and C are input-dependent and thus time-varying.\n\\begin{align}\nh_t &amp;= s_{\\bar{A}}(x_t)h_{t - 1} + s_\\bar{B}(x_t)x_t\\\\\ny_t &amp;= s_C(x_t)h_t\n\\end{align}\nSuch change renders the convolutional formulation impossible since each time step requires different parameters. However, such sequential calculation can be remedied by scan algorithm or a prefix sum, compound with hardware-aware implementation utilising memory hierarchy, and kernel fusions.\nScan Algorithm\nTo calculate the hidden state in parallel, we can use the following step to illustrate the idea:\n\\begin{align}\nh_t &amp;= s_{\\bar{A}}(x_t)h_{t - 1} + s_\\bar{B}(x_t)x_t\\\\\n&amp;=s_{\\bar{A}}(x_t)(s_{\\bar{A}}(x_{t-1})h_{t - 2} + s_\\bar{B}(x_{t-1})x_{t-1}) + s_\\bar{B}(x_t)x_t\\\\\n&amp;=s_{\\bar{A}}(x_t)s_{\\bar{A}}(x_{t-1})h_{t - 2} + s_{\\bar{A}}(x_t)s_\\bar{B}(x_{t-1})x_{t-1} + s_\\bar{B}(x_t)x_t\\\\\n\\end{align}\nwe can calculate sAˉ​(xt​)sAˉ​, s_{\\bar{A}}(x_t)s_\\bar{B}(x_{t-1})x_{t-1}, and s_\\bar{B}(x_t)x_t first while ht−2​ is being calculated elsewhere in a different thread/core. This can also be illustrated with the following prefix-sum graph:\n\nFile:Prefix sum 16.svg - Wikimedia Commons\nFurthermore, recalculation of the activation is also used to save the memory load."},"notes/20240218204257":{"title":"About Me","links":[],"tags":[],"content":"About Me\n\nA machine learning engineer living in Dublin, Ireland, focusing mostly on NLP. I am more drawn to the ethical and social impact conversation related to AI lately.\nI love cooking. My ideal male model has always been somebody who can support one’s family with both money and food, grew up watching my father, my grandfathers from either side, providing for the family with dishes I still relish today. Food or cooking has been a huge portion of my childhood, my culture, and my identity.\nCooking is so habitual to me that I often need to remind myself that not all is interested in or good at it. I would feel attacked if someone dismisses it as a hobby because everyone does it, like part of me suddenly tarnishes.\nI am trying to pick up my reading and writing habits again. I used to journal a lot in high school, then I stopped after graduation. Life has been busy."},"notes/20240219220703":{"title":"VCware","links":["highlights/Omnivore/20240211165618"],"tags":[],"content":"VCware\nSource: 100% user-supported — Steph Ango\nSoftware built on VC investments. VC money can subsidise the cost during the early stage to attract and lock-in users, e.g. by holding their data or social network hostage. Eventually, VCware has more pressure to answer the stakeholders instead of its users. Priorities shift, prices increases, and functionality decreases."},"notes/20240220222025":{"title":"robots.txt","links":["highlights/Omnivore/20240215093449"],"tags":[],"content":"robots.txt\nIs this our only defence to the crawlers and consequently the AI overlords?\nWhy website owners have to shield themselves when corporate content stealers are roaming free? Do we have to choose among paywalls, captchas, and spiders?\nSome companies are knowingly violating the handshake rule defined in robots.txt,  or have done so before under public scrutiny1. Should we hold them accountable? Especially when they are profiting in the same market as the original content producers? If so, how?\nFootnotes\n\n\nWith the rise of AI, web crawlers are suddenly controversial - The Verge ↩\n\n\n"},"notes/20240225133536":{"title":"RAG","links":["highlights/Omnivore/20240224094409"],"tags":[],"content":"RAG\nSource: No, RAG is probably not going to rescue the current situation\nRetrieval augmented generation (RAG) doesn’t guarantee more factuality in the generation. Robust and reliable generation, even when the source materials are present, is still an unsolved problem.\nThe generation might be more correlated to the data source, but such correlation has nothing to do with truth, nor causality."},"notes/20240225142211":{"title":"Social Media is a Slot Machine","links":["highlights/Omnivore/20240222211311"],"tags":[],"content":"Social Media is a Slot Machine\nSource: YouTube addiction, one month sober\n\nIt’s a content feed you can doom scroll, satisfying your insatiable curiosity and yearning for distraction. Good content is rare, but more often than not, you’re in a trance, fallen prey to the information consumerism (a.k.a, attention economy).\nIt’s also isolating in a sense that you’re replacing moment with family and friends with screen time, surrounded by an illusion of being social.\n"},"notes/20240226230347":{"title":"The Shirky Principle","links":["highlights/Omnivore/20240224173921"],"tags":[],"content":"The Shirky Principle\nSource: The Shirky Principle: Institutions Try to Preserve the Problem to Which They Are the Solution – Effectiviology\n\nIt is difficult to get a man to understanding something when his salary depends on his not understanding it.\n— Uptoon Sinclair\n\nThere are three types of formulations for the Shirky Principle:\n\nInstitutions will try to preserve the problem to which they are the solution, implying intentionality.\nComplex solutions can become so absorbed in the problem they are solving that they inadvertently perpetuate the problem as an unintentional consequence.\nEvery entity will prolong the problem it is solving, regardless of their intentions.\n\nMore generally, we can express the shirky principle as “Entities often promote problems that they benefit from”.\nIn conjunction, two other useful ideas can also be referenced together with the Shirky Principle:\n\nCui bono: a latin phrase meaning “who benefits?“. It suggests that it is likely whoever is responsible for an event is most likely to benefit from it. This draws a similar connection between the problem and the beneficiary.\nHanlon’s razoe — never attribute to malice when it can be explained adequately by stupidity. This can be used to refer to the intention part mentioned above.\n"},"notes/20240304220029":{"title":"On Giving Up On Github","links":["notes/20240105204049","highlights/Omnivore/20240302085656"],"tags":[],"content":"On Giving Up On Github\nInspiration: Give Up GitHub - Software Freedom Conservancy\nTo choice a service is to invest in it over others. Just like how we build our habits around our identity, we choose a platform not just because it has a better quality or reach, but what value it stands for and what kind of future it represents1.\nWhen Github does not practise what it preaches by choosing to close source its platform, takes our collective contribution without consent and acknowledgement and demands a paid subscription, we should know it is time to give up on Github.\nIt could be a slow and painful experience. But the pain today pales in comparison to a Techno-Feudalism tomorrow — a tomorrow we could have built with a much better transparent alternative without sacrificing our rights or our code.\nFootnotes\n\n\nPlease don’t use Discord for FOSS projects ↩\n\n\n"},"notes/20240305210648":{"title":"The Internet Was Problematic Before, and Now It Will Be Forever","links":["highlights/Omnivore/20240305173225","highlights/Omnivore/20240301200325","highlights/Omnivore/20240305163001","highlights/Omnivore/20240302181302","highlights/Omnivore/20240305173215","highlights/Omnivore/20240306224044","highlights/Omnivore/20240307204001","notes/20231224131830","notes/20230212204146","notes/20230521211543"],"tags":[],"content":"The Internet Was Problematic Before, and Now It Will Be Forever\nThe synthetic output we see today from generative models is often modelled from materials collected from the open Internet, mostly from the Anglosphere, with a cut-off date.\nRecent issues emerged from Gemini1 2 and others3 demonstrated how a model can be influenced by human decision-makers and the data that powered them. Even more so, by the downstream abusers45. Unfortunately, all the guardrails deployed as an afterthought have never solved the problem6 7.\nIf people who actually have the power to fight it is actively contributing to such entrenchment of the bias and misinformation, then what hope do we have8 9 10?\nFootnotes\n\n\nGoogle’s Gemini AI Doesn’t Want to Talk About Palestine ↩\n\n\nChatGPT and Google Gemini Are Both Doomed ↩\n\n\nCovert racism in LLMs - by Gary Marcus - Marcus on AI ↩\n\n\nHere lies the internet, murdered by generative AI ↩\n\n\nInside the World of TikTok Spammers and the AI Tools That Enable Them ↩\n\n\nMicrosoft accused of selling AI tool that spews violent, sexual images to kids | Ars Technica ↩\n\n\nElevenLabs Block on Cloning Biden’s Voice Easily Bypassed ↩\n\n\nTech Monopoly and Power Displacement ↩\n\n\nAI Democratization ↩\n\n\nPredictable and Preventable AI Bias ↩\n\n\n"},"notes/20240305213832":{"title":"Will Open Internet Become a Past?","links":["highlights/Omnivore/20240218090131"],"tags":[],"content":"Will Open Internet Become a Past?\nI can’t stop wondering whether this paradigm shift, which was introduced by AI where companies are scrambling to leverage or sell their customer data in bundle and web crawlers gorging on the open internet like there is no tomorrow, would lead to a more closed internet.\nSome will still hold the hope for a diverse internet future, despite the possibility of losing one’s identity1. Some will fight against corporate or abusers who are taking all the benefits. Some may decide to move away from building in public. It will be interesting to see how this will play out.\nFootnotes\n\n\nWhat’s the fun in writing on the internet anymore? ↩\n\n\n"},"notes/20240319202009":{"title":"Malicious Compliance","links":["notes/20231224131140","highlights/Omnivore/20240318135302"],"tags":[],"content":"Malicious Compliance\nA phrase that has been popularised by Apple’s recent implementations w.r.t EU’s DMA, which essentially means being compliant with the law but with obnoxious malice. The Core Technology Fee is a perfect example showing Apple’s reluctance of relenting control and insatiable appetite for profit over its users — an ecosystem with Feudal Security.\nAnother less obvious example is the cookie banner. There is no specific implementation requirement from the law that stats a banner is needed. It is the company that has chosen to display the banner in an abtrusive way, and to turn on all data sharing options by default1. Fighting with the banners is a constant reminder of how frequent and easy it is to let go of our privacy in return for quick convenience.\nFootnotes\n\n\nThere is no cookie banner law ↩\n\n\n"},"notes/20240319210756":{"title":"Moat","links":["highlights/Readwise/34276322","highlights/Omnivore/20240313065912"],"tags":[],"content":"Moat\nThe real moat those big tech companies have is the means of computation1 2 — expensive GPU clusters, data, and talents.\nThis sad reality makes open sourcing large model weight less appealing because only a handful of companies hold enough compute power to leverage those models, and most of them are competitors. If they benefit from such model release, few of them would acknowledge it, not to mention returning the favour.\nFootnotes\n\n\nThe Internet Con: How to Seize the Means of Computation ↩\n\n\nAny Technology Indistinguishable From Magic is Hiding Something￼ ↩\n\n\n"},"notes/20240329144259":{"title":"Refusal as an Act of Design","links":["highlights/Omnivore/20240327100956","notes/20230725083514"],"tags":[],"content":"Refusal as an Act of Design\nSource: Q&amp;A: How refusal can be an act of design | MIT News | Massachusetts Institute of Technology\nWhen it comes to data privacy and data rights, choices are not enough. Equally accessible and carefully thought-out choices should be the bare minimum, along with A Default No to Something New.\nBy refusal, especially in the presence of insatiable surveillance and data harvesting, it creates room for alternatives and asserts inclusion, which should have been considered early on if all voices were invited and heard.\nRefusal Design Aspects\nEach aspect is a spectrum with varying effects: some might cause seismic socio-technical changes while some hardly make a dent.\n\nAutonomy: individuals and organisations can each take different approaches in response to such issues, such as opt-out, class-action lawsuit, boycott, and legislation.\nTime: lawsuits can be launched for past and present harm, and legistation can prevent future harm.\nPower: legistation usually has more power and control over corporation behaviors than individual actions.\nCost: with great power comes great cost. Some measures might take years and many back-and-forth legal and political battles.\n"},"notes/20240331144139":{"title":"Fact-checking in the LLM Era","links":["highlights/Zotero/wei_2024","highlights/Zotero/xu_2024","notes/20231214212913","highlights/Zotero/min_","20221210185344"],"tags":[],"content":"Fact-checking in the LLM Era\nGenerative LLMs suffer from hallucinations1 2 and even when specifically trained to synthesis citations, they have little to no correlation with factual precision3.\nTo automate the fact-checking process, Long-form factuality in large language models proposed a system called Search-Augmented Factuality Evaluator (SAFE) that:\n\nbreaks down a response/generation into individual statements, revised to be self-contained if necessary;\nchecks each statement relevancy to the query with a model;\nuses a search enigne (in this case Google) to determine if a statement is supported;\naggregates the results for final decision and reasoning.\n\nThis underlying assumption that a search engine can and will provide factual data in the first place can be undermined in light of the information ecosystem pollution with GenAI artefacts and rampant misinformation and disinformation4.\nFootnotes\n\n\nHallucination is Inevitable: An Innate Limitation of Large Language Models ↩\n\n\nHallucination is Here to Stay ↩\n\n\nFACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation ↩\n\n\nOn the Dangers of Large Generative Models ↩\n\n\n"},"notes/20240331145646":{"title":"AI and Writing","links":["highlights/Omnivore/20240313234559","highlights/Omnivore/20240330205654","highlights/Omnivore/20240209182438"],"tags":[],"content":"AI and Writing\nSources:\n\nAI and the End of Writing\nHow to Resist the Temptation of AI When Writing | WIRED\n\nWe often joked about how AI can’t replace software engineers because then PMs would have to be very specific about their requirements which aren’t so different from the actual programming by that time. I believe it’s the same for writing — it can’t take your job just because it can extrude some meaningful sentences.\nTo delegate writing to decision-making automation systems, AI or not, it requires you to understand how it works and where it’s most applicable, like any other instruments we humans have wielded before. To better collaborate, we now have to plan, think, and reason better instead of letting those models cut all the corners. We should also prioritise more human connections and community forming1. If not, then we aren’t necessarily improving, we’re just lazier, cheaper and easily replaceable.\n\nOnly if you know what you want and understand what you’re doing, can you use your tools appropriately to achieve the results you desire2.\n\nFootnotes\n\n\nHere’s the Thing AI Just Can’t Do | WIRED ↩\n\n\nAI and the End of Writing ↩\n\n\n"},"notes/20240407125740":{"title":"Steal When You Can and Distract When You Do","links":["notes/20240220222025","highlights/Omnivore/20240407092032"],"tags":[],"content":"Steal When You Can and Distract When You Do\n\nWhen I looked into the first few rows of a LLM dataset called RefinedWeb, it is immediately obvious that terms of those websites were violated:\n100parts.wordpress.com\nThe first record in the dataviewer. Original link: ast/ray (Baden-Baden, day 31) – once upon each day\nLegal and Privacy Page states:\n\nSämtliche Texte und Bilder sind urheberrechtlich geschützt. Verwendung nur mit schriftlicher Genehmigung.\n\nGoogle translate in English:\n\nAll texts and images are protected by copyright. Use only with written permission.\n\n1037theloon.com\nThe forth record in the dataset viewer. The second one is not accessible anymore and the third one does not contain any license or legal links. Original link: Scorpions &gt; 103.7 THE LOON\nThe footer:\n\n2024 103.7 THE LOON, Townsquare Media, Inc. All rights reserved.\n\nThe terms:\n\nTownsquare owns and retains all proprietary rights in the Websites. The Websites contains copyrighted material, trademarks, and other proprietary information of Townsquare. Except for that information which is in the public domain or for which you have been given written permission, you may not copy, modify, publish, transmit, distribute, perform, display, or sell any such proprietary information. RSS feeds may be republished so long as they are not modified in any way.\n\nThis is enough demonstration of how double-standarded people are in terms of data rights. As soon as one slaps the “to be trained for LLM” label on the content one illegally acquired, one is free to use, to distribute, to re-license, and to profit from it1. All has and will be forgiven in the name of progress. Too bad robots.txt is not a law, am I right?\nTo steal is not enough too. Being a large enough tech company also means you have resources to ward yourself off potential scrutiny and attention, such as releasing policy updates during the holidays1, hiding AI data usage updates behind legalese and UI dark patterns, or lobbying against legistation that could threaten your profits.\nFootnotes\n\n\nOpenAI transcribed over a million hours of YouTube videos to train GPT-4 - The Verge ↩ ↩2\n\n\n"},"notes/20240407214522":{"title":"Public Speak Tips","links":["highlights/Matter/10-Public-Speaking-Tips-I-Learned-After-My-TED-Talk"],"tags":[],"content":"Public Speak Tips\nSource: 10 Public Speaking Tips I Learned After My TED Talk\n\nUse one sentence to convey a point and remove the rest;\nEnd a section with a confident and firm tone;\nUtilise pauses wisely so the audience can digest the information;\nProvide personal experience and unique perspective instead of something generic and google-able;\nUse gestures, movements, and expressions;\nAvoid saying filler words, or replace them with pauses;\nNo reciting or reading a script;\nBe humble, friendly, and engaging;\nClose strong with succinct takeaways;\n"},"notes/__order__":{"title":"__order__","links":[],"tags":[],"content":""},"posts/20230220150602":{"title":"Large-scale Near-deduplication Behind BigCode","links":[],"tags":[],"content":"Large-scale Near-deduplication Behind BigCode\n\nIntended Audience\nPeople who are interested in document-level near-deduplication at a large scale, and have some understanding of hashing, graph and text processing.\nMotivations\nIt is important to take care of our data before feeding it to the model, as the old saying goes, garbage in, garbage out. Even though it’s increasingly difficult to do so with headline-grabbing models (or should I say APIs) creating an illusion that data quality matters less.\nOne of the problems we face in both BigScience and BigCode for data quality is duplication, including possible benchmark contamination. It has been shown that models tend to output training data verbatim when there are many duplicates1 (though it is less clear in some other cases2), and it also makes the model vulnerable to privacy attacks3. Additionally, some typical advantages of deduplication also include:\n\nEfficient training: You can achieve the same performance with less training steps4 5.\nPrevent possible data leakage and benchmark contamination: Non-zero duplicates discredit your evaluations and potentially make so-called improvement a false claim.\nAccessibility. Most of us cannot afford to download or transfer thousands of gigabytes of text repeatedly, not to mention training a model with it. Deduplication, for a fix-sized dataset, makes it easier to study, transfer and collaborate with.\n\nFrom BigScience to BigCode\nAllow me to share a story first on how I jumped on this near-deduplication quest, how the results have progressed, and what lessons I have learned along the way.\nIt all started with a conversation on LinkedIn when BigScience had already started for a couple of months. Huu Nguyen approached me when he noticed my pet project on GitHub, asking me if I were interested in working on deduplication for BigScience. Of course, my answer was a yes, completely ignorant of just how much effort will be required alone due to the sheer mount of the data.\nIt was fun and challenging at the same time. It is challenging in a sense that I didn’t really have much research experience with that sheer scale of data, and everyone was still welcoming and trusting you with thousands of dollars of cloud compute budget. Yes, I had to wake up from my sleep to double-check that I had turned off those machines several times. As a result, I had to learn on the job through all the trials and errors, which in the end opened me to a new perspective that I don’t think I would ever have if it weren’t BigScience.\nMoving forward, one year later, I am putting what I have learned back into BigCode, working on even bigger datasets. In addition to LLMs that are trained for English4, we have confirmed that deduplication improves code models too5, while using a much smaller dataset. And now, I am sharing what I have learned with you, my dear reader, and hopefully, you can also get a sense of what is happening behind the scene of BigCode through the lens of deduplication.\nIn case you are interested, here is an updated version of the deduplication comparison that I started in BigScience:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDatasetInput SizeOutput Size or DeductionLevelMethodParametersLanguageTimeOpenWebText26After URL dedup: 193.89 GB (69M)After MinHashLSH: 65.86 GB (17M)URL + DocumentURL(Exact) + Document(MinHash LSH)(10,0.5,?,?,?)EnglishPile-CC6~306 GB227.12 GiB (~55M)DocumentDocument(MinHash LSH)(10,0.5,?,?,?)English”several days”BNE572TB570 GBDocumentOnion5-gramSpanishMassiveText80.001 TB ~ 2.1 TBDocumentDocument(Exact + MinHash LSH)(?,0.8,13,?,?)EnglishCC100-XL90.01 GiB ~ 3324.45 GiBURL + ParagraphURL(Exact) + Paragraph(Exact)SHA-1MultilingualC44806.92 GB (364M)3.04% ~ 7.18% ↓ (train)Substring or DocumentSubstring(Suffix Array) or Document(MinHash)Suffix Array: 50-token, MinHash: (9000,0.8,5,20,450)EnglishReal News4~120 GiB13.63% ~ 19.4% ↓ (train)Same as C4Same as C4Same as C4EnglishLM1B4~4.40 GiB (30M)0.76% ~ 4.86% ↓ (train)Same as C4Same as C4Same as C4EnglishWIKI40B4~2.9M0.39% ~ 2.76% ↓ (train)Same as C4Same as C4Same as C4EnglishThe BigScience ROOTS Corpus100.07% ~ 2.7% ↓ (document) + 10.61%~32.30% ↓ (substring)Document + SubstringDocument (SimHash) + Substring (Suffix Array)SimHash: 6-grams, hamming distance of 4, Suffix Array: 50-tokenMultilingual12 hours ~ few days\nThis is the one for code datasets I created for BigCode as well. Model names are used when the dataset name isn’t available.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelMethodParametersLevelInCoder11ExactAlphanumeric tokens/md5 + Bloom filterDocumentCodeGen12ExactSHA256DocumentAlphaCode13Exactignore whiespacesDocumentPolyCode14ExactSHA256DocumentPaLM Coder15Levenshtein distanceDocumentCodeParrot16MinHash + LSH(256,0.8,1)DocumentThe Stack17MinHash + LSH(256,0.7,5)Document\nMinHash + LSH parameters (P,T,K,B,R):\n\nP number of permutations/hashes\nT Jaccard similarity threshold\nK n-gram/shingle size\nB number of bands\nR number of rows\n\nTo get a sense of how those parameters might impact your results, here is a simple demo to illustrate the computation mathematically: MinHash Math Demo.\nMinHash Walkthrough\nIn this section, we will cover each step of MinHash, the one used in BigCode, and potential scaling issues and solutions. We will demonstrate the workflow via one example of three documents in English:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndoc_idcontent0Deduplication is so much fun!1Deduplication is so much fun and easy!2I wish spider dog18 is a thing.\nShingles\nLike in most applications involving text, we need to begin with tokenization. N-grams, a.k.a. shingles, are often used. In our example, we will be using word-level tri-grams, without any punctuations. We will circle back to how the size of ngrams impacts the performance in a later section.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndoc_idshingles0{“Deduplication is so”, “is so much”, “so much fun”}1{‘so much fun’, ‘fun and easy’, ‘Deduplication is so’, ‘is so much’}2{‘dog is a’, ‘is a thing’, ‘wish spider dog’, ‘spider dog is’, ‘I wish spider’}\nThis operation has a time complexity of O(NM) where N is the number of documents and M is the length of the document. This step can be easily scaled by parallelization by multiprocessing or distributed computation.\nFingerprint Computation\nIn MinHash, each shingle will typically either be 1) hashed multiple times, or 2) permuted multiple times using one hash. Here, we choose to permute each hash 5 times.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshinglepermuted hashesDeduplication is so[403996643, 2764117407, 3550129378, 3548765886, 2353686061]is so much[3594692244, 3595617149, 1564558780, 2888962350, 432993166]so much fun[1556191985, 840529008, 1008110251, 3095214118, 3194813501]\nTaking the minimum value of each column within each document, we arrive at the final MinHash for this document:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndoc_idminhash0[403996643, 840529008, 1008110251, 2888962350, 432993166]1[403996643, 840529008, 1008110251, 1998729813, 432993166]2[166417565, 213933364, 1129612544, 1419614622, 1370935710]\nIn implementation, you can easily vectorize these steps with numpy and expect to have a time complexity of O(NMK) where K is your number of permutations. Code modified based on Datasketch.\ndef embed_func(\n    content: str,\n    idx: int,\n    *,\n    num_perm: int,\n    ngram_size: int,\n    hashranges: List[Tuple[int, int]],\n    permutations: np.ndarray,\n) -&gt; Dict[str, Any]:\n    a, b = permutations\n    masks: np.ndarray = np.full(shape=num_perm, dtype=np.uint64, fill_value=MAX_HASH)\n    tokens: Set[str] = {&quot; &quot;.join(t) for t in ngrams(NON_ALPHA.split(content), ngram_size)}\n    hashvalues: np.ndarray = np.array([sha1_hash(token.encode(&quot;utf-8&quot;)) for token in tokens], dtype=np.uint64)\n    permuted_hashvalues = np.bitwise_and(\n        ((hashvalues * np.tile(a, (len(hashvalues), 1)).T).T + b) % MERSENNE_PRIME, MAX_HASH\n    )\n    hashvalues = np.vstack([permuted_hashvalues, masks]).min(axis=0)\n    Hs = [bytes(hashvalues[start:end].byteswap().data) for start, end in hashranges]\n    return {&quot;__signatures__&quot;: Hs, &quot;__id__&quot;: idx}\nIf you are familiar with Datasketch, you might ask, why do we bother to strip all the nice high-level functions the library provides? It is not because we want to avoid adding dependencies, but because we intend to squeeze as much CPU computation as possible during parallelization. Fusing few steps into one function call enables us to utilize our compute resources better.\nSince one document’s calculation is not dependent on anything else. A good parallelizatin choice would be using the map function from the datasets library:\nembedded = ds.map(\n\tfunction=embed_func,\n\tfn_kwargs={\n\t\t&quot;num_perm&quot;: args.num_perm,\n\t\t&quot;hashranges&quot;: HASH_RANGES,\n\t\t&quot;ngram_size&quot;: args.ngram,\n\t\t&quot;permutations&quot;: PERMUTATIONS,\n\t},\n\tinput_columns=[args.column],\n\tremove_columns=ds.column_names,\n\tnum_proc=os.cpu_count(),\n\twith_indices=True,\n\tdesc=&quot;Fingerprinting...&quot;,\n)\nAfter the fingerprint calculation, one particular document is mapped to one array of integer values. To figure out what documents are similar to each other, we need to group them based on such fingerprints. Entering the stage, Locality Sensitive Hashing (LSH).\nLSH breaks the fingerprint array into bands, each band containing the same number of rows. If two documents share the same hashes in a band, they will be clustered into the same bucket and will be considered as candidates. Let’s use b=2 bands and r=2 rows to group those documents. (Notice that the last value of the MinHash is ignored)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nband offsetband valuedoc_ids(0, 2)[403996643, 840529008]0, 1(2, 4)[1008110251, 2888962350]0, 1(0, 2)[166417565, 213933364]2(2, 4)[1129612544, 1419614622]2\nFor each row in the doc_ids column, we can generate candidate pairs by paring every two of them. From the above table, we can infer two pairs, even though they are the same:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nxy0101\nBeyond Duplicate Pairs\nThis is where many deduplication descriptions in papers or tutorials stop. We are still left with the question of what to do with them. Generally, we can proceed with two options:\n\nDouble-check their Jaccard similarities by calculating their shingle overlap, which now becomes much more doable than computing all-pair similarities. This is also what we did at BigCode at the beginning, which worked reasonably well.\nTreat them as true positives. You probably already noticed the issue here: the Jaccard similarity isn’t transitive, meaning A is similar to B and B is similar to C, but A and C do not necessary share the similarity. However, our experiments from The Stack show that treating all of them as duplicates improves the downstream model’s performance the best. And now we gradually moved towards this method instead, and it saves time as well. But to apply this to your dataset, I still suggest going over your dataset and looking at your duplicates, and then making a data-driven decision.\n\nFrom such pairs, whether they are validated or not, we can now construct a graph with those pairs as edges, and duplicates will be clustered into communities or connected components. In terms of implementation, unfortunately, this is where datasets couldn’t help much because now we need something like a groupby where we can cluster documents based on their band offset and band values. Here are some options we have tried:\nOption 1: Iterate the datasets the old-fashioned way and collect edges. Then use a graph library to do community detection or connected component detection.\nThis did not scale well in my test, and the reasons are multifold. First, iterating the whole dataset is slow and memory consuming at a large scale. Second, popular graph libraries like graphtool or networkx have a lot of overhead for graph creation.\nOption 2: Popular python frameworks such as dask to allow more efficient groupby operations, but then you still have problems of slow iteration and slow graph creation.\nSo, we ended up with a simple iteration + union find algorithm combo that works relatively well for medium datasets.\nfor table in tqdm(HASH_TABLES, dynamic_ncols=True, desc=&quot;Clustering...&quot;):\n\tfor cluster in table.values():\n\t\tif len(cluster) &lt;= 1:\n\t\t\tcontinue\n\t\tidx = min(cluster)\n\t\tfor x in cluster:\n\t\t\tuf.union(x, idx)\nFor large datasets, our current best option is Spark.\nWe already know that steps up to the LSH part can be parallelized, which is also achievable in Spark. In addition to that, Spark supports distributed groupBy out of the box, and it is also straightforward to implement algorithms like 3 for connected component detection. If you are wondering why we didn’t use Spark’s implementation of MinHash, the answer is that all our experiments so far stemmed from Datasketch, which uses an entirely different implementation than Spark, and we want to ensure that we carry on the lessons and insights learned from that without going into another rabbit hole of ablation experiments.\nedges = (\n\trecords.flatMap(\n\t\tlambda x: generate_hash_values(\n\t\t\tcontent=x[1],\n\t\t\tidx=x[0],\n\t\t\tnum_perm=args.num_perm,\n\t\t\tngram_size=args.ngram_size,\n\t\t\thashranges=HASH_RANGES,\n\t\t\tpermutations=PERMUTATIONS,\n\t\t)\n\t)\n\t.groupBy(lambda x: (x[0], x[1]))\n\t.flatMap(lambda x: generate_edges([i[2] for i in x[1]]))\n\t.distinct()\n\t.cache()\n)\nA simple connected component algorithm based on 3 implemented in Spark.\na = edges\nwhile True:\n\tb = a.flatMap(large_star_map).groupByKey().flatMap(large_star_reduce).distinct().cache()\n\ta = b.map(small_star_map).groupByKey().flatMap(small_star_reduce).distinct().cache()\n\tchanges = a.subtract(b).union(b.subtract(a)).collect()\n\tif len(changes) == 0:\n\t\tbreak\n \nresults = a.collect()\nAdditionally, thanks to cloud providers like GCP, we can set up Spark clusters like a breeze with services like DataProc. In the end, we can comfortably run the program to deduplicate 1.4 TB of data in just under 4 hours with a budget of $15 an hour.\nQuality Matters\nScaling a ladder doesn’t get us to the moon. That’s why we need to make sure this is the right direction, and we are using it the right way.\nEarly on, our parameters were largely inherited from the CodeParrot experiments, and our ablation experiment indicated that those settings did improve the model’s downstream performance17. We then set to further explore this path and can confirm that5:\n\nNear-deduplication improves the model’s downstream performance with a much smaller dataset (6 TB VS. 3 TB)\nWe haven’t figured out the limit yet, but a more aggressive deduplication (6 TB VS. 2.4 TB) can improve the performance even more:\n\nLower the similarity threshold\nIncrease the shingle size (unigram → 5-gram)\nDitch false positive checking because we can afford to lose a small percentage of false positives\n\n\n\n\n\n\nImage: Two graphs showing the impact of similarity threshold and shingle size, the first one is using unigram and the second one 5-gram. The red dash line shows the similarity cutoff: any documents below would be considered as false positives — their similarities with other documents within a cluster are lower than the threshold.\n\nThese graphs can help us understand why it was necessary to double-check the false positives for CodeParrot and early version of the Stack: using unigram creates many false positives; They also demonstrate that by increasing the shingle size to 5-gram, the percentage of false positives decreases significantly. A smaller threshold is desired if we want to keep the deduplication aggressiveness.\nAdditional experiments also showed that lowering the threshold removes more documents that have high similarities pairs, meaning an increased recall in the segment we actually would like to remove the most.\nScaling\n\nImage: Deduplication time versus raw dataset size. This is achieved with 15 worker c2d-standard-16 machines on GCP, and each costed around $0.7 per hour. \n\nImage: CPU usage screenshot for the cluster during processing JSON dataset.\nThis isn’t the most rigorous scaling proof you can find, but the deduplication time, given a fixed computation budget, looks practically linear to the physical size of the dataset. When you take a closer look at the cluster resource usage when processing JSON dataset, the largest subset in the Stack, you can see the MinHash + LSH (stage 2) dominated the total real computation time (stage 2 + 3), which from our previous analysis is O(NM) — linear to the dataset physical volume.\nProceed with Caution\nDeduplication doesn’t exempt you from thorough data exploration and analysis. These discoveries hold true for The Stack, but it does not mean it is appliable to other datasets or languages. We still encourage you to perform similar analysis on your datasets before training. For example, it might not be very helpful to do deduplication if you have tight time and compute budget: @geiping_2022 mentions that substring deduplication didn’t improve their model’s downstream performance. Existing datasets might also require thorough examination before use, for example, @gao_2020 states that they only made sure the Pile itself, along with its splits, are deduplicated, and they won’t proactively deduplicating for any downstream benchmarks and leave that decision to readers.\nIn terms of data leakage and benchmark contamination, there is still much to explore. We had to retrain our code models because HumanEval was published in one of the GitHub repos in Python. Early near-deduplication results also suggest that MBPP19, one of the most popular benchmarks for coding, shares a lot of similarity with many Leetcode problems (e.g., task 601 in MBPP is basically Leetcode 646, task 604 ≃ Leetcode 151.). And we all know GitHub is no short of those coding challenges and solutions. It will be even more difficult if someone with bad intentions upload all the benchmarks in the form of python scripts, or other less obvious ways, and pollute all your training data.\nFuture Directions\n\nSubstring deduplication. Even though it showed some benefits for English4, it is not clear yet if this should be applied to code data as well;\nRepetition: paragraphs that are repeated multiple times in one document. @rae_2021 shared some interesting heuristics on how to detect and remove them.\nUsing model embeddings for semantic deduplication. It is another whole research question with scaling, cost, ablation experiments, and trade-off with near-deduplication. There are some intriguing takes on this20, but we still need more situated evidence to draw a conclusion (e.g, @abbas_2023’s only text deduplication reference is @lee_2022a, whose main claim is deduplicating helps instead of trying to be SOTA).\nOptimization. There is always room for optimization: better quality evaluation, scaling, downstream performance impact analysis etc.\nThen there is another direction to look at things: To what extent near-deduplication starts to hurt performance? To what extent similarity is needed for diversity instead of being considered as redundancy?\n\nCredits\nThe banner image contains emojis (hugging face, Santa, document, wizard, and wand) from Noto Emoji (Apache 2.0). This blog post is proudly written without any generative APIs.\nHuge thanks to Huu Nguyen and Hugo Laurençon for the collaboration in BigScience and everyone at BigCode for the help along the way! If you ever find any error, feel free to contact me: mouchenghao at gmail dot com.\nSupporting Resources\n\nDatasketch (MIT)\nsimhash-py and simhash-cpp (MIT)\nDeduplicating Training Data Makes Language Models Better (Apache 2.0)\nGaoya (MIT)\nBigScience (Apache 2.0)\nBigCode (Apache 2.0)\n\nReferences\nFootnotes\n\n\nNikhil Kandpal, Eric Wallace, Colin Raffel, Deduplicating Training Data Mitigates Privacy Risks in Language Models, 2022 ↩\n\n\nGowthami Somepalli, et al., Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models, 2022 ↩\n\n\nRaimondas Kiveris, Silvio Lattanzi, et al., Connected Components in MapReduce and Beyond, 2014 ↩ ↩2 ↩3\n\n\nKatherine Lee, Daphne Ippolito, et al., Deduplicating Training Data Makes Language Models Better, 2022 ↩ ↩2 ↩3 ↩4 ↩5 ↩6 ↩7\n\n\nLoubna Ben Allal, Raymond Li, et al., SantaCoder: Don’t reach for the stars!, 2023 ↩ ↩2 ↩3\n\n\nLeo Gao, Stella Biderman, et al., The Pile: An 800GB Dataset of Diverse Text for Language Modeling, 2020 ↩ ↩2\n\n\nAsier Gutiérrez-Fandiño, Jordi Armengol-Estapé, et al., MarIA: Spanish Language Models, 2022 ↩\n\n\nJack W. Rae, Sebastian Borgeaud, et al., Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher, 2021 ↩\n\n\nXi Victoria Lin, Todor Mihaylov, et al., Few-shot Learning with Multilingual Language Models, 2021 ↩\n\n\nHugo Laurençon, Lucile Saulnier, et al., The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset, 2022 ↩\n\n\nDaniel Fried, Armen Aghajanyan, et al., InCoder: A Generative Model for Code Infilling and Synthesis, 2022 ↩\n\n\nErik Nijkamp, Bo Pang, et al., CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis, 2023 ↩\n\n\nYujia Li, David Choi, et al., Competition-Level Code Generation with AlphaCode, 2022 ↩\n\n\nFrank F. Xu, Uri Alon, et al., A Systematic Evaluation of Large Language Models of Code, 2022 ↩\n\n\nAakanksha Chowdhery, Sharan Narang, et al., PaLM: Scaling Language Modeling with Pathways, 2022 ↩\n\n\nLewis Tunstall, Leandro von Werra, Thomas Wolf, Natural Language Processing with Transformers, Revised Edition, 2022 ↩\n\n\nDenis Kocetkov, Raymond Li, et al., The Stack: 3 TB of permissively licensed source code, 2022 ↩ ↩2\n\n\nRocky | Project Hail Mary Wiki | Fandom ↩\n\n\nJacob Austin, Augustus Odena, et al., Program Synthesis with Large Language Models, 2021 ↩\n\n\nAmro Abbas, Kushal Tirumala, et al., SemDeDup: Data-efficient learning at web-scale through semantic deduplication, 2023 ↩\n\n\n"}}